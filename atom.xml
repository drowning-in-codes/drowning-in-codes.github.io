<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sekyoro的博客小屋</title>
  
  
  <link href="https://www.sekyoro.top/atom.xml" rel="self"/>
  
  <link href="https://www.sekyoro.top/"/>
  <updated>2024-07-08T15:22:46.235Z</updated>
  <id>https://www.sekyoro.top/</id>
  
  <author>
    <name>Sekyoro</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>学习llama3</title>
    <link href="https://www.sekyoro.top/2024/07/08/%E5%AD%A6%E4%B9%A0llama3/"/>
    <id>https://www.sekyoro.top/2024/07/08/%E5%AD%A6%E4%B9%A0llama3/</id>
    <published>2024-07-08T06:44:29.000Z</published>
    <updated>2024-07-08T15:22:46.235Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>llama3是meta开源的大模型,在开源大模型中占着重要地位,在这之前可能是Mistral,目前也有gemma2,Qwen2以及微软的Phi3等.<br><span id="more"></span></p><p>llama表现很不错,<a href="https://toloka.ai/llm-leaderboard/">LLM Leaderboard (toloka.ai)</a>,很多模型都是在它基础上微调得到的.</p><p>这里将llama介绍分为位置编码,transformer层,ffn层以及其中的norm的改进.</p><p>llama3相比于llama2,上下文窗口增大,tokenizer从sentencepiece变为tiktoken,token数也增多了.</p><div class="table-container"><table><thead><tr><th><strong>Feature</strong></th><th><strong>LLaMa 2</strong></th><th><strong>LLaMa 3</strong></th></tr></thead><tbody><tr><td><strong>Training Data Size</strong></td><td>2 trillion tokens</td><td>15 trillion tokens (7x larger)</td></tr><tr><td><strong>Context Window</strong></td><td>4K tokens</td><td>8k tokens</td></tr><tr><td><strong>Focus Area</strong></td><td>General language understanding</td><td>Nuance, context, complex tasks</td></tr><tr><td><strong>False Refusal Rate</strong></td><td>Higher</td><td>Lower</td></tr><tr><td><strong>Response Diversity</strong></td><td>Lower</td><td>Higher</td></tr><tr><td><strong>Code Generation</strong></td><td>Limited capability</td><td>Enhanced capability</td></tr></tbody></table></div><h2 id="旋转位置编码"><a href="#旋转位置编码" class="headerlink" title="旋转位置编码"></a>旋转位置编码</h2><blockquote><p>旋转位置嵌入（RoPE）是一种用于基于transformer模型的技术，可将位置信息纳入标记表示中。与依赖正弦和余弦函数的传统位置编码不同，<strong>RoPE 利用旋转矩阵来编码绝对和相对位置信息</strong>。这种方法的提出是为了提高位置嵌入在transformer中的有效性。Meta的LLaMA、清华的ChatGLM都采用了RoPE</p></blockquote><script type="math/tex; mode=display">\begin{aligned}\mathrm{RoPE}(x,m)& =xe^{mi\theta} \\\langle\mathrm{RoPE}(q_j,m),\mathrm{RoPE}(k_j,n)\rangle & =\langle q_je^{mi\theta},k_je^{ni\theta}\rangle  \\&=q_jk_je^{mi\theta}\overline{e^{ni\theta}} \\&=q_jk_je^{(m-n)i\theta} \\&=\mathrm{RoPE}(q_jk_j,m-n)\end{aligned}\begin{aligned}\mathrm{RoPE}(x,m)& =xe^{mi\theta} \\\langle\mathrm{RoPE}(q_j,m),\mathrm{RoPE}(k_j,n)\rangle & =\langle q_je^{mi\theta},k_je^{ni\theta}\rangle  \\&=q_jk_je^{mi\theta}\overline{e^{ni\theta}} \\&=q_jk_je^{(m-n)i\theta} \\&=\mathrm{RoPE}(q_jk_j,m-n)\end{aligned}</script><p>在llama3中代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">precompute_freqs_cis</span>(<span class="params">dim: <span class="built_in">int</span>, end: <span class="built_in">int</span>, theta: <span class="built_in">float</span> = <span class="number">10000.0</span></span>):</span></span><br><span class="line">    freqs = <span class="number">1.0</span> / (theta ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>)[: (dim // <span class="number">2</span>)].<span class="built_in">float</span>() / dim)) <span class="comment"># 一个位置上的特征</span></span><br><span class="line">    t = torch.arange(end, device=freqs.device, dtype=torch.float32)</span><br><span class="line">    freqs = torch.outer(t, freqs)</span><br><span class="line">    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  <span class="comment"># complex64 # 得到e^freqs^ shape [T,dim//2]</span></span><br><span class="line">    <span class="keyword">return</span> freqs_cis</span><br><span class="line"></span><br><span class="line">self.freqs_cis = precompute_freqs_cis(</span><br><span class="line">    params.dim // params.n_heads,</span><br><span class="line">    params.max_seq_len * <span class="number">2</span>,</span><br><span class="line">    params.rope_theta,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_for_broadcast</span>(<span class="params">freqs_cis: torch.Tensor, x: torch.Tensor</span>):</span></span><br><span class="line">    ndim = x.ndim</span><br><span class="line">    <span class="keyword">assert</span> <span class="number">0</span> &lt;= <span class="number">1</span> &lt; ndim</span><br><span class="line">    <span class="keyword">assert</span> freqs_cis.shape == (x.shape[<span class="number">1</span>], x.shape[-<span class="number">1</span>])</span><br><span class="line">    shape = [d <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">or</span> i == ndim - <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">enumerate</span>(x.shape)]</span><br><span class="line">    <span class="keyword">return</span> freqs_cis.view(*shape)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_rotary_emb</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        xq: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">        xk: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">        freqs_cis: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span></span><br><span class="line">    xq_ = torch.view_as_complex(xq.<span class="built_in">float</span>().reshape(*xq.shape[:-<span class="number">1</span>], -<span class="number">1</span>, <span class="number">2</span>)) <span class="comment">#shape [bs,seq_len,dim//2,2] -&gt; [bs,seq_len,dim]</span></span><br><span class="line">    xk_ = torch.view_as_complex(xk.<span class="built_in">float</span>().reshape(*xk.shape[:-<span class="number">1</span>], -<span class="number">1</span>, <span class="number">2</span>))<span class="comment">#shape [bs,seq_len,dim//2,2] -&gt; [bs,seq_len,dim]</span></span><br><span class="line">    freqs_cis = reshape_for_broadcast(freqs_cis, xq_) <span class="comment"># [1,seq_len,dim]</span></span><br><span class="line">    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class="number">3</span>)<span class="comment">#[bs,seq_len,dim//2,2] type float32 -&gt; </span></span><br><span class="line">    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> xq_out.type_as(xq), xk_out.type_as(xk)</span><br><span class="line"></span><br><span class="line">xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)</span><br></pre></td></tr></table></figure><p>计算freqs_cis,其是一个复数,旋转编码通常应用在q和k上.</p><script type="math/tex; mode=display">\mathrm{RoPE}(x_m^{(1)},x_m^{(2)},m)=\begin{bmatrix}\cos(m\theta)&-\sin(m\theta)\\\sin(m\theta)&\cos(m\theta)\end{bmatrix}\begin{bmatrix}x_m^{(1)}\\x_m^{(2)}\end{bmatrix}=\begin{bmatrix}x_m^{(1)}\cos(m\theta)-x_m^{(2)}\sin(m\theta)\\x_m^{(2)}\cos(m\theta)+x_m^{(1)}\sin(m\theta)\end{bmatrix}\\\Theta=\theta_i=10,000^{-\frac{2(i-1)}d},where(i\in[1,2,\ldots,d])\text{ for the $\frac{d}{2}$ pairs of features.}</script><p>下面是另一种实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RotaryPositionalEmbeddings</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d: <span class="built_in">int</span>, base: <span class="built_in">int</span> = <span class="number">10_000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.base = base</span><br><span class="line">        self.d = d</span><br><span class="line">        self.cos_cached = <span class="literal">None</span></span><br><span class="line">        self.sin_cached = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_build_cache</span>(<span class="params">self, x: torch.Tensor</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.cos_cached <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> x.shape[<span class="number">0</span>] &lt;= self.cos_cached.shape[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        seq_len = x.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># THETA = 10,000^(-2*i/d) or 1/10,000^(2i/d)</span></span><br><span class="line">        theta = <span class="number">1.</span> / (self.base ** (torch.arange(<span class="number">0</span>, self.d, <span class="number">2</span>).<span class="built_in">float</span>() / self.d)).to(x.device)</span><br><span class="line">        <span class="comment"># Position index [0,1,...]</span></span><br><span class="line">        seq_idx = torch.arange(seq_len, device=x.device).<span class="built_in">float</span>().to(x.device)</span><br><span class="line"></span><br><span class="line">        idx_theta = torch.einsum(<span class="string">&#x27;n,d-&gt;nd&#x27;</span>, seq_idx,</span><br><span class="line">                                 theta)  <span class="comment"># Calculates m*(THETA) = [ [0, 0...], [THETA_1, THETA_2...THETA_d/2], ... [seq-1*(THETA_1), seq-1*(THETA_2)...] ]</span></span><br><span class="line"></span><br><span class="line">        idx_theta2 = torch.cat([idx_theta, idx_theta],</span><br><span class="line">                               dim=<span class="number">1</span>)  <span class="comment"># [THETA_1, THETA_2...THETA_d/2] -&gt; [THETA_1, THETA_2...THETA_d]</span></span><br><span class="line">        self.cos_cached = idx_theta2.cos()[:, <span class="literal">None</span>, <span class="literal">None</span>, :]  <span class="comment"># Cache [cosTHETA_1, cosTHETA_2...cosTHETA_d]</span></span><br><span class="line">        self.sin_cached = idx_theta2.sin()[:, <span class="literal">None</span>, <span class="literal">None</span>, :]  <span class="comment"># cache [sinTHETA_1, sinTHETA_2...sinTHETA_d]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_neg_half</span>(<span class="params">self, x: torch.Tensor</span>):</span></span><br><span class="line">        d_2 = self.d // <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat([-x[:, :, :, d_2:], x[:, :, :, :d_2]], dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span></span><br><span class="line">        self._build_cache(x)</span><br><span class="line">        neg_half_x = self._neg_half(x)</span><br><span class="line">        x_rope = (x * self.cos_cached[:x.shape[<span class="number">0</span>]]) + (neg_half_x * self.sin_cached[:x.shape[<span class="number">0</span>]])</span><br><span class="line">        <span class="keyword">return</span> x_rope</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    x = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    x = x[:, <span class="literal">None</span>, <span class="literal">None</span>, :]</span><br><span class="line"></span><br><span class="line">    p = RotaryPositionalEmbeddings(<span class="number">4</span>)(x)</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"></span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{bmatrix}x_m^{(i)}\\x_m^{(i+d/2)}\end{bmatrix}=\begin{bmatrix}x_m^{(i)}\cos(m\theta_i)-x_m^{(i+d/2)}\sin(m\theta_i)\\x_m^{(i+d/2)}\cos(m\theta_i)+x_m^{(i)}\sin(m\theta_i)\end{bmatrix}</script><h2 id="RSMNorm"><a href="#RSMNorm" class="headerlink" title="RSMNorm"></a>RSMNorm</h2><p>另一种规范化的方式,方法是在2019年的论文中提出的<a href="https://arxiv.org/pdf/1910.07467">1910.07467 (arxiv.org)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RMSNorm</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim: <span class="built_in">int</span>, eps: <span class="built_in">float</span> = <span class="number">1e-6</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_norm</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * torch.rsqrt(x.<span class="built_in">pow</span>(<span class="number">2</span>).mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + self.eps)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        output = self._norm(x.<span class="built_in">float</span>()).type_as(x)</span><br><span class="line">        <span class="keyword">return</span> output * self.weight</span><br><span class="line"></span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">y=\frac{x}{\sqrt{\text{RMS}[x]+\epsilon}}*\gamma</script><p>在llama3中,有三个地方使用,在attention,ffn以及在所有transformer layer之后,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h = x + self.attention(self.attention_norm(x), start_pos, freqs_cis, mask)</span><br><span class="line">out = h + self.feed_forward(self.ffn_norm(h))</span><br></pre></td></tr></table></figure><h2 id="GroupQuery-Attention-amp-amp-KVcache"><a href="#GroupQuery-Attention-amp-amp-KVcache" class="headerlink" title="GroupQuery Attention&amp;&amp;KVcache"></a>GroupQuery Attention&amp;&amp;KVcache</h2><p>GroupQuery:query的head数是kv的head数的若干倍.</p><p>KV cache:在生成新的token时,K和V往往改变不大,也就不需要怎么计算,所以只需要存下计算的值即可.这是节约显存的操作.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, args: ModelArgs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.n_kv_heads = args.n_heads <span class="keyword">if</span> args.n_kv_heads <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> args.n_kv_heads</span><br><span class="line">        model_parallel_size = fs_init.get_model_parallel_world_size()</span><br><span class="line">        self.n_local_heads = args.n_heads // model_parallel_size</span><br><span class="line">        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size</span><br><span class="line">        self.n_rep = self.n_local_heads // self.n_local_kv_heads</span><br><span class="line">        self.head_dim = args.dim // args.n_heads</span><br><span class="line"></span><br><span class="line">        self.wq = ColumnParallelLinear(</span><br><span class="line">            args.dim,</span><br><span class="line">            args.n_heads * self.head_dim,</span><br><span class="line">            bias=<span class="literal">False</span>,</span><br><span class="line">            gather_output=<span class="literal">False</span>,</span><br><span class="line">            init_method=<span class="keyword">lambda</span> x: x,</span><br><span class="line">        )</span><br><span class="line">        self.wk = ColumnParallelLinear(</span><br><span class="line">            args.dim,</span><br><span class="line">            self.n_kv_heads * self.head_dim,</span><br><span class="line">            bias=<span class="literal">False</span>,</span><br><span class="line">            gather_output=<span class="literal">False</span>,</span><br><span class="line">            init_method=<span class="keyword">lambda</span> x: x,</span><br><span class="line">        )</span><br><span class="line">        self.wv = ColumnParallelLinear(</span><br><span class="line">            args.dim,</span><br><span class="line">            self.n_kv_heads * self.head_dim,</span><br><span class="line">            bias=<span class="literal">False</span>,</span><br><span class="line">            gather_output=<span class="literal">False</span>,</span><br><span class="line">            init_method=<span class="keyword">lambda</span> x: x,</span><br><span class="line">        )</span><br><span class="line">        self.wo = RowParallelLinear(</span><br><span class="line">            args.n_heads * self.head_dim,</span><br><span class="line">            args.dim,</span><br><span class="line">            bias=<span class="literal">False</span>,</span><br><span class="line">            input_is_parallel=<span class="literal">True</span>,</span><br><span class="line">            init_method=<span class="keyword">lambda</span> x: x,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.cache_k = torch.zeros(</span><br><span class="line">            (</span><br><span class="line">                args.max_batch_size,</span><br><span class="line">                args.max_seq_len,</span><br><span class="line">                self.n_local_kv_heads,</span><br><span class="line">                self.head_dim,</span><br><span class="line">            )</span><br><span class="line">        ).cuda()</span><br><span class="line">        self.cache_v = torch.zeros(</span><br><span class="line">            (</span><br><span class="line">                args.max_batch_size,</span><br><span class="line">                args.max_seq_len,</span><br><span class="line">                self.n_local_kv_heads,</span><br><span class="line">                self.head_dim,</span><br><span class="line">            )</span><br><span class="line">        ).cuda()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">            self,</span></span></span><br><span class="line"><span class="params"><span class="function">            x: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">            start_pos: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            freqs_cis: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">            mask: <span class="type">Optional</span>[torch.Tensor],</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        bsz, seqlen, _ = x.shape</span><br><span class="line">        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)</span><br><span class="line"></span><br><span class="line">        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)</span><br><span class="line">        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)</span><br><span class="line">        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)</span><br><span class="line"></span><br><span class="line">        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)</span><br><span class="line"></span><br><span class="line">        self.cache_k = self.cache_k.to(xq)</span><br><span class="line">        self.cache_v = self.cache_v.to(xq)</span><br><span class="line"></span><br><span class="line">        self.cache_k[:bsz, start_pos: start_pos + seqlen] = xk</span><br><span class="line">        self.cache_v[:bsz, start_pos: start_pos + seqlen] = xv</span><br><span class="line"></span><br><span class="line">        keys = self.cache_k[:bsz, : start_pos + seqlen]</span><br><span class="line">        values = self.cache_v[:bsz, : start_pos + seqlen]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># repeat k/v heads if n_kv_heads &lt; n_heads</span></span><br><span class="line">        keys = repeat_kv(</span><br><span class="line">            keys, self.n_rep</span><br><span class="line">        )  <span class="comment"># (bs, cache_len + seqlen, n_local_heads, head_dim)</span></span><br><span class="line">        values = repeat_kv(</span><br><span class="line">            values, self.n_rep</span><br><span class="line">        )  <span class="comment"># (bs, cache_len + seqlen, n_local_heads, head_dim)</span></span><br><span class="line"></span><br><span class="line">        xq = xq.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (bs, n_local_heads, seqlen, head_dim)</span></span><br><span class="line">        keys = keys.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (bs, n_local_heads, cache_len + seqlen, head_dim)</span></span><br><span class="line">        values = values.transpose(</span><br><span class="line">            <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">        )  <span class="comment"># (bs, n_local_heads, cache_len + seqlen, head_dim)</span></span><br><span class="line">        scores = torch.matmul(xq, keys.transpose(<span class="number">2</span>, <span class="number">3</span>)) / math.sqrt(self.head_dim)</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            scores = scores + mask  <span class="comment"># (bs, n_local_heads, seqlen, cache_len + seqlen)</span></span><br><span class="line">        scores = F.softmax(scores.<span class="built_in">float</span>(), dim=-<span class="number">1</span>).type_as(xq)</span><br><span class="line">        output = torch.matmul(scores, values)  <span class="comment"># (bs, n_local_heads, seqlen, head_dim)</span></span><br><span class="line">        output = output.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(bsz, seqlen, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.wo(output)</span><br></pre></td></tr></table></figure><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, params: ModelArgs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = params</span><br><span class="line">        self.vocab_size = params.vocab_size</span><br><span class="line">        self.n_layers = params.n_layers</span><br><span class="line"></span><br><span class="line">        self.tok_embeddings = VocabParallelEmbedding(</span><br><span class="line">            params.vocab_size, params.dim, init_method=<span class="keyword">lambda</span> x: x</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.layers = torch.nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(params.n_layers):</span><br><span class="line">            self.layers.append(TransformerBlock(layer_id, params))</span><br><span class="line"></span><br><span class="line">        self.norm = RMSNorm(params.dim, eps=params.norm_eps)</span><br><span class="line">        self.output = ColumnParallelLinear(</span><br><span class="line">            params.dim, params.vocab_size, bias=<span class="literal">False</span>, init_method=<span class="keyword">lambda</span> x: x</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.freqs_cis = precompute_freqs_cis(</span><br><span class="line">            params.dim // params.n_heads,</span><br><span class="line">            params.max_seq_len * <span class="number">2</span>,</span><br><span class="line">            params.rope_theta,</span><br><span class="line">        )</span><br><span class="line"><span class="meta">    @torch.inference_mode()</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, tokens: torch.Tensor, start_pos: <span class="built_in">int</span></span>):</span></span><br><span class="line">        _bsz, seqlen = tokens.shape</span><br><span class="line">        h = self.tok_embeddings(tokens)</span><br><span class="line">        self.freqs_cis = self.freqs_cis.to(h.device)</span><br><span class="line">        freqs_cis = self.freqs_cis[start_pos: start_pos + seqlen]</span><br><span class="line"></span><br><span class="line">        mask = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> seqlen &gt; <span class="number">1</span>:</span><br><span class="line">            mask = torch.full((seqlen, seqlen), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), device=tokens.device)</span><br><span class="line"></span><br><span class="line">            mask = torch.triu(mask, diagonal=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># When performing key-value caching, we compute the attention scores</span></span><br><span class="line">            <span class="comment"># only for the new sequence. Thus, the matrix of scores is of size</span></span><br><span class="line">            <span class="comment"># (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for</span></span><br><span class="line">            <span class="comment"># j &gt; cache_len + i, since row i corresponds to token cache_len + i.</span></span><br><span class="line">            mask = torch.hstack(</span><br><span class="line">                [torch.zeros((seqlen, start_pos), device=tokens.device), mask]</span><br><span class="line">            ).type_as(h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            h = layer(h, start_pos, freqs_cis, mask)</span><br><span class="line">        h = self.norm(h)</span><br><span class="line">        output = self.output(h).<span class="built_in">float</span>()</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransformerBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, layer_id: <span class="built_in">int</span>, args: ModelArgs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.n_heads = args.n_heads</span><br><span class="line">        self.dim = args.dim</span><br><span class="line">        self.head_dim = args.dim // args.n_heads</span><br><span class="line">        self.attention = Attention(args)</span><br><span class="line">        self.feed_forward = FeedForward(</span><br><span class="line">            dim=args.dim,</span><br><span class="line">            hidden_dim=<span class="number">4</span> * args.dim,</span><br><span class="line">            multiple_of=args.multiple_of,</span><br><span class="line">            ffn_dim_multiplier=args.ffn_dim_multiplier,</span><br><span class="line">        )</span><br><span class="line">        self.layer_id = layer_id</span><br><span class="line">        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)</span><br><span class="line">        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)</span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">            self,</span></span></span><br><span class="line"><span class="params"><span class="function">            x: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">            start_pos: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            freqs_cis: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">            mask: <span class="type">Optional</span>[torch.Tensor],</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        h = x + self.attention(self.attention_norm(x), start_pos, freqs_cis, mask)</span><br><span class="line">        out = h + self.feed_forward(self.ffn_norm(h))</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="silu激活函数"><a href="#silu激活函数" class="headerlink" title="silu激活函数"></a>silu激活函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">            self,</span></span></span><br><span class="line"><span class="params"><span class="function">            dim: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            hidden_dim: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            multiple_of: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            ffn_dim_multiplier: <span class="type">Optional</span>[<span class="built_in">float</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_dim = <span class="built_in">int</span>(<span class="number">2</span> * hidden_dim / <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># custom dim factor multiplier</span></span><br><span class="line">        <span class="keyword">if</span> ffn_dim_multiplier <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            hidden_dim = <span class="built_in">int</span>(ffn_dim_multiplier * hidden_dim)</span><br><span class="line">        hidden_dim = multiple_of * ((hidden_dim + multiple_of - <span class="number">1</span>) // multiple_of)</span><br><span class="line"></span><br><span class="line">        self.w1 = ColumnParallelLinear(</span><br><span class="line">            dim, hidden_dim, bias=<span class="literal">False</span>, gather_output=<span class="literal">False</span>, init_method=<span class="keyword">lambda</span> x: x</span><br><span class="line">        )</span><br><span class="line">        self.w2 = RowParallelLinear(</span><br><span class="line">            hidden_dim, dim, bias=<span class="literal">False</span>, input_is_parallel=<span class="literal">True</span>, init_method=<span class="keyword">lambda</span> x: x</span><br><span class="line">        )</span><br><span class="line">        self.w3 = ColumnParallelLinear(</span><br><span class="line">            dim, hidden_dim, bias=<span class="literal">False</span>, gather_output=<span class="literal">False</span>, init_method=<span class="keyword">lambda</span> x: x</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.w2(F.silu(self.w1(x)) * self.w3(x)) <span class="comment">#注意这里与一般的ffn差别,F.silu(self.w1(x))起了类似gate的作用</span></span><br></pre></td></tr></table></figure><p><img data-src="https://pytorch.org/docs/stable/_images/SiLU.png" alt="../_images/SiLU.png" style="zoom:67%;" /></p><script type="math/tex; mode=display">silu(x)=x*σ(x)</script><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://github.com/naklecha/llama3-from-scratch">naklecha/llama3-from-scratch: llama3 implementation one matrix multiplication at a time (github.com)</a></li><li><a href="https://github.com/meta-llama/llama3">github.com</a></li><li><a href="https://github.com/aju22/RoPE-PyTorch/blob/main/RoPE.ipynb">RoPE-PyTorch/RoPE.ipynb at main · aju22/RoPE-PyTorch (github.com)</a></li><li><a href="https://nn.labml.ai/transformers/rope/index.html">Rotary Positional Embeddings (RoPE) (labml.ai)</a></li><li><a href="https://mett29.github.io/posts/kv-cache/">What is the KV cache? | Matt Log (mett29.github.io)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;llama3是meta开源的大模型,在开源大模型中占着重要地位,在这之前可能是Mistral,目前也有gemma2,Qwen2以及微软的Phi3等.&lt;br&gt;</summary>
    
    
    
    
    <category term="llm" scheme="https://www.sekyoro.top/tags/llm/"/>
    
  </entry>
  
  <entry>
    <title>from grad to tensor</title>
    <link href="https://www.sekyoro.top/2024/07/08/from-grad-to-tensor/"/>
    <id>https://www.sekyoro.top/2024/07/08/from-grad-to-tensor/</id>
    <published>2024-07-08T02:09:09.000Z</published>
    <updated>2024-07-11T12:07:58.832Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>inspired by <a href="https://github.com/karpathy/micrograd">karpathy/micrograd: A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API (github.com)</a>and <a href="https://nrehiew.github.io/blog/pytorch/">Taking PyTorch for Granted | wh (nrehiew.github.io)</a>. </p><p>感谢Karpathy以及x上所有真心探讨技术的网友.这属于karpathy的<a href="https://github.com/karpathy/nn-zero-to-hero?tab=readme-ov-file">karpathy/nn-zero-to-hero: Neural Networks: Zero to Hero ,(github.com)</a>课程.事实上他还有很多值得一看的课程和repos.</p><span id="more"></span><p>tensor分成哪些部分?</p><blockquote><p>一个tensor可以分为元数据区和存储区（Storage）</p><p>信息区主要保存着tensor的形状（size）、步长（stride）、数据类型（type）,storage_offset,layout等信息,而真正的<strong>数据则保存成连续数组,存储在存储区</strong></p></blockquote><h3 id="tensor的存储"><a href="#tensor的存储" class="headerlink" title="tensor的存储"></a>tensor的存储</h3><p>tensor数据底层存储是<strong>连续的</strong>,<del>相对应的就是链表</del>. pytorch使用Storage类存储数据. 可以使用tensor.storage()访问存储的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = torch.arange(<span class="number">9</span>)</span><br><span class="line"><span class="built_in">print</span>(data.storage().dtype)</span><br><span class="line"><span class="built_in">print</span>(data.storage().device)</span><br><span class="line"><span class="built_in">print</span>(data.storage().data_ptr()) <span class="comment">#这里 存储数据也能访问数据的属性</span></span><br></pre></td></tr></table></figure><blockquote><p>All storage classes except for <a href="https://pytorch.org/docs/stable/storage.html#torch.UntypedStorage"><code>torch.UntypedStorage</code></a> will be removed in the future, and <a href="https://pytorch.org/docs/stable/storage.html#torch.UntypedStorage"><code>torch.UntypedStorage</code></a> will be used in all cases.</p></blockquote><p>但是在最新的python中除了untypedstorage类其他都已经deprecated了,而在untypedstorage中数据是字节类型,并且也无法调用<code>dtype</code>这些属性,变得更加纯粹了.</p><p><img data-src="https://s2.loli.net/2024/07/10/Ns8SM3QlpoeB4Ix.png" alt="image-20240710221322389"></p><h3 id="tensor的访问"><a href="#tensor的访问" class="headerlink" title="tensor的访问"></a>tensor的访问</h3><p>pytorch数据存储是一维的,但是会根据它的一些元数据改变对它的”解释”,而影响解释的元数据就是tride (<code>as_strided</code>可以使得两个tensor的size,stride和storage_offset一致)</p><blockquote><p><strong>stride</strong> stride是从一个元素到指定维度的另一个元素的间隔数,如果不指定维度,就返回在每个维度上的stride的tuple</p><p>Stride is the jump necessary to go from one element to the next one in the specified dimension <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.dim"><code>dim</code></a>. </p><p>A tuple of all strides is returned when no argument is passed in. Otherwise, an integer value is returned as the stride in the particular dimension <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.dim"><code>dim</code></a>.</p><p><strong>storage_offset</strong>  返回tensor的第一个元素与storage的第一个元素的偏移量。</p><p>Returns <code>self</code> tensor’s offset in the underlying storage in terms of number of storage elements (not bytes).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">&gt;x.storage_offset()</span><br><span class="line">&gt;x[<span class="number">3</span>:].storage_offset()</span><br></pre></td></tr></table></figure></blockquote><p>pytorch中tensor存储区的数据是连续的,而stride规定了如何访问.访问的方式就是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = torch.randn(<span class="number">1</span>,<span class="number">20</span>,<span class="number">20</span>) </span><br><span class="line">stride = data.stride() <span class="comment"># -&gt; (400, 20, 1)</span></span><br><span class="line">data[<span class="number">0</span>][<span class="number">2</span>][<span class="number">3</span>] -&gt;  <span class="number">0</span>*stride[<span class="number">0</span>]+<span class="number">2</span>*stride[<span class="number">2</span>]+<span class="number">3</span>*stride[<span class="number">3</span>]-&gt;也就是说这个数据在第<span class="number">2</span>*<span class="number">20</span>+<span class="number">3</span>*<span class="number">1</span>=<span class="number">43</span>个</span><br></pre></td></tr></table></figure><p>注意torch存储数据是行优先,也就是说,像下面这样的数据,第二个是0.6960而不是-0.5163. 所以访问时就类似索引乘以对应的行/列数,从这个角度来看,stride就是一个映射函数.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">1.6427</span>,  <span class="number">0.6960</span>,  <span class="number">0.7865</span>,  <span class="number">0.9934</span>,  <span class="number">0.4952</span>],</span><br><span class="line">        [-<span class="number">0.5163</span>, -<span class="number">0.0823</span>, -<span class="number">1.2630</span>, -<span class="number">0.9474</span>,  <span class="number">1.1055</span>],</span><br><span class="line">        [ <span class="number">0.1538</span>,  <span class="number">1.0177</span>, -<span class="number">1.8064</span>,  <span class="number">0.6440</span>, -<span class="number">1.4661</span>],</span><br><span class="line">        [ <span class="number">0.3305</span>,  <span class="number">0.2681</span>,  <span class="number">0.2768</span>, -<span class="number">0.3924</span>,  <span class="number">0.1743</span>],</span><br><span class="line">        [-<span class="number">0.8965</span>, -<span class="number">0.5499</span>, -<span class="number">0.4545</span>, -<span class="number">1.1470</span>,  <span class="number">0.6883</span>]])</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/07/10/s7ZuEzmD3vnAoiH.png" alt="image-20240710220152997"></p><h3 id="tensor操作"><a href="#tensor操作" class="headerlink" title="tensor操作"></a>tensor操作</h3><p>可以对tensor的数据进行操作,比如下面运算,会改变tensor的存储数据.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = torch.randn((<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line">stride = data.stride()</span><br><span class="line"><span class="built_in">print</span>(data, stride)</span><br><span class="line">data[<span class="number">0</span>, <span class="number">1</span>] = <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(data, stride)</span><br><span class="line">data.add_(torch.ones((<span class="number">4</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="built_in">print</span>(data, stride)</span><br></pre></td></tr></table></figure><p>但是有些操作不会,其只会返回数据相同(指的是数据在底层存储上相同)的<strong>视图</strong>(view),这些操作包括<code>t()</code>,<code>expand</code>,<code>transpose</code>,<code>permute</code>,<code>view</code>,<code>squeeze</code>等等,操作后的tensor数据不变(也就是views),但stride<strong>可能</strong>会改变,也就是说解释数据的方式会变.</p><blockquote><p>底层存储并没有改变,只需将映射函数从旧形状的坐标系调整为新形状的坐标系。 如果映射函数已经将形状作为输入,那么只需更改形状属性即可。</p></blockquote><ul><li><code>reshape()</code>、<code>reshape_as()</code> 和 <code>flatten()</code> 可以返回视图或新张量,所以后续代码不要假定它返回的存储数据是否跟原本输入相同.</li><li>如果输入的张量已经连续,<code>contiguous()</code> 会返回自身,否则会通过复制数据返回一个新的连续张量.</li></ul><p>下面一个例子报错原因,就是stride的问题,具体来说,这里转置之后stride变了,size没变,使得后续的view操作不满足条件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">9</span>).reshape(<span class="number">3</span>, <span class="number">3</span>) <span class="comment"># 3 x 3 stride (3,1)  size(3,3)</span></span><br><span class="line">x.t().view(<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># x.t() stride (1,3)  size(3,3)</span></span><br><span class="line"><span class="comment"># &gt;&gt; RuntimeError: view size is not compatible with input tensor&#x27;s </span></span><br><span class="line"><span class="comment"># size and stride. Use .reshape() instead</span></span><br></pre></td></tr></table></figure><p>首先,<code>view</code>作用是返回一个存储数据相同,但shape/size可能不同的视图,要求新的视图与输入数据<strong>相兼容</strong>( 1.<strong>新的视图的每个dimension必须是输入的子空间</strong>或者2.<strong>新的视图的维度满足下面条件</strong>（连续性),否则不能得到新的视图.</p><script type="math/tex; mode=display"> 假设得到的新的tensor维度\\\text{stride}[i]=\text{stride}[i+1]\times\text{size}[i+1]</script><blockquote><p>如果不清楚是否可以执行 view()，建议使用 reshape()</p><p>reshape:如果形状兼容,则返回视图,否则返回副本（相当于调用 contiguous()）</p></blockquote><p>view之后size变为(1,9),这符合条件1,也就是size相符,再看这里(1,9)表明第二个维度跨域(span across)了原本输入的两个维度,而原本输入的两个维度中的第一个维度需要满足连续性条件,但是 stride[0] =  1 , stride[1]*size[1] = 1*3=3 不符合,所以view操作失败.</p><p>更抽象地说,因为没有办法在不改变底层数据的情况下对张量进行flatten处理.</p><blockquote><p>我们能否从tensor的stride(3,1)推得tensor size是(3,3)?</p><p>答案是不能,它的size也完全可以是(4,3). 反过来size也不能推出stride.</p></blockquote><p>在上面的例子中,比如底层数据是[1,2,3,4,5,6,7,8,9],stride是[3,1]. 也就是说在第一个维度下,数据到相同维度的下个数据间隔为3,同理第二个维度间隔为1,</p><p>经过转置之后,因为解释数据的方式变了,因为需要改变解释数据的方式,所以stride需要改变为(1,3).  再进行view(1,-1),如果不报错的话,size就是(1,9),你可能会认为结果不就是[[1,4,7,2,5,8…]]吗,但这个tensor的stride为多少呢? 是(9,1)吗,并不是.为什么呢,</p><p>因为底层数据[1,2,3,4,5,6,7,8,9],要查找第二个维度上的数据,比如1到4,在底层数据中是stride是3,而4到7也是3,所以是stride是(9,3),然而这跟size(1,9)不匹配(stride乘起来应该跟size乘起来应该相同,这是最起码的保证).</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor(<span class="string">[[1, 2, 3],</span></span><br><span class="line"><span class="string">        [4, 5, 6],</span></span><br><span class="line"><span class="string">        [7, 8, 9]]</span>) </span><br><span class="line">        ⬇⬇</span><br><span class="line">        tensor(<span class="string">[[1, 4, 7],</span></span><br><span class="line"><span class="string">        [2, 5, 8],</span></span><br><span class="line"><span class="string">        [3, 6, 9]]</span>)</span><br></pre></td></tr></table></figure><p><img data-src="https://img-blog.csdnimg.cn/20200922221433607.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NjUzNDM3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom: 67%;" /></p><h3 id="tensor的广播"><a href="#tensor的广播" class="headerlink" title="tensor的广播"></a>tensor的广播</h3><p>PyTorch 的广播规则:(如何说一个tensor是可广播的)</p><ul><li><p>两个张量必须至少有一个维度</p></li><li><p>从最右边的维开始,两个维必须大小相等,其中一个为 1 或者其中一个不存在。</p><blockquote><p>Two tensors are “broadcastable” if the following rules hold:</p><ul><li>Each tensor has at least one dimension.</li><li>When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.</li></ul><p><a href="https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics">Broadcasting semantics — PyTorch 2.3 documentation</a></p><p>If two tensors <code>x</code>, <code>y</code> are “broadcastable”, the resulting tensor size is calculated as follows:</p><ul><li>If the number of dimensions of <code>x</code> and <code>y</code> are not equal, prepend 1 to the dimensions of the tensor with fewer dimensions to make them equal length.</li><li>Then, for each dimension size, the resulting dimension size is the max of the sizes of <code>x</code> and <code>y</code> along that dimension.</li></ul></blockquote></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from https://nrehiew.github.io/blog/pytorch/</span></span><br><span class="line"><span class="keyword">for</span> each dimension, starting from the right:</span><br><span class="line"><span class="keyword">if</span> both shapes have this dimension:</span><br><span class="line"><span class="keyword">if</span> they are different:</span><br><span class="line">neither is 1: error</span><br><span class="line"><span class="keyword">else</span>: use larger dimension </span><br><span class="line"><span class="keyword">else</span> they are the same: use dimension</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">use whichever dimension exists</span><br></pre></td></tr></table></figure><p>广播,不存在数据copy.这意味着,如果将一个小张量广播到一个大得多的形状,就不会产生内存或性能开销。</p><p>其次,由于较小张量中使用的实际元素是相同的,因此梯度会沿着这个较小维度中的项目累积.这在调试梯度或执行涉及广播的自定义自动梯度函数时特别有用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x=torch.empty(<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">y=torch.empty(  <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">(x+y).size()</span><br><span class="line"></span><br><span class="line">x=torch.empty(<span class="number">1</span>)</span><br><span class="line">y=torch.empty(<span class="number">3</span>,<span class="number">1</span>,<span class="number">7</span>)</span><br><span class="line">(x+y).size()</span><br><span class="line"></span><br><span class="line">x=torch.empty(<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">y=torch.empty(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">(x+y).size()</span><br></pre></td></tr></table></figure><p>如果一个 PyTorch 操作支持广播,那么它的张量数据就会自动扩展为大小相等的数据(无需复制数据),所以本质上也是返回一个视图.</p><h3 id="利用矩阵乘法进行广播"><a href="#利用矩阵乘法进行广播" class="headerlink" title="利用矩阵乘法进行广播"></a>利用矩阵乘法进行广播</h3><p>矩阵是二维的,但是tensor是不限制的.</p><p><strong>多维tensor如何相乘的呢?</strong></p><ol><li>取两个张量的最后两个维度,检查它们是否可以相乘.如果不能,则出错</li><li>广播剩余维数.结果形状为 [广播后的维数] + [矩阵乘法的结果形状]。</li><li>将 [广播后的维数] 作为批处理维度，执行batched matrix multiplication(其实就是矩阵乘法,但是两个相乘的矩阵分别来自不同的batch中的相同的index)</li></ol><p>使用torch.matmul进行tensor相乘,它的计算方式如下</p><ul><li><p>如果都是一维,进行点乘</p></li><li><p>如果都是二维,进行矩阵乘,,如果是1维和二维,在一维度之前添加一个维度在进行矩阵乘,乘完之后再去掉.</p></li><li><p>如果是二维和1维,进行矩阵-向量乘法,得到向量.</p></li><li><p>如果两个参数都至少为 1 维,且至少一个参数为 N 维(N &gt; 2),则返回一个batched matrix multiplication.</p><p>如果第一个参数是一维的,那么在进行batched matrix multiplication,会在其维度前添加一维,然后删除.</p><p>如果第二个参数是一维的,则在其维度后加上 1,以便进行batched matrix multiply,并在运算后删除.</p><p>非矩阵(即批处理)维度将被广播(因此必须是<strong>可广播的</strong>)</p><p>比如(jx1xnxn)和(kxnxn)得到(jxkxnxn),在batch上广播得到(jxk),简单来说就是最后两维(不够进行广播)进行相乘,除了后面两维,其他维度直接进行广播.</p></li></ul><blockquote><p>注意:广播逻辑在确定输入是否可广播时，只查看批次维度，而不查看矩阵维度。</p><p>这跟上面的广播逻辑不同.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn((<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># 3 x 4 x 1 x 2</span></span><br><span class="line">b = torch.randn((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)) <span class="comment"># 1 x 2 x 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix Multiply Shape: 1x2 @ 2x3 -&gt; 1x3</span></span><br><span class="line"><span class="comment"># Batch Shape: We broadcast (3, 4) and (1) -&gt; (3, 4)</span></span><br><span class="line"><span class="comment"># Result shape: 3 x 4 x 1 x 3</span></span><br><span class="line">c = torch.zeros((<span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># iterate over the batch dimensions of (3, 4)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">a_slice = a[i][j] <span class="comment"># 1 x 2</span></span><br><span class="line">b_slice = b[<span class="number">0</span>] <span class="comment"># 2 x 3</span></span><br><span class="line">c[i][j] = a_slice @ b_slice <span class="comment"># 1 x 3</span></span><br><span class="line"><span class="keyword">assert</span> torch.equal(torch.matmul(a, b), c)</span><br></pre></td></tr></table></figure><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>PyTorch 的核心是它的自动微分引擎.一般来说,<strong>每次在两个张量之间进行微分操作时,PyTorch 都会通过回调函数自动构建出整个计算图. 然后,当调用 .backward() 时,每个张量的梯度都会被更新</strong>. 这是 PyTorch 最大的抽象.</p><p>从标量的求导开始扩展到高维,这并不困难.首先需要理解标量的基本运算中的加/减法,乘法,幂、指以及对数.一个softmax操作就包含了加,幂指的操作.</p><p> 可以将矩阵乘法看作是多个标量值的一系列乘法和加法运算,只需指定这些标量运算的后向运算,两个矩阵相乘的导数就自然而然地产生了.</p><p>从标量的角度来考虑梯度还有一个好处，就是可以直观地了解张量操作对梯度的影响。</p><p>例如，.reshape()、.transpose()、.cat 和 .split()等操作不会影响单个值及其在标量的梯度。 因此这些操作对张量梯度的影响自然就是操作梯度本身。 </p><p>例如,使用 .reshape(-1) 对张量进行扁平化处理,对梯度的影响与调用 .reshape(-1) 对张量的梯度的影响相同。</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><h4 id="矩阵相乘"><a href="#矩阵相乘" class="headerlink" title="矩阵相乘"></a>矩阵相乘</h4><p>不使用 GPU 也能实现的优化方法.</p><p> 一种可能的优化方法是利用内存访问模式,而不是改变算法。 回想一下,在给定 A @ B 的情况下，我们正在重复计算 A 中的一行和 B 中的一列的点乘. </p><p>简单的解决方法是转置,将其转为列主模式(column-first),这样每次从内存加载时,我们就可以在同一缓存行中加载 B 列中的正确项目.</p><p>转置是一种O(N) 操作，因此只适用于较大的矩阵.</p><p>另一种无需缓存的算法是对矩阵块进行运算，而不是一次性对整个矩阵进行运算。 这就是所谓的<strong>块矩阵乘法</strong>。 其原理是将矩阵分解成较小的块，然后在这些块上执行矩阵乘法。 这样做的另一个好处是减少了高速缓存的读取次数，因为我们现在是在矩阵的较小块上进行运算。</p><h4 id="内存和中间值"><a href="#内存和中间值" class="headerlink" title="内存和中间值"></a>内存和中间值</h4><blockquote><p>这里原文<a href="https://nrehiew.github.io/blog/pytorch/">Taking PyTorch for Granted | wh (nrehiew.github.io)</a>似乎有typos,我进行了修正</p></blockquote><p>在反向传播时,符合直觉的想法是保留中间值的梯度,以便后续计算leaf tensor的梯度.但是有些时候并不需要中间值的梯度</p><p>比如(a*b)+(c*d)=e,进行反向传播求e在a的梯度时如下</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">_t1</span> = a * b</span><br><span class="line"><span class="attr">_t2</span> = c * d</span><br><span class="line"><span class="attr">e</span> = _t1 + _t2</span><br></pre></td></tr></table></figure><p>其实就是求b,所以并不需要保留_t1和_t2的值.</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://github.com/karpathy/micrograd">karpathy/micrograd: A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API (github.com)</a></li><li><a href="https://github.com/karpathy/nn-zero-to-hero?tab=readme-ov-file">karpathy/nn-zero-to-hero: Neural Networks: Zero to Hero (github.com)</a></li><li><a href="https://github.com/karpathy/nanoGPT">karpathy/nanoGPT: The simplest, fastest repository for training/finetuning medium-sized GPTs. (github.com)</a></li><li><a href="https://blog.csdn.net/weixin_44008424/article/details/110764494">pytorch笔记（一）——tensor的storage()、stride()、storage_offset（）_pytorch storage-CSDN博客</a></li><li><a href="https://blog.csdn.net/m0_46653437/article/details/108742525">PyTorch中张量的shape和stride的关系_shape和strides-CSDN博客</a></li><li><a href="http://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals : ezyang’s blog</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;inspired by &lt;a href=&quot;https://github.com/karpathy/micrograd&quot;&gt;karpathy/micrograd: A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API (github.com)&lt;/a&gt;and &lt;a href=&quot;https://nrehiew.github.io/blog/pytorch/&quot;&gt;Taking PyTorch for Granted | wh (nrehiew.github.io)&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;感谢Karpathy以及x上所有真心探讨技术的网友.这属于karpathy的&lt;a href=&quot;https://github.com/karpathy/nn-zero-to-hero?tab=readme-ov-file&quot;&gt;karpathy/nn-zero-to-hero: Neural Networks: Zero to Hero ,(github.com)&lt;/a&gt;课程.事实上他还有很多值得一看的课程和repos.&lt;/p&gt;</summary>
    
    
    
    
    <category term="tensor" scheme="https://www.sekyoro.top/tags/tensor/"/>
    
  </entry>
  
  <entry>
    <title>i3wm,Neovim与Alacritty的使用与配置</title>
    <link href="https://www.sekyoro.top/2024/07/06/i3wm%E3%80%81Neovim%E4%B8%8EAlacritty%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.sekyoro.top/2024/07/06/i3wm%E3%80%81Neovim%E4%B8%8EAlacritty%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/</id>
    <published>2024-07-06T03:54:41.000Z</published>
    <updated>2024-07-06T15:11:39.814Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>常用的窗口管理器,编辑器与终端模拟器等等<br><span id="more"></span><br>这些工具都有相对的优劣,我个人觉得<strong>生态</strong>,<strong>稳定性</strong>是两个非常重要的因素. 生态好就会有不断的更新和维护,稳定性会让用户更好的长期适应.</p><h3 id="i3wm"><a href="#i3wm" class="headerlink" title="i3wm"></a>i3wm</h3><p>i3wm是个基于x11的窗口管理器,生态很强<a href="https://github.com/fz-wu/i3_user_guide_Chinese">fz-wu/i3_user_guide_Chinese: i3wm官方指南,方便同学们学习i3wm. i3是一个平铺式的窗口管理器 (github.com)</a></p><p><img data-src="https://i3wm.org/docs/modes.png" alt="Container modes"></p><p>类似的还有awesome wm,dwm,也有基于wayland的compositor hyprland(没有使用hyprland也是因为感觉还不太稳定,等过段时间再看看).详情看<a href="https://wiki.archlinux.org/title/Comparison_of_tiling_window_managers">Comparison of tiling window managers - ArchWiki (archlinux.org)</a>和<a href="https://wiki.archlinux.org/title/Wayland#Tiling">Wayland - ArchWiki (archlinux.org)</a></p><p>具体配置文档<a href="https://i3wm.org/docs/userguide.html#configuring">i3: i3 User’s Guide (i3wm.org)</a></p><p>一个例子<a href="https://github.com/levinit/i3wm-config/blob/master/i3/config">i3wm-config/i3/config at master · levinit/i3wm-config (github.com)</a></p><p>i3本身不支持透明等功能,还需要安装其他工具<a href="https://zocoxx.com/archlinux-i3wm.html">ArchLinux系统i3wm配置及体验记录 – ZocoXX</a>,<a href="https://levinit.github.io/i3wm-config/#:~:text=编辑 i3%2Fconfig 文件可切换模式。,随机模式：自动切换壁纸，将要用作壁纸的图片放到 ~%2FPictures%2Fwallpapers 即可。">i3wm-config | my i3wm config (levinit.github.io)</a></p><h3 id="awesomewm"><a href="#awesomewm" class="headerlink" title="awesomewm"></a>awesomewm</h3><p>使用lua配置,相对i3的文本配置,个人认为更友好,上手门槛更低.<a href="https://github.com/atsepkov/awesome-awesome-wm">atsepkov/awesome-awesome-wm: A curated list of awesome tools/scripts/configs for Awesome Window Manager. (github.com)</a>,除了本身窗口管理外,还有查看CPU资源,图片等工具需要额外安装.</p><p>所以比较方便的做法就是clone其他人的配置😅</p><p><strong>i3</strong></p><ul><li><a href="https://github.com/addy-dclxvi/i3-starterpack">addy-dclxvi/i3-starterpack: A simple guide (and example of configuration) to install i3 &amp; its and essentials packages, then make them look eye candy. (github.com)</a></li><li><a href="https://github.com/sainathadapa/i3-wm-config">sainathadapa/i3-wm-config: I3 tiling window manager configuration (github.com)</a></li><li><a href="https://github.com/levinit/i3wm-config">levinit/i3wm-config: my i3wm config (github.com)</a></li><li><a href="https://github.com/typecraft-dev/dotfiles">typecraft-dev/dotfiles (github.com)</a></li></ul><p><strong>awesome</strong></p><ul><li><a href="https://github.com/raven2cz/dotfiles">raven2cz/dotfiles: Dotfiles are the customization files in GNU/Linux. This repository assembly together all my others github config repos to one union. You can choose this global conf for your system or check other repos.</a></li><li><a href="https://github.com/pw4ever/awesome-wm-config">pw4ever/awesome-wm-config: awesome window manager config with persistent dynamic tagging (github.com)</a></li></ul><p><strong>hyprland</strong><a href="https://wiki.hyprland.org/Configuring/">Configuring – Hyprland Wiki</a></p><ul><li><a href="https://github.com/SolDoesTech/hyprland">SolDoesTech/hyprland: collection of dot config files for hyprland with a simple install script for a fresh Arch linux with yay (github.com)</a></li><li><a href="https://github.com/notwidow/hyprland">notwidow/hyprland: hyprland config (github.com)</a></li><li><a href="https://github.com/AhmedSaadi0/my-hyprland-config/blob/main/hyprland.conf">my-hyprland-config/hyprland.conf at main · AhmedSaadi0/my-hyprland-config (github.com)</a></li></ul><p>个人感觉还是hyprland的配置和文档好,但是使用上bug可能不少.</p><h3 id="Neovim"><a href="#Neovim" class="headerlink" title="Neovim"></a>Neovim</h3><p>基于vim的编辑器,更好地进行配置、安装插件.</p><p>主要是需要了解neovim的一些配置语法,如果为了方便直接使用lazyvim等配置即可.</p><p><a href="https://neovim.io/doc/user/lua-guide.html">Lua-guide - Neovim docs</a> neovim使用vim.*等变量替代了原本的vimscript,不过你依然可以使用vim.cmd执行vimscript,使用vim.fn执行函数</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim.cmd(<span class="string">&quot;colorscheme habamax&quot;</span>)</span><br><span class="line">vim.cmd.highlight(&#123; <span class="string">&quot;Error&quot;</span>, <span class="string">&quot;guibg=red&quot;</span> &#125;)</span><br><span class="line"><span class="built_in">print</span>(vim.fn.printf(<span class="string">&#x27;Hello from %s&#x27;</span>, <span class="string">&#x27;Lua&#x27;</span>))</span><br><span class="line"><span class="keyword">local</span> reversed_list = vim.fn.<span class="built_in">reverse</span>(&#123; <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span> &#125;)</span><br><span class="line">vim.<span class="built_in">print</span>(reversed_list) <span class="comment">-- &#123; &quot;c&quot;, &quot;b&quot;, &quot;a&quot; &#125;</span></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">print_stdout</span><span class="params">(chan_id, data, name)</span></span></span><br><span class="line">  <span class="built_in">print</span>(data[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">vim.fn.jobstart(<span class="string">&#x27;ls&#x27;</span>, &#123; on_stdout = print_stdout &#125;)</span><br></pre></td></tr></table></figure><h4 id="vim-变量"><a href="#vim-变量" class="headerlink" title="vim.*变量"></a>vim.*变量</h4><p><a href="https://neovim.io/doc/user/lua.html#vim.g">vim.g</a>: global variables (<a href="https://neovim.io/doc/user/eval.html#g%3A">g:</a>)</p><p><a href="https://neovim.io/doc/user/lua.html#vim.b">vim.b</a>: variables for the current buffer (<a href="https://neovim.io/doc/user/eval.html#b%3A">b:</a>)</p><p><a href="https://neovim.io/doc/user/lua.html#vim.w">vim.w</a>: variables for the current window (<a href="https://neovim.io/doc/user/eval.html#w%3A">w:</a>)</p><p><a href="https://neovim.io/doc/user/lua.html#vim.t">vim.t</a>: variables for the current tabpage (<a href="https://neovim.io/doc/user/eval.html#t%3A">t:</a>)</p><p><a href="https://neovim.io/doc/user/lua.html#vim.v">vim.v</a>: predefined Vim variables (<a href="https://neovim.io/doc/user/eval.html#v%3A">v:</a>)</p><p><a href="https://neovim.io/doc/user/lua.html#vim.env">vim.env</a>: environment variables defined in the editor session</p><h4 id="设置options"><a href="#设置options" class="headerlink" title="设置options"></a>设置options</h4><p>options就是vim中的表现比如set smarttab</p><p>设置全局和本地选项（例如在 init.lua 中）最方便的方法是通过 vim.opt.<br>设置全局和本地选项最方便的方法是通过 vim.opt 和它的朋友们：<br>vim.opt: 行为类似于 :set<br>vim.opt_global: 行为类似于 :setglobal<br>vim.opt_local：行为类似于 :setlocal</p><h5 id="vim-opt"><a href="#vim-opt" class="headerlink" title="vim.opt"></a>vim.opt</h5><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim.opt.smarttab = <span class="literal">true</span></span><br><span class="line">vim.opt.smarttab = <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>代价是不能直接访问选项值，而必须<br>使用 vim.opt:get()：</p><h5 id="vim-o"><a href="#vim-o" class="headerlink" title="vim.o"></a>vim.o</h5><p>有一种更直接的类似变量的访问方式,使用 vim.o<br>vim.o：行为类似于 :set<br>vim.go：行为类似于 :setglobal<br>vim.bo：用于缓冲区选项<br>vim.wo：用于窗口的选项</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">vim.o.smarttab = <span class="literal">false</span> <span class="comment">-- :set nosmarttab</span></span><br><span class="line"><span class="built_in">print</span>(vim.o.smarttab)</span><br><span class="line"><span class="comment">--&gt; false</span></span><br><span class="line">vim.o.listchars = <span class="string">&#x27;space:_,tab:&gt;~&#x27;</span> <span class="comment">-- :set listchars=&#x27;space:_,tab:&gt;~&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(vim.o.listchars)</span><br><span class="line"><span class="comment">--&gt; &#x27;space:_,tab:&gt;~&#x27;</span></span><br><span class="line">vim.o.isfname = vim.o.isfname .. <span class="string">&#x27;,@-@&#x27;</span> <span class="comment">-- :set isfname+=@-@</span></span><br><span class="line"><span class="built_in">print</span>(vim.o.isfname)</span><br><span class="line"><span class="comment">--&gt; &#x27;@,48-57,/,.,-,_,+,,,#,$,%,~,=,@-@&#x27;</span></span><br><span class="line">vim.bo.shiftwidth = <span class="number">4</span> <span class="comment">-- :setlocal shiftwidth=4</span></span><br><span class="line"><span class="built_in">print</span>(vim.bo.shiftwidth)</span><br><span class="line"><span class="comment">--&gt; 4</span></span><br><span class="line">vim.bo[<span class="number">4</span>].expandtab = <span class="literal">true</span> <span class="comment">-- sets expandtab to true in buffer 4</span></span><br><span class="line">vim.wo.number = <span class="literal">true</span>       <span class="comment">-- sets number to true in current window</span></span><br><span class="line">vim.wo[<span class="number">0</span>].number = <span class="literal">true</span>    <span class="comment">-- same as above</span></span><br><span class="line">vim.wo[<span class="number">0</span>][<span class="number">0</span>].number = <span class="literal">true</span> <span class="comment">-- sets number to true in current buffer</span></span><br><span class="line">                           <span class="comment">-- in current window only</span></span><br><span class="line"><span class="built_in">print</span>(vim.wo[<span class="number">0</span>].number)    <span class="comment">--&gt; true</span></span><br></pre></td></tr></table></figure><h4 id="Mappings"><a href="#Mappings" class="headerlink" title="Mappings"></a>Mappings</h4><p>设置执行命令的快捷键.</p><p>可以使用 vim.keymap.set() 创建映射。该函数需要三个参数：<br>{mode} 是一个字符串或字符串表，包含映射生效的模式前缀。前缀是 :map-modes 中列出的前缀，或 :map! 中的”!”，或 :map 中的空字符串。<br>{lhs} 是一个字符串，包含应触发映射的键序列。<br>{rhs} 是包含 Vim 命令或 Lua 函数的字符串，当输入 {lhs} 时应执行该命令或函数。空字符串等同于 <Nop>，表示禁用按键。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- Normal mode mapping for Vim command</span></span><br><span class="line">vim.keymap.set(<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;&lt;Leader&gt;ex1&#x27;</span>, <span class="string">&#x27;&lt;cmd&gt;echo &quot;Example 1&quot;&lt;cr&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">-- Normal and Command-line mode mapping for Vim command</span></span><br><span class="line">vim.keymap.set(&#123;<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;c&#x27;</span>&#125;, <span class="string">&#x27;&lt;Leader&gt;ex2&#x27;</span>, <span class="string">&#x27;&lt;cmd&gt;echo &quot;Example 2&quot;&lt;cr&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">-- Normal mode mapping for Lua function</span></span><br><span class="line">vim.keymap.set(<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;&lt;Leader&gt;ex3&#x27;</span>, vim.treesitter.start)</span><br><span class="line"><span class="comment">-- Normal mode mapping for Lua function with arguments</span></span><br><span class="line">vim.keymap.set(<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;&lt;Leader&gt;ex4&#x27;</span>, <span class="function"><span class="keyword">function</span><span class="params">()</span></span> <span class="built_in">print</span>(<span class="string">&#x27;Example 4&#x27;</span>) <span class="keyword">end</span>)</span><br></pre></td></tr></table></figure><h4 id="Autocommands"><a href="#Autocommands" class="headerlink" title="Autocommands"></a>Autocommands</h4><p>自动命令是一个 Vim 命令或一个 Lua 函数，每当触发一个或多个事件（如文件被打开）时就会自动执行。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim.api.nvim_create_autocmd(&#123;<span class="string">&quot;BufEnter&quot;</span>, <span class="string">&quot;BufWinEnter&quot;</span>&#125;, &#123;</span><br><span class="line">  pattern = &#123;<span class="string">&quot;*.c&quot;</span>, <span class="string">&quot;*.h&quot;</span>&#125;,</span><br><span class="line">  command = <span class="string">&quot;echo &#x27;Entering a C or C++ file&#x27;&quot;</span>,</span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">-- Same autocommand written with a Lua function instead</span></span><br><span class="line">vim.api.nvim_create_autocmd(&#123;<span class="string">&quot;BufEnter&quot;</span>, <span class="string">&quot;BufWinEnter&quot;</span>&#125;, &#123;</span><br><span class="line">  pattern = &#123;<span class="string">&quot;*.c&quot;</span>, <span class="string">&quot;*.h&quot;</span>&#125;,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span> <span class="built_in">print</span>(<span class="string">&quot;Entering a C or C++ file&quot;</span>) <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">-- User event triggered by MyPlugin</span></span><br><span class="line">vim.api.nvim_create_autocmd(<span class="string">&quot;User&quot;</span>, &#123;</span><br><span class="line">  pattern = <span class="string">&quot;MyPlugin&quot;</span>,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span> <span class="built_in">print</span>(<span class="string">&quot;My Plugin Works!&quot;</span>) <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h4 id="User-commands"><a href="#User-commands" class="headerlink" title="User commands"></a>User commands</h4><p>用户命令可通过 nvim_create_user_command() 创建。该函数须要三个参数：<br>命令名称字符串（必须以大写字母开头，以区别于内置命令）；<br>一个包含 Vim 命令或 Lua 函数的字符串，命令调用时执行该字符串；<br>包含命令属性的表格；此外，它还可以包含关键字 desc（描述命令的字符串）、force（设置为 false 以避免替换已存在的同名命令）和 preview（用于 :command-preview 的 Lua 函数）。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim.api.nvim_create_user_command(<span class="string">&#x27;Test&#x27;</span>, <span class="string">&#x27;echo &quot;It works!&quot;&#x27;</span>, &#123;&#125;)</span><br><span class="line">vim.cmd.Test()</span><br><span class="line"><span class="comment">--&gt; It works!</span></span><br></pre></td></tr></table></figure><p>可以使用lazyvim,lunarvim,Astrovim或者nvchad等配置文件,已经为我们配置好了很多东西.</p><h4 id="LazyVim"><a href="#LazyVim" class="headerlink" title="LazyVim"></a>LazyVim</h4><p><code>lazyvim</code>规定了每个lazyvim的库应该怎么编写,编写方式按照文档规定.<code>nvchad</code>,<code>astrovim</code>都是按照这种方式的.</p><p>默认keymaps<a href="https://www.lazyvim.org/keymaps">⌨️ Keymaps | LazyVim</a></p><p><a href="https://www.lazyvim.org/configuration/plugins">Plugins | LazyVim</a></p><p>拿Lazyvim举例,相当于packer.nvim等插件管理器的替代,<code>lazy.vim</code>中默认设置如下</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  root = vim.fn.stdpath(<span class="string">&quot;data&quot;</span>) .. <span class="string">&quot;/lazy&quot;</span>, <span class="comment">-- directory where plugins will be installed</span></span><br><span class="line">  defaults = &#123;</span><br><span class="line">    <span class="comment">-- Set this to `true` to have all your plugins lazy-loaded by default.</span></span><br><span class="line">    <span class="comment">-- Only do this if you know what you are doing, as it can lead to unexpected behavior.</span></span><br><span class="line">    lazy = <span class="literal">false</span>, <span class="comment">-- should plugins be lazy-loaded?</span></span><br><span class="line">    <span class="comment">-- It&#x27;s recommended to leave version=false for now, since a lot the plugin that support versioning,</span></span><br><span class="line">    <span class="comment">-- have outdated releases, which may break your Neovim install.</span></span><br><span class="line">    version = <span class="literal">nil</span>, <span class="comment">-- always use the latest git commit</span></span><br><span class="line">    <span class="comment">-- version = &quot;*&quot;, -- try installing the latest stable version for plugins that support semver</span></span><br><span class="line">    <span class="comment">-- default `cond` you can use to globally disable a lot of plugins</span></span><br><span class="line">    <span class="comment">-- when running inside vscode for example</span></span><br><span class="line">    cond = <span class="literal">nil</span>, <span class="comment">---@type boolean|fun(self:LazyPlugin):boolean|nil</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">-- leave nil when passing the spec as the first argument to setup()</span></span><br><span class="line">  spec = <span class="literal">nil</span>, <span class="comment">---@type LazySpec</span></span><br><span class="line">  local_spec = <span class="literal">true</span>, <span class="comment">-- load project specific .lazy.lua spec files. They will be added at the end of the spec.</span></span><br><span class="line">  lockfile = vim.fn.stdpath(<span class="string">&quot;config&quot;</span>) .. <span class="string">&quot;/lazy-lock.json&quot;</span>, <span class="comment">-- lockfile generated after running update.</span></span><br><span class="line">  <span class="comment">---@type number? limit the maximum amount of concurrent tasks</span></span><br><span class="line">  concurrency = jit.<span class="built_in">os</span>:<span class="built_in">find</span>(<span class="string">&quot;Windows&quot;</span>) <span class="keyword">and</span> (vim.uv.available_parallelism() * <span class="number">2</span>) <span class="keyword">or</span> <span class="literal">nil</span>,</span><br><span class="line">  git = &#123;</span><br><span class="line">    <span class="comment">-- defaults for the `Lazy log` command</span></span><br><span class="line">    <span class="comment">-- log = &#123; &quot;--since=3 days ago&quot; &#125;, -- show commits from the last 3 days</span></span><br><span class="line">    <span class="built_in">log</span> = &#123; <span class="string">&quot;-8&quot;</span> &#125;, <span class="comment">-- show the last 8 commits</span></span><br><span class="line">    timeout = <span class="number">120</span>, <span class="comment">-- kill processes that take more than 2 minutes</span></span><br><span class="line">    url_format = <span class="string">&quot;https://github.com/%s.git&quot;</span>,</span><br><span class="line">    <span class="comment">-- lazy.nvim requires git &gt;=2.19.0. If you really want to use lazy with an older version,</span></span><br><span class="line">    <span class="comment">-- then set the below to false. This should work, but is NOT supported and will</span></span><br><span class="line">    <span class="comment">-- increase downloads a lot.</span></span><br><span class="line">    filter = <span class="literal">true</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  pkg = &#123;</span><br><span class="line">    enabled = <span class="literal">true</span>,</span><br><span class="line">    cache = vim.fn.stdpath(<span class="string">&quot;state&quot;</span>) .. <span class="string">&quot;/lazy/pkg-cache.lua&quot;</span>,</span><br><span class="line">    versions = <span class="literal">true</span>, <span class="comment">-- Honor versions in pkg sources</span></span><br><span class="line">    <span class="comment">-- the first package source that is found for a plugin will be used.</span></span><br><span class="line">    sources = &#123;</span><br><span class="line">      <span class="string">&quot;lazy&quot;</span>,</span><br><span class="line">      <span class="string">&quot;rockspec&quot;</span>,</span><br><span class="line">      <span class="string">&quot;packspec&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  rocks = &#123;</span><br><span class="line">    root = vim.fn.stdpath(<span class="string">&quot;data&quot;</span>) .. <span class="string">&quot;/lazy-rocks&quot;</span>,</span><br><span class="line">    server = <span class="string">&quot;https://nvim-neorocks.github.io/rocks-binaries/&quot;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  dev = &#123;</span><br><span class="line">    <span class="comment">---@type string | fun(plugin: LazyPlugin): string directory where you store your local plugin projects</span></span><br><span class="line">    <span class="built_in">path</span> = <span class="string">&quot;~/projects&quot;</span>,</span><br><span class="line">    <span class="comment">---@type string[] plugins that match these patterns will use your local versions instead of being fetched from GitHub</span></span><br><span class="line">    patterns = &#123;&#125;, <span class="comment">-- For example &#123;&quot;folke&quot;&#125;</span></span><br><span class="line">    fallback = <span class="literal">false</span>, <span class="comment">-- Fallback to git when local plugin doesn&#x27;t exist</span></span><br><span class="line">  &#125;,</span><br><span class="line">  install = &#123;</span><br><span class="line">    <span class="comment">-- install missing plugins on startup. This doesn&#x27;t increase startup time.</span></span><br><span class="line">    missing = <span class="literal">true</span>,</span><br><span class="line">    <span class="comment">-- try to load one of these colorschemes when starting an installation during startup</span></span><br><span class="line">    colorscheme = &#123; <span class="string">&quot;habamax&quot;</span> &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  ui = &#123;</span><br><span class="line">    <span class="comment">-- a number &lt;1 is a percentage., &gt;1 is a fixed size</span></span><br><span class="line">    size = &#123; width = <span class="number">0.8</span>, height = <span class="number">0.8</span> &#125;,</span><br><span class="line">    <span class="built_in">wrap</span> = <span class="literal">true</span>, <span class="comment">-- wrap the lines in the ui</span></span><br><span class="line">    <span class="comment">-- The border to use for the UI window. Accepts same border values as |nvim_open_win()|.</span></span><br><span class="line">    border = <span class="string">&quot;none&quot;</span>,</span><br><span class="line">    <span class="comment">-- The backdrop opacity. 0 is fully opaque, 100 is fully transparent.</span></span><br><span class="line">    backdrop = <span class="number">60</span>,</span><br><span class="line">    title = <span class="literal">nil</span>, <span class="comment">---@type string only works when border is not &quot;none&quot;</span></span><br><span class="line">    title_pos = <span class="string">&quot;center&quot;</span>, <span class="comment">---@type &quot;center&quot; | &quot;left&quot; | &quot;right&quot;</span></span><br><span class="line">    <span class="comment">-- Show pills on top of the Lazy window</span></span><br><span class="line">    pills = <span class="literal">true</span>, <span class="comment">---@type boolean</span></span><br><span class="line">    icons = &#123;</span><br><span class="line">      cmd = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      <span class="built_in">config</span> = <span class="string">&quot;&quot;</span>,</span><br><span class="line">      event = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      favorite = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      ft = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      init = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      import = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      keys = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      lazy = <span class="string">&quot;󰒲 &quot;</span>,</span><br><span class="line">      <span class="built_in">loaded</span> = <span class="string">&quot;●&quot;</span>,</span><br><span class="line">      not_loaded = <span class="string">&quot;○&quot;</span>,</span><br><span class="line">      plugin = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      runtime = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      <span class="built_in">require</span> = <span class="string">&quot;󰢱 &quot;</span>,</span><br><span class="line">      source = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      start = <span class="string">&quot; &quot;</span>,</span><br><span class="line">      task = <span class="string">&quot;✔ &quot;</span>,</span><br><span class="line">      list = &#123;</span><br><span class="line">        <span class="string">&quot;●&quot;</span>,</span><br><span class="line">        <span class="string">&quot;➜&quot;</span>,</span><br><span class="line">        <span class="string">&quot;★&quot;</span>,</span><br><span class="line">        <span class="string">&quot;‒&quot;</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment">-- leave nil, to automatically select a browser depending on your OS.</span></span><br><span class="line">    <span class="comment">-- If you want to use a specific browser, you can define it here</span></span><br><span class="line">    browser = <span class="literal">nil</span>, <span class="comment">---@type string?</span></span><br><span class="line">    throttle = <span class="number">20</span>, <span class="comment">-- how frequently should the ui process render events</span></span><br><span class="line">    custom_keys = &#123;</span><br><span class="line">      <span class="comment">-- You can define custom key maps here. If present, the description will</span></span><br><span class="line">      <span class="comment">-- be shown in the help menu.</span></span><br><span class="line">      <span class="comment">-- To disable one of the defaults, set it to false.</span></span><br><span class="line"></span><br><span class="line">      [<span class="string">&quot;&lt;localleader&gt;l&quot;</span>] = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">function</span><span class="params">(plugin)</span></span></span><br><span class="line">          <span class="built_in">require</span>(<span class="string">&quot;lazy.util&quot;</span>).float_term(&#123; <span class="string">&quot;lazygit&quot;</span>, <span class="string">&quot;log&quot;</span> &#125;, &#123;</span><br><span class="line">            cwd = plugin.dir,</span><br><span class="line">          &#125;)</span><br><span class="line">        <span class="keyword">end</span>,</span><br><span class="line">        desc = <span class="string">&quot;Open lazygit log&quot;</span>,</span><br><span class="line">      &#125;,</span><br><span class="line"></span><br><span class="line">      [<span class="string">&quot;&lt;localleader&gt;t&quot;</span>] = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">function</span><span class="params">(plugin)</span></span></span><br><span class="line">          <span class="built_in">require</span>(<span class="string">&quot;lazy.util&quot;</span>).float_term(<span class="literal">nil</span>, &#123;</span><br><span class="line">            cwd = plugin.dir,</span><br><span class="line">          &#125;)</span><br><span class="line">        <span class="keyword">end</span>,</span><br><span class="line">        desc = <span class="string">&quot;Open terminal in plugin dir&quot;</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  diff = &#123;</span><br><span class="line">    <span class="comment">-- diff command &lt;d&gt; can be one of:</span></span><br><span class="line">    <span class="comment">-- * browser: opens the github compare view. Note that this is always mapped to &lt;K&gt; as well,</span></span><br><span class="line">    <span class="comment">--   so you can have a different command for diff &lt;d&gt;</span></span><br><span class="line">    <span class="comment">-- * git: will run git diff and open a buffer with filetype git</span></span><br><span class="line">    <span class="comment">-- * terminal_git: will open a pseudo terminal with git diff</span></span><br><span class="line">    <span class="comment">-- * diffview.nvim: will open Diffview to show the diff</span></span><br><span class="line">    cmd = <span class="string">&quot;git&quot;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  checker = &#123;</span><br><span class="line">    <span class="comment">-- automatically check for plugin updates</span></span><br><span class="line">    enabled = <span class="literal">false</span>,</span><br><span class="line">    concurrency = <span class="literal">nil</span>, <span class="comment">---@type number? set to 1 to check for updates very slowly</span></span><br><span class="line">    notify = <span class="literal">true</span>, <span class="comment">-- get a notification when new updates are found</span></span><br><span class="line">    frequency = <span class="number">3600</span>, <span class="comment">-- check for updates every hour</span></span><br><span class="line">    check_pinned = <span class="literal">false</span>, <span class="comment">-- check for pinned packages that can&#x27;t be updated</span></span><br><span class="line">  &#125;,</span><br><span class="line">  change_detection = &#123;</span><br><span class="line">    <span class="comment">-- automatically check for config file changes and reload the ui</span></span><br><span class="line">    enabled = <span class="literal">true</span>,</span><br><span class="line">    notify = <span class="literal">true</span>, <span class="comment">-- get a notification when changes are found</span></span><br><span class="line">  &#125;,</span><br><span class="line">  performance = &#123;</span><br><span class="line">    cache = &#123;</span><br><span class="line">      enabled = <span class="literal">true</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    reset_packpath = <span class="literal">true</span>, <span class="comment">-- reset the package path to improve startup time</span></span><br><span class="line">    rtp = &#123;</span><br><span class="line">      reset = <span class="literal">true</span>, <span class="comment">-- reset the runtime path to $VIMRUNTIME and your config directory</span></span><br><span class="line">      <span class="comment">---@type string[]</span></span><br><span class="line">      paths = &#123;&#125;, <span class="comment">-- add any custom paths here that you want to includes in the rtp</span></span><br><span class="line">      <span class="comment">---@type string[] list any plugins you want to disable here</span></span><br><span class="line">      disabled_plugins = &#123;</span><br><span class="line">        <span class="comment">-- &quot;gzip&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;matchit&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;matchparen&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;netrwPlugin&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;tarPlugin&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;tohtml&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;tutor&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;zipPlugin&quot;,</span></span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">-- lazy can generate helptags from the headings in markdown readme files,</span></span><br><span class="line">  <span class="comment">-- so :help works even for plugins that don&#x27;t have vim docs.</span></span><br><span class="line">  <span class="comment">-- when the readme opens with :help it will be correctly displayed as markdown</span></span><br><span class="line">  readme = &#123;</span><br><span class="line">    enabled = <span class="literal">true</span>,</span><br><span class="line">    root = vim.fn.stdpath(<span class="string">&quot;state&quot;</span>) .. <span class="string">&quot;/lazy/readme&quot;</span>,</span><br><span class="line">    files = &#123; <span class="string">&quot;README.md&quot;</span>, <span class="string">&quot;lua/**/README.md&quot;</span> &#125;,</span><br><span class="line">    <span class="comment">-- only generate markdown helptags for plugins that dont have docs</span></span><br><span class="line">    skip_if_doc_exists = <span class="literal">true</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  state = vim.fn.stdpath(<span class="string">&quot;state&quot;</span>) .. <span class="string">&quot;/lazy/state.json&quot;</span>, <span class="comment">-- state info for checker and other things</span></span><br><span class="line">  <span class="comment">-- Enable profiling of lazy.nvim. This will add some overhead,</span></span><br><span class="line">  <span class="comment">-- so only enable this when you are debugging lazy.nvim</span></span><br><span class="line">  profiling = &#123;</span><br><span class="line">    <span class="comment">-- Enables extra stats on the debug tab related to the loader cache.</span></span><br><span class="line">    <span class="comment">-- Additionally gathers stats about all package.loaders</span></span><br><span class="line">    loader = <span class="literal">false</span>,</span><br><span class="line">    <span class="comment">-- Track each new require in the Lazy profiling tab</span></span><br><span class="line">    <span class="built_in">require</span> = <span class="literal">false</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>options.lua</code>中配置了一些全局变量以及vim许多属性.</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- This file is automatically loaded by plugins.core</span></span><br><span class="line">vim.g.mapleader = <span class="string">&quot; &quot;</span></span><br><span class="line">vim.g.maplocalleader = <span class="string">&quot;\\&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- LazyVim auto format</span></span><br><span class="line">vim.g.autoformat = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- LazyVim picker to use.</span></span><br><span class="line"><span class="comment">-- Can be one of: telescope, fzf</span></span><br><span class="line"><span class="comment">-- Leave it to &quot;auto&quot; to automatically use the picker</span></span><br><span class="line"><span class="comment">-- enabled with `:LazyExtras`</span></span><br><span class="line">vim.g.lazyvim_picker = <span class="string">&quot;auto&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- LazyVim root dir detection</span></span><br><span class="line"><span class="comment">-- Each entry can be:</span></span><br><span class="line"><span class="comment">-- * the name of a detector function like `lsp` or `cwd`</span></span><br><span class="line"><span class="comment">-- * a pattern or array of patterns like `.git` or `lua`.</span></span><br><span class="line"><span class="comment">-- * a function with signature `function(buf) -&gt; string|string[]`</span></span><br><span class="line">vim.g.root_spec = &#123; <span class="string">&quot;lsp&quot;</span>, &#123; <span class="string">&quot;.git&quot;</span>, <span class="string">&quot;lua&quot;</span> &#125;, <span class="string">&quot;cwd&quot;</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- LazyVim automatically configures lazygit:</span></span><br><span class="line"><span class="comment">--  * theme, based on the active colorscheme.</span></span><br><span class="line"><span class="comment">--  * editorPreset to nvim-remote</span></span><br><span class="line"><span class="comment">--  * enables nerd font icons</span></span><br><span class="line"><span class="comment">-- Set to false to disable.</span></span><br><span class="line">vim.g.lazygit_config = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Options for the LazyVim statuscolumn</span></span><br><span class="line">vim.g.lazyvim_statuscolumn = &#123;</span><br><span class="line">  folds_open = <span class="literal">false</span>, <span class="comment">-- show fold sign when fold is open</span></span><br><span class="line">  folds_githl = <span class="literal">false</span>, <span class="comment">-- highlight fold sign with git sign color</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Optionally setup the terminal to use</span></span><br><span class="line"><span class="comment">-- This sets `vim.o.shell` and does some additional configuration for:</span></span><br><span class="line"><span class="comment">-- * pwsh</span></span><br><span class="line"><span class="comment">-- * powershell</span></span><br><span class="line"><span class="comment">-- LazyVim.terminal.setup(&quot;pwsh&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Hide deprecation warnings</span></span><br><span class="line">vim.g.deprecation_warnings = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Set filetype to `bigfile` for files larger than 1.5 MB</span></span><br><span class="line"><span class="comment">-- Only vim syntax will be enabled (with the correct filetype)</span></span><br><span class="line"><span class="comment">-- LSP, treesitter and other ft plugins will be disabled.</span></span><br><span class="line"><span class="comment">-- mini.animate will also be disabled.</span></span><br><span class="line">vim.g.bigfile_size = <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1.5</span> <span class="comment">-- 1.5 MB</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Show the current document symbols location from Trouble in lualine</span></span><br><span class="line">vim.g.trouble_lualine = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> opt = vim.opt</span><br><span class="line"></span><br><span class="line">opt.autowrite = <span class="literal">true</span> <span class="comment">-- Enable auto write</span></span><br><span class="line"><span class="comment">-- only set clipboard if not in ssh, to make sure the OSC 52</span></span><br><span class="line"><span class="comment">-- integration works automatically. Requires Neovim &gt;= 0.10.0</span></span><br><span class="line">opt.clipboard = vim.env.SSH_TTY <span class="keyword">and</span> <span class="string">&quot;&quot;</span> <span class="keyword">or</span> <span class="string">&quot;unnamedplus&quot;</span> <span class="comment">-- Sync with system clipboard</span></span><br><span class="line">opt.completeopt = <span class="string">&quot;menu,menuone,noselect&quot;</span></span><br><span class="line">opt.conceallevel = <span class="number">2</span> <span class="comment">-- Hide * markup for bold and italic, but not markers with substitutions</span></span><br><span class="line">opt.confirm = <span class="literal">true</span> <span class="comment">-- Confirm to save changes before exiting modified buffer</span></span><br><span class="line">opt.cursorline = <span class="literal">true</span> <span class="comment">-- Enable highlighting of the current line</span></span><br><span class="line">opt.expandtab = <span class="literal">true</span> <span class="comment">-- Use spaces instead of tabs</span></span><br><span class="line">opt.fillchars = &#123;</span><br><span class="line">  foldopen = <span class="string">&quot;&quot;</span>,</span><br><span class="line">  foldclose = <span class="string">&quot;&quot;</span>,</span><br><span class="line">  fold = <span class="string">&quot; &quot;</span>,</span><br><span class="line">  foldsep = <span class="string">&quot; &quot;</span>,</span><br><span class="line">  diff = <span class="string">&quot;╱&quot;</span>,</span><br><span class="line">  eob = <span class="string">&quot; &quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">opt.foldlevel = <span class="number">99</span></span><br><span class="line">opt.formatexpr = <span class="string">&quot;v:lua.require&#x27;lazyvim.util&#x27;.format.formatexpr()&quot;</span></span><br><span class="line">opt.formatoptions = <span class="string">&quot;jcroqlnt&quot;</span> <span class="comment">-- tcqj</span></span><br><span class="line">opt.grepformat = <span class="string">&quot;%f:%l:%c:%m&quot;</span></span><br><span class="line">opt.grepprg = <span class="string">&quot;rg --vimgrep&quot;</span></span><br><span class="line">opt.ignorecase = <span class="literal">true</span> <span class="comment">-- Ignore case</span></span><br><span class="line">opt.inccommand = <span class="string">&quot;nosplit&quot;</span> <span class="comment">-- preview incremental substitute</span></span><br><span class="line">opt.jumpoptions = <span class="string">&quot;view&quot;</span></span><br><span class="line">opt.laststatus = <span class="number">3</span> <span class="comment">-- global statusline</span></span><br><span class="line">opt.linebreak = <span class="literal">true</span> <span class="comment">-- Wrap lines at convenient points</span></span><br><span class="line">opt.list = <span class="literal">true</span> <span class="comment">-- Show some invisible characters (tabs...</span></span><br><span class="line">opt.mouse = <span class="string">&quot;a&quot;</span> <span class="comment">-- Enable mouse mode</span></span><br><span class="line">opt.number = <span class="literal">true</span> <span class="comment">-- Print line number</span></span><br><span class="line">opt.pumblend = <span class="number">10</span> <span class="comment">-- Popup blend</span></span><br><span class="line">opt.pumheight = <span class="number">10</span> <span class="comment">-- Maximum number of entries in a popup</span></span><br><span class="line">opt.relativenumber = <span class="literal">true</span> <span class="comment">-- Relative line numbers</span></span><br><span class="line">opt.scrolloff = <span class="number">4</span> <span class="comment">-- Lines of context</span></span><br><span class="line">opt.sessionoptions = &#123; <span class="string">&quot;buffers&quot;</span>, <span class="string">&quot;curdir&quot;</span>, <span class="string">&quot;tabpages&quot;</span>, <span class="string">&quot;winsize&quot;</span>, <span class="string">&quot;help&quot;</span>, <span class="string">&quot;globals&quot;</span>, <span class="string">&quot;skiprtp&quot;</span>, <span class="string">&quot;folds&quot;</span> &#125;</span><br><span class="line">opt.shiftround = <span class="literal">true</span> <span class="comment">-- Round indent</span></span><br><span class="line">opt.shiftwidth = <span class="number">2</span> <span class="comment">-- Size of an indent</span></span><br><span class="line">opt.shortmess:append(&#123; W = <span class="literal">true</span>, I = <span class="literal">true</span>, c = <span class="literal">true</span>, C = <span class="literal">true</span> &#125;)</span><br><span class="line">opt.showmode = <span class="literal">false</span> <span class="comment">-- Dont show mode since we have a statusline</span></span><br><span class="line">opt.sidescrolloff = <span class="number">8</span> <span class="comment">-- Columns of context</span></span><br><span class="line">opt.signcolumn = <span class="string">&quot;yes&quot;</span> <span class="comment">-- Always show the signcolumn, otherwise it would shift the text each time</span></span><br><span class="line">opt.smartcase = <span class="literal">true</span> <span class="comment">-- Don&#x27;t ignore case with capitals</span></span><br><span class="line">opt.smartindent = <span class="literal">true</span> <span class="comment">-- Insert indents automatically</span></span><br><span class="line">opt.spelllang = &#123; <span class="string">&quot;en&quot;</span> &#125;</span><br><span class="line">opt.spelloptions:append(<span class="string">&quot;noplainbuffer&quot;</span>)</span><br><span class="line">opt.splitbelow = <span class="literal">true</span> <span class="comment">-- Put new windows below current</span></span><br><span class="line">opt.splitkeep = <span class="string">&quot;screen&quot;</span></span><br><span class="line">opt.splitright = <span class="literal">true</span> <span class="comment">-- Put new windows right of current</span></span><br><span class="line">opt.statuscolumn = <span class="string">[[%!v:lua.require&#x27;lazyvim.util&#x27;.ui.statuscolumn()]]</span></span><br><span class="line">opt.tabstop = <span class="number">2</span> <span class="comment">-- Number of spaces tabs count for</span></span><br><span class="line">opt.termguicolors = <span class="literal">true</span> <span class="comment">-- True color support</span></span><br><span class="line">opt.timeoutlen = vim.g.vscode <span class="keyword">and</span> <span class="number">1000</span> <span class="keyword">or</span> <span class="number">300</span> <span class="comment">-- Lower than default (1000) to quickly trigger which-key</span></span><br><span class="line">opt.undofile = <span class="literal">true</span></span><br><span class="line">opt.undolevels = <span class="number">10000</span></span><br><span class="line">opt.updatetime = <span class="number">200</span> <span class="comment">-- Save swap file and trigger CursorHold</span></span><br><span class="line">opt.virtualedit = <span class="string">&quot;block&quot;</span> <span class="comment">-- Allow cursor to move where there is no text in visual block mode</span></span><br><span class="line">opt.wildmode = <span class="string">&quot;longest:full,full&quot;</span> <span class="comment">-- Command-line completion mode</span></span><br><span class="line">opt.winminwidth = <span class="number">5</span> <span class="comment">-- Minimum window width</span></span><br><span class="line">opt.<span class="built_in">wrap</span> = <span class="literal">false</span> <span class="comment">-- Disable line wrap</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> vim.fn.has(<span class="string">&quot;nvim-0.10&quot;</span>) == <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">  opt.smoothscroll = <span class="literal">true</span></span><br><span class="line">  opt.foldexpr = <span class="string">&quot;v:lua.require&#x27;lazyvim.util&#x27;.ui.foldexpr()&quot;</span></span><br><span class="line">  opt.foldmethod = <span class="string">&quot;expr&quot;</span></span><br><span class="line">  opt.foldtext = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  opt.foldmethod = <span class="string">&quot;indent&quot;</span></span><br><span class="line">  opt.foldtext = <span class="string">&quot;v:lua.require&#x27;lazyvim.util&#x27;.ui.foldtext()&quot;</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Fix markdown indentation settings</span></span><br><span class="line">vim.g.markdown_recommended_style = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>自定义的一些keymap如下</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- This file is automatically loaded by lazyvim.config.init</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- DO NOT USE `LazyVim.safe_keymap_set` IN YOUR OWN CONFIG!!</span></span><br><span class="line"><span class="comment">-- use `vim.keymap.set` instead</span></span><br><span class="line"><span class="keyword">local</span> map = LazyVim.safe_keymap_set</span><br><span class="line"></span><br><span class="line"><span class="comment">-- better up/down</span></span><br><span class="line">map(&#123; <span class="string">&quot;n&quot;</span>, <span class="string">&quot;x&quot;</span> &#125;, <span class="string">&quot;j&quot;</span>, <span class="string">&quot;v:count == 0 ? &#x27;gj&#x27; : &#x27;j&#x27;&quot;</span>, &#123; desc = <span class="string">&quot;Down&quot;</span>, expr = <span class="literal">true</span>, silent = <span class="literal">true</span> &#125;)</span><br><span class="line">map(&#123; <span class="string">&quot;n&quot;</span>, <span class="string">&quot;x&quot;</span> &#125;, <span class="string">&quot;&lt;Down&gt;&quot;</span>, <span class="string">&quot;v:count == 0 ? &#x27;gj&#x27; : &#x27;j&#x27;&quot;</span>, &#123; desc = <span class="string">&quot;Down&quot;</span>, expr = <span class="literal">true</span>, silent = <span class="literal">true</span> &#125;)</span><br><span class="line">map(&#123; <span class="string">&quot;n&quot;</span>, <span class="string">&quot;x&quot;</span> &#125;, <span class="string">&quot;k&quot;</span>, <span class="string">&quot;v:count == 0 ? &#x27;gk&#x27; : &#x27;k&#x27;&quot;</span>, &#123; desc = <span class="string">&quot;Up&quot;</span>, expr = <span class="literal">true</span>, silent = <span class="literal">true</span> &#125;)</span><br><span class="line">map(&#123; <span class="string">&quot;n&quot;</span>, <span class="string">&quot;x&quot;</span> &#125;, <span class="string">&quot;&lt;Up&gt;&quot;</span>, <span class="string">&quot;v:count == 0 ? &#x27;gk&#x27; : &#x27;k&#x27;&quot;</span>, &#123; desc = <span class="string">&quot;Up&quot;</span>, expr = <span class="literal">true</span>, silent = <span class="literal">true</span> &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Move to window using the &lt;ctrl&gt; hjkl keys</span></span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-h&gt;&quot;</span>, <span class="string">&quot;&lt;C-w&gt;h&quot;</span>, &#123; desc = <span class="string">&quot;Go to Left Window&quot;</span>, remap = <span class="literal">true</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-j&gt;&quot;</span>, <span class="string">&quot;&lt;C-w&gt;j&quot;</span>, &#123; desc = <span class="string">&quot;Go to Lower Window&quot;</span>, remap = <span class="literal">true</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-k&gt;&quot;</span>, <span class="string">&quot;&lt;C-w&gt;k&quot;</span>, &#123; desc = <span class="string">&quot;Go to Upper Window&quot;</span>, remap = <span class="literal">true</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-l&gt;&quot;</span>, <span class="string">&quot;&lt;C-w&gt;l&quot;</span>, &#123; desc = <span class="string">&quot;Go to Right Window&quot;</span>, remap = <span class="literal">true</span> &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Resize window using &lt;ctrl&gt; arrow keys</span></span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-Up&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;resize +2&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Increase Window Height&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-Down&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;resize -2&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Decrease Window Height&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-Left&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;vertical resize -2&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Decrease Window Width&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;C-Right&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;vertical resize +2&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Increase Window Width&quot;</span> &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Move Lines</span></span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;A-j&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;m .+1&lt;cr&gt;==&quot;</span>, &#123; desc = <span class="string">&quot;Move Down&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;A-k&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;m .-2&lt;cr&gt;==&quot;</span>, &#123; desc = <span class="string">&quot;Move Up&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;i&quot;</span>, <span class="string">&quot;&lt;A-j&gt;&quot;</span>, <span class="string">&quot;&lt;esc&gt;&lt;cmd&gt;m .+1&lt;cr&gt;==gi&quot;</span>, &#123; desc = <span class="string">&quot;Move Down&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;i&quot;</span>, <span class="string">&quot;&lt;A-k&gt;&quot;</span>, <span class="string">&quot;&lt;esc&gt;&lt;cmd&gt;m .-2&lt;cr&gt;==gi&quot;</span>, &#123; desc = <span class="string">&quot;Move Up&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;v&quot;</span>, <span class="string">&quot;&lt;A-j&gt;&quot;</span>, <span class="string">&quot;:m &#x27;&gt;+1&lt;cr&gt;gv=gv&quot;</span>, &#123; desc = <span class="string">&quot;Move Down&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;v&quot;</span>, <span class="string">&quot;&lt;A-k&gt;&quot;</span>, <span class="string">&quot;:m &#x27;&lt;-2&lt;cr&gt;gv=gv&quot;</span>, &#123; desc = <span class="string">&quot;Move Up&quot;</span> &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- buffers</span></span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;S-h&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;bprevious&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Prev Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;S-l&gt;&quot;</span>, <span class="string">&quot;&lt;cmd&gt;bnext&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Next Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;[b&quot;</span>, <span class="string">&quot;&lt;cmd&gt;bprevious&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Prev Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;]b&quot;</span>, <span class="string">&quot;&lt;cmd&gt;bnext&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Next Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;leader&gt;bb&quot;</span>, <span class="string">&quot;&lt;cmd&gt;e #&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Switch to Other Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;leader&gt;`&quot;</span>, <span class="string">&quot;&lt;cmd&gt;e #&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Switch to Other Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;leader&gt;bd&quot;</span>, LazyVim.ui.bufremove, &#123; desc = <span class="string">&quot;Delete Buffer&quot;</span> &#125;)</span><br><span class="line">map(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;&lt;leader&gt;bD&quot;</span>, <span class="string">&quot;&lt;cmd&gt;:bd&lt;cr&gt;&quot;</span>, &#123; desc = <span class="string">&quot;Delete Buffer and Window&quot;</span> &#125;)</span><br><span class="line">....</span><br></pre></td></tr></table></figure><p><code>autocmd.lua</code>如下</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- This file is automatically loaded by lazyvim.config.init.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">augroup</span><span class="params">(name)</span></span></span><br><span class="line">  <span class="keyword">return</span> vim.api.nvim_create_augroup(<span class="string">&quot;lazyvim_&quot;</span> .. name, &#123; clear = <span class="literal">true</span> &#125;)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- Check if we need to reload the file when it changed</span></span><br><span class="line">vim.api.nvim_create_autocmd(&#123; <span class="string">&quot;FocusGained&quot;</span>, <span class="string">&quot;TermClose&quot;</span>, <span class="string">&quot;TermLeave&quot;</span> &#125;, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;checktime&quot;</span>),</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">if</span> vim.o.buftype ~= <span class="string">&quot;nofile&quot;</span> <span class="keyword">then</span></span><br><span class="line">      vim.cmd(<span class="string">&quot;checktime&quot;</span>)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Highlight on yank</span></span><br><span class="line">vim.api.nvim_create_autocmd(<span class="string">&quot;TextYankPost&quot;</span>, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;highlight_yank&quot;</span>),</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">    vim.highlight.on_yank()</span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- resize splits if window got resized</span></span><br><span class="line">vim.api.nvim_create_autocmd(&#123; <span class="string">&quot;VimResized&quot;</span> &#125;, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;resize_splits&quot;</span>),</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> current_tab = vim.fn.tabpagenr()</span><br><span class="line">    vim.cmd(<span class="string">&quot;tabdo wincmd =&quot;</span>)</span><br><span class="line">    vim.cmd(<span class="string">&quot;tabnext &quot;</span> .. current_tab)</span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- go to last loc when opening a buffer</span></span><br><span class="line">vim.api.nvim_create_autocmd(<span class="string">&quot;BufReadPost&quot;</span>, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;last_loc&quot;</span>),</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">(event)</span></span></span><br><span class="line">    <span class="keyword">local</span> exclude = &#123; <span class="string">&quot;gitcommit&quot;</span> &#125;</span><br><span class="line">    <span class="keyword">local</span> buf = event.buf</span><br><span class="line">    <span class="keyword">if</span> vim.tbl_contains(exclude, vim.bo[buf].filetype) <span class="keyword">or</span> vim.b[buf].lazyvim_last_loc <span class="keyword">then</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    vim.b[buf].lazyvim_last_loc = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">local</span> mark = vim.api.nvim_buf_get_mark(buf, <span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">    <span class="keyword">local</span> lcount = vim.api.nvim_buf_line_count(buf)</span><br><span class="line">    <span class="keyword">if</span> mark[<span class="number">1</span>] &gt; <span class="number">0</span> <span class="keyword">and</span> mark[<span class="number">1</span>] &lt;= lcount <span class="keyword">then</span></span><br><span class="line">      <span class="built_in">pcall</span>(vim.api.nvim_win_set_cursor, <span class="number">0</span>, mark)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- close some filetypes with &lt;q&gt;</span></span><br><span class="line">vim.api.nvim_create_autocmd(<span class="string">&quot;FileType&quot;</span>, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;close_with_q&quot;</span>),</span><br><span class="line">  pattern = &#123;</span><br><span class="line">    <span class="string">&quot;PlenaryTestPopup&quot;</span>,</span><br><span class="line">    <span class="string">&quot;help&quot;</span>,</span><br><span class="line">    <span class="string">&quot;lspinfo&quot;</span>,</span><br><span class="line">    <span class="string">&quot;notify&quot;</span>,</span><br><span class="line">    <span class="string">&quot;qf&quot;</span>,</span><br><span class="line">    <span class="string">&quot;spectre_panel&quot;</span>,</span><br><span class="line">    <span class="string">&quot;startuptime&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tsplayground&quot;</span>,</span><br><span class="line">    <span class="string">&quot;neotest-output&quot;</span>,</span><br><span class="line">    <span class="string">&quot;checkhealth&quot;</span>,</span><br><span class="line">    <span class="string">&quot;neotest-summary&quot;</span>,</span><br><span class="line">    <span class="string">&quot;neotest-output-panel&quot;</span>,</span><br><span class="line">    <span class="string">&quot;dbout&quot;</span>,</span><br><span class="line">    <span class="string">&quot;gitsigns.blame&quot;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">(event)</span></span></span><br><span class="line">    vim.bo[event.buf].buflisted = <span class="literal">false</span></span><br><span class="line">    vim.keymap.set(<span class="string">&quot;n&quot;</span>, <span class="string">&quot;q&quot;</span>, <span class="string">&quot;&lt;cmd&gt;close&lt;cr&gt;&quot;</span>, &#123; buffer = event.buf, silent = <span class="literal">true</span> &#125;)</span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- make it easier to close man-files when opened inline</span></span><br><span class="line">vim.api.nvim_create_autocmd(<span class="string">&quot;FileType&quot;</span>, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;man_unlisted&quot;</span>),</span><br><span class="line">  pattern = &#123; <span class="string">&quot;man&quot;</span> &#125;,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">(event)</span></span></span><br><span class="line">    vim.bo[event.buf].buflisted = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- wrap and check for spell in text filetypes</span></span><br><span class="line">vim.api.nvim_create_autocmd(<span class="string">&quot;FileType&quot;</span>, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;wrap_spell&quot;</span>),</span><br><span class="line">  pattern = &#123; <span class="string">&quot;*.txt&quot;</span>, <span class="string">&quot;*.tex&quot;</span>, <span class="string">&quot;*.typ&quot;</span>, <span class="string">&quot;gitcommit&quot;</span>, <span class="string">&quot;markdown&quot;</span> &#125;,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">    vim.opt_local.<span class="built_in">wrap</span> = <span class="literal">true</span></span><br><span class="line">    vim.opt_local.spell = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Fix conceallevel for json files</span></span><br><span class="line">vim.api.nvim_create_autocmd(&#123; <span class="string">&quot;FileType&quot;</span> &#125;, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;json_conceal&quot;</span>),</span><br><span class="line">  pattern = &#123; <span class="string">&quot;json&quot;</span>, <span class="string">&quot;jsonc&quot;</span>, <span class="string">&quot;json5&quot;</span> &#125;,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">    vim.opt_local.conceallevel = <span class="number">0</span></span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Auto create dir when saving a file, in case some intermediate directory does not exist</span></span><br><span class="line">vim.api.nvim_create_autocmd(&#123; <span class="string">&quot;BufWritePre&quot;</span> &#125;, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;auto_create_dir&quot;</span>),</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">(event)</span></span></span><br><span class="line">    <span class="keyword">if</span> event.<span class="built_in">match</span>:<span class="built_in">match</span>(<span class="string">&quot;^%w%w+:[\\/][\\/]&quot;</span>) <span class="keyword">then</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">local</span> file = vim.uv.fs_realpath(event.<span class="built_in">match</span>) <span class="keyword">or</span> event.<span class="built_in">match</span></span><br><span class="line">    vim.fn.mkdir(vim.fn.fnamemodify(file, <span class="string">&quot;:p:h&quot;</span>), <span class="string">&quot;p&quot;</span>)</span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">vim.filetype.add(&#123;</span><br><span class="line">  pattern = &#123;</span><br><span class="line">    [<span class="string">&quot;.*&quot;</span>] = &#123;</span><br><span class="line">      <span class="function"><span class="keyword">function</span><span class="params">(path, buf)</span></span></span><br><span class="line">        <span class="keyword">return</span> vim.bo[buf]</span><br><span class="line">            <span class="keyword">and</span> vim.bo[buf].filetype ~= <span class="string">&quot;bigfile&quot;</span></span><br><span class="line">            <span class="keyword">and</span> <span class="built_in">path</span></span><br><span class="line">            <span class="keyword">and</span> vim.fn.getfsize(<span class="built_in">path</span>) &gt; vim.g.bigfile_size</span><br><span class="line">            <span class="keyword">and</span> <span class="string">&quot;bigfile&quot;</span></span><br><span class="line">          <span class="keyword">or</span> <span class="literal">nil</span></span><br><span class="line">      <span class="keyword">end</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">vim.api.nvim_create_autocmd(&#123; <span class="string">&quot;FileType&quot;</span> &#125;, &#123;</span><br><span class="line">  group = augroup(<span class="string">&quot;bigfile&quot;</span>),</span><br><span class="line">  pattern = <span class="string">&quot;bigfile&quot;</span>,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">(ev)</span></span></span><br><span class="line">    vim.b.minianimate_disable = <span class="literal">true</span></span><br><span class="line">    vim.schedule(<span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">      vim.bo[ev.buf].syntax = vim.filetype.<span class="built_in">match</span>(&#123; buf = ev.buf &#125;) <span class="keyword">or</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">end</span>)</span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h5 id="如何配置Lazyvim"><a href="#如何配置Lazyvim" class="headerlink" title="如何配置Lazyvim"></a>如何配置Lazyvim</h5><p>lazyvim的官方建议:</p><ol><li>文件结构如下,可以在plugins文件夹中设置</li></ol><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~/.config/nvim</span><br><span class="line">├── <span class="keyword">lua</span></span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── lazy.<span class="keyword">lua</span></span><br><span class="line">│   └── plugins</span><br><span class="line">│       ├── spec1.<span class="keyword">lua</span></span><br><span class="line">│       ├── **</span><br><span class="line">│       └── spec2.<span class="keyword">lua</span></span><br><span class="line">└── init.<span class="keyword">lua</span></span><br></pre></td></tr></table></figure><p>默认的<code>lazy.lua</code>大概长下面这样,通过lazy.lua修改一些简单配置</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> lazypath = vim.fn.stdpath(<span class="string">&quot;data&quot;</span>) .. <span class="string">&quot;/lazy/lazy.nvim&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (vim.uv <span class="keyword">or</span> vim.loop).fs_stat(lazypath) <span class="keyword">then</span></span><br><span class="line">  <span class="keyword">local</span> lazyrepo = <span class="string">&quot;https://github.com/folke/lazy.nvim.git&quot;</span></span><br><span class="line">  <span class="keyword">local</span> out = vim.fn.system(&#123; <span class="string">&quot;git&quot;</span>, <span class="string">&quot;clone&quot;</span>, <span class="string">&quot;--filter=blob:none&quot;</span>, <span class="string">&quot;--branch=stable&quot;</span>, lazyrepo, lazypath &#125;)</span><br><span class="line">  <span class="keyword">if</span> vim.v.shell_error ~= <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line">    vim.api.nvim_echo(&#123;</span><br><span class="line">      &#123; <span class="string">&quot;Failed to clone lazy.nvim:\n&quot;</span>, <span class="string">&quot;ErrorMsg&quot;</span> &#125;,</span><br><span class="line">      &#123; out, <span class="string">&quot;WarningMsg&quot;</span> &#125;,</span><br><span class="line">      &#123; <span class="string">&quot;\nPress any key to exit...&quot;</span> &#125;,</span><br><span class="line">    &#125;, <span class="literal">true</span>, &#123;&#125;)</span><br><span class="line">    vim.fn.getchar()</span><br><span class="line">    <span class="built_in">os</span>.<span class="built_in">exit</span>(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">vim.opt.rtp:prepend(lazypath)</span><br><span class="line"></span><br><span class="line"><span class="built_in">require</span>(<span class="string">&quot;lazy&quot;</span>).setup(&#123;</span><br><span class="line">  spec = &#123;</span><br><span class="line">    <span class="comment">-- add LazyVim and import its plugins</span></span><br><span class="line">    &#123; <span class="string">&quot;LazyVim/LazyVim&quot;</span>, import = <span class="string">&quot;lazyvim.plugins&quot;</span> &#125;,</span><br><span class="line">    <span class="comment">-- import/override with your plugins</span></span><br><span class="line">    &#123; import = <span class="string">&quot;plugins&quot;</span> &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  defaults = &#123;</span><br><span class="line">    <span class="comment">-- By default, only LazyVim plugins will be lazy-loaded. Your custom plugins will load during startup.</span></span><br><span class="line">    <span class="comment">-- If you know what you&#x27;re doing, you can set this to `true` to have all your custom plugins lazy-loaded by default.</span></span><br><span class="line">    lazy = <span class="literal">false</span>,</span><br><span class="line">    <span class="comment">-- It&#x27;s recommended to leave version=false for now, since a lot the plugin that support versioning,</span></span><br><span class="line">    <span class="comment">-- have outdated releases, which may break your Neovim install.</span></span><br><span class="line">    version = <span class="literal">false</span>, <span class="comment">-- always use the latest git commit</span></span><br><span class="line">    <span class="comment">-- version = &quot;*&quot;, -- try installing the latest stable version for plugins that support semver</span></span><br><span class="line">  &#125;,</span><br><span class="line">  install = &#123; colorscheme = &#123; <span class="string">&quot;tokyonight&quot;</span>, <span class="string">&quot;habamax&quot;</span> &#125; &#125;,</span><br><span class="line">  checker = &#123; enabled = <span class="literal">true</span> &#125;, <span class="comment">-- automatically check for plugin updates</span></span><br><span class="line">  performance = &#123;</span><br><span class="line">    rtp = &#123;</span><br><span class="line">      <span class="comment">-- disable some rtp plugins</span></span><br><span class="line">      disabled_plugins = &#123;</span><br><span class="line">        <span class="string">&quot;gzip&quot;</span>,</span><br><span class="line">        <span class="comment">-- &quot;matchit&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;matchparen&quot;,</span></span><br><span class="line">        <span class="comment">-- &quot;netrwPlugin&quot;,</span></span><br><span class="line">        <span class="string">&quot;tarPlugin&quot;</span>,</span><br><span class="line">        <span class="string">&quot;tohtml&quot;</span>,</span><br><span class="line">        <span class="string">&quot;tutor&quot;</span>,</span><br><span class="line">        <span class="string">&quot;zipPlugin&quot;</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h5 id="pugin-spec"><a href="#pugin-spec" class="headerlink" title="pugin spec"></a>pugin spec</h5><p>可以这样修改插件的一些选项<a href="https://lazy.folke.io/spec">🔌 Plugin Spec | lazy.nvim (folke.io)</a></p><p>此外通过plugin spec下载或者更改插件的配置</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &#123;</span><br><span class="line">  <span class="comment">-- the colorscheme should be available when starting Neovim</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;folke/tokyonight.nvim&quot;</span>,</span><br><span class="line">    lazy = <span class="literal">false</span>, <span class="comment">-- make sure we load this during startup if it is your main colorscheme</span></span><br><span class="line">    priority = <span class="number">1000</span>, <span class="comment">-- make sure to load this before all the other start plugins</span></span><br><span class="line">    <span class="built_in">config</span> = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">      <span class="comment">-- load the colorscheme here</span></span><br><span class="line">      vim.cmd(<span class="string">[[colorscheme tokyonight]]</span>)</span><br><span class="line">    <span class="keyword">end</span>,</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- I have a separate config.mappings file where I require which-key.</span></span><br><span class="line">  <span class="comment">-- With lazy the plugin will be automatically loaded when it is required somewhere</span></span><br><span class="line">  &#123; <span class="string">&quot;folke/which-key.nvim&quot;</span>, lazy = <span class="literal">true</span> &#125;,</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;nvim-neorg/neorg&quot;</span>,</span><br><span class="line">    <span class="comment">-- lazy-load on filetype</span></span><br><span class="line">    ft = <span class="string">&quot;norg&quot;</span>,</span><br><span class="line">    <span class="comment">-- options for neorg. This will automatically call `require(&quot;neorg&quot;).setup(opts)`</span></span><br><span class="line">    opts = &#123;</span><br><span class="line">      <span class="built_in">load</span> = &#123;</span><br><span class="line">        [<span class="string">&quot;core.defaults&quot;</span>] = &#123;&#125;,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;dstein64/vim-startuptime&quot;</span>,</span><br><span class="line">    <span class="comment">-- lazy-load on a command</span></span><br><span class="line">    cmd = <span class="string">&quot;StartupTime&quot;</span>,</span><br><span class="line">    <span class="comment">-- init is called during startup. Configuration for vim plugins typically should be set in an init function</span></span><br><span class="line">    init = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">      vim.g.startuptime_tries = <span class="number">10</span></span><br><span class="line">    <span class="keyword">end</span>,</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;hrsh7th/nvim-cmp&quot;</span>,</span><br><span class="line">    <span class="comment">-- load cmp on InsertEnter</span></span><br><span class="line">    event = <span class="string">&quot;InsertEnter&quot;</span>,</span><br><span class="line">    <span class="comment">-- these dependencies will only be loaded when cmp loads</span></span><br><span class="line">    <span class="comment">-- dependencies are always lazy-loaded unless specified otherwise</span></span><br><span class="line">    dependencies = &#123;</span><br><span class="line">      <span class="string">&quot;hrsh7th/cmp-nvim-lsp&quot;</span>,</span><br><span class="line">      <span class="string">&quot;hrsh7th/cmp-buffer&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="built_in">config</span> = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">      <span class="comment">-- ...</span></span><br><span class="line">    <span class="keyword">end</span>,</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- if some code requires a module from an unloaded plugin, it will be automatically loaded.</span></span><br><span class="line">  <span class="comment">-- So for api plugins like devicons, we can always set lazy=true</span></span><br><span class="line">  &#123; <span class="string">&quot;nvim-tree/nvim-web-devicons&quot;</span>, lazy = <span class="literal">true</span> &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- you can use the VeryLazy event for things that can</span></span><br><span class="line">  <span class="comment">-- load later and are not important for the initial UI</span></span><br><span class="line">  &#123; <span class="string">&quot;stevearc/dressing.nvim&quot;</span>, event = <span class="string">&quot;VeryLazy&quot;</span> &#125;,</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;Wansmer/treesj&quot;</span>,</span><br><span class="line">    keys = &#123;</span><br><span class="line">      &#123; <span class="string">&quot;J&quot;</span>, <span class="string">&quot;&lt;cmd&gt;TSJToggle&lt;cr&gt;&quot;</span>, desc = <span class="string">&quot;Join Toggle&quot;</span> &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    opts = &#123; use_default_keymaps = <span class="literal">false</span>, max_join_length = <span class="number">150</span> &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;monaqa/dial.nvim&quot;</span>,</span><br><span class="line">    <span class="comment">-- lazy-load on keys</span></span><br><span class="line">    <span class="comment">-- mode is `n` by default. For more advanced options, check the section on key mappings</span></span><br><span class="line">    keys = &#123; <span class="string">&quot;&lt;C-a&gt;&quot;</span>, &#123; <span class="string">&quot;&lt;C-x&gt;&quot;</span>, mode = <span class="string">&quot;n&quot;</span> &#125; &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- local plugins need to be explicitly configured with dir</span></span><br><span class="line">  &#123; dir = <span class="string">&quot;~/projects/secret.nvim&quot;</span> &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- you can use a custom url to fetch a plugin</span></span><br><span class="line">  &#123; url = <span class="string">&quot;git@github.com:folke/noice.nvim.git&quot;</span> &#125;,</span><br><span class="line"></span><br><span class="line">  <span class="comment">-- local plugins can also be configured with the dev option.</span></span><br><span class="line">  <span class="comment">-- This will use &#123;config.dev.path&#125;/noice.nvim/ instead of fetching it from GitHub</span></span><br><span class="line">  <span class="comment">-- With the dev option, you can easily switch between the local and installed version of a plugin</span></span><br><span class="line">  &#123; <span class="string">&quot;folke/noice.nvim&quot;</span>, dev = <span class="literal">true</span> &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>Property</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><strong>[1]</strong></td><td><code>string?</code></td><td>Short plugin url. Will be expanded using <a href="https://lazy.folke.io/configuration"><code>config.git.url_format</code></a>. Can also be a <code>url</code> or <code>dir</code>.</td></tr><tr><td><strong>dependencies</strong></td><td><code>LazySpec[]</code></td><td>A list of plugin names or plugin specs that should be loaded when the plugin loads. Dependencies are always lazy-loaded unless specified otherwise. When specifying a name, make sure the plugin spec has been defined somewhere else.</td></tr><tr><td><strong>enabled</strong></td><td><code>boolean?</code> or <code>fun():boolean</code></td><td>When <code>false</code>, or if the <code>function</code> returns false, then this plugin will not be included in the spec</td></tr><tr><td><strong>cond</strong></td><td><code>boolean?</code> or <code>fun(LazyPlugin):boolean</code></td><td>Behaves the same as <code>enabled</code>, but won’t uninstall the plugin when the condition is <code>false</code>. Useful to disable some plugins in vscode, or firenvim for example.</td></tr><tr><td><strong>priority</strong></td><td><code>number?</code></td><td>Only useful for <strong>start</strong> plugins (<code>lazy=false</code>) to force loading certain plugins first. Default priority is <code>50</code>. It’s recommended to set this to a high number for colorschemes</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th><strong>init</strong></th><th><code>fun(LazyPlugin)</code></th><th><code>init</code> functions are always executed during. Mostly useful for setting <code>vim.g.*</code> configuration used by <strong>Vim</strong> plugins startup</th></tr></thead><tbody><tr><td><strong>opts</strong></td><td><code>table</code> or <code>fun(LazyPlugin, opts:table)</code></td><td><code>opts</code> should be a table (will be merged with parent specs), return a table (replaces parent specs) or should change a table. The table will be passed to the <code>Plugin.config()</code> function. Setting this value will imply <code>Plugin.config()</code></td></tr><tr><td><strong>config</strong></td><td><code>fun(LazyPlugin, opts:table)</code> or <code>true</code></td><td><code>config</code> is executed when the plugin loads. The default implementation will automatically run <code>require(MAIN).setup(opts)</code> if <code>opts</code> or <code>config = true</code> is set. Lazy uses several heuristics to determine the plugin’s <code>MAIN</code> module automatically based on the plugin’s <strong>name</strong>. <em>(<code>opts</code> is the recommended way to configure plugins)</em>.</td></tr><tr><td><strong>main</strong></td><td><code>string?</code></td><td>You can specify the <code>main</code> module to use for <code>config()</code> and <code>opts()</code>, in case it can not be determined automatically. See <code>config()</code></td></tr><tr><td><strong>build</strong></td><td><code>fun(LazyPlugin)</code> or <code>string</code> or <code>false</code> or a list of build commands</td><td><code>build</code> is executed when a plugin is installed or updated. See <a href="https://lazy.folke.io/developers#building">Building</a> for more information.</td></tr></tbody></table></div><h5 id="添加插件"><a href="#添加插件" class="headerlink" title="添加插件"></a>添加插件</h5><p>添加插件非常简单，只需将插件规格添加到 lua/plugins/*.lua 下的某个文件中即可。可以在其中创建任意数量的文件。允许缓存所有插件spec。<br>规格更改更新时将自动重新加载，因此 :Lazy UI 始终是最新的。</p><p>可以在 lua/plugins 文件夹中为每个插件创建一个文件,也可以为某些功能创建一个包含所有插件规格的独立文件.</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &#123;</span><br><span class="line">  <span class="comment">-- add symbols-outline</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&quot;simrat39/symbols-outline.nvim&quot;</span>,</span><br><span class="line">    cmd = <span class="string">&quot;SymbolsOutline&quot;</span>, # 根据命令进行懒惰加载</span><br><span class="line">    keys = &#123; &#123; <span class="string">&quot;&lt;leader&gt;cs&quot;</span>, <span class="string">&quot;&lt;cmd&gt;SymbolsOutline&lt;cr&gt;&quot;</span>, desc = <span class="string">&quot;Symbols Outline&quot;</span> &#125; &#125;, #Lazy-<span class="built_in">load</span> on key mapping</span><br><span class="line">    opts = &#123;</span><br><span class="line">      <span class="comment">-- add your options that should be passed to the setup() function here</span></span><br><span class="line">      position = <span class="string">&quot;right&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>懒加载规则</strong></p><p>lazy.nvim 可自动懒加载 Lua 模块. 这意味着,如果你有一个懒加载的插件 A 和一个需要插件 A 的模块的插件 B,那么插件 A 将按照预期按需加载。</p><p>此外,还可以对事件(events)、命令(cmd)、文件类型(filetype)和按键映射(key mappings)进行懒加载.</p><p>当以下情况之一为真时，插件将被懒加载：</p><ul><li>该插件仅作为依赖项(dependency)存在于plugin spec中</li><li>它有一个事件、cmd、ft 或keys关键字</li><li>config.defaults.lazy == true</li></ul><p><strong>自定义Plugin Specs</strong></p><p>默认合并规则：</p><p>cmd：将使用自定义命令扩展命令列表<br>event：事件列表，将使用自定义事件进行扩展<br>ft：文件类型列表将使用自定义文件类型进行扩展<br>keys：键映射列表，将使用自定义键映射进行扩展<br>opts：自定义选项将与默认选项合并<br>dependencies：依赖项列表将使用自定义依赖项进行扩展<br>任何其他属性都将<strong>覆盖</strong>默认值,比如spec</p><p>也就是说如果lazyvim中有了你想下载的插件,你可通过在plugins目录下添加一个lua文件修改,如果你想添加一个没有的插件,操作是一样的,无非是少了一些默认的配置<strong>.</strong></p><blockquote><p>在可能的情况下，始终使用 opts 而不是 config。</p></blockquote><p><strong>增加或者禁用插件keymap</strong></p><p>添加 keys= 的规则。</p><p>也可以通过设置默认 keymap 为 false 来禁用.要覆盖一个关键映射,只需添加一个具有相同 lhs 和新 rhs 的关键映射(也就是按键相同,操作不同)</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &#123;</span><br><span class="line">  <span class="string">&quot;nvim-telescope/telescope.nvim&quot;</span>,</span><br><span class="line">  keys = &#123;</span><br><span class="line">    <span class="comment">-- disable the keymap to grep files</span></span><br><span class="line">    &#123;<span class="string">&quot;&lt;leader&gt;/&quot;</span>, <span class="literal">false</span>&#125;,</span><br><span class="line">    <span class="comment">-- change a keymap</span></span><br><span class="line">    &#123; <span class="string">&quot;&lt;leader&gt;ff&quot;</span>, <span class="string">&quot;&lt;cmd&gt;Telescope find_files&lt;cr&gt;&quot;</span>, desc = <span class="string">&quot;Find Files&quot;</span> &#125;,</span><br><span class="line">    <span class="comment">-- add a keymap to browse plugin files</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;&lt;leader&gt;fp&quot;</span>,</span><br><span class="line">      <span class="function"><span class="keyword">function</span><span class="params">()</span></span> <span class="built_in">require</span>(<span class="string">&quot;telescope.builtin&quot;</span>).find_files(&#123; cwd = <span class="built_in">require</span>(<span class="string">&quot;lazy.core.config&quot;</span>).options.root &#125;) <span class="keyword">end</span>,</span><br><span class="line">      desc = <span class="string">&quot;Find Plugin File&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><h5 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h5><ul><li>如果想去的缓冲区离您所在的位置很近，请使用 H 和 L。</li><li>否则，如果缓冲区已打开，请使用 \<leader>，</li><li>对于其他文件，使用 <leader><space>。</li><li>使用 \<leader>bd 关闭不再需要的缓冲区</li><li>使用 \<leader>ss 快速跳转到所处缓冲区中的函数</li><li><p>使用 \<c-o>、\<c-i> 和 gd 浏览代码</p></li><li><p>使用 \<leader>bp 可以固定缓冲区，使用 \<leader>bP 可以删除所有未固定的缓冲区</p></li><li>在你将来想做但现在不需要的文件中添加 TODO,并删除它们的缓冲区,git 会跟踪它们</li><li>如果要禁用某个缓冲区的自动格式化，则为该缓冲区设置 <code>vim.b.autoformat = false</code>。</li></ul><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- Disable autoformat for lua files</span></span><br><span class="line">vim.api.nvim_create_autocmd(&#123; <span class="string">&quot;FileType&quot;</span> &#125;, &#123;</span><br><span class="line">  pattern = &#123; <span class="string">&quot;lua&quot;</span> &#125;,</span><br><span class="line">  callback = <span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">    vim.b.autoformat = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">end</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>可以使用 <code>&lt;leader&gt;uf</code>来启用该缓冲区的自动格式化。</p><p>除了layvim的配置,neotree等使用的插件的配置也应该看看</p><p>如果你想学习vim,可以通过vim tutor或者在线的vim adventure练习.</p><h3 id="Alacritty"><a href="#Alacritty" class="headerlink" title="Alacritty"></a>Alacritty</h3><p>GPU加速的终端模拟器,保持了最小的核心功能,没有窗口分割等(如果想要更多功能,考虑使用wezterm(基本不需要什么配置),配置使用lua).</p><p>Alacritty的配置非常轻松,使用.toml<a href="https://alacritty.org/config-alacritty.html">Alacritty</a>,结构比较清晰</p><p>下面是一个例子</p><p><a href="https://github.com/TwiggieSmallz/Default-Alacritty-TOML-Config/blob/main/alacritty.toml">Default-Alacritty-TOML-Config/alacritty.toml at main · TwiggieSmallz/Default-Alacritty-TOML-Config (github.com)</a></p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[GENERAL]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[ENV]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[WINDOW]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[SCROLLING]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[FONT]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[SELECTION]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[TERMINAL]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[CURSOR]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[font]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[HINTS]</span></span><br><span class="line"></span><br><span class="line"><span class="attr">size</span> = <span class="number">12.0</span></span><br><span class="line"></span><br><span class="line"><span class="section">[font.bold]</span></span><br><span class="line"><span class="attr">family</span> = <span class="string">&quot;monospace&quot;</span></span><br><span class="line"><span class="attr">style</span> = <span class="string">&quot;Bold&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[font.bold_italic]</span></span><br><span class="line"><span class="attr">family</span> = <span class="string">&quot;monospace&quot;</span></span><br><span class="line"><span class="attr">style</span> = <span class="string">&quot;Bold Italic&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[font.italic]</span></span><br><span class="line"><span class="attr">family</span> = <span class="string">&quot;monospace&quot;</span></span><br><span class="line"><span class="attr">style</span> = <span class="string">&quot;Italic&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[font.normal]</span></span><br><span class="line"><span class="attr">family</span> = <span class="string">&quot;monospace&quot;</span></span><br><span class="line"><span class="attr">style</span> = <span class="string">&quot;Regular&quot;</span></span><br></pre></td></tr></table></figure><h3 id="后言"><a href="#后言" class="headerlink" title="后言"></a>后言</h3><p>有许多操作具体我也在学习,欢迎交流.感觉目前使用neovim写点小demo还是不错的,大项目可以使用jetbrains的IDE.</p><p>如果你想geek一点,使用arch的文档以及常用的软件<a href="https://wiki.archlinux.org/">ArchWiki (archlinux.org)</a>和<a href="https://github.com/ihchiz/Awesome-Linux-Software-zh_CN#窗口管理">ihchiz/Awesome-Linux-Software-zh_CN: 🐧 一个 Linux 上超赞的应用，软件，工具以及其它资源的集中地。 (github.com)</a>,下载和使用这类软件非常全面和方便. 可以考虑使用<a href="https://github.com/archcraft-os">Archcraft (github.com)</a>试试,自带许多配置文件.</p><p>也可以看看我介绍的一些日常开发setup<a href="https://protool-ten.vercel.app/setup/setup.html">protools (protool-ten.vercel.app)</a></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;常用的窗口管理器,编辑器与终端模拟器等等&lt;br&gt;</summary>
    
    
    
    
    <category term="setup" scheme="https://www.sekyoro.top/tags/setup/"/>
    
  </entry>
  
  <entry>
    <title>协作感知算法:三</title>
    <link href="https://www.sekyoro.top/2024/06/30/%E5%8D%8F%E4%BD%9C%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95-%E4%B8%89/"/>
    <id>https://www.sekyoro.top/2024/06/30/%E5%8D%8F%E4%BD%9C%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95-%E4%B8%89/</id>
    <published>2024-06-30T05:46:08.000Z</published>
    <updated>2024-07-02T15:00:30.751Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>一些稍微新一点或者之前没看到的想法还不错的协同感知论文<br><span id="more"></span></p><h2 id="晚期和中期协同融合感知"><a href="#晚期和中期协同融合感知" class="headerlink" title="晚期和中期协同融合感知"></a>晚期和中期协同融合感知</h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/CatOneTwo/Collaborative-Perception-in-Autonomous-Driving/tree/main?tab=readme-ov-file">CatOneTwo/Collaborative-Perception-in-Autonomous-Driving: (2023 ITSM) Collaborative Perception in Autonomous Driving: Methods, Datasets and Challenges (github.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;一些稍微新一点或者之前没看到的想法还不错的协同感知论文&lt;br&gt;</summary>
    
    
    
    
    <category term="collaborative perception" scheme="https://www.sekyoro.top/tags/collaborative-perception/"/>
    
  </entry>
  
  <entry>
    <title>Rust learning:from germ to grave</title>
    <link href="https://www.sekyoro.top/2024/06/29/Rust-learning-from-germ-to-grave/"/>
    <id>https://www.sekyoro.top/2024/06/29/Rust-learning-from-germ-to-grave/</id>
    <published>2024-06-29T04:51:24.000Z</published>
    <updated>2024-06-29T14:41:54.273Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Rust官方推荐的三个资料,分别是The Rust programming language,Rust by examples以及ruslings,已经相当充足了.包括相对全面的书,代码例子以及方便的互动式exercises.个人觉得,the book相当于字典,虽然其实还有内容更多的reference,而examples更加易懂上手,rustlings相当于刷题,把关键东西了解一遍.</p><p>所以从这三个东西入手开始Rust学习之旅,一些地方会跟c++对比.<br><span id="more"></span></p><h3 id="宏macro"><a href="#宏macro" class="headerlink" title="宏macro"></a>宏macro</h3><h3 id="变量binding"><a href="#变量binding" class="headerlink" title="变量binding"></a>变量binding</h3><p>知识点:</p><ol><li>不变性 Rust默认不可变,不像c++到处声明const</li><li>scope和shadowing 主要有variable shadowing,也就是可以重声明,在c++中不允许</li><li>将一个mut的值赋值给non-mut的值,在那个域内,non-mute的值也不能被改变</li></ol><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> x = <span class="number">3</span>;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Number &#123;&#125;&quot;</span>, x);</span><br><span class="line">    x = <span class="number">5</span>; </span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Number &#123;&#125;&quot;</span>, x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> number = <span class="string">&quot;T-H-R-E-E&quot;</span>; <span class="comment">// don&#x27;t change this line</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Spell a Number : &#123;&#125;&quot;</span>, number);</span><br><span class="line">    <span class="keyword">let</span> number = <span class="number">3</span>; <span class="comment">// don&#x27;t rename this variable</span></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Number plus two is : &#123;&#125;&quot;</span>, number + <span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut</span> _mutable_integer = <span class="number">7i32</span>;</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Shadowing by immutable `_mutable_integer`</span></span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut</span> _mutable_integer = _mutable_integer;</span><br><span class="line">        </span><br><span class="line">        _mutable_integer = <span class="number">50</span>;</span><br><span class="line">       </span><br><span class="line">        <span class="comment">// `_mutable_integer` goes out of scope</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Ok! `_mutable_integer` is not frozen in this scope</span></span><br><span class="line">    _mutable_integer = <span class="number">3</span>;</span><br></pre></td></tr></table></figure><h3 id="Primitives"><a href="#Primitives" class="headerlink" title="Primitives"></a>Primitives</h3><h4 id="字面量和操作符"><a href="#字面量和操作符" class="headerlink" title="字面量和操作符"></a>字面量和操作符</h4><ol><li>推荐在使用字面量是后面加上类型.</li><li>原生类型本身可以printable</li></ol><p>元组、数组与slices. </p><p>元组,通过()表示,通过.num索引,可以使用#[derive(Debug)]实现方法打印.</p><p>数组 [T;length]声明,编译时已知.</p><p>切片(Slices)与数组类似,但它们的长度在编译时是未知的。相反,切片是一个由两个字(word)组成的对象:第一个字是指向数据的指针,第二个字是切片的长度。字的大小与 <code>usize</code> 类型相同,由处理器架构决定,例如在 x86-64 上为 64 位。切片可用于借用数组的一部分,它的类型签名为 <code>&amp;[T]</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This function borrows a slice.</span></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">analyze_slice</span></span>(slice: &amp;[<span class="built_in">i32</span>]) &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;First element of the slice: &#123;&#125;&quot;</span>, slice[<span class="number">0</span>]);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;The slice has &#123;&#125; elements&quot;</span>, slice.len());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> xs: [<span class="built_in">i32</span>; <span class="number">5</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line"><span class="comment">// All elements can be initialized to the same value.</span></span><br><span class="line"><span class="keyword">let</span> ys: [<span class="built_in">i32</span>; <span class="number">500</span>] = [<span class="number">0</span>; <span class="number">500</span>];</span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;Borrow the whole array as a slice.&quot;</span>);</span><br><span class="line">analyze_slice(&amp;xs);</span><br></pre></td></tr></table></figure><h3 id="自定义类型"><a href="#自定义类型" class="headerlink" title="自定义类型"></a>自定义类型</h3><h4 id="structures"><a href="#structures" class="headerlink" title="structures"></a>structures</h4><p>使用 <code>struct</code> 关键字可以创建三种类型的结构体(struct):</p><ol><li>元组结构体(Tuple structs)，基本上是命名元组。</li><li>经典的 C 风格结构体。</li><li>无字段的单元结构体(Unit structs)，在泛型编程中很有用。</li></ol><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Person</span></span> &#123;</span><br><span class="line">    name: <span class="built_in">String</span>,</span><br><span class="line">    age: <span class="built_in">u8</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// A unit struct</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Unit</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A tuple struct</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Pair</span></span>(<span class="built_in">i32</span>, <span class="built_in">f32</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// A struct with two fields</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Point</span></span> &#123;</span><br><span class="line">    x: <span class="built_in">f32</span>,</span><br><span class="line">    y: <span class="built_in">f32</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// A tuple struct</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Pair</span></span>(<span class="built_in">i32</span>, <span class="built_in">f32</span>);</span><br><span class="line"><span class="comment">// Instantiate a tuple struct</span></span><br><span class="line"><span class="keyword">let</span> pair = Pair(<span class="number">1</span>, <span class="number">0.1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Access the fields of a tuple struct</span></span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;pair contains &#123;:?&#125; and &#123;:?&#125;&quot;</span>, pair.<span class="number">0</span>, pair.<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Destructure a tuple struct</span></span><br><span class="line"><span class="keyword">let</span> Pair(integer, decimal) = pair;</span><br></pre></td></tr></table></figure><h4 id="Enums"><a href="#Enums" class="headerlink" title="Enums"></a>Enums</h4><p><code>enum</code>关键字允许创建一个可以是几种不同变体(variant)之一的类型。任何在结构体(struct)中有效的变体,在枚举(enum)中也是有效的。</p><h4 id="constants"><a href="#constants" class="headerlink" title="constants"></a>constants</h4><p>Rust 有两种不同类型的常量,可以在任何作用域(包括全局)中声明。两种常量都需要显式的类型注解:</p><ol><li><code>const</code>: 不可变的值(最常见的情况)。</li><li><code>static</code>: 可能是可变的变量,拥有 <code>&#39;static</code> 生命周期。<code>&#39;static</code> 生命周期是被推断出来的,不需要显式指定。访问或修改可变的 <code>static</code> 变量是不安全的</li></ol><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>作为偏底层的编程语言,c/c++,rust,zig等目前都还在发展,即使c++已过五十年,但C++2a中Concepts,Modules,Coroutines等新特性都不断出现,所以还是地位仍在的.而后两者在前端工具构建上均大显身手,期待后续发展.</p><p>我也很喜欢使用C/C++,Go,Rust等写一些小程序demo.</p><h3 id="FYI"><a href="#FYI" class="headerlink" title="FYI"></a>FYI</h3><p>一些语言高级特性</p><ol><li><a href="https://draveness.me/metaprogramming/">谈元编程与表达能力 - 面向信仰编程 (draveness.me)</a></li><li><a href="https://mirrors.tuna.tsinghua.edu.cn/tuna/tunight/2020-04-25-generics-and-metaprogramming/slides.pdf">从泛型 (Generics) 到元编程 (Metaprogramming) (tsinghua.edu.cn)</a></li></ol><p><img data-src="https://s2.loli.net/2024/06/29/5tfZJquDxgvKros.png" alt="image-20240629202803323"></p><p><img data-src="https://s2.loli.net/2024/06/29/gZaJPSIc5sdzM91.png" alt="image-20240629202943879"></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Rust官方推荐的三个资料,分别是The Rust programming language,Rust by examples以及ruslings,已经相当充足了.包括相对全面的书,代码例子以及方便的互动式exercises.个人觉得,the book相当于字典,虽然其实还有内容更多的reference,而examples更加易懂上手,rustlings相当于刷题,把关键东西了解一遍.&lt;/p&gt;
&lt;p&gt;所以从这三个东西入手开始Rust学习之旅,一些地方会跟c++对比.&lt;br&gt;</summary>
    
    
    
    
    <category term="Rust" scheme="https://www.sekyoro.top/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>不同编程语言之间的互操作</title>
    <link href="https://www.sekyoro.top/2024/06/25/%E4%B8%8D%E5%90%8C%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BA%92%E6%93%8D%E4%BD%9C/"/>
    <id>https://www.sekyoro.top/2024/06/25/%E4%B8%8D%E5%90%8C%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BA%92%E6%93%8D%E4%BD%9C/</id>
    <published>2024-06-25T02:55:48.000Z</published>
    <updated>2024-06-26T14:30:06.066Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>当项目比较大涉及到多门编程语言时会有这种需求.通常是要求调用C/C++等.<br>某些语言之间相对来说调用就比较简单,比如Go和C,Rust和C等.但是其他语言相对来说就麻烦了.本文主要涉及Python,JS,Java和C/C+的互相调用,以备不时之需.</p><p>TL;DR:Python使用pybind11,JS使用emcc,Java使用JNI.<br><span id="more"></span></p><h2 id="Python和C或Cpp"><a href="#Python和C或Cpp" class="headerlink" title="Python和C或Cpp"></a>Python和C或Cpp</h2><h3 id="Python调用C-Cpp"><a href="#Python调用C-Cpp" class="headerlink" title="Python调用C/Cpp"></a>Python调用C/Cpp</h3><h4 id="Ctypes"><a href="#Ctypes" class="headerlink" title="Ctypes"></a>Ctypes</h4><p>ctypes 是Python的外部函数库。它提供了与 C语言兼容的数据类型，并允许调用 DLL 或共享库中的函数。可使用该模块以纯 Python 形式对这些库进行封装</p><p>写一个c文件</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// func.c</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">func</span><span class="params">(<span class="keyword">int</span> a)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> a*a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译成动态库</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc func.c -fPIC -shared -std=c99 -o func.so</span><br></pre></td></tr></table></figure><blockquote><p>-fPIC 作用于编译阶段，告诉编译器产生<strong>与位置无关代码</strong>(Position-Independent Code)，则产生的代码中，没有绝对地址，全部使用相对地址，故而代码可以被加载器加载到内存的任意位置，都可以正确的执行。这正是共享库所要求的，共享库被加载时，在内存的位置不是固定的。</p></blockquote><p>得到动态库后就能直接调用了,注意在windows上(其实指的是使用MSVC生成dll)需要使用<code>ctypes.WinDLL</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> cdll</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    f = cdll.LoadLibrary(<span class="string">&quot;./func.so&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(f.func(<span class="number">99</span>))</span><br></pre></td></tr></table></figure><p>这种方法缺点是是能调用一些已有的动态库,且不涉及复杂数据结构,只能是c语言.</p><h4 id="C-C-扩展Python"><a href="#C-C-扩展Python" class="headerlink" title="C/C++扩展Python"></a>C/C++扩展Python</h4><p>使用<code>Python.h</code>头文件</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;Python.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> PY_MAJOR_VERSION &gt;= 3</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PyInt_Check PyLong_Check</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PyInt_AsLong PyLong_AsLong</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> PyObject* <span class="title">list_sum</span><span class="params">(PyObject *self, PyObject *args)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PyObject *pList;</span><br><span class="line">    PyObject *pItem;</span><br><span class="line">    Py_ssize_t n = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(!PyArg_ParseTuple(args, <span class="string">&quot;O!&quot;</span>, &amp;PyList_Type, &amp;pList))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    n = PyList_Size(pList);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) &#123;</span><br><span class="line">        pItem = PyList_GetItem(pList, i);</span><br><span class="line">        <span class="keyword">if</span>(!PyInt_Check(pItem)) &#123;</span><br><span class="line">            PyErr_SetString(PyExc_TypeError, <span class="string">&quot;list items must be integers.&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        result += PyInt_AsLong(pItem);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Py_BuildValue(<span class="string">&quot;i&quot;</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> PyMethodDef methods[] = &#123;</span><br><span class="line">   &#123; <span class="string">&quot;sum&quot;</span>, (PyCFunction)list_sum, METH_VARARGS, <span class="string">&quot;sum method&quot;</span> &#125;,</span><br><span class="line">   &#123; <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span> &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">python_api_sum_module</span> =</span> &#123;</span><br><span class="line">    PyModuleDef_HEAD_INIT,</span><br><span class="line">    <span class="string">&quot;python_api_sum&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Python interface for the array sum&quot;</span>,</span><br><span class="line">    <span class="number">-1</span>,</span><br><span class="line">    methods</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">PyInit_python_api_sum</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">return</span> PyModule_Create(&amp;python_api_sum_module);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="https://docs.python.org/zh-cn/3/extending/extending.html">1. 使用 C 或 C++ 扩展 Python — Python 3.12.4 文档</a></p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -Wall -shared  -std=c99 -fPIC <span class="constructor">$(<span class="params">python3</span>-<span class="params">config</span> --<span class="params">includes</span>)</span> <span class="constructor">$(<span class="params">python3</span>-<span class="params">config</span> --<span class="params">ldflags</span>)</span> test.c -o test<span class="constructor">$(<span class="params">python3</span>-<span class="params">config</span> --<span class="params">extension</span>-<span class="params">suffix</span>)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在windows上推荐使用msys2工具下载Mingw工具链,</p><h4 id="pybind11"><a href="#pybind11" class="headerlink" title="pybind11"></a>pybind11</h4><p>这是最简单的方式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pybind11</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PYBIND11_MODULE(example, m) &#123;</span><br><span class="line">    m.doc() = <span class="string">&quot;pybind11 example plugin&quot;</span>; <span class="comment">// optional module docstring</span></span><br><span class="line"></span><br><span class="line">    m.def(<span class="string">&quot;add&quot;</span>, &amp;add, <span class="string">&quot;A function that adds two numbers&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面两种方式注意gcc与python版本问题,两者都需要通过gcc/g++访问其下的python的include和lib目录. 我在windows上Mingw的python版本太低,比如<code>--extension-suffix</code>总是报错,我建议直接在Linux上写.</p><h3 id="C-Cpp调用Python"><a href="#C-Cpp调用Python" class="headerlink" title="C/Cpp调用Python"></a>C/Cpp调用Python</h3><h4 id="C-C-扩展Python-1"><a href="#C-C-扩展Python-1" class="headerlink" title="C/C++扩展Python"></a>C/C++扩展Python</h4><p>类似上面的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;Python.h&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">int</span> main(<span class="built_in">int</span> argc, char *argv[]) &#123;</span><br><span class="line">  // 初始化python解释器.C/C++中调用Python之前必须先初始化解释器</span><br><span class="line">  Py_Initialize();</span><br><span class="line">  // 执行一个简单的执行python脚本命令</span><br><span class="line">  PyRun_SimpleString(<span class="string">&quot;print(&#x27;hello world&#x27;)\n&quot;</span>);</span><br><span class="line">  PyRun_SimpleString(<span class="string">&quot;import sys&quot;</span>);</span><br><span class="line">  PyRun_SimpleString(<span class="string">&quot;sys.path.append(&#x27;.&#x27;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">  PyObject* pModule = PyImport_ImportModule(<span class="string">&quot;sum&quot;</span>);</span><br><span class="line">  <span class="keyword">if</span>( pModule == NULL )&#123;</span><br><span class="line">        cout &lt;&lt;<span class="string">&quot;module not found&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">    // <span class="number">4</span>、调用函数</span><br><span class="line">    PyObject* pFunc = PyObject_GetAttrString(pModule, <span class="string">&quot;say&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span>( !pFunc || !PyCallable_Check(pFunc))&#123;</span><br><span class="line">        cout &lt;&lt;<span class="string">&quot;not found function add_num&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    // </span><br><span class="line">    PyObject_CallObject(pFunc, NULL);</span><br><span class="line">  // 撤销Py_Initialize()和随后使用Python/C API函数进行的所有初始化</span><br><span class="line">  Py_Finalize();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Pybind"><a href="#Pybind" class="headerlink" title="Pybind"></a>Pybind</h4><p>同上</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/stl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/embed.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> py = pybind11;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">  py::scoped_interpreter guard&#123;&#125;; </span><br><span class="line">  py::object sum = py::module_::<span class="built_in"><span class="keyword">import</span></span>(<span class="string">&quot;sum&quot;</span>);</span><br><span class="line">  py::object py_list_sum = sum.<span class="built_in">attr</span>(<span class="string">&quot;py_list_sum&quot;</span>);</span><br><span class="line">  <span class="keyword">int</span> result = <span class="built_in">py_list_sum</span>(std::vector&lt;<span class="keyword">int</span>&gt;&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;).cast&lt;<span class="keyword">int</span>&gt;();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;py_list_sum([1,2,3,4,5]) result:&quot;</span> &lt;&lt; result &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>事实上还有更多方式,不过上面的已经足够了,详细的可以看看其他教程.</p><p><a href="https://www.hbblog.cn/python%26C%2B%2B/python和C的交互/#32-pybind11python">一文总结Python和C/C++的交互方式 - 海滨的Blog (hbblog.cn)</a></p><p><a href="https://python3-cookbook-personal.readthedocs.io/zh-cn/latest/chapters/p15_c_extensions.html">第十五章：C语言扩展 — python3-cookbook 2.0.0 文档 (python3-cookbook-personal.readthedocs.io)</a></p><p>这里推荐pybind的方法,相对功能更强,使用也不复杂.</p><h2 id="JavaScript和C或Cpp"><a href="#JavaScript和C或Cpp" class="headerlink" title="JavaScript和C或Cpp"></a>JavaScript和C或Cpp</h2><h3 id="Js调用C-Cpp"><a href="#Js调用C-Cpp" class="headerlink" title="Js调用C/Cpp"></a>Js调用C/Cpp</h3><h4 id="WebAssembly"><a href="#WebAssembly" class="headerlink" title="WebAssembly"></a>WebAssembly</h4><p>对于浏览器端,这应该是最通用的方式了.使用Emscripten,将源代码转为assembly格式通过浏览器调用.但是需要浏览器支持. </p><p><a href="https://developer.mozilla.org/en-US/docs/WebAssembly/C_to_Wasm">Compiling a New C/C++ Module to WebAssembly - WebAssembly | MDN (mozilla.org)</a></p><p>按照官网方式下载安装,</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Hello World\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">emcc hello.c -s WASM=1 -o hello.html</span><br></pre></td></tr></table></figure><ul><li><code>-s WASM=1</code> — 指定我们想要的 wasm 输出形式。最新版emcc默认为1,0表示输出asm.js</li><li><code>-o hello.html</code> — 指定这个选项将会生成 HTML 页面来运行我们的代码，并且会生成 wasm 模块，以及编译和实例化 wasm 模块所需要的“胶水”js 代码，这样我们就可以直接在 web 环境中使用了。</li></ul><p>这个时候在你的源码文件夹应该有下列文件：</p><ul><li><code>hello.wasm</code> 二进制的 wasm 模块代码</li><li><code>hello.js</code> 一个包含了用来在原生 C 函数和 JavaScript/wasm 之间转换的胶水代码的 JavaScript 文件</li><li><code>hello.html</code> 一个用来加载，编译，实例化你的 wasm 代码并且将它输出在浏览器显示上的一个 HTML 文件</li></ul><p>使用一个支持 WebAssembly 的浏览器，加载生成的 <code>hello.html</code>。自从 Firefox 版本 52、Chrome 版本 57 和 Opera 版本 44 开始，已经默认启用了 WebAssembly(注意不是通过文件方式打开)</p><p>上面是在html加载后会调用main函数中的代码</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;emscripten/emscripten.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello World\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> EMSCRIPTEN_KEEPALIVE <span class="title">myFunction</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;我的函数已被调用\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">emcc -o hello3.html hello3.c -O3 -s WASM=1 -s <span class="string">&quot;EXPORTED_RUNTIME_METHODS=[&#x27;ccall&#x27;]&quot;</span> --shell-file html_template/shell_minimal.html</span><br></pre></td></tr></table></figure><p>如果要导入函数,通过设置EXPORTED_RUNTIME_METHODS导出ccall,而ccall会在 JS 代码之中调用 C 函数</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//&lt;button class=&quot;mybutton&quot;&gt;运行我的函数&lt;/button&gt; //html</span></span><br><span class="line"><span class="built_in">document</span>.querySelector(<span class="string">&quot;.mybutton&quot;</span>).addEventListener(<span class="string">&quot;click&quot;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">  alert(<span class="string">&quot;检查控制台&quot;</span>);</span><br><span class="line">  <span class="keyword">var</span> result = Module.ccall(</span><br><span class="line">    <span class="string">&quot;myFunction&quot;</span>, <span class="comment">// name of C function</span></span><br><span class="line">    <span class="literal">null</span>, <span class="comment">// return type</span></span><br><span class="line">    <span class="literal">null</span>, <span class="comment">// argument types</span></span><br><span class="line">    <span class="literal">null</span>,</span><br><span class="line">  ); <span class="comment">// arguments</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><a href="https://ruanyifeng.com/blog/2017/09/asmjs_emscripten.html">asm.js 和 Emscripten 入门教程 - 阮一峰的网络日志 (ruanyifeng.com)</a></p><p>emcc既支持asm.js也支持WASM,两者都能实现类似的效果,不过目前还是WASM风头正劲</p><h4 id="c-addons"><a href="#c-addons" class="headerlink" title="c++ addons"></a>c++ addons</h4><p><a href="https://nodejs.org/docs/v20.15.0/api/addons.html#c-addons">C++ addons | Node.js v20.15.0 Documentation (nodejs.org)</a></p><p>使用<code>node.h</code>头文件并下载node-gyp编译得到动态库,再通过node调用.</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hello.cc</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;node.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> demo &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> v8::FunctionCallbackInfo;</span><br><span class="line"><span class="keyword">using</span> v8::Isolate;</span><br><span class="line"><span class="keyword">using</span> v8::Local;</span><br><span class="line"><span class="keyword">using</span> v8::Object;</span><br><span class="line"><span class="keyword">using</span> v8::<span class="keyword">String</span>;</span><br><span class="line"><span class="keyword">using</span> v8::Value;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Method</span><span class="params">(<span class="keyword">const</span> FunctionCallbackInfo&lt;Value&gt;&amp; args)</span> </span>&#123;</span><br><span class="line">  Isolate* isolate = args.<span class="built_in">GetIsolate</span>();</span><br><span class="line">  args.<span class="built_in">GetReturnValue</span>().<span class="built_in">Set</span>(<span class="keyword">String</span>::<span class="built_in">NewFromUtf8</span>(</span><br><span class="line">      isolate, <span class="string">&quot;world&quot;</span>).<span class="built_in">ToLocalChecked</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Initialize</span><span class="params">(Local&lt;Object&gt; exports)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">NODE_SET_METHOD</span>(exports, <span class="string">&quot;hello&quot;</span>, Method);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">NODE_MODULE</span>(NODE_GYP_MODULE_NAME, Initialize)</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace demo</span></span><br></pre></td></tr></table></figure><p>这个也要注意使用的编译器,我在windows上默认使用visual studio,需要后缀.cpp.</p><p>创建binding.gyp,然后使用node-gyp</p><figure class="highlight gyp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&#x27;targets&#x27;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&#x27;target_name&#x27;</span>: <span class="string">&#x27;hello&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;sources&#x27;</span>: [ </span><br><span class="line">                <span class="string">&#x27;src/hello.cc&#x27;</span>,</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node-gyp configure</span><br><span class="line">node-gyp build</span><br></pre></td></tr></table></figure><p>编译后得到.node文件使用js调用即可</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">require</span>(<span class="string">&#x27;./build/Release/addon.node&#x27;</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">require</span>(<span class="string">&#x27;./build/Debug/addon.node&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Native-abstractions-for-Node-js"><a href="#Native-abstractions-for-Node-js" class="headerlink" title="Native abstractions for Node.js"></a>Native abstractions for Node.js</h4><p>Node-API 是用于构建native addons的 API。它<strong>独立于底层 JavaScript 运行时</strong>（如 V8），并作为 Node.js 自身的一部分进行维护。该 API 在不同版本的 Node.js 中具有稳定的应用二进制接口 (ABI)<strong>。其目的是使附加组件不受底层 JavaScript 引擎变化的影响</strong>，并允许为某一版本编译的模块无需重新编译即可在以后版本的 Node.js 上运行。addons使用node-gyp 等构建/打包。</p><p><a href="https://nodejs.org/docs/v20.15.0/api/addons.html#native-abstractions-for-nodejs">C++ addons | Node.js v20.15.0 Documentation (nodejs.org)</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hello.cc using Node-API</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;node_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> demo &#123;</span><br><span class="line"></span><br><span class="line"><span class="function">napi_value <span class="title">Method</span><span class="params">(napi_env env, napi_callback_info args)</span> </span>&#123;</span><br><span class="line">  napi_value greeting;</span><br><span class="line">  napi_status status;</span><br><span class="line"></span><br><span class="line">  status = <span class="built_in">napi_create_string_utf8</span>(env, <span class="string">&quot;world&quot;</span>, NAPI_AUTO_LENGTH, &amp;greeting);</span><br><span class="line">  <span class="keyword">if</span> (status != napi_ok) <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="keyword">return</span> greeting;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">napi_value <span class="title">init</span><span class="params">(napi_env env, napi_value exports)</span> </span>&#123;</span><br><span class="line">  napi_status status;</span><br><span class="line">  napi_value fn;</span><br><span class="line"></span><br><span class="line">  status = <span class="built_in">napi_create_function</span>(env, <span class="literal">nullptr</span>, <span class="number">0</span>, Method, <span class="literal">nullptr</span>, &amp;fn);</span><br><span class="line">  <span class="keyword">if</span> (status != napi_ok) <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  status = <span class="built_in">napi_set_named_property</span>(env, exports, <span class="string">&quot;hello&quot;</span>, fn);</span><br><span class="line">  <span class="keyword">if</span> (status != napi_ok) <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="keyword">return</span> exports;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">NAPI_MODULE</span>(NODE_GYP_MODULE_NAME, init)</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace demo</span></span><br></pre></td></tr></table></figure><p>好处是兼容性更高,api看起来也更易懂.</p><h3 id="C-Cpp调用Js"><a href="#C-Cpp调用Js" class="headerlink" title="C/Cpp调用Js"></a>C/Cpp调用Js</h3><h4 id="C-addons"><a href="#C-addons" class="headerlink" title="C addons"></a>C addons</h4><p>同上,可以考虑使用回调等方法在c中调用js.</p><p><a href="https://ruanyifeng.com/blog/2017/09/asmjs_emscripten.html">asm.js 和 Emscripten 入门教程 - 阮一峰的网络日志 (ruanyifeng.com)</a></p><p>如果是node那就按照官方文档使用addons(事实上也可以使用Emscripte转为asm.js进行调用),如果是浏览器,那推荐使用WASM,除能转换c/c++之外还有Rust等,在前端也是有前景的技术之一.<a href="https://developer.mozilla.org/zh-CN/docs/WebAssembly/C_to_Wasm#编译_emscripten">Emscripten</a></p><p>通过asm.js调用c++代码,方法类似,目前emcc的WASM默认为1也就是默认生成WASM,但使用时通过下面命令得到asm.js</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">emcc index.cpp -s <span class="string">&quot;EXPORTED_FUNCTIONS=[‘_main’,&#x27;_myFunction&#x27;]&quot;</span> -s WASM=0 -s EXPORTED_RUNTIME_METHODS=<span class="string">&quot;[&#x27;ccall&#x27;]&quot;</span> -o index.js</span><br></pre></td></tr></table></figure><p>在js文件中调用</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="built_in">module</span> = <span class="built_in">require</span>(<span class="string">&quot;./output.js&quot;</span>)</span><br><span class="line"><span class="keyword">let</span> resulst = <span class="built_in">module</span>.onRuntimeInitialized(<span class="function">()=&gt;</span>&#123;</span><br><span class="line"><span class="built_in">module</span>.ccall(<span class="string">&#x27;myFunction&#x27;</span>,&#123;</span><br><span class="line"><span class="literal">null</span>, <span class="comment">// return type</span></span><br><span class="line"><span class="literal">null</span>, <span class="comment">// argument type</span></span><br><span class="line"><span class="literal">null</span>, <span class="comment">// arguments</span></span><br><span class="line">&#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><blockquote><p>asm.js 的技术能将 C / C++ 转成 JS 引擎可以运行的代码。那么它与 WASM有何区别呢？</p><p>回答是，两者的功能基本一致，就是转出来的代码不一样<strong>：asm.js 是文本，WebAssembly 是二进制字节码</strong>，因此运行速度更快、体积更小。从长远来看，WebAssembly 的前景更光明。</p><p>但是，这并不意味着 asm.js 肯定会被淘汰，因为它有两个优点：首先，它是文本，人类可读，比较直观；其次，所有浏览器都支持 asm.js，不会有兼容性问题。</p></blockquote><h2 id="Java和C或Cpp"><a href="#Java和C或Cpp" class="headerlink" title="Java和C或Cpp"></a>Java和C或Cpp</h2><p>Java调用C/Cpp有多种方式,这里只介绍一种.</p><p>JNI,通过native声明</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">package org.example;</span><br><span class="line"><span class="comment">//TIP To &lt;b&gt;Run&lt;/b&gt; code, press &lt;shortcut actionId=&quot;Run&quot;/&gt; or</span></span><br><span class="line"><span class="comment">// click the &lt;icon src=&quot;AllIcons.Actions.Execute&quot;/&gt; icon in the gutter.</span></span><br><span class="line">public <span class="keyword">class</span> Main &#123;</span><br><span class="line">    public native void say<span class="constructor">Hello()</span>;</span><br><span class="line"></span><br><span class="line">    static &#123;</span><br><span class="line"><span class="comment">//        System.load(&quot;./sayHello.dll&quot;);</span></span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">System</span>.</span></span>load<span class="constructor">Library(<span class="string">&quot;sayHello&quot;</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String<span class="literal">[]</span> args) &#123;</span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">System</span>.</span></span>out.println(<span class="string">&quot;Hi&quot;</span>);</span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">System</span>.</span></span>out.println(<span class="module-access"><span class="module"><span class="identifier">System</span>.</span></span>get<span class="constructor">Property(<span class="string">&quot;java.library.path&quot;</span>)</span>);</span><br><span class="line">        Main m = <span class="keyword">new</span> <span class="constructor">Main()</span>;</span><br><span class="line">        m.say<span class="constructor">Hello()</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>javac -h ./ Main.java</code>转为头文件,内容如下</p><figure class="highlight h"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* DO NOT EDIT THIS FILE - it is machine generated */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></span><br><span class="line"><span class="comment">/* Header for class org_example_Main */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _Included_org_example_Main</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _Included_org_example_Main</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Class:     org_example_Main</span></span><br><span class="line"><span class="comment"> * Method:    sayHello</span></span><br><span class="line"><span class="comment"> * Signature: ()V</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">JNIEXPORT <span class="keyword">void</span> JNICALL <span class="title">Java_org_example_Main_sayHello</span></span></span><br><span class="line"><span class="function">  <span class="params">(JNIEnv *, jobject)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后写一个cpp去实现方法</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;org_example_Main.h&quot;</span></span></span><br><span class="line"><span class="function">JNIEXPORT <span class="keyword">void</span> JNICALL <span class="title">Java_org_example_Main_sayHello</span><span class="params">(JNIEnv *, jobject)</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Hello im from cpp&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后生成dll文件,注意头文件要有jdk中的头文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -Wall -shared -fPIC -IC:/Users/proanimer/.jdks/openjdk-22.0.1/include -IC:/Users/proanimer/.jdks/openjdk-22.0.1/include/win32 sayHello.cpp -o sayHello.dll</span><br></pre></td></tr></table></figure><p>得到的dll文件就能被<code>`System.loadLibrary</code>加载了,但注意dll文件放的位置,会去环境变量中的PATH去找,如果直接放在同一目录下没有额外设置是没有导入的.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example;</span><br><span class="line"><span class="comment">//TIP To &lt;b&gt;Run&lt;/b&gt; code, press &lt;shortcut actionId=&quot;Run&quot;/&gt; or</span></span><br><span class="line"><span class="comment">// click the &lt;icon src=&quot;AllIcons.Actions.Execute&quot;/&gt; icon in the gutter.</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">sayHello</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.loadLibrary(<span class="string">&quot;sayHello&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Hi&quot;</span>);</span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;java.library.path&quot;</span>));</span><br><span class="line">        Main m = <span class="keyword">new</span> Main();</span><br><span class="line">        m.sayHello();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以通过class打包为jarr包,然后直接调用jar包(jar包需要调用dll)即可.</p><ol><li><code>java -jar &lt;jarfile&gt;</code>: 运行指定的 Java 归档文件(JAR 文件)。</li><li><code>java -cp &lt;classpath&gt; &lt;main-class&gt;</code>: 指定类路径并运行指定的主类。</li><li><code>java -D&lt;property&gt;=&lt;value&gt;</code>: 设置 Java 系统属性。</li><li><code>java -verbose</code>: 开启详细输出模式。</li><li><code>java -version</code>: 显示 Java 版本信息。</li><li><code>java -help</code>: 显示 Java 命令行帮助。</li></ol><p>其他方法可以看看<a href="https://blog.csdn.net/giveaname/article/details/106615257">JNA —— Java调用C/C++动态库_jna调用c++类-CSDN博客</a></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://blog.csdn.net/weixin_43552133/article/details/128377535">gcc生成静态库与动态库（附带使用方法）_gcc 生成静态库-CSDN博客</a></li><li><a href="https://www.runoob.com/w3cnote/cpp-static-library-and-dynamic-library.html">C++静态库与动态库 | 菜鸟教程 (runoob.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;当项目比较大涉及到多门编程语言时会有这种需求.通常是要求调用C/C++等.&lt;br&gt;某些语言之间相对来说调用就比较简单,比如Go和C,Rust和C等.但是其他语言相对来说就麻烦了.本文主要涉及Python,JS,Java和C/C+的互相调用,以备不时之需.&lt;/p&gt;
&lt;p&gt;TL;DR:Python使用pybind11,JS使用emcc,Java使用JNI.&lt;br&gt;</summary>
    
    
    
    
    <category term="programming" scheme="https://www.sekyoro.top/tags/programming/"/>
    
  </entry>
  
  <entry>
    <title>函数式编程介绍与入门</title>
    <link href="https://www.sekyoro.top/2024/06/23/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%85%A5%E9%97%A8/"/>
    <id>https://www.sekyoro.top/2024/06/23/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%85%A5%E9%97%A8/</id>
    <published>2024-06-23T12:21:01.000Z</published>
    <updated>2024-06-28T04:08:28.489Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>之前在看其他人交流帖子的时候提到学习函数式编程提升思维(虽然感觉有点大肆宣传的感觉),但看了一些函数式编程的例子,感觉在数据处理和多线程上有独特的效果,如果使用面向对象,那就会变得比较麻烦,所以这里仅作简单介绍.<br><span id="more"></span><br>个人认为,函式编程是一种思想,而不是具体某种工具. C++可以进行函数式编程,Java也可以,只不过看支持程度而已.<strong>现代的编程语言已经把函数式编程的思想融入进去了</strong> .</p><p>什么是函数式编程呢？在网上你可以看到很多定义，但大都离不开这些特性。</p><ul><li><strong>First Class</strong> 函数：函数可以被应用，也可以被当作数据。</li><li><strong>Pure</strong> 纯函数，无副作用：任意时刻以相同参数调用函数任意次数得到的结果都一样。</li><li><strong>Referential Transparency</strong> 引用透明：可以被表达式替代。</li><li><strong>Expression</strong> 基于表达式：表达式可以被计算，促进数据流动，状态声明就像是一个暂停，好像数据到这里就会停滞了一下。</li><li><strong>Immutable</strong> 不可变性：参数不可被修改、变量不可被修改—宁可牺牲性能，也要产生新的数据（Rust内存模型例外）。</li><li><strong>High Order Function</strong> 大量使用高阶函数：变量存储、闭包应用、函数高度可组合。</li><li><strong>Curry</strong> 柯里化：对函数进行降维，方便进行组合。</li><li><strong>Composition</strong> 函数组合：将多个单函数进行组合，像流水线一样工作。</li></ul><p>另外还有一些特性，有的会提到，有的一笔带过，但实际也是一个特性（以Haskell为例）。</p><ul><li><strong>Type Inference</strong> 类型推导：如果无法确定数据的类型，那函数怎么去组合？（常见，但非必需）</li><li><strong>Lazy Evaluation</strong> 惰性求值：函数天然就是一个执行环境，惰性求值是很自然的选择。</li><li><strong>Side Effect</strong> IO：一种类型，用于处理副作用。一个不能执行打印文字、修改文件等操作的程序，是没有意义的，总要有位置处理副作用。（边缘）</li></ul><blockquote><p>函数式编程语言的一些核心特点,如不可变数据、高阶函数、惰性求值等。它们为现代软件开发带来了新的编程模式和思维方式。<br>本质上，函数式编程只是范畴论的运算方法，跟数理逻辑、微积分、行列式是同一类东西，都是数学方法，只是碰巧它能用来写程序。</p></blockquote><ul><li><p>数据是不可变(immutable)的： 如果要更改数据（如数组），需要返回一个包含更改内容的新数组，而不是原来的数组。</p></li><li><p>函数是无状态的： 函数每次都像第一次一样运行！换句话说，对于相同的参数，函数总是给出相同的返回值。</p></li></ul><p>一般来说，您应该遵循三个最佳实践：</p><ol><li><strong>函数应至少接受一个参数。</strong></li><li><p><strong>函数应返回数据或另一个函数。</strong></p></li><li><p><strong>不要使用循环</strong></p></li></ol><h3 id="函数一等公民"><a href="#函数一等公民" class="headerlink" title="函数一等公民"></a>函数一等公民</h3><ul><li>函数是”头等公民”,可以作为参数传递,返回值,赋值给变量等。</li><li>允许编写高阶函数,增强了代码的灵活性和表达力。</li></ul><blockquote><p>函数没什么特殊的，你可以像对待任何其他数据类型一样对待它们——把它们存在数组里，当作参数传递，赋值给变量…等等。</p></blockquote><p>具体来说,看看别人的例子</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> hi = <span class="function"><span class="params">name</span> =&gt;</span> <span class="string">`Hi <span class="subst">$&#123;name&#125;</span>`</span>;</span><br><span class="line"><span class="keyword">const</span> greeting = <span class="function"><span class="params">name</span> =&gt;</span> hi(name); <span class="comment">// 没有必要的操作</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> greeting = hi; <span class="comment">// 相同的作用</span></span><br><span class="line">greeting(<span class="string">&quot;times&quot;</span>); <span class="comment">// &quot;Hi times&quot;</span></span><br></pre></td></tr></table></figure><p>再来一个例子</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这行</span></span><br><span class="line">ajaxCall(<span class="function"><span class="params">json</span> =&gt;</span> callback(json));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等价于这行</span></span><br><span class="line">ajaxCall(callback);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 那么，重构下 getServerStuff</span></span><br><span class="line"><span class="keyword">const</span> getServerStuff = <span class="function"><span class="params">callback</span> =&gt;</span> ajaxCall(callback);</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...就等于</span></span><br><span class="line"><span class="keyword">const</span> getServerStuff = ajaxCall <span class="comment">// &lt;-- 看，没有括号哦</span></span><br></pre></td></tr></table></figure><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> BlogController = &#123;</span><br><span class="line">  <span class="built_in">index</span>(posts) &#123; <span class="keyword">return</span> Views.<span class="built_in">index</span>(posts); &#125;,</span><br><span class="line">  show(<span class="keyword">post</span>) &#123; <span class="keyword">return</span> Views.show(<span class="keyword">post</span>); &#125;,</span><br><span class="line">  create(attrs) &#123; <span class="keyword">return</span> <span class="keyword">Db</span>.create(attrs); &#125;,</span><br><span class="line">  <span class="keyword">update</span>(<span class="keyword">post</span>, attrs) &#123; <span class="keyword">return</span> <span class="keyword">Db</span>.<span class="keyword">update</span>(<span class="keyword">post</span>, attrs); &#125;,</span><br><span class="line">  destroy(<span class="keyword">post</span>) &#123; <span class="keyword">return</span> <span class="keyword">Db</span>.destroy(<span class="keyword">post</span>); &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> BlogController = &#123;</span><br><span class="line">  index: Views.index,</span><br><span class="line">  show: Views.show,</span><br><span class="line">  create: <span class="keyword">Db</span>.create,</span><br><span class="line">  <span class="keyword">update</span>: <span class="keyword">Db</span>.<span class="keyword">update</span>,</span><br><span class="line">  destroy: <span class="keyword">Db</span>.destroy,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这样修改有什么意义?=&gt;除了节省代码,减少冗余之外,外面的函数修改后,里面的函数可以不用改了.这也增加了可重用性,说到可重用性,还有一点就是在不涉及到具体业务的函数上命名应该更加通用.</p><p>另外涉及到类似js中的this值时最好使用bind,apply等绑定避免出错.</p><h3 id="纯函数"><a href="#纯函数" class="headerlink" title="纯函数"></a>纯函数</h3><p>纯函数(Pure Function)是函数式编程中的一个核心概念。它有以下几个特点:</p><ol><li><strong>无副作用(No Side Effects)</strong>:<ul><li><strong>纯函数不会修改函数外部的任何状态</strong>,如全局变量、I/O操作等。</li><li><strong>只依赖于输入参数</strong>,不会产生意外的输出。</li></ul></li><li><strong>确定性(Deterministic)</strong>:<ul><li>对于相同的输入,纯函数总是返回相同的输出。</li><li>没有”隐藏的”依赖或状态会影响函数的结果。</li></ul></li><li><strong>可测试性(Testable)</strong>:<ul><li>纯函数易于单元测试,因为不需要考虑外部环境的影响。</li><li>可以独立地测试每个函数,不会受到其他函数的干扰。</li></ul></li><li><strong>可组合性(Composable)</strong>:<ul><li>纯函数可以被轻松地组合成更复杂的功能。</li><li>函数的输出可以作为另一个函数的输入,形成管道式的数据处理。</li></ul></li><li><strong>并发性(Concurrency)</strong>:<ul><li>由于没有副作用,纯函数可以安全地在多线程环境中并发执行。</li><li>不需要担心竞争条件和同步问题。</li></ul></li></ol><p>通常我们定义输入输出（IO）是不纯的，因为<strong>IO操作不仅操作了数据，还操作了这个数据范畴外部的世界，比如打印、播放声音、修改变量状态、网络请求等。这些操作并不是说对程序造成了破坏，相反，一个完整的程序一定是需要它们的，不然我们的所有计算都将毫无意义</strong>。</p><p>但纯函数是可预测的，引用透明的，我们希望代码中更多地出现纯函数式的代码，<strong>这样的代码可以被预测，可以被表达式替换，而更多地把IO操作放到一个统一的位置做处理</strong></p><blockquote><p><em>副作用</em>是在计算结果的过程中，系统状态的一种变化，或者与外部世界进行的<em>可观察的交互</em>。</p></blockquote><p>此外会对输入数据原地改变的函数也是不纯的。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> xs = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 纯的</span></span><br><span class="line">xs.slice(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line"><span class="comment">//=&gt; [1,2,3]</span></span><br><span class="line"></span><br><span class="line">xs.slice(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line"><span class="comment">//=&gt; [1,2,3]</span></span><br><span class="line"></span><br><span class="line">xs.slice(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line"><span class="comment">//=&gt; [1,2,3]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 不纯的</span></span><br><span class="line">xs.splice(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line"><span class="comment">//=&gt; [1,2,3]</span></span><br><span class="line"></span><br><span class="line">xs.splice(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line"><span class="comment">//=&gt; [4,5]</span></span><br><span class="line"></span><br><span class="line">xs.splice(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line"><span class="comment">//=&gt; []</span></span><br></pre></td></tr></table></figure><h4 id="追求“纯”的理由"><a href="#追求“纯”的理由" class="headerlink" title="追求“纯”的理由"></a>追求“纯”的理由</h4><p>from <a href="https://llh911001.gitbooks.io/mostly-adequate-guide-chinese/content/ch3.html">第 3 章: 纯函数的好处 · 函数式编程指北 (gitbooks.io)</a></p><p><strong>可缓存性（Cacheable）</strong></p><p>首先，纯函数总能够根据输入来做缓存。实现缓存的一种典型方式是 memoize 技术：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> squareNumber  = memoize(<span class="function"><span class="keyword">function</span>(<span class="params">x</span>)</span>&#123; <span class="keyword">return</span> x*x; &#125;);</span><br><span class="line"></span><br><span class="line">squareNumber(<span class="number">4</span>);</span><br><span class="line"><span class="comment">//=&gt; 16</span></span><br><span class="line"></span><br><span class="line">squareNumber(<span class="number">4</span>); <span class="comment">// 从缓存中读取输入值为 4 的结果</span></span><br><span class="line"><span class="comment">//=&gt; 16</span></span><br><span class="line"></span><br><span class="line">squareNumber(<span class="number">5</span>);</span><br><span class="line"><span class="comment">//=&gt; 25</span></span><br><span class="line"></span><br><span class="line">squareNumber(<span class="number">5</span>); <span class="comment">// 从缓存中读取输入值为 5 的结果</span></span><br><span class="line"><span class="comment">//=&gt; 25</span></span><br></pre></td></tr></table></figure><p>下面的代码是一个简单的实现，尽管它不太健壮。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> memoize = <span class="function"><span class="keyword">function</span>(<span class="params">f</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> cache = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> arg_str = <span class="built_in">JSON</span>.stringify(<span class="built_in">arguments</span>);</span><br><span class="line">    cache[arg_str] = cache[arg_str] || f.apply(f, <span class="built_in">arguments</span>);</span><br><span class="line">    <span class="keyword">return</span> cache[arg_str];</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>值得注意的一点是，可以通过延迟执行的方式把不纯的函数转换为纯函数：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> pureHttpCall = memoize(<span class="function"><span class="keyword">function</span>(<span class="params">url, params</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123; <span class="keyword">return</span> $.getJSON(url, params); &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>这里有趣的地方在于我们并没有真正发送 http 请求——只是返回了一个函数，当调用它的时候才会发请求。这个函数之所以有资格成为纯函数，是因为它总是会根据相同的输入返回相同的输出：给定了 <code>url</code> 和 <code>params</code> 之后，它就只会返回同一个发送 http 请求的函数。</p><p>我们的 <code>memoize</code> 函数工作起来没有任何问题，虽然它缓存的并不是 http 请求所返回的结果，而是生成的函数。</p><p>现在来看这种方式意义不大，不过很快我们就会学习一些技巧来发掘它的用处。重点是<strong>可以缓存任意一个函数，不管它们看起来多么具有破坏性</strong>。</p><p><strong>可移植性／自文档化（Portable / Self-Documenting）</strong></p><p>纯函数是完全自给自足的，它需要的所有东西都能轻易获得。仔细思考思考这一点…这种自给自足的好处是什么呢？首先，纯函数的依赖很明确，因此更易于观察和理解——没有偷偷摸摸的小动作。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 不纯的</span></span><br><span class="line"><span class="keyword">var</span> signUp = <span class="function"><span class="keyword">function</span>(<span class="params">attrs</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> user = saveUser(attrs);</span><br><span class="line">  welcomeUser(user);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> saveUser = <span class="function"><span class="keyword">function</span>(<span class="params">attrs</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> user = Db.save(attrs);</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> welcomeUser = <span class="function"><span class="keyword">function</span>(<span class="params">user</span>) </span>&#123;</span><br><span class="line">    Email(user, ...);</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 纯的</span></span><br><span class="line"><span class="keyword">var</span> signUp = <span class="function"><span class="keyword">function</span>(<span class="params">Db, Email, attrs</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> user = saveUser(Db, attrs);</span><br><span class="line">    welcomeUser(Email, user);</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> saveUser = <span class="function"><span class="keyword">function</span>(<span class="params">Db, attrs</span>) </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> welcomeUser = <span class="function"><span class="keyword">function</span>(<span class="params">Email, user</span>) </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个例子表明，纯函数对于其依赖必须要诚实，这样我们就能知道它的目的。仅从纯函数版本的 <code>signUp</code> 的签名就可以看出，它将要用到 <code>Db</code>、<code>Email</code> 和 <code>attrs</code>，这在最小程度上给了我们足够多的信息。</p><p>后面我们会学习如何<strong>不通过这种仅仅是延迟执行的方式来让一个函数变纯，不过这里的重点应该很清楚，那就是相比不纯的函数，纯函数能够提供多得多的信息</strong></p><p>其次，通过强迫“注入”依赖，或者把它们当作参数传递，我们的应用也更加灵活；因为数据库或者邮件客户端等等都参数化了（别担心，我们有办法让这种方式不那么单调乏味）。如果要使用另一个 <code>Db</code>，只需把它传给函数就行了。如果想在一个新应用中使用这个可靠的函数，尽管把新的 <code>Db</code> 和 <code>Email</code> 传递过去就好了，非常简单。</p><p>在 JavaScript 的设定中，可移植性可以意味着把函数序列化（serializing）并通过 socket 发送。也可以意味着代码能够在 web workers 中运行。总之，可移植性是一个非常强大的特性。</p><p>命令式编程中“典型”的方法和过程都深深地根植于它们所在的环境中，通过状态、依赖和有效作用（available effects）达成；纯函数与此相反，它与环境无关，只要我们愿意，可以在任何地方运行它。</p><p>你上一次把某个类方法拷贝到新的应用中是什么时候？我最喜欢的名言之一是 Erlang 语言的作者 Joe Armstrong 说的这句话：“面向对象语言的问题是，它们永远都要随身携带那些隐式的环境。你只需要一个香蕉，但却得到一个拿着香蕉的大猩猩…以及整个丛林”。</p><p><strong>可测试性（Testable）</strong></p><p>第三点，纯函数让测试更加容易。我们不需要伪造一个“真实的”支付网关，或者每一次测试之前都要配置、之后都要断言状态（assert the state）。只需简单地给函数一个输入，然后断言输出就好了。</p><p>事实上，我们发现函数式编程的社区正在开创一些新的测试工具，能够帮助我们自动生成输入并断言输出。这超出了本书范围，但是我强烈推荐你去试试 <em>Quickcheck</em>——一个为函数式环境量身定制的测试工具。</p><p><strong>合理性（Reasonable）</strong></p><p>很多人相信使用纯函数最大的好处是<em>引用透明性</em>（referential transparency）。如果一段代码可以替换成它执行所得的结果，而且是在不改变整个程序行为的前提下替换的，那么我们就说这段代码是引用透明的。</p><p>由于纯函数总是能够根据相同的输入返回相同的输出，所以它们就能够保证总是返回同一个结果，这也就保证了引用透明性。我们来看一个例子。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> Immutable = <span class="built_in">require</span>(<span class="string">&#x27;immutable&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> decrementHP = <span class="function"><span class="keyword">function</span>(<span class="params">player</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> player.set(<span class="string">&quot;hp&quot;</span>, player.hp-<span class="number">1</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> isSameTeam = <span class="function"><span class="keyword">function</span>(<span class="params">player1, player2</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> player1.team === player2.team;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> punch = <span class="function"><span class="keyword">function</span>(<span class="params">player, target</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(isSameTeam(player, target)) &#123;</span><br><span class="line">    <span class="keyword">return</span> target;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> decrementHP(target);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> jobe = Immutable.Map(&#123;<span class="attr">name</span>:<span class="string">&quot;Jobe&quot;</span>, <span class="attr">hp</span>:<span class="number">20</span>, <span class="attr">team</span>: <span class="string">&quot;red&quot;</span>&#125;);</span><br><span class="line"><span class="keyword">var</span> michael = Immutable.Map(&#123;<span class="attr">name</span>:<span class="string">&quot;Michael&quot;</span>, <span class="attr">hp</span>:<span class="number">20</span>, <span class="attr">team</span>: <span class="string">&quot;green&quot;</span>&#125;);</span><br><span class="line"></span><br><span class="line">punch(jobe, michael);</span><br><span class="line"><span class="comment">//=&gt; Immutable.Map(&#123;name:&quot;Michael&quot;, hp:19, team: &quot;green&quot;&#125;)</span></span><br></pre></td></tr></table></figure><p><code>decrementHP</code>、<code>isSameTeam</code> 和 <code>punch</code> 都是纯函数，所以是引用透明的。我们可以使用一种叫做“等式推导”（equational reasoning）的技术来分析代码。所谓“等式推导”就是“一对一”替换，有点像在不考虑程序性执行的怪异行为（quirks of programmatic evaluation）的情况下，手动执行相关代码。我们借助引用透明性来剖析一下这段代码。</p><p>首先内联 <code>isSameTeam</code> 函数：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> punch = <span class="function"><span class="keyword">function</span>(<span class="params">player, target</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(player.team === target.team) &#123;</span><br><span class="line">    <span class="keyword">return</span> target;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> decrementHP(target);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>因为是不可变数据，我们可以直接把 <code>team</code> 替换为实际值：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> punch = <span class="function"><span class="keyword">function</span>(<span class="params">player, target</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(<span class="string">&quot;red&quot;</span> === <span class="string">&quot;green&quot;</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> target;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> decrementHP(target);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>if</code> 语句执行结果为 <code>false</code>，所以可以把整个 <code>if</code> 语句都删掉：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> punch = <span class="function"><span class="keyword">function</span>(<span class="params">player, target</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> decrementHP(target);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>如果再内联 <code>decrementHP</code>，我们会发现这种情况下，<code>punch</code> 变成了一个让 <code>hp</code> 的值减 1 的调用：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> punch = <span class="function"><span class="keyword">function</span>(<span class="params">player, target</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> target.set(<span class="string">&quot;hp&quot;</span>, target.hp-<span class="number">1</span>);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>总之，等式推导带来的分析代码的能力对重构和理解代码非常重要。事实上，我们重构海鸥程序使用的正是这项技术：利用加和乘的特性。对这些技术的使用将会贯穿本书，真的。</p><p><strong>并行代码</strong></p><p>因为可以并行运行任意纯函数。因为纯函数根本不需要访问共享的内存，而且根据其定义，纯函数也不会因副作用而进入竞争态（race condition）。</p><p>并行代码在服务端 js 环境以及使用了 web worker 的浏览器那里是非常容易实现的，因为它们使用了线程（thread）。不过出于对非纯函数复杂度的考虑，当前主流观点还是避免使用这种并行。</p><h3 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h3><p>如果一个值要经过多个函数，才能变成另外一个值，就可以把所有中间步骤合并成一个函数，这叫做”函数的合成”（compose）</p><p>将计算过程分解成可复用的函数，典型例子就是<code>map</code>方法和<code>reduce</code>方法组合而成MapReduce算法</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">compose(f, compose(g, h))</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line">compose(compose(f, g), h)</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line">compose(f, g, h)</span><br></pre></td></tr></table></figure><h3 id="柯里化"><a href="#柯里化" class="headerlink" title="柯里化"></a>柯里化</h3><p>在学习JS的时候,你可能已经注意到这个概念了</p><p><code>f(x)</code>和<code>g(x)</code>合成为<code>f(g(x))</code>，有一个隐藏的前提，就是<code>f</code>和<code>g</code>都只能接受一个参数。如果可以接受多个参数，比如<code>f(x, y)</code>和<code>g(a, b, c)</code>，函数合成就非常麻烦。</p><p>这时就需要函数柯里化了。所谓”柯里化”，就是把一个多参数的函数，转化为单参数函数。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 柯里化之前</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">add</span>(<span class="params">x, y</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">add(<span class="number">1</span>, <span class="number">2</span>) <span class="comment">// 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 柯里化之后</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">addX</span>(<span class="params">y</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span> (<span class="params">x</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x + y;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">addX(<span class="number">2</span>)(<span class="number">1</span>) <span class="comment">// 3</span></span><br></pre></td></tr></table></figure><p>有了柯里化以后，我们就能做到，所有函数只接受一个参数。后文的内容除非另有说明，都默认函数只有一个参数，就是所要处理的那个值。</p><p>除了上面提到的之外,还有很多其他特性,就需要自己学习了.</p><h3 id="Functor"><a href="#Functor" class="headerlink" title="Functor"></a>Functor</h3><blockquote><p>Functor可以简单地理解为一个能够保存值,并且能够对这些值执行某些操作的容器。更具体地说,Functor是一个实现了<code>fmap</code>函数的类型类。<code>fmap</code>函数允许我们对Functor中包含的值执行某种变换操作,并将结果包装到新的Functor中返回。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个列表</span></span><br><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用fmap对列表中的元素进行平方变换</span></span><br><span class="line">squared_numbers = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x**<span class="number">2</span>, numbers))</span><br><span class="line"><span class="built_in">print</span>(squared_numbers) <span class="comment"># Output: [1, 4, 9, 16, 25]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"><span class="comment"># Option类型作为Functor</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">safe_divide</span>(<span class="params">a: <span class="built_in">int</span>, b: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">    <span class="keyword">if</span> b == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> a / b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用fmap对Optional类型执行变换</span></span><br><span class="line">result1 = safe_divide(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(result1)  <span class="comment"># Output: 5.0</span></span><br><span class="line"></span><br><span class="line">result2 = safe_divide(<span class="number">10</span>, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(result2)  <span class="comment"># Output: None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用fmap对Maybe类型执行变换</span></span><br><span class="line">doubled_result1 = <span class="keyword">lambda</span> x: x * <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">map</span>(doubled_result1, [result1, result2]))) <span class="comment"># Output: [10.0, None]</span></span><br></pre></td></tr></table></figure><h3 id="Monoid"><a href="#Monoid" class="headerlink" title="Monoid"></a>Monoid</h3><blockquote><p>Monoid是一个具有以下两个特性的代数结构:</p><ol><li>二元操作(称为”合并”操作)</li><li>一个特殊的单位元</li></ol><p>更具体地说,一个类型<code>T</code>是一个Monoid,如果它满足以下两个条件:</p><ol><li>存在一个二元操作<code>combine(a: T, b: T) -&gt; T</code>，该操作是<strong>associative</strong>的,即<code>combine(a, combine(b, c)) = combine(combine(a, b), c)</code>。</li><li>存在一个特殊的值<code>empty: T</code>，被称为单位元,对于任意<code>x: T</code>都有<code>combine(x, empty) = x</code>和<code>combine(empty, x) = x</code></li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 整数求和操作</span></span><br><span class="line">numbers1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">numbers2 = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">total = <span class="built_in">sum</span>(numbers1) + <span class="built_in">sum</span>(numbers2)</span><br><span class="line"><span class="built_in">print</span>(total)  <span class="comment"># Output: 21</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0作为单位元</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>([]) + <span class="built_in">sum</span>(numbers1))  <span class="comment"># Output: 6</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>(numbers1) + <span class="built_in">sum</span>([]))  <span class="comment"># Output: 6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串拼接操作</span></span><br><span class="line">greeting1 = <span class="string">&quot;Hello, &quot;</span></span><br><span class="line">greeting2 = <span class="string">&quot;world!&quot;</span></span><br><span class="line">combined_greeting = greeting1 + greeting2</span><br><span class="line"><span class="built_in">print</span>(combined_greeting)  <span class="comment"># Output: &quot;Hello, world!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 空字符串作为单位元</span></span><br><span class="line">empty_string = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(empty_string + greeting1)  <span class="comment"># Output: &quot;Hello, &quot;</span></span><br><span class="line"><span class="built_in">print</span>(greeting1 + empty_string)  <span class="comment"># Output: &quot;Hello, &quot;</span></span><br></pre></td></tr></table></figure><h3 id="Monad"><a href="#Monad" class="headerlink" title="Monad"></a>Monad</h3><blockquote><p>可以被视为Functor的一种特殊形式,具有额外的性质和操作。</p><p>简单来说,Monad是一个满足以下条件的类型<code>M[_]</code>:</p><ol><li>它是一个Functor,即存在<code>fmap</code>操作,可以对Monad内部的值进行变换。</li><li>它具有一个<code>return</code>操作,可以将一个值包装进Monad。</li><li>它具有一个<code>flatMap</code>(或<code>bind</code>)操作,可以对Monad内部的值进行变换并”扁平化”结果。</li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiply</span>(<span class="params">x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">list</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">    <span class="keyword">return</span> [x, x * <span class="number">2</span>, x * <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用flatMap操作</span></span><br><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">results = [y <span class="keyword">for</span> x <span class="keyword">in</span> numbers <span class="keyword">for</span> y <span class="keyword">in</span> multiply(x)]</span><br><span class="line"><span class="built_in">print</span>(results)  <span class="comment"># Output: [1, 2, 3, 2, 4, 6, 3, 6, 9]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用列表推导式实现flatMap</span></span><br><span class="line">results = [multiply(x) <span class="keyword">for</span> x <span class="keyword">in</span> numbers]</span><br><span class="line"><span class="built_in">print</span>(results)  <span class="comment"># Output: [[1, 2, 3], [2, 4, 6], [3, 6, 9]]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="https://ruanyifeng.com/blog/2015/07/monad.html">图解 Monad - 阮一峰的网络日志 (ruanyifeng.com)</a></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// IO类型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IO</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="title">constructor</span>(<span class="params">effect</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>._effect = effect;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// pure操作</span></span><br><span class="line">  <span class="keyword">static</span> <span class="function"><span class="title">of</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> IO(<span class="function">() =&gt;</span> value);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// bind操作</span></span><br><span class="line">  <span class="function"><span class="title">bind</span>(<span class="params">fn</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> IO(<span class="function">() =&gt;</span> fn(<span class="built_in">this</span>._effect()).run());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="title">run</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>._effect();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">const</span> greet = <span class="function"><span class="params">name</span> =&gt;</span> <span class="string">`Hello, <span class="subst">$&#123;name&#125;</span>!`</span>;</span><br><span class="line"><span class="keyword">const</span> getInput = <span class="function">() =&gt;</span> prompt(<span class="string">&#x27;What is your name?&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> sayHello = <span class="keyword">new</span> IO(getInput)</span><br><span class="line">  .bind(<span class="function"><span class="params">name</span> =&gt;</span> <span class="keyword">new</span> IO(<span class="function">() =&gt;</span> greet(name)))</span><br><span class="line">  .bind(<span class="function"><span class="params">message</span> =&gt;</span> <span class="keyword">new</span> IO(<span class="function">() =&gt;</span> alert(message)));</span><br><span class="line"></span><br><span class="line">sayHello.run(); <span class="comment">// 弹出对话框并显示&#x27;Hello, &#123;输入的名字&#125;!&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="Applicative"><a href="#Applicative" class="headerlink" title="Applicative"></a>Applicative</h3><blockquote><p>Applicative可以被视为Functor的一种特殊形式,具有以下特点:</p><ol><li>它是一个Functor,即存在<code>fmap</code>操作,可以对Applicative内部的值进行变换。</li><li>它具有一个<code>pure</code>操作,可以将一个值包装进Applicative。</li><li>它具有一个<code>ap</code>(apply)操作,可以将一个函数包装进Applicative应用到另一个Applicative上</li></ol></blockquote><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Either类型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Either</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="title">constructor</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>._value = value;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> <span class="function"><span class="title">of</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Right(value);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> <span class="function"><span class="title">left</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Left(value);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ap操作</span></span><br><span class="line">  <span class="function"><span class="title">ap</span>(<span class="params">other</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">this</span> <span class="keyword">instanceof</span> Left) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (other <span class="keyword">instanceof</span> Left) &#123;</span><br><span class="line">      <span class="keyword">return</span> other;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Right(<span class="built_in">this</span>._value(other._value));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Right</span> <span class="keyword">extends</span> <span class="title">Either</span> </span>&#123;</span><br><span class="line">  <span class="comment">// pure操作</span></span><br><span class="line">  <span class="keyword">static</span> <span class="function"><span class="title">of</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Right(value);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Left</span> <span class="keyword">extends</span> <span class="title">Either</span> </span>&#123;</span><br><span class="line">  <span class="comment">// pure操作</span></span><br><span class="line">  <span class="keyword">static</span> <span class="function"><span class="title">of</span>(<span class="params">value</span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Left(value);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 示例</span></span><br><span class="line"><span class="keyword">const</span> add = <span class="function">(<span class="params">x, y</span>) =&gt;</span> x + y;</span><br><span class="line"><span class="keyword">const</span> result1 = Either.of(add).ap(Either.of(<span class="number">3</span>)).ap(Either.of(<span class="number">4</span>)); <span class="comment">// Right(7)</span></span><br><span class="line"><span class="keyword">const</span> result2 = Either.of(add).ap(Either.of(<span class="number">3</span>)).ap(Either.left(<span class="string">&#x27;error&#x27;</span>)); <span class="comment">// Left(&#x27;error&#x27;)</span></span><br></pre></td></tr></table></figure><p><a href="https://sxyz.blog/functors-applicatives-and-monads-in-pictures/">图解 Functor、Applicative、Monad (sxyz.blog)</a></p><p><a href="https://blog.forec.cn/2017/03/02/translation-adit-faamip/">图解 Functor, Applicative 和 Monad | Forec’s Notes</a></p><p><img data-src="https://p0.meituan.net/travelcube/652d533cc899998d4822ac6ed58cce89128094.png" alt="图 30" style="zoom:50%;" /></p><p><strong>使用函数式编程的一些原因</strong></p><ul><li>方便debug</li></ul><p>因为写成了函数,方便写单元测试而且由于是纯函数，输入固定那输出就是固定的</p><ul><li>代码重用</li></ul><p>纯函数方便组合也方便使用</p><ul><li>另一种思维方式</li></ul><p>是的，除了OOP之外，你可以站在这样的角度写特别的代码</p><p>如果你要学习具体某个函数式编程语言,可以考虑Clojure,Elixir,Haskell或者更加新的Ocaml.(我个人推荐)</p><p>下面给一些函数式编程语言分个类.</p><p>Lisp 家族</p><ul><li>Common Lisp</li><li>Scheme</li><li>Racket</li><li>Clojure</li></ul><p>这些语言都属于 Lisp 语言家族,具有强大的宏系统和元编程能力,非常适合进行函数式和声明式编程。</p><p>支持函数式编程的多范式语言</p><ul><li>Scala</li><li>F#</li><li>Clojure</li><li>Kotlin</li><li>Swift</li></ul><p>这类语言融合了函数式和面向对象等多种编程范式,兼具函数式和命令式编程的特点。它们在工业界应用较为广泛。</p><p>纯函数式语言</p><ul><li>Haskell</li><li>PureScript</li></ul><p>这类语言严格遵循函数式编程的原则,没有可变状态,强调代数类型系统和惰性求值。它们更偏向于学术和研究领域。</p><p>并发/分布式函数式语言:</p><ul><li>Erlang</li><li>Elixir</li><li>OCaml</li></ul><p>这些语言擅长构建高并发、分布式和容错的应用程序,利用函数式编程的优势来应对复杂的并发问题。</p><p>JavaScript 衍生语言</p><ul><li>PureScript</li><li>Elm</li><li>ReasonML</li><li>TypeScript</li></ul><p>这类语言在 JavaScript 的基础上增加了静态类型系统和其他函数式特性,旨在提高 JavaScript 的可靠性和可维护性</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/readme/guides/functional-programming-basics">Functional Programming 101 (github.com)</a></li><li><a href="https://llh911001.gitbooks.io/mostly-adequate-guide-chinese/content/">Introduction · 函数式编程指北 (gitbooks.io)</a></li><li><a href="https://ruanyifeng.com/blog/2017/02/fp-tutorial.html">函数式编程入门教程 - 阮一峰的网络日志 (ruanyifeng.com)</a></li><li><a href="https://tech.meituan.com/2022/10/13/dive-into-functional-programming-01.html">深入理解函数式编程（上） - 美团技术团队 (meituan.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;之前在看其他人交流帖子的时候提到学习函数式编程提升思维(虽然感觉有点大肆宣传的感觉),但看了一些函数式编程的例子,感觉在数据处理和多线程上有独特的效果,如果使用面向对象,那就会变得比较麻烦,所以这里仅作简单介绍.&lt;br&gt;</summary>
    
    
    
    
    <category term="functional programming" scheme="https://www.sekyoro.top/tags/functional-programming/"/>
    
  </entry>
  
  <entry>
    <title>使用pytorch时你可能需要注意的地方</title>
    <link href="https://www.sekyoro.top/2024/06/23/effective_pytorch/"/>
    <id>https://www.sekyoro.top/2024/06/23/effective_pytorch/</id>
    <published>2024-06-23T08:16:46.000Z</published>
    <updated>2024-07-11T10:03:32.279Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Pytorch是很好的深度学习框架,但在使用时你可能仍然不清楚其中一些概念.这里我只以官方文档为依据尝试解释其中一些概念和方法. 我这里可以称作Effective Pytorch.<br><span id="more"></span></p><blockquote><p>update:为了更好的理解pytorch,也许可以从零写点代码<a href="https://github.com/karpathy/micrograd">karpathy/micrograd: A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API (github.com)</a></p><p><a href="https://nrehiew.github.io/blog/pytorch/">Taking PyTorch for Granted | wh (nrehiew.github.io)</a></p></blockquote><h2 id="tensor"><a href="#tensor" class="headerlink" title="tensor"></a>tensor</h2><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><p>pytorch默认浮点类型是torch.float32,可以使用<code>torch.set_default_dtype</code>修改</p><p>torch.zeros等默认类型就是就是torch.float32,使用<code>torch.set_default_dtype</code>修改默认类型.</p><p>torch.tensor() 总是复制<code>data</code>(深拷贝,表示地址不相同).如果你有一个张量数据,<strong>只是想更改它的 requires<em>grad 标志,请使用 requires_grad</em>() 或 detach() 来避免复制</strong>.</p><p>如果你有一个 numpy 数组,并<strong>希望避免复制,请使用 torch.as_tensor()</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">torch.device(<span class="string">&#x27;mps&#x27;</span>)</span><br><span class="line"></span><br><span class="line">torch.device(<span class="string">&#x27;cuda&#x27;</span>)  <span class="comment"># current cuda device</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]])</span><br><span class="line">x.stride() <span class="comment">#(5,1)</span></span><br><span class="line"></span><br><span class="line">x.t().stride() <span class="comment">#(1,5)</span></span><br></pre></td></tr></table></figure><h3 id="Views"><a href="#Views" class="headerlink" title="Views"></a>Views</h3><p>PyTorch 允许张量成为现有张量的 “views”.<strong>视图张量与其基础张量共享相同的底层数据</strong>.支持 “views “可以避免显式数据复制,从而使我们能够进行快速、高效的内存重塑、切片和元素操作.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">t = torch.rand(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">b = t.view(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">t.storage().data_ptr() == b.storage().data_ptr()  <span class="comment"># `t` and `b` share the same underlying data.</span></span><br><span class="line">b[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">3.14</span></span><br><span class="line">t[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>由于views与其基础张量共享底层数据,因此如果修改views中的数据,也会反映在基础张量中.</p><p>通常,PyTorch 操作会返回一个新的张量作为输出,例如 add().但在视图操作中,输出是输入张量的视图,以避免不必要的数据复制.创建视图时不会发生数据移动,视图张量只是改变了解释相同数据的方式.</p><p><strong>对连续张量进行视图处理可能会产生非连续张量</strong>.transpose() 就是一个常见的例子.(包括view,transpose等操作都会返回view,也就是数据存储与输入相同)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">base = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>],[<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">base.is_contiguous()</span><br><span class="line">t = base.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># `t` is a view of `base`. No data movement happened here.</span></span><br><span class="line">t.is_contiguous()</span><br><span class="line">c = t.contiguous()</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/06/25/vKDYZ7A1jb3g9kO.png" alt="image-20240625212647753"></p><p><a href="https://zhuanlan.zhihu.com/p/342856639">通过公式判断张量是否连续 - 知乎 (zhihu.com)</a></p><h2 id="Extending-PyTorch"><a href="#Extending-PyTorch" class="headerlink" title="Extending PyTorch"></a>Extending PyTorch</h2><p>原文<a href="https://pytorch.org/docs/stable/notes/extending.html">Extending PyTorch — PyTorch 2.3 documentation</a></p><h3 id="extending-torch-autograd"><a href="#extending-torch-autograd" class="headerlink" title="extending torch.autograd"></a>extending torch.autograd</h3><p>为 autograd 添加操作需要为每个操作实现一个新的 Function 子类.</p><h5 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h5><p>一般来说,如果想在模型中<strong>执行不可微分的计算或依赖非 PyTorch 库</strong>（如 NumPy）,但仍希望您的操作能与其他操作连锁并与 autograd 引擎一起工作,那么请使用自定义函数.</p><p>在某些情况下,也可以<strong>使用自定义函数来提高性能和内存使用率</strong>: 如果您使用 C++ 扩展实现了前向和后向传递,您可以将它们封装在 Function 中,以便与 autograd 引擎对接.如果您想减少为后向传递保存的缓冲区数量,可以使用自定义函数将操作组合在一起.</p><p>如果想在后向传递过程中改变梯度或执行副作用，可以考虑register一个张量或模块hook</p><h5 id="什么时候不用"><a href="#什么时候不用" class="headerlink" title="什么时候不用"></a>什么时候不用</h5><p>如果已经可以用 PyTorch 的内置操作来编写函数,那么它的反向图（很可能）已经可以被 autograd 记录下来.在这种情况下,不需要自己实现后向函数.可以考虑使用一个普通的 Python 函数。</p><p>如果需要维护状态,即可训练参数,则应（也可以）使用自定义模块torch.nn. </p><p>如果想在后向传递过程中改变梯度或执行副作用,可以考虑注册一个张量或模块钩子。</p><blockquote><p>注意,我在看pytorch2.3时 register_backward_hook已经deprecated了,使用register_full_backward_hook</p></blockquote><p>使用一个<code>register_full_backward_hook</code>将梯度变为相反数.</p><p><code>hook(module, grad_input, grad_output) -&gt; tuple(Tensor) 或 None</code><br>grad_input 和 grad_output 是元组，分别包含<strong>相对于输入和输出的梯度</strong>。<strong>钩子不应修改其参数</strong>,但<strong>可以选择返回一个新的相对于输入的梯度，该梯度将在后续计算中代替 grad_input</strong>.对于所有非张量参数，grad_input 和 grad_output 中的条目均为 “None”.</p><p>如果想在后向传递过程中改变梯度或执行副作用，可以考虑注册一个张量或模块钩子.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_hook</span>(<span class="params">module, grad_input, grad_output</span>):</span></span><br><span class="line">    output_grad_input = - grad_input[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> (output_grad_input,)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">negGradient</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(negGradient, self).__init__()</span><br><span class="line">        self.register_full_backward_hook(backward_hook)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>在domain adaptation的早期论文比如DANN中,一般会使用<code>Function</code>进行梯度变为负数,其实也可以注册backward的hook实现.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_GradReverseLayer</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, x, constant</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(constant, <span class="built_in">int</span>) <span class="keyword">and</span> constant &gt; <span class="number">0</span></span><br><span class="line">        ctx.constant = constant</span><br><span class="line">        <span class="keyword">return</span> x.view_as(x)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        <span class="keyword">return</span> grad_output.neg() * ctx.constant, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradReverseLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GradReverseLayer, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> _GradReverseLayer.apply(x, self.weight)</span><br></pre></td></tr></table></figure><p>既然介绍了<code>register_full_backward_hook</code>,再说说<code>register_forward_hook</code>,每次 forward() 计算完输出后，都会调用该钩子。如果 with_kwargs 为 False 或未指定，输入将只包含给模块的位置参数。关键字参数不会传递给钩子，只会传递给 forward。<strong>钩子可以修改输出.钩子可以就地修改输入,但不会对 forward 产生影响</strong>,因为钩子是在调用 forward() 之后才调用的.</p><p>可以看看这篇文章<a href="https://blog.csdn.net/m0_51661400/article/details/135091359">深入理解PyTorch中的Hook机制：特征可视化的重要工具与实践-CSDN博客</a></p><h5 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h5><p>采取以下步骤 1. 继承类 Function 并实现 forward()、（可选）setup_context() 和 backward() 方法。2. 在 ctx 参数上调用适当的方法。3. 声明您的函数是否支持 double backward。4. 使用 gradcheck 验证梯度是否正确。</p><p>step1:</p><ol><li>forward() 是执行操作的代码。它可以接受任意多个参数,如果指定默认值,其中一些参数是可选的.在调用之前,跟踪历史的张量参数（即 requires_grad=True）将被转换为不跟踪历史的参数,它们的使用将被记录在图中。请注意,此逻辑不会遍历列表/数据集/任何其他数据结构,只会考虑作为调用直接参数的张量.您可以返回一个张量输出，如果有多个输出，也可以返回一个张量元组。</li><li>setup_context()（可选）。可以编写一个接受 ctx 对象的 “组合 “forward()，或者（从 PyTorch 2.0 开始）编写一个不接受 ctx 的单独 forward()，以及一个用于修改 ctx 的 setup_context()方法。forward() 应该具有计算功能，而 <strong>setup_context() 应该只负责修改 ctx（而不具有任何计算功能</strong>）。一般来说，独立的 forward() 和 setup_context()更接近 PyTorch 本机操作的工作方式，因此更容易与各种 PyTorch 子系统兼容。</li><li>backward()（或 vjp()）定义梯度公式。<strong>输出有多少个张量参数，它就有多少个张量参数，每个张量参数都代表该输出的梯度</strong>。<strong>切勿就地修改这些参数。它应该返回与输入相同数量的张量，其中每个张量都包含对应输入的梯度。</strong>如果输入不需要梯度（needs_input_grad 是一个布尔元组，表示每个输入是否需要梯度计算）,或者是非张量对象，则可以返回 python:None。此外,如果 forward() 的参数是可选的,只要它们都是 None,返回的梯度值就会多于输入值。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Exp</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, i</span>):</span></span><br><span class="line">        result = i.exp()</span><br><span class="line">        ctx.save_for_backward(result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        result, = ctx.saved_tensors</span><br><span class="line">        <span class="keyword">return</span> grad_output * result</span><br><span class="line"><span class="comment"># Use it by calling the apply method:</span></span><br><span class="line">output = Exp.apply(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure><p>step 2：正确使用 ctx 中的函数，以确保新函数在 autograd 引擎中正常工作。</p><p>ctx上有许多方法可用于调用,比较多的就是<code>save_for_backward</code></p><blockquote><p>必须<strong>使用 save_for_backward()来保存要在后向传递中使用的张量</strong>。<strong>非张量应直接保存在 ctx 上</strong>。如果既不是输入也不是输出的张量被保存,那函数函数可能不支持double backward 。</p></blockquote><p>此外还有<code>set_materialize_grads</code></p><blockquote><p>set_materialize_grads()可以用来告诉 autograd 引擎，在输出不依赖于输入的情况下，<strong>通过不对后向函数中的梯度张量进行实体化来优化梯度计算</strong>。</p></blockquote><p>step3:如果函数不支持double backward ，则应通过使用 once_differentiable() 对逆运算进行装饰来明确声明这一点。使用此装饰器后，通过函数执行double backward 的尝试将产生错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.autograd.gradcheck(Exp.apply, x)</span><br></pre></td></tr></table></figure><p>step4:建议使用 torch.autograd.gradcheck() 检查后向函数是否能正确计算前向梯度,方法是使用后向函数计算雅各布矩阵,并将该值与使用有限差分法数值计算的雅各布值进行逐元素比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Inherit from Function</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearFunction</span>(<span class="params">Function</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Note that forward, setup_context, and backward are @staticmethods</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params"><span class="built_in">input</span>, weight, bias</span>):</span></span><br><span class="line">        output = <span class="built_in">input</span>.mm(weight.t())</span><br><span class="line">        <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            output += bias.unsqueeze(<span class="number">0</span>).expand_as(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="comment"># inputs is a Tuple of all of the inputs passed to forward.</span></span><br><span class="line">    <span class="comment"># output is the output of the forward().</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_context</span>(<span class="params">ctx, inputs, output</span>):</span></span><br><span class="line">        <span class="built_in">input</span>, weight, bias = inputs</span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>, weight, bias)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># This function has only a single output, so it gets only one gradient</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        <span class="comment"># This is a pattern that is very convenient - at the top of backward</span></span><br><span class="line">        <span class="comment"># unpack saved_tensors and initialize all gradients w.r.t. inputs to</span></span><br><span class="line">        <span class="comment"># None. Thanks to the fact that additional trailing Nones are</span></span><br><span class="line">        <span class="comment"># ignored, the return statement is simple even when the function has</span></span><br><span class="line">        <span class="comment"># optional inputs.</span></span><br><span class="line">        <span class="built_in">input</span>, weight, bias = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_weight = grad_bias = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># These needs_input_grad checks are optional and there only to</span></span><br><span class="line">        <span class="comment"># improve efficiency. If you want to make your code simpler, you can</span></span><br><span class="line">        <span class="comment"># skip them. Returning gradients for inputs that don&#x27;t require it is</span></span><br><span class="line">        <span class="comment"># not an error.</span></span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">0</span>]:</span><br><span class="line">            grad_input = grad_output.mm(weight)</span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">1</span>]:</span><br><span class="line">            grad_weight = grad_output.t().mm(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> ctx.needs_input_grad[<span class="number">2</span>]:</span><br><span class="line">            grad_bias = grad_output.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> grad_input, grad_weight, grad_bias</span><br></pre></td></tr></table></figure><p>上面这个例子已经写得很好了.为了更方便地使用这些自定义操作，<strong>建议将它们别名或封装在一个函数中。</strong>使用函数封装可以让我们支持默认参数和关键字参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Option 1: alias</span></span><br><span class="line">linear = LinearFunction.apply</span><br><span class="line"></span><br><span class="line"><span class="comment"># Option 2: wrap in a function, to support default args and keyword args.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span>(<span class="params"><span class="built_in">input</span>, weight, bias=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> LinearFunction.apply(<span class="built_in">input</span>, weight, bias)</span><br></pre></td></tr></table></figure><p>此外还有输入没有tensor的情况,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MulConstant</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">tensor, constant</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tensor * constant</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_context</span>(<span class="params">ctx, inputs, output</span>):</span></span><br><span class="line">        <span class="comment"># ctx is a context object that can be used to stash information</span></span><br><span class="line">        <span class="comment"># for backward computation</span></span><br><span class="line">        tensor, constant = inputs</span><br><span class="line">        ctx.constant = constant <span class="comment"># 注意这里直接使用ctx.xx = xx</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        <span class="comment"># We return as many input gradients as there were arguments.</span></span><br><span class="line">        <span class="comment"># Gradients of non-Tensor arguments to forward must be None.</span></span><br><span class="line">        <span class="keyword">return</span> grad_output * ctx.constant, <span class="literal">None</span></span><br><span class="line">  <span class="comment"># 上面代码可以改为 使用set_materialize_grads,因为计算梯度不需要tensor.</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MulConstant</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">tensor, constant</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tensor * constant</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_context</span>(<span class="params">ctx, inputs, output</span>):</span></span><br><span class="line">        tensor, constant = inputs</span><br><span class="line">        ctx.set_materialize_grads(<span class="literal">False</span>)</span><br><span class="line">        ctx.constant = constant</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        <span class="comment"># Here we must handle None grad_output tensor. In this case we</span></span><br><span class="line">        <span class="comment"># can skip unnecessary computations and just return None.</span></span><br><span class="line">        <span class="keyword">if</span> grad_output <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># We return as many input gradients as there were arguments.</span></span><br><span class="line">        <span class="comment"># Gradients of non-Tensor arguments to forward must be None.</span></span><br><span class="line">        <span class="keyword">return</span> grad_output * ctx.constant, <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>如果需要保存在 forward() 中计算的任何 “中间 “张量，必须将它们作为输出返回，或者将 forward 和 setup_context()合并.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCube</span>(<span class="params">torch.autograd.Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="comment"># We wish to save dx for backward. In order to do so, it must</span></span><br><span class="line">        <span class="comment"># be returned as an output.</span></span><br><span class="line">        dx = <span class="number">3</span> * x ** <span class="number">2</span></span><br><span class="line">        result = x ** <span class="number">3</span></span><br><span class="line">        <span class="keyword">return</span> result, dx</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_context</span>(<span class="params">ctx, inputs, output</span>):</span></span><br><span class="line">        x, = inputs</span><br><span class="line">        result, dx = output</span><br><span class="line">        ctx.save_for_backward(x, dx)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output, grad_dx</span>):</span></span><br><span class="line">        x, dx = ctx.saved_tensors</span><br><span class="line">        <span class="comment"># In order for the autograd.Function to work with higher-order</span></span><br><span class="line">        <span class="comment"># gradients, we must add the gradient contribution of `dx`,</span></span><br><span class="line">        <span class="comment"># which is grad_dx * 6 * x.</span></span><br><span class="line">        result = grad_output * dx + grad_dx * <span class="number">6</span> * x</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># Wrap MyCube in a function so that it is clearer what the output is</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_cube</span>(<span class="params">x</span>):</span></span><br><span class="line">    result, dx = MyCube.apply(x)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>将forward和setup_context合在一起</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearFunction</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="comment"># ctx is the first argument to forward</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, <span class="built_in">input</span>, weight, bias=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># The forward pass can use ctx.</span></span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>, weight, bias)</span><br><span class="line">        output = <span class="built_in">input</span>.mm(weight.t())</span><br><span class="line">        <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            output += bias.unsqueeze(<span class="number">0</span>).expand_as(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        <span class="built_in">input</span>, weight, bias = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_weight = grad_bias = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">0</span>]:</span><br><span class="line">            grad_input = grad_output.mm(weight)</span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">1</span>]:</span><br><span class="line">            grad_weight = grad_output.t().mm(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">if</span> bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> ctx.needs_input_grad[<span class="number">2</span>]:</span><br><span class="line">            grad_bias = grad_output.<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> grad_input, grad_weight, grad_bias</span><br></pre></td></tr></table></figure><h3 id="extending-torch-nn"><a href="#extending-torch-nn" class="headerlink" title="extending torch.nn"></a>extending torch.nn</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_features, output_features, bias=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.input_features = input_features</span><br><span class="line">        self.output_features = output_features</span><br><span class="line"></span><br><span class="line">        <span class="comment"># nn.Parameter is a special kind of Tensor, that will get</span></span><br><span class="line">        <span class="comment"># automatically registered as Module&#x27;s parameter once it&#x27;s assigned</span></span><br><span class="line">        <span class="comment"># as an attribute. Parameters and buffers need to be registered, or</span></span><br><span class="line">        <span class="comment"># they won&#x27;t appear in .parameters() (doesn&#x27;t apply to buffers), and</span></span><br><span class="line">        <span class="comment"># won&#x27;t be converted when e.g. .cuda() is called. You can use</span></span><br><span class="line">        <span class="comment"># .register_buffer() to register buffers.</span></span><br><span class="line">        <span class="comment"># nn.Parameters require gradients by default.</span></span><br><span class="line">        self.weight = nn.Parameter(torch.empty(output_features, input_features))</span><br><span class="line">        <span class="keyword">if</span> bias:</span><br><span class="line">            self.bias = nn.Parameter(torch.empty(output_features))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># You should always register all possible parameters, but the</span></span><br><span class="line">            <span class="comment"># optional ones can be None if you want.</span></span><br><span class="line">            self.register_parameter(<span class="string">&#x27;bias&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Not a very smart way to initialize weights</span></span><br><span class="line">        nn.init.uniform_(self.weight, -<span class="number">0.1</span>, <span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.uniform_(self.bias, -<span class="number">0.1</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="comment"># See the autograd section for explanation of what happens here.</span></span><br><span class="line">        <span class="keyword">return</span> LinearFunction.apply(<span class="built_in">input</span>, self.weight, self.bias)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extra_repr</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># (Optional)Set the extra information about this module. You can test</span></span><br><span class="line">        <span class="comment"># it by printing an object of this class.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;input_features=&#123;&#125;, output_features=&#123;&#125;, bias=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">            self.input_features, self.output_features, self.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>可以通过定义具有与 Tensor 匹配的方法的自定义类来创建模拟 Tensor 的自定义类型。如果自定义 Python 类型定义了名为<code>__torch_function__</code>的方法，当您的自定义类的实例<strong>被传递给 torch 命名空间中的函数时</strong>，PyTorch 将调用您的 <code>__torch_function__</code>实现。这使得为 torch 命名空间中的任何函数定义自定义实现成为可能，<code>__torch_function__</code>实现可以调用这些函数，从而允许您的用户在他们已经为 Tensor 编写的现有 PyTorch 工作流中使用您的自定义类型。</p><p>这适用于<strong>与 Tensor 无关的 “duck “类型</strong>以及 <strong>Tensor 子类</strong>。</p><h5 id="Extending-torch-Tensor-like-type"><a href="#Extending-torch-Tensor-like-type" class="headerlink" title="Extending torch Tensor-like type"></a>Extending torch Tensor-like type</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">HANDLED_FUNCTIONS = &#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScalarTensor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, N, value</span>):</span></span><br><span class="line">        self._N = N</span><br><span class="line">        self._value = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;ScalarTensor(N=&#123;&#125;, value=&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(self._N, self._value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tensor</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._value * torch.eye(self._N)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__torch_function__</span>(<span class="params">cls, func, types, args=(<span class="params"></span>), kwargs=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> kwargs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            kwargs = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> func <span class="keyword">not</span> <span class="keyword">in</span> HANDLED_FUNCTIONS <span class="keyword">or</span> <span class="keyword">not</span> <span class="built_in">all</span>(</span><br><span class="line">            <span class="built_in">issubclass</span>(t, (torch.Tensor, ScalarTensor))</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> types</span><br><span class="line">        ):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NotImplemented</span></span><br><span class="line">        <span class="keyword">return</span> HANDLED_FUNCTIONS[func](*args, **kwargs)</span><br></pre></td></tr></table></figure><p>为 ScalarTensor 添加 <code>__torch_function__</code> 实现后,上述操作就有可能成功.这次添加一个<code>__torch_function__</code> 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">HANDLED_FUNCTIONS = &#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScalarTensor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, N, value</span>):</span></span><br><span class="line">        self._N = N</span><br><span class="line">        self._value = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;ScalarTensor(N=&#123;&#125;, value=&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(self._N, self._value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tensor</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._value * torch.eye(self._N)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__torch_function__</span>(<span class="params">cls, func, types, args=(<span class="params"></span>), kwargs=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> kwargs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            kwargs = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> func <span class="keyword">not</span> <span class="keyword">in</span> HANDLED_FUNCTIONS <span class="keyword">or</span> <span class="keyword">not</span> <span class="built_in">all</span>(</span><br><span class="line">            <span class="built_in">issubclass</span>(t, (torch.Tensor, ScalarTensor))</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> types</span><br><span class="line">        ):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NotImplemented</span></span><br><span class="line">        <span class="keyword">return</span> HANDLED_FUNCTIONS[func](*args, **kwargs)</span><br></pre></td></tr></table></figure><p><code>__torch_function__</code>方法需要四个参数:func,对要重载的 torch API 函数的引用；types，实现 <code>__torch_function__</code>的 Tensor-likes 类型列表；args,传递给函数的参数元组；kwargs,传递给函数的关键字参数 dict,它使用名为 HANDLED_FUNCTIONS 的全局调度表来存储自定义实现.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">implements</span>(<span class="params">torch_function</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Register a torch function override for ScalarTensor&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span>(<span class="params">func</span>):</span></span><br><span class="line">        functools.update_wrapper(func, torch_function)</span><br><span class="line">        HANDLED_FUNCTIONS[torch_function] = func</span><br><span class="line">        <span class="keyword">return</span> func</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line"><span class="meta">@implements(<span class="params">torch.mean</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(<span class="built_in">input</span>._value) / <span class="built_in">input</span>._N</span><br><span class="line"></span><br><span class="line">d = ScalarTensor(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">torch.mean(d)</span><br></pre></td></tr></table></figure><p>从 1.7.0 版开始，应用于 torch.Tensor 子类的 <strong>torch.Tensor 方法</strong>和<strong>公共 torch.* 命名空间中的函数</strong>将返回子类实例，而不是 torch.Tensor 实例.</p><p>如果希望对所有张量方法进行全局覆盖,可以使用<code>__torch_function__</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoggingTensor</span>(<span class="params">torch.Tensor</span>):</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__torch_function__</span>(<span class="params">cls, func, types, args=(<span class="params"></span>), kwargs=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> Logging calls Tensor.__repr__, so we can&#x27;t log __repr__ without infinite recursion</span></span><br><span class="line">        <span class="keyword">if</span> func <span class="keyword">is</span> <span class="keyword">not</span> torch.Tensor.__repr__:</span><br><span class="line">            logging.info(<span class="string">f&quot;func: <span class="subst">&#123;func.__name__&#125;</span>, args: <span class="subst">&#123;args!r&#125;</span>, kwargs: <span class="subst">&#123;kwargs!r&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> kwargs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            kwargs = &#123;&#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().__torch_function__(func, types, args, kwargs)</span><br></pre></td></tr></table></figure><p>在子类的<code>__torch_function__</code> 中应注意始终调用 super().<strong>torch_function</strong>(func,…)，而不是直接调用 func。如果不这样做，可能会导致 func 返回到 <code>__torch_function__</code>中，从而引起无限递归。</p><h2 id="torch-autograd"><a href="#torch-autograd" class="headerlink" title="torch.autograd"></a>torch.autograd</h2><p>torch.autograd 提供了实现任意标量值函数自动微分的类和函数.</p><p>它只需对现有代码做极少的改动—你只需用 requires_grad=True 关键字声明需要计算梯度的张量.</p><p>目前只持浮点张量类型（半浮点、浮点、双浮点和 bfloat16）和复合张量类型（cfloat、cdouble）的 autograd.</p><h3 id="detach-计算图与leaf-tensor"><a href="#detach-计算图与leaf-tensor" class="headerlink" title="detach 计算图与leaf tensor"></a>detach 计算图与leaf tensor</h3><p><code>Tensor.detach()</code>返回一个从当前计算图中分离出来的新张量,生成的张量永远不需要梯度,目前替代了<code>.data</code>方法.</p><p> PyTorch 中,计算图(Computation Graph)是一个非常重要的概念.它是一种用于表示和执行机器学习模型的数据结构.</p><p>具体来说,PyTorch 中的计算图由以下几个关键组件组成:</p><ol><li><strong>张量(Tensor)</strong>:计算图的基本单元,表示输入数据、中间结果和最终输出.</li><li><strong>操作(Operation)</strong>:在张量上执行的各种数学运算,如加法、乘法、卷积等.</li><li><strong>节点(Node)</strong>:表示张量和操作,计算图由这些节点组成.</li><li><strong>边(Edge)</strong>:表示节点之间的依赖关系,数据沿着边流动.</li></ol><p>当在 PyTorch 中定义和执行机器学习模型时,PyTorch 会自动构建一个计算图来表示模型的结构和数据流.这个计算图可以用于以下几个方面:</p><ol><li><strong>前向传播</strong>:通过计算图,PyTorch 可以自动计算模型的输出.</li><li><strong>反向传播</strong>:当您调用 <code>loss.backward()</code> 时,PyTorch 会沿着计算图反向传播梯度,从而更新模型参数.</li><li><strong>可视化</strong>:您可以使用 PyTorch 提供的工具(如 TensorBoard)来可视化计算图,更好地理解模型的结构.</li><li><strong>优化</strong>:PyTorch 的优化器会利用计算图的结构来提高优化效率.</li></ol><p>detach使得tensor从计算图中分离具体是什么含义?简单来说,使得它本身requires_grad=False,它之前的计算也被阻断了.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">20</span>, <span class="number">10</span>)</span><br><span class="line">model = nn.Linear(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">inter = model(<span class="built_in">input</span>)</span><br><span class="line">model2 = nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">output = model2(inter.detach())</span><br><span class="line">loss = torch.mean(output - <span class="number">1</span>)</span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(model.weight.grad) <span class="comment"># None</span></span><br></pre></td></tr></table></figure><p>按照惯例,所有<strong>requires_grad 为False的张量都是leaf tensor</strong>.</p><p>对于<strong>requires_grad 为 True 的张量,如果它们是由用户创建(没有经过计算,包括移动到GPU的操作)的,那么它们将是叶子张量</strong>.这意味着它们不是操作的结果,因此 grad_fn 为 None.</p><p>只有叶子张量才会在调用 backward() 时被填充梯度.要为非叶子张量填充阶值,可以使用 retain_grad().</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">xx = torch.randn(<span class="number">1</span>, <span class="number">3</span>).requires_grad_(<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(xx.grad_fn, xx.is_leaf) <span class="comment"># None,True</span></span><br><span class="line">model = nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">output = model(xx)</span><br><span class="line">loss = torch.mean(output - <span class="number">1</span>)</span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(xx.grad_fn, xx.grad) <span class="comment"># None,tensor([[.., ..,  ..]])</span></span><br><span class="line"><span class="built_in">print</span>(model.weight.grad_fn, model.weight.grad) <span class="comment"># None,,tensor([[.., ..,  ..]])</span></span><br><span class="line"><span class="built_in">print</span>(model.bias.grad_fn, model.bias.grad) <span class="comment"># None,tensor([1])</span></span><br><span class="line"><span class="built_in">print</span>(model.weight.is_leaf, model.bias.is_leaf) <span class="comment"># True,True</span></span><br></pre></td></tr></table></figure><p>只能获取计算图中叶子节点的梯度属性,这些节点的 requires_grad 属性设置为 True.对于图中的所有其他节点,梯度属性将不可用.</p><p>出于性能考虑,我们只能在给定图形上使用一次后向操作执行梯度计算.如果我们需要在同一图形上执行多次 backward 调用,则需要向 backward 调用传递 retain_graph=True 属性.</p><p>几个问题:</p><p>leaf tensor的grad_fn一定为空吗? 不一定,用户创建的requires_grad为True的tensor的grad_fn不为空</p><p>leaf tensor一定是模型输入吗?不一定,事实上直接创建一个模型,它的weight和bias也是leaf tensor</p><h3 id="属于旧时代的Variable和data"><a href="#属于旧时代的Variable和data" class="headerlink" title="属于旧时代的Variable和data"></a>属于旧时代的Variable和data</h3><p>Variable API 已被弃用:使用张量时,不再需要Variable.如果 requires_grad 设置为 True,Autograd 将自动支持张量.</p><p>Variable(tensor) 和 Variable(tensor, requires_grad) 仍按预期工作,但它们返回的是张量而不是变量.</p><p>var.data 与 tensor.data 相同.</p><p>var.backward()、var.detach()、var.register_hook() 等方法现在可以在具有相同方法名的张量上运行.</p><p>此外,现在还可以使用 torch.randn()、torch.zeros()、torch.none() 等工厂方法创建 requires_grad=True 的张量:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">autograd_tensor = torch.randn((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>api</th><th>介绍</th></tr></thead><tbody><tr><td><code>torch.Tensor.grad</code></td><td>This attribute is <code>None</code> by default and becomes a Tensor the first time a call to <a href="https://pytorch.org/docs/stable/generated/torch.autograd.backward.html#torch.autograd.backward"><code>backward()</code></a> computes gradients for <code>self</code></td></tr><tr><td><code>torch.Tensor.requires_grad</code></td><td>Is <code>True</code> if gradients need to be computed for this Tensor, <code>False</code> otherwise.</td></tr><tr><td><code>torch.Tensor.is_leaf</code></td><td>All Tensors that have <code>requires_grad</code> which is <code>False</code> will be leaf Tensors by convention.</td></tr><tr><td><code>torch.Tensor.backward</code>([gradient, …])</td><td>Computes the gradient of current tensor wrt graph leaves.</td></tr><tr><td><code>torch.Tensor.detach</code></td><td>Returns a new Tensor, detached from the current graph.</td></tr><tr><td><code>torch.Tensor.detach_</code></td><td>Detaches the Tensor from the graph that created it, making it a leaf.</td></tr><tr><td><code>torch.Tensor.register_hook</code>(hook)</td><td>Registers a backward hook.</td></tr><tr><td><code>torch.Tensor.register_post_accumulate_grad_hook</code>(hook)</td><td>Registers a backward hook that runs after grad accumulation.</td></tr><tr><td><code>torch.Tensor.retain_grad</code>()</td><td>Enables this Tensor to have their <a href="https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad"><code>grad</code></a> populated during <a href="https://pytorch.org/docs/stable/generated/torch.autograd.backward.html#torch.autograd.backward"><code>backward()</code></a>.</td></tr></tbody></table></div><h3 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h3><p>要创建自定义 autograd.Function,请继承该类并实现 forward() 和 backward() 静态方法.然后,要在前向传递中使用自定义 op,调用类方法 apply.不要直接调用 forward().</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Exp</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, i</span>):</span></span><br><span class="line">        result = i.exp()</span><br><span class="line">        ctx.save_for_backward(result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        result, = ctx.saved_tensors</span><br><span class="line">        <span class="keyword">return</span> grad_output * result</span><br><span class="line"></span><br><span class="line">Use it by calling the apply method:</span><br><span class="line">output = Exp.apply(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure><h2 id="ONNX格式"><a href="#ONNX格式" class="headerlink" title="ONNX格式"></a>ONNX格式</h2><p>在实际部署时非常常用的模型格式,是屏蔽了框架的.</p><p><a href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime — PyTorch Tutorials 2.3.0+cu121 documentation</a></p><h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">dummy_input = torch.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">model = torchvision.models.alexnet(pretrained=<span class="literal">True</span>).cuda()</span><br><span class="line"></span><br><span class="line">input_names = [ <span class="string">&quot;actual_input_1&quot;</span> ] + [ <span class="string">&quot;learned_%d&quot;</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>) ]</span><br><span class="line">output_names = [ <span class="string">&quot;output1&quot;</span> ]</span><br><span class="line"></span><br><span class="line">torch.onnx.export(model, dummy_input, <span class="string">&quot;alexnet.onnx&quot;</span>, verbose=<span class="literal">True</span>, input_names=input_names, output_names=output_names)</span><br></pre></td></tr></table></figure><p>生成的 <code>alexnet.onnx</code> 文件包含一个 <a href="https://developers.google.com/protocol-buffers/">protocol buffer</a>,其中包含了导出的模型(在本例中为 AlexNet)的网络结构和参数.<code>verbose=True</code> 参数会导致导出器打印出模型的人类可读表示.</p><h4 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install onnx</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="comment"># Load the ONNX model</span></span><br><span class="line">model = onnx.load(<span class="string">&quot;alexnet.onnx&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check that the model is well formed</span></span><br><span class="line">onnx.checker.check_model(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print a human readable representation of the graph</span></span><br><span class="line"><span class="built_in">print</span>(onnx.helper.printable_graph(model.graph))</span><br><span class="line">You can also run the exported model <span class="keyword">with</span> one of the many runtimes that support ONNX. For example after installing ONNX Runtime, you can load <span class="keyword">and</span> run the model:</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> ort</span><br><span class="line"></span><br><span class="line">ort_session = ort.InferenceSession(<span class="string">&quot;alexnet.onnx&quot;</span>)</span><br><span class="line"></span><br><span class="line">outputs = ort_session.run(</span><br><span class="line">    <span class="literal">None</span>,</span><br><span class="line">    &#123;<span class="string">&quot;actual_input_1&quot;</span>: np.random.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>).astype(np.float32)&#125;,</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(outputs[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># Print a human readable representation of the graph</span></span><br><span class="line"><span class="built_in">print</span>(onnx.helper.printable_graph(model.graph))</span><br></pre></td></tr></table></figure><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Input to the model</span></span><br><span class="line">x = torch.randn(batch_size, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">torch_out = torch_model(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Export the model</span></span><br><span class="line">torch.onnx.export(torch_model,               <span class="comment"># model being run</span></span><br><span class="line">                  x,                         <span class="comment"># model input (or a tuple for multiple inputs)</span></span><br><span class="line">                  <span class="string">&quot;super_resolution.onnx&quot;</span>,   <span class="comment"># where to save the model (can be a file or file-like object)</span></span><br><span class="line">                  export_params=<span class="literal">True</span>,        <span class="comment"># store the trained parameter weights inside the model file</span></span><br><span class="line">                  opset_version=<span class="number">10</span>,          <span class="comment"># the ONNX version to export the model to</span></span><br><span class="line">                  do_constant_folding=<span class="literal">True</span>,  <span class="comment"># whether to execute constant folding for optimization</span></span><br><span class="line">                  input_names = [<span class="string">&#x27;input&#x27;</span>],   <span class="comment"># the model&#x27;s input names</span></span><br><span class="line">                  output_names = [<span class="string">&#x27;output&#x27;</span>], <span class="comment"># the model&#x27;s output names</span></span><br><span class="line">                  dynamic_axes=&#123;<span class="string">&#x27;input&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;,    <span class="comment"># variable length axes</span></span><br><span class="line">                                <span class="string">&#x27;output&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;&#125;)</span><br></pre></td></tr></table></figure><p>在pytorch中直接使用<code>torch.onnx.export</code>即可.</p><p>因为导出运行了模型,我们需要提供一个输入张量 <code>x</code>.这个输入的值可以是随机的,只要它的类型和大小是正确的.请注意,除非指定为dynamic_axes,否则导出的 ONNX 图中输入的所有维度大小都会被固定下来.在这个示例中,使用批量大小为 1 的输入导出模型,但在 <code>torch.onnx.export()</code> 的 <code>dynamic_axes</code> 参数中指定了第一个维度为动态的.因此,导出的模型将接受大小为 <code>[batch_size, 1, 224, 224]</code> 的输入,其中 <code>batch_size</code> 可以是可变的.</p><p>同时还计算了模型输出 <code>torch_out</code>,我们将使用它来验证在 ONNX Runtime 中运行时导出的模型是否计算出相同的值.</p><p>但在使用 ONNX Runtime 验证模型输出之前,我们会先使用 ONNX API 检查 ONNX 模型.首先,<code>onnx.load(&quot;super_resolution.onnx&quot;)</code> 会加载保存的模型,并输出一个 <code>onnx.ModelProto</code> 结构.然后,<code>onnx.checker.check_model(onnx_model)</code> 会验证模型的结构,并确认模型具有有效的架构.通过检查模型的版本、图结构以及节点及其输入和输出,来验证 ONNX 图的有效性.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line">onnx_model = onnx.load(<span class="string">&quot;super_resolution.onnx&quot;</span>)</span><br><span class="line">onnx.checker.check_model(onnx_model)</span><br></pre></td></tr></table></figure><p>使用 ONNX Runtime 的 Python API 计算输出,通常情况下,这一部分可以在单独的进程中或其他机器上完成,但我们将继续在同一进程中进行,这样我们就可以验证 ONNX Runtime 和 PyTorch 为该网络计算出的值是否相同.</p><p>为了使用 ONNX Runtime 运行模型,我们需要为模型创建一个InferenceSession,并设置所需的配置参数(这里我们使用默认配置).创建会话后,我们就可以使用 <code>run()</code> API 来评估模型了.该调用的输出是一个列表,包含 ONNX Runtime 计算得出的模型输出.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"></span><br><span class="line">ort_session = onnxruntime.InferenceSession(<span class="string">&quot;super_resolution.onnx&quot;</span>, providers=[<span class="string">&quot;CPUExecutionProvider&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_numpy</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tensor.detach().cpu().numpy() <span class="keyword">if</span> tensor.requires_grad <span class="keyword">else</span> tensor.cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute ONNX Runtime output prediction</span></span><br><span class="line">ort_inputs = &#123;ort_session.get_inputs()[<span class="number">0</span>].name: to_numpy(x)&#125;</span><br><span class="line">ort_outs = ort_session.run(<span class="literal">None</span>, ort_inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compare ONNX Runtime and PyTorch results</span></span><br><span class="line">np.testing.assert_allclose(to_numpy(torch_out), ort_outs[<span class="number">0</span>], rtol=<span class="number">1e-03</span>, atol=<span class="number">1e-05</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Exported model has been tested with ONNXRuntime, and the result looks good!&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>在模型中避免使用numpy,tensor.data,tensor.shape不能使用in_place操作</p><h2 id="自动混合精度"><a href="#自动混合精度" class="headerlink" title="自动混合精度"></a>自动混合精度</h2><p>torch.amp 为混合精度提供了方便的方法,其中一些操作使用 torch.float32 （浮点）数据类型,另一些操作使用较低精度的浮点数据类型 (lower_precision_fp):torch.float16（半精度）或 torch.bfloat16.一些操作,如线性层和卷积,在 lower_precision_fp 下速度更快.其他操作,如还原,通常需要 float32 的动态范围.混合精度试图将每个操作与相应的数据类型相匹配.</p><p>通常,数据类型为 torch.float16 的 “自动混合精度训练 “使用 torch.autocast 和 torch.cpu.amp.GradScaler 或 torch.cuda.amp.GradScaler.</p><p>torch.autocast 实例可对所选上下文进行自动casting.自动cast会自动选择 GPU 运算的精度,从而在保持精度的同时提高性能.</p><p>torch.cuda.amp.GradScaler 的实例有助于方便地执行梯度缩放步骤.<strong>梯度缩放可最大限度地减少梯度下溢</strong>,从而改善具有 float16 梯度的网络的收敛性.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creates model and optimizer in default precision</span></span><br><span class="line">model = Net().cuda()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), ...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creates a GradScaler once at the beginning of training.</span></span><br><span class="line">scaler = GradScaler()  <span class="comment"># 1. 创建gradscaler</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Runs the forward pass with autocasting.</span></span><br><span class="line">        <span class="comment"># 2.使得模型训练时相关参数类型自动转换</span></span><br><span class="line">        <span class="keyword">with</span> autocast(device_type=<span class="string">&#x27;cuda&#x27;</span>, dtype=torch.float16):</span><br><span class="line">            output = model(<span class="built_in">input</span>)</span><br><span class="line">            loss = loss_fn(output, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Scales loss.  Calls backward() on scaled loss to create scaled gradients.</span></span><br><span class="line">        <span class="comment"># Backward passes under autocast are not recommended.</span></span><br><span class="line">        <span class="comment"># Backward ops run in the same dtype autocast chose for corresponding forward ops.</span></span><br><span class="line">        scaler.scale(loss).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scaler.step() first unscales the gradients of the optimizer&#x27;s assigned params.</span></span><br><span class="line">        <span class="comment"># If these gradients do not contain infs or NaNs, optimizer.step() is then called,</span></span><br><span class="line">        <span class="comment"># otherwise, optimizer.step() is skipped.</span></span><br><span class="line">        scaler.step(optimizer)   </span><br><span class="line">        <span class="comment"># Updates the scale for next iteration.</span></span><br><span class="line">        scaler.update()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creates model and optimizer in default precision</span></span><br><span class="line">model = Net().cuda()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), ...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Enables autocasting for the forward pass (model + loss)</span></span><br><span class="line">    <span class="keyword">with</span> torch.autocast(device_type=<span class="string">&quot;cuda&quot;</span>):</span><br><span class="line">        output = model(<span class="built_in">input</span>)</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Exits the context manager before backward()</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><p>所有由 scaler.scale(loss).backward() 生成的梯度都是按比例缩放的.如果要在 backward() 和 scaler.step(optimizer) 之间修改或检查参数的 .grad 属性,应首先取消缩放.</p><p><strong>梯度惩罚</strong></p><p>梯度惩罚的实现通常使用 torch.autograd.grad() 创建梯度,将它们组合起来创建惩罚值,并将惩罚值添加到损失中.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(<span class="built_in">input</span>)</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Creates gradients</span></span><br><span class="line">        grad_params = torch.autograd.grad(outputs=loss,</span><br><span class="line">                                          inputs=model.parameters(),</span><br><span class="line">                                          create_graph=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Computes the penalty term and adds it to the loss</span></span><br><span class="line">        grad_norm = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> grad <span class="keyword">in</span> grad_params:</span><br><span class="line">            grad_norm += grad.<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">        grad_norm = grad_norm.sqrt()</span><br><span class="line">        loss = loss + grad_norm</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># clip gradients here, if desired</span></span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure><p>要通过梯度缩放实现梯度惩罚,应缩放传递给 torch.autograd.grad() 的输出张量.因此,生成的梯度也将被缩放,在合并生成惩罚值之前应取消缩放.</p><p>此外,惩罚项的计算是前向传递的一部分,因此应在自动传递上下文中进行.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">        optimizer0.zero_grad()</span><br><span class="line">        optimizer1.zero_grad()</span><br><span class="line">        <span class="keyword">with</span> autocast(device_type=<span class="string">&#x27;cuda&#x27;</span>, dtype=torch.float16):</span><br><span class="line">            output0 = model0(<span class="built_in">input</span>)</span><br><span class="line">            output1 = model1(<span class="built_in">input</span>)</span><br><span class="line">            loss0 = loss_fn(<span class="number">2</span> * output0 + <span class="number">3</span> * output1, target)</span><br><span class="line">            loss1 = loss_fn(<span class="number">3</span> * output0 - <span class="number">5</span> * output1, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (retain_graph here is unrelated to amp, it&#x27;s present because in this</span></span><br><span class="line">        <span class="comment"># example, both backward() calls share some sections of graph.)</span></span><br><span class="line">        scaler.scale(loss0).backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">        scaler.scale(loss1).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># You can choose which optimizers receive explicit unscaling, if you</span></span><br><span class="line">        <span class="comment"># want to inspect or modify the gradients of the params they own.</span></span><br><span class="line">        scaler.unscale_(optimizer0)</span><br><span class="line"></span><br><span class="line">        scaler.step(optimizer0)</span><br><span class="line">        scaler.step(optimizer1)</span><br><span class="line"></span><br><span class="line">        scaler.update()</span><br></pre></td></tr></table></figure><p>如果网络有多个损失,则必须对每个损耗单独调用 scaler.scale.如果的网络有多个优化器,您可以在任何一个优化器上单独调用 scaler.unscale_,并且必须在每个优化器上单独调用 scaler.step.</p><p>autocast不在在 float64 或非浮点类型上进行转换.。为了获得最佳性能和稳定性,在autocast区域中使用out-of-place运算,也就是使用类似a.addmm(b, c)这种操作.</p><p>autocast会将with下的区域中的运算自动转换,自动转发应只包含网络的前向传递，包括损失计算。 </p><p>不建议使用自动转发的后向传递. 后向操作的运算类型是autocast之前的类型.</p><h4 id="cuda上会转为float16的运算"><a href="#cuda上会转为float16的运算" class="headerlink" title="cuda上会转为float16的运算"></a>cuda上会转为float16的运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__matmul__`, `addbmm`, `addmm`, `addmv`, `addr`, `baddbmm`, `bmm`, `chain_matmul`, `multi_dot`, `conv1d`, `conv2d`, `conv3d`, `conv_transpose1d`, `conv_transpose2d`, `conv_transpose3d`, `GRUCell`, `linear`, `LSTMCell`, `matmul`, `mm`, `mv`, `prelu`, `RNNCell</span><br></pre></td></tr></table></figure><h4 id="cuda上会转为float32的运算"><a href="#cuda上会转为float32的运算" class="headerlink" title="cuda上会转为float32的运算"></a>cuda上会转为float32的运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__pow__`, `__rdiv__`, `__rpow__`, `__rtruediv__`, `acos`, `asin`, `binary_cross_entropy_with_logits`, `cosh`, `cosine_embedding_loss`, `cdist`, `cosine_similarity`, `cross_entropy`, `cumprod`, `cumsum`, `dist`, `erfinv`, `exp`, `expm1`, `group_norm`, `hinge_embedding_loss`, `kl_div`, `l1_loss`, `layer_norm`, `log`, `log_softmax`, `log10`, `log1p`, `log2`, `margin_ranking_loss`, `mse_loss`, `multilabel_margin_loss`, `multi_margin_loss`, `nll_loss`, `norm`, `normalize`, `pdist`, `poisson_nll_loss`, `<span class="built_in">pow</span>`, `prod`, `reciprocal`, `rsqrt`, `sinh`, `smooth_l1_loss`, `soft_margin_loss`, `softmax`, `softmin`, `softplus`, `<span class="built_in">sum</span>`, `renorm`, `tan`, `triplet_margin_loss</span><br></pre></td></tr></table></figure><p>还有一些运算需要多个输入,如果输入全是float32那输出就是float32.也就是promote to the widest input type</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addcdiv`, `addcmul`, `atan2`, `bilinear`, `cross`, `dot`, `grid_sample`, `index_put`, `scatter_add`, `tensordot</span><br></pre></td></tr></table></figure><h4 id="CPU上会转为bfloat16的运算"><a href="#CPU上会转为bfloat16的运算" class="headerlink" title="CPU上会转为bfloat16的运算"></a>CPU上会转为bfloat16的运算</h4><p>bfloat是比较特殊的数据类型,是针对深度学习运算特别调整指数位和小数位,使得相对于同等位数的float,其精度更小,但能表示的值范围更大,而且针对显卡运算更快(显卡厂商调整了)</p><div class="table-container"><table><thead><tr><th>Format</th><th>Bits</th><th>Exponent</th><th>Fraction</th><th>sign(符号)</th></tr></thead><tbody><tr><td>FP32</td><td>32</td><td>8</td><td>23</td><td>1</td></tr><tr><td>FP16</td><td>16</td><td>5</td><td>10</td><td>1</td></tr><tr><td>BF16</td><td>16</td><td>8</td><td>7</td><td>1</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv1d`, `conv2d`, `conv3d`, `bmm`, `mm`, `baddbmm`, `addmm`, `addbmm`, `linear`, `matmul`, `_convolution</span><br></pre></td></tr></table></figure><h4 id="CPU上会转为bfloat32的运算"><a href="#CPU上会转为bfloat32的运算" class="headerlink" title="CPU上会转为bfloat32的运算"></a>CPU上会转为bfloat32的运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_transpose1d, conv_transpose2d, conv_transpose3d, avg_pool3d, binary_cross_entropy, grid_sampler, grid_sampler_2d, _grid_sampler_2d_cpu_fallback, grid_sampler_3d, polar, prod, quantile, nanquantile, stft, cdist, trace, view_as_complex, cholesky, cholesky_inverse, cholesky_solve, inverse, lu_solve, orgqr, inverse, ormqr, pinverse, max_pool3d, max_unpool2d, max_unpool3d, adaptive_avg_pool3d, reflection_pad1d, reflection_pad2d, replication_pad1d, replication_pad2d, replication_pad3d, mse_loss, ctc_loss, kl_div, multilabel_margin_loss, fft_fft, fft_ifft, fft_fft2, fft_ifft2, fft_fftn, fft_ifftn, fft_rfft, fft_irfft, fft_rfft2, fft_irfft2, fft_rfftn, fft_irfftn, fft_hfft, fft_ihfft, linalg_matrix_norm, linalg_cond, linalg_matrix_rank, linalg_solve, linalg_cholesky, linalg_svdvals, linalg_eigvals, linalg_eigvalsh, linalg_inv, linalg_householder_product, linalg_tensorinv, linalg_tensorsolve, fake_quantize_per_tensor_affine, eig, geqrf, lstsq, _lu_with_info, qr, solve, svd, symeig, triangular_solve, fractional_max_pool2d, fractional_max_pool3d, adaptive_max_pool3d, multilabel_margin_loss_forward, linalg_qr, linalg_cholesky_ex, linalg_svd, linalg_eig, linalg_eigh, linalg_lstsq, linalg_inv_ex</span><br></pre></td></tr></table></figure><p>类似的,cpu上也有promote to the widest input type的运算.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat, stack, index_copy</span><br></pre></td></tr></table></figure><h2 id="单机器-多GPU-训练最佳实践"><a href="#单机器-多GPU-训练最佳实践" class="headerlink" title="单机器(多GPU)训练最佳实践"></a>单机器(多GPU)训练最佳实践</h2><p>如果有多个GPU,每个GPU上运行复制的权重相同的模型,数据分发到多个GPU上,这样就能加快训练.但是有些使用一个GPU上容不下一个完整的模型,这个时候,将一个模型拆到不同的GPU上就是一个可行的方案.</p><p>这里就要提到model parallel(模型并行),模型并行是将一个模型的不同子网络放到不同的设备上,并相应地forward,以便在设备间移动中间输出.</p><blockquote><p>如果是跨机器,可以通过RPC<a href="https://pytorch.org/tutorials/intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework — PyTorch Tutorials 2.3.0+cu121 documentation</a></p></blockquote><p>一个简单的例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToyModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ToyModel, self).__init__()</span><br><span class="line">        self.net1 = torch.nn.Linear(<span class="number">10</span>, <span class="number">10</span>).to(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line">        self.net2 = torch.nn.Linear(<span class="number">10</span>, <span class="number">5</span>).to(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.relu(self.net1(x.to(<span class="string">&#x27;cuda:0&#x27;</span>)))</span><br><span class="line">        <span class="keyword">return</span> self.net2(x.to(<span class="string">&#x27;cuda:1&#x27;</span>))</span><br><span class="line">model = ToyModel()</span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">outputs = model(torch.randn(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">labels = torch.randn(<span class="number">20</span>, <span class="number">5</span>).to(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line">loss_fn(outputs, labels).backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><p>把模型不同部分放在了不同GPU上,并且forward时把数据也放在对应位置.注意计算损失时,label也要放对应位置.</p><p>只需修改几行代码，就可以在多个 GPU 上运行现有的单 GPU 模块.继承现有的 ResNet 模块,并在构建过程中将各层拆分到两个 GPU.然后,覆盖forward方法,通过相应移动中间输出来缝合两个子网络.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models.resnet <span class="keyword">import</span> ResNet, Bottleneck</span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelParallelResNet50</span>(<span class="params">ResNet</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ModelParallelResNet50, self).__init__(</span><br><span class="line">            Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">        self.seq1 = nn.Sequential(</span><br><span class="line">            self.conv1,</span><br><span class="line">            self.bn1,</span><br><span class="line">            self.relu,</span><br><span class="line">            self.maxpool,</span><br><span class="line"></span><br><span class="line">            self.layer1,</span><br><span class="line">            self.layer2</span><br><span class="line">        ).to(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.seq2 = nn.Sequential(</span><br><span class="line">            self.layer3,</span><br><span class="line">            self.layer4,</span><br><span class="line">            self.avgpool,</span><br><span class="line">        ).to(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.fc.to(<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.seq2(self.seq1(x).to(<span class="string">&#x27;cuda:1&#x27;</span>))</span><br><span class="line">        <span class="keyword">return</span> self.fc(x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>最后做了相关实验,发现在多个GPU上模型并行执行时间更长,因为多个 GPU 中只有一个在工作，而其他的也不做,同时数据从不同GPU中复制时也需要时间.</p><p><img data-src="https://pytorch.org/tutorials/_images/mp_vs_rn.png" alt="img"></p><h2 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h2><h4 id="并行方案"><a href="#并行方案" class="headerlink" title="并行方案"></a>并行方案</h4><p><code>DataParallel</code>是单进程、多线程的,只能在单台机器上(可以多GPU)运行,而 <code>DistributedDataParallel</code> 是多进程的,可以在单台和多台机器上运行.</p><p>即使在单台机器上,DataParallel 通常也比 DistributedDataParallel 慢,这是因为线程间的 GIL 竞争、每次迭代的复制模型，以及分散输入和收集输出所带来的额外开销.</p><blockquote><p>实际为了方便,通常使用DataParaller在多GPU上运行就够了.</p></blockquote><div class="table-container"><table><thead><tr><th>DataParallel</th><th>disc</th></tr></thead><tbody><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel"><code>nn.DataParallel</code></a></td><td>Implements data parallelism at the module level.</td></tr><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel"><code>nn.parallel.DistributedDataParallel</code></a></td><td>Implement distributed data parallelism based on <code>torch.distributed</code> at module level.</td></tr></tbody></table></div><p>模型并行:如果模型太大,无法在单个 GPU 上运行,就必须使用模型并行功能将其分割到多个 GPU 上.</p><p>分布式数据并行（DistributedDataParallel,DDP）可与模型并行一起使用，而数据并行（DataParallel）目前还不能。当 DDP 与模型并行相结合时,每个 DDP 进程都将使用模型并行,而所有进程都将使用数据并行。</p><p>多GPU训练有每个GPU一个线程</p><p><code>torch.nn.DataParallel</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = MyModel()</span><br><span class="line">dp_model = nn.DataParallel(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sets autocast in the main thread</span></span><br><span class="line"><span class="keyword">with</span> autocast(device_type=<span class="string">&#x27;cuda&#x27;</span>, dtype=torch.float16):</span><br><span class="line">    <span class="comment"># dp_model&#x27;s internal threads will autocast.</span></span><br><span class="line">    output = dp_model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="comment"># loss_fn also autocast</span></span><br><span class="line">    loss = loss_fn(output)</span><br></pre></td></tr></table></figure><p>上面方法是最简单的弊端是后续的loss计算只会在<code>cuda:0</code>上进行,没法并行,因此会导致负载不均衡的问题</p><p>文档推荐使用<code>DistributedDataParallel</code></p><blockquote><p>为什么尽管增加了复杂性,还是会考虑使用 DistributedDataParallel 而不是 DataParallel:</p><p>首先,DataParallel 是单进程、多线程的,只能在单机上运行,而 <strong>DistributedDataParallel 是多进程的,可以在单机和多机训练中运行.即使在单台机器上,DataParallel 通常也比 DistributedDataParallel 慢,这是由于线程间的 GIL 竞争、每次迭代的复制模型,以及分散输入和收集输出所带来的额外开销.</strong></p><p>分布式数据并行（DistributedDataParallel）可与模型并行一起使用,而数据并行（DataParallel）目前还不能.当 DDP 与模型并行相结合时,每个 DDP 进程都将使用模型并行,而所有进程都将使用数据并行.</p><p>如果模型需要跨越多台机器,或者您的用例不符合数据并行模式,请使用RPC API,以通用的分布式训练.</p></blockquote><p>在模块级基于 torch.distributed 实现分布式数据并行.<br>该容器通过在每个模型副本之间同步梯度来提供数据并行性.要同步的设备由输入 process_group 指定,默认情况下是整个世界.请注意,DistributedDataParallel 不会在参与的 GPU 之间对输入进行分块或分片；用户负责定义如何进行分块或分片,例如通过使用 DistributedSampler.</p><p>此外需要进行初始化 torch.distributed.init_process_group()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example</span>(<span class="params">rank, world_size</span>):</span></span><br><span class="line">    <span class="comment"># create default process group</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;gloo&quot;</span>, rank=rank, world_size=world_size)</span><br><span class="line">    <span class="comment"># create local model</span></span><br><span class="line">    model = nn.Linear(<span class="number">10</span>, <span class="number">10</span>).to(rank)</span><br><span class="line">    <span class="comment"># construct DDP model</span></span><br><span class="line">    ddp_model = DDP(model, device_ids=[rank])</span><br><span class="line">    <span class="comment"># define loss function and optimizer</span></span><br><span class="line">    loss_fn = nn.MSELoss()</span><br><span class="line">    optimizer = optim.SGD(ddp_model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward pass</span></span><br><span class="line">    outputs = ddp_model(torch.randn(<span class="number">20</span>, <span class="number">10</span>).to(rank))</span><br><span class="line">    labels = torch.randn(<span class="number">20</span>, <span class="number">10</span>).to(rank)</span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss_fn(outputs, labels).backward()</span><br><span class="line">    <span class="comment"># update parameters</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    world_size = <span class="number">2</span></span><br><span class="line">    mp.spawn(example,</span><br><span class="line">        args=(world_size,),</span><br><span class="line">        nprocs=world_size,</span><br><span class="line">        join=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># Environment variables which need to be</span></span><br><span class="line">    <span class="comment"># set when using c10d&#x27;s default &quot;env&quot;</span></span><br><span class="line">    <span class="comment"># initialization mode.</span></span><br><span class="line">    os.environ[<span class="string">&quot;MASTER_ADDR&quot;</span>] = <span class="string">&quot;localhost&quot;</span></span><br><span class="line">    os.environ[<span class="string">&quot;MASTER_PORT&quot;</span>] = <span class="string">&quot;29500&quot;</span></span><br><span class="line">    main()                                  </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">demo_model_parallel</span>(<span class="params">rank, world_size</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Running DDP with model parallel example on rank <span class="subst">&#123;rank&#125;</span>.&quot;</span>)</span><br><span class="line">    setup(rank, world_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># setup mp_model and devices for this process</span></span><br><span class="line">    dev0 = rank * <span class="number">2</span></span><br><span class="line">    dev1 = rank * <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">    mp_model = ToyMpModel(dev0, dev1)</span><br><span class="line">    ddp_mp_model = DDP(mp_model)</span><br><span class="line"></span><br><span class="line">    loss_fn = nn.MSELoss()</span><br><span class="line">    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># outputs will be on dev1</span></span><br><span class="line">    outputs = ddp_mp_model(torch.randn(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    labels = torch.randn(<span class="number">20</span>, <span class="number">5</span>).to(dev1)</span><br><span class="line">    loss_fn(outputs, labels).backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    cleanup()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    n_gpus = torch.cuda.device_count()</span><br><span class="line">    <span class="keyword">assert</span> n_gpus &gt;= <span class="number">2</span>, <span class="string">f&quot;Requires at least 2 GPUs to run, but got <span class="subst">&#123;n_gpus&#125;</span>&quot;</span></span><br><span class="line">    world_size = n_gpus</span><br><span class="line">    run_demo(demo_basic, world_size)</span><br><span class="line">    run_demo(demo_checkpoint, world_size)</span><br><span class="line">    world_size = n_gpus//<span class="number">2</span></span><br><span class="line">    run_demo(demo_model_parallel, world_size)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sampler = DistributedSampler(dataset) <span class="keyword">if</span> is_distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">loader = DataLoader(dataset, shuffle=(sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line">                    sampler=sampler)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, n_epochs):</span><br><span class="line">     <span class="keyword">if</span> is_distributed:</span><br><span class="line">         sampler.set_epoch(epoch)</span><br><span class="line">     train(loader)</span><br></pre></td></tr></table></figure><p>它与 torch.nn.parallel.DistributedDataParallel 结合使用尤其有用.在这种情况下,<strong>每个进程都可以传递一个 DistributedSampler 实例作为 DataLoader 采样器</strong>,并加载其独有的原始数据集子集.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist  </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  </span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim  </span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset, DistributedSampler  </span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 自定义数据集和模型  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">Dataset</span>):</span>  </span><br><span class="line">    <span class="comment"># 实现__len__和__getitem__方法  </span></span><br><span class="line">    <span class="keyword">pass</span>  </span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">nn.Module</span>):</span>  </span><br><span class="line">    <span class="comment"># 定义模型结构,可能需要考虑如何拆分模型  </span></span><br><span class="line">    <span class="keyword">pass</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 初始化分布式环境  </span></span><br><span class="line">dist.init_process_group(backend=<span class="string">&#x27;nccl&#x27;</span>, init_method=<span class="string">&#x27;tcp://localhost:23456&#x27;</span>, rank=<span class="number">0</span>, world_size=torch.cuda.device_count())  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 初始化数据集和模型  </span></span><br><span class="line">dataset = MyDataset()  </span><br><span class="line">sampler = DistributedSampler(dataset)  </span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">False</span>, sampler=sampler)  </span><br><span class="line">model = MyModel()  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 拆分模型（这通常需要根据模型的具体结构来手动完成）  </span></span><br><span class="line"><span class="comment">#### 例如,如果模型有两个主要部分,可以将它们分别放到不同的设备上  </span></span><br><span class="line">model_part1 = model.part1.to(<span class="string">&#x27;cuda:0&#x27;</span>)  </span><br><span class="line">model_part2 = model.part2.to(<span class="string">&#x27;cuda:1&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 使用DistributedDataParallel包装模型  </span></span><br><span class="line">model = DDP(model, device_ids=[torch.cuda.current_device()])  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 定义损失函数和优化器  </span></span><br><span class="line">criterion = nn.CrossEntropyLoss()  </span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 训练循环  </span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):  </span><br><span class="line">    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloader:  </span><br><span class="line">        inputs, labels = inputs.to(model.device), labels.to(model.device)  </span><br><span class="line">        optimizer.zero_grad()  </span><br><span class="line">        outputs = model(inputs)  </span><br><span class="line">        loss = criterion(outputs, labels)  </span><br><span class="line">        loss.backward()  </span><br><span class="line">        optimizer.step()  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#### 销毁分布式进程组  </span></span><br><span class="line">dist.destroy_process_group()</span><br></pre></td></tr></table></figure><p><a href="https://github.com/jia-zhuang/pytorch-multi-gpu-training">jia-zhuang/pytorch-multi-gpu-training: 整理 pytorch 单机多 GPU 训练方法与原理 (github.com)</a></p><h2 id="常用Container"><a href="#常用Container" class="headerlink" title="常用Container"></a>常用Container</h2><div class="table-container"><table><thead><tr><th>Containers</th><th>介绍</th></tr></thead><tbody><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module"><code>Module</code></a></td><td>Base class for all neural network modules.</td></tr><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential"><code>Sequential</code></a></td><td>A sequential container.</td></tr><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList"><code>ModuleList</code></a></td><td>Holds submodules in a list.</td></tr><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict"><code>ModuleDict</code></a></td><td>Holds submodules in a dictionary.</td></tr><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList"><code>ParameterList</code></a></td><td>Holds parameters in a list.</td></tr><tr><td><a href="https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict"><code>ParameterDict</code></a></td><td>Holds parameters in a dictionary.</td></tr></tbody></table></div><p><code>Module</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="keyword">return</span> F.relu(self.conv2(x))</span><br></pre></td></tr></table></figure><p><code>Sequential</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using Sequential with OrderedDict. This is functionally the</span></span><br><span class="line"><span class="comment"># same as the above code</span></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu2&#x27;</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br></pre></td></tr></table></figure><p><code>ModuleList</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.linears = nn.ModuleList([nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># ModuleList can act as an iterable, or be indexed using ints</span></span><br><span class="line">        <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.linears):</span><br><span class="line">            x = self.linears[i // <span class="number">2</span>](x) + l(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><code>ModuleDict</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.choices = nn.ModuleDict(&#123;</span><br><span class="line">                <span class="string">&#x27;conv&#x27;</span>: nn.Conv2d(<span class="number">10</span>, <span class="number">10</span>, <span class="number">3</span>),</span><br><span class="line">                <span class="string">&#x27;pool&#x27;</span>: nn.MaxPool2d(<span class="number">3</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">        self.activations = nn.ModuleDict([</span><br><span class="line">                [<span class="string">&#x27;lrelu&#x27;</span>, nn.LeakyReLU()],</span><br><span class="line">                [<span class="string">&#x27;prelu&#x27;</span>, nn.PReLU()]</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice, act</span>):</span></span><br><span class="line">        x = self.choices[choice](x)</span><br><span class="line">        x = self.activations[act](x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><code>ParameterList</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">10</span>, <span class="number">10</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># ParameterList can act as an iterable, or be indexed using ints</span></span><br><span class="line">        <span class="keyword">for</span> i, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.params):</span><br><span class="line">            x = self.params[i // <span class="number">2</span>].mm(x) + p.mm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><code>ParameterDict</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">                <span class="string">&#x27;left&#x27;</span>: nn.Parameter(torch.randn(<span class="number">5</span>, <span class="number">10</span>)),</span><br><span class="line">                <span class="string">&#x27;right&#x27;</span>: nn.Parameter(torch.randn(<span class="number">5</span>, <span class="number">10</span>))</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice</span>):</span></span><br><span class="line">        x = self.params[choice].mm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="容易混淆和遗忘的方法"><a href="#容易混淆和遗忘的方法" class="headerlink" title="容易混淆和遗忘的方法"></a>容易混淆和遗忘的方法</h2><h3 id="torch-scatter"><a href="#torch-scatter" class="headerlink" title="torch.scatter"></a>torch.scatter</h3><p><code>Tensor.scatter_(dim, index, src, *, reduce=None) → [Tensor</code>]</p><p><strong>按照 <code>index</code> 张量中指定的索引,将张量 <code>src</code> 中的所有值写入 <code>self</code> 中</strong>.</p><p>对于 <code>src</code> 中的每个值,其输出索引在 <code>dimension != dim</code> 时由 <code>src</code> 中的索引指定,在 <code>dimension = dim</code> 时由 <code>index</code> 中的相应值指定.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self[index[i][j][k]][j][k] = src[i][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">self[i][index[i][j][k]][k] = src[i][j][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">self[i][j][index[i][j][k]] = src[i][j][k]  <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure><p>self、index 和 src（如果是张量）的<strong>维数应该相同</strong>.对于<strong>所有维度d,index.size(d) &lt;= src.size(d)</strong>；对于所有<strong>维度 d != dim,index.size(d) &lt;= self.size(d)</strong>,index 和 src 不会广播.</p><p>与gather逆操作,常用作写one-hot量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">value = <span class="number">2</span></span><br><span class="line">torch.zeros(<span class="number">3</span>, <span class="number">5</span>).scatter_(<span class="number">0</span>, index, value)</span><br><span class="line"></span><br><span class="line">src = torch.arange(<span class="number">1</span>, <span class="number">11</span>).reshape((<span class="number">2</span>, <span class="number">5</span>))</span><br><span class="line">src</span><br><span class="line">index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]])</span><br><span class="line">torch.zeros(<span class="number">3</span>, <span class="number">5</span>, dtype=src.dtype).scatter_(<span class="number">0</span>, index, src)</span><br><span class="line">index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>]])</span><br><span class="line">torch.zeros(<span class="number">3</span>, <span class="number">5</span>, dtype=src.dtype).scatter_(<span class="number">1</span>, index, src)</span><br><span class="line"></span><br><span class="line">torch.full((<span class="number">2</span>, <span class="number">4</span>), <span class="number">2.</span>).scatter_(<span class="number">1</span>, torch.tensor([[<span class="number">2</span>], [<span class="number">3</span>]]),</span><br><span class="line">           <span class="number">1.23</span>, reduce=<span class="string">&#x27;multiply&#x27;</span>)</span><br><span class="line">torch.full((<span class="number">2</span>, <span class="number">4</span>), <span class="number">2.</span>).scatter_(<span class="number">1</span>, torch.tensor([[<span class="number">2</span>], [<span class="number">3</span>]]),</span><br><span class="line">           <span class="number">1.23</span>, reduce=<span class="string">&#x27;add&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="torch-gather"><a href="#torch-gather" class="headerlink" title="torch.gather"></a>torch.gather</h3><p><code>torch.gather(input, dim, index, *, sparse_grad=False, out=None) → [Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)</code></p><p>输入和索引的维数必须相同. <strong>在 d != dim的维度 中，index.size(d) &lt;= input.size(d)</strong>。输入和index不会相互广播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][index[i][j][k]][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][j][index[i][j][k]]  <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">torch.gather(t, <span class="number">1</span>, torch.tensor([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>]]))</span><br></pre></td></tr></table></figure><p>上面的代码就是把t根据index torch.tensor([[0, 0], [1, 0]])重新得到一个tensor.</p><blockquote><p>scatter是通过index将src的数据放在input中</p><p>gather是通过index将input的数据取出来</p></blockquote><h3 id="torch-split"><a href="#torch-split" class="headerlink" title="torch.split"></a>torch.split</h3><p><code>torch.split(tensor, split_size_or_sections, dim=0</code></p><p>将张量分割成块.每个块都是原始张量的一个view.</p><p>如果 split_size_or_sections 是整数类型,那么张量将被分割成大小相等的块（如果可能）.如果张量在给定维度 dim 上的大小不能被 split_size 整除,则最后一个块的大小会变小.</p><p>如果 split_size_or_sections 是一个列表,那么张量将被分割成 len(split_size_or_sections)小块,其大小与 split_size_or_sections 一致.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">10</span>).reshape(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">torch.split(a, <span class="number">2</span>)</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">3</span>]]),</span><br><span class="line"> tensor([[<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>]]),</span><br><span class="line"> tensor([[<span class="number">8</span>, <span class="number">9</span>]]))</span><br><span class="line">torch.split(a, [<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">(tensor([[<span class="number">0</span>, <span class="number">1</span>]]),</span><br><span class="line"> tensor([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">         [<span class="number">8</span>, <span class="number">9</span>]]))</span><br></pre></td></tr></table></figure><h3 id="torch-tensor-split"><a href="#torch-tensor-split" class="headerlink" title="torch.tensor_split"></a>torch.tensor_split</h3><p><code>torch.tensor_split(input, indices_or_sections, dim=0) → List of Tensors</code></p><p>根据 indices_or_sections 指定的索引或部分数,将张量沿维度 dim 分割成多个子张量,所有子张量都是输入的视图.</p><ul><li><p>如果 indices_or_sections 是一个整数 n 或一个数值为 n 的零维长张量，则输入会沿着维度 dim 被分割成 n 个部分。如果输入沿着维数 dim 被 n 整除，则每个部分的大小相等，即 input.size(dim) / n。如果输入不能被 n 整除，则第一个 int(input.size(dim) % n) 部分的大小为 int(input.size(dim) / n) + 1，其余部分的大小为 int(input.size(dim)/n)。</p></li><li><p>如果 indices_or_sections 是一个 ints 列表或元组，或者是一个一维长张量，那么输入将在列表、元组或张量中的每个索引处沿着维度 dim 分割。例如，如果 indices_or_sections=[2,3]，dim=0，则会产生张量 input[:2]、input[2:3] 和 input[3:]。</p></li><li><p>如果 indices_or_sections 是张量，在 CPU 上必须是零维或一维长张量。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">8</span>)</span><br><span class="line">torch.tensor_split(x, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">7</span>)</span><br><span class="line">torch.tensor_split(x, <span class="number">3</span>)</span><br><span class="line">torch.tensor_split(x, (<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">14</span>).reshape(<span class="number">2</span>, <span class="number">7</span>)</span><br><span class="line">x</span><br><span class="line">torch.tensor_split(x, <span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line">torch.tensor_split(x, (<span class="number">1</span>, <span class="number">6</span>), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><blockquote><p>split如果输入是整数,按照dim分成多段,每段dim上的大小等于这个整数(如果能除尽)</p><p>如果输入是list,每段大小就对应list中的值(list的长度也跟dim对应的大小相同).返回tuple[Tensor,…]</p><p>tensor_split如果输入是整数,能除尽的话结果就跟split类似,否则前<code>int(input.size(dim) % n)</code> 段 大小<code>int(input.size(dim) / n) + 1</code>, 后面的大小 为<code>int(input.size(dim) / n)</code></p><p>如果是list,每一段数据是list中的两个indices,也就是</p><p>For instance, <code>indices_or_sections=[2, 3]</code> and <code>dim=0</code> would result in the tensors <code>input[:2]</code>, <code>input[2:3]</code>, and <code>input[3:]</code></p><p>两者默认dim都是0</p></blockquote><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Pytorch是很好的深度学习框架,但在使用时你可能仍然不清楚其中一些概念.这里我只以官方文档为依据尝试解释其中一些概念和方法. 我这里可以称作Effective Pytorch.&lt;br&gt;</summary>
    
    
    
    
    <category term="pytorch" scheme="https://www.sekyoro.top/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>A better C:from C++, Go,Rust to Zig</title>
    <link href="https://www.sekyoro.top/2024/06/23/A-better-C-from-C-Go-Rust-to-Zig/"/>
    <id>https://www.sekyoro.top/2024/06/23/A-better-C-from-C-Go-Rust-to-Zig/</id>
    <published>2024-06-23T03:28:16.000Z</published>
    <updated>2024-06-25T03:09:37.398Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>从C语言诞生已经五十多年了,现在已经有了许多高级语言,其中很多背靠大厂,比如Java,Go,C#,Dart,Swift等等(甲骨文,谷歌微软和苹果,这类语言通过公司更新).也有很多社区的语言,比如Python,Rust,PHP,Ruby等(这类语言往往通过早期创建者和一些核心成员更新和维护,这里面也有很多开源的语言,允许其他人修改).<br>相较于公司旗下的语言,社区类型的语言往往更加简洁,在使用或者生产下效率高,但也存在生态相对较差、工具链不够、更新发力不够持久、文档不够丰富的问题.</p><p>而 A better C的意思就是在后面的语言中找到性能较强,使用友好并且生态持续发展的语言.TLDR:在大型项目上还是使用C++,在一些工具链或者代码重构上可以考虑Rust. </p><span id="more"></span><blockquote><p>“世上其实只有两种编程语言，一种是大家一直喷它难用的，一种是根本没人用的。” —— C++ 的作者 Bjarne Stroustrup </p></blockquote><p>相对于Java,C#这种语言,我们尝试找到使用上更加轻型(指的是不依赖某种领域),性能更强占用更小的语言.</p><h2 id="Better-C"><a href="#Better-C" class="headerlink" title="Better C"></a>Better C</h2><h3 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h3><p>C++20目前已经有了很多Modern的特性,但是目前仍然缺乏的依然还是<code>build system,test harness, linter</code>,C++社区整体比较离散,也没有大公司拿出类似js的all in one的工具链,目前用得多的是vcpkg+cmake. 也有conan和xmake等等,但相对来说还是有欠缺,主要原因是C++没有所谓的官方,只有c++标准委员会,也不像其他公司常用的编程语言会有公司推出工具链.</p><p>但C++语言本身还是不错的,足够底层,足够值得学习.</p><h3 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h3><p>Go背靠谷歌,生态目前感觉还是不够明朗,个人感觉可能是云原生基础设施上,如果你写过Go,就知道大型Web项目写Go还是有所欠缺,拿来写事务还是麻烦.</p><p>并且go的nil错误处理,module等依然遭受诟病.但是Go本身代码还是很容易读的,而且工具链也相对完善,有包管理工具,项目构建也可以使用cmake.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;html/template&quot;</span></span><br><span class="line">    <span class="string">&quot;net/http&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">    Name <span class="keyword">string</span></span><br><span class="line">    Age  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    http.HandleFunc(<span class="string">&quot;/&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">        p := Person&#123;</span><br><span class="line">            Name: <span class="string">&quot;John Doe&quot;</span>,</span><br><span class="line">            Age:  <span class="number">30</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        t, err := template.ParseFiles(<span class="string">&quot;templates/index.html&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            http.Error(w, err.Error(), http.StatusInternalServerError)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        t.Execute(w, p)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    fmt.Println(<span class="string">&quot;Starting server on :8080&quot;</span>)</span><br><span class="line">    http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">worker</span><span class="params">(wrkID <span class="keyword">int</span>, jobs &lt;-<span class="keyword">chan</span> <span class="keyword">int</span>, results <span class="keyword">chan</span>&lt;- <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> job := <span class="keyword">range</span> jobs &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;worker %d started job %d\n&quot;</span>, wrkID, job)</span><br><span class="line">        time.Sleep(time.Second)</span><br><span class="line">        fmt.Printf(<span class="string">&quot;worker %d finished job %d\n&quot;</span>, wrkID, job)</span><br><span class="line">        results &lt;- job * <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    jobs := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">100</span>)</span><br><span class="line">    results := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start workers</span></span><br><span class="line">    <span class="keyword">for</span> w := <span class="number">1</span>; w &lt;= <span class="number">3</span>; w++ &#123;</span><br><span class="line">        <span class="keyword">go</span> worker(w, jobs, results)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Send jobs</span></span><br><span class="line">    <span class="keyword">for</span> j := <span class="number">1</span>; j &lt;= <span class="number">9</span>; j++ &#123;</span><br><span class="line">        jobs &lt;- j</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">close</span>(jobs)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Collect results</span></span><br><span class="line">    <span class="keyword">for</span> a := <span class="number">1</span>; a &lt;= <span class="number">9</span>; a++ &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;Result: %d\n&quot;</span>, &lt;-results)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h3><p>Rust,最近几年热度很高,但是也存在不少问题,上手门槛高,需要额外理解的概念不少.</p><p>Rust的一些优势包括以下几点：</p><ul><li>并发和并行：Rust内置对并行编程的支持，以及安全高效的多线程特性</li><li>性能：由于Rust代码不需要运行时，同时它不需要额外的垃圾回收器功耗，从而可以使用更少的资源并提高性能，</li><li>内存安全且无垃圾回收：由于所有权和借用等规则，Rust在没有垃圾回收器的情况下管理内存，从而实现更高效和可预测的性能</li><li>跨平台兼容性：Rust支持跨平台开发，意味着可以在多个系统上编译代码而不需要太多的修改代码</li><li>强大的生态系统：Rust拥有强大的工具和库生态系统。它的包管理器Cargo显著简化了依赖管理和与外部库集成的难度</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Person</span></span> &#123;</span><br><span class="line">    name: <span class="built_in">String</span>,</span><br><span class="line">    age: <span class="built_in">u32</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> Person &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">new</span></span>(name: &amp;<span class="built_in">str</span>, age: <span class="built_in">u32</span>) -&gt; Person &#123;</span><br><span class="line">        Person &#123;</span><br><span class="line">            name: <span class="built_in">String</span>::from(name),</span><br><span class="line">            age,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">greet</span></span>(&amp;<span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;Hello, my name is &#123;&#125; and I&#x27;m &#123;&#125; years old.&quot;</span>, <span class="keyword">self</span>.name, <span class="keyword">self</span>.name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> alice = Person::new(<span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>);</span><br><span class="line">    alice.greet();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Direction</span></span> &#123;</span><br><span class="line">    Up,</span><br><span class="line">    Down,</span><br><span class="line">    Left,</span><br><span class="line">    Right,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">move_player</span></span>(direction: Direction) &#123;</span><br><span class="line">    <span class="keyword">match</span> direction &#123;</span><br><span class="line">        Direction::Up =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Moving up&quot;</span>),</span><br><span class="line">        Direction::Down =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Moving down&quot;</span>),</span><br><span class="line">        Direction::Left =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Moving left&quot;</span>),</span><br><span class="line">        Direction::Right =&gt; <span class="built_in">println!</span>(<span class="string">&quot;Moving right&quot;</span>),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">main</span></span>() &#123;</span><br><span class="line">    move_player(Direction::Up);</span><br><span class="line">    move_player(Direction::Left);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Zig"><a href="#Zig" class="headerlink" title="Zig"></a>Zig</h3><p>Zig官方是这么说的:Zig 是一种通用的编程语言和工具链，用于维护<strong>健壮</strong>、<strong>最优</strong>和<strong>可重用</strong>的软件.</p><p>既然有了C++和Rust,为什么又要搞这么多东西?<a href="https://ziglang.org/zh/learn/why_zig_rust_d_cpp/">有了 C++、D 和 Rust，为什么还需要 Zig？ ⚡ Zig Programming Language (ziglang.org)</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line">const parseInt = std.fmt.parseInt;</span><br><span class="line"></span><br><span class="line">test &quot;parse integers&quot; &#123;</span><br><span class="line">    const input = &quot;123 67 89,99&quot;;</span><br><span class="line">    const ally = std.testing.allocator;</span><br><span class="line"></span><br><span class="line">    var list = std.ArrayList(u32).init(ally);</span><br><span class="line">    // Ensure the list is freed at scope exit.</span><br><span class="line">    // Try commenting out this line!</span><br><span class="line">    defer list.deinit();</span><br><span class="line"></span><br><span class="line">    var it = std.mem.tokenizeAny(u8, input, &quot; ,&quot;);</span><br><span class="line">    while (it.next()) |num| &#123;</span><br><span class="line">        const n = try parseInt(u32, num, 10);</span><br><span class="line">        try list.append(n);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    const expected = [_]u32&#123; 123, 67, 89, 99 &#125;;</span><br><span class="line"></span><br><span class="line">    for (expected, list.items) |exp, actual| &#123;</span><br><span class="line">        try std.testing.expectEqual(exp, actual);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">pub fn main() !void &#123;</span><br><span class="line">    const x: i32 = 5;</span><br><span class="line">    const y: i32 = 10;</span><br><span class="line">    const sum = x + y;</span><br><span class="line">    std.log.info(&quot;The sum of &#123;&#125; and &#123;&#125; is &#123;&#125;&quot;, .&#123; x, y, sum &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">const std = @import(&quot;std&quot;);</span><br><span class="line"></span><br><span class="line">fn greet(name: []const u8) void &#123;</span><br><span class="line">    std.log.info(&quot;Hello, &#123;&#125;!&quot;, .&#123;name&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pub fn main() !void &#123;</span><br><span class="line">    greet(&quot;Alice&quot;);</span><br><span class="line">    greet(&quot;Bob&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>官方文档阐述了非常多Zig的优势,看起来特别吸引人,但是目前使用的人还是不多.</p><p>Zig的一些<strong>劣势</strong>包括：</p><ul><li>有限的生态系统：因为它仍处于早期阶段，Zig语言的生态系统比成熟语言更小</li><li>成熟度和工具：Zig是一种新语言，还有改进的空间。但请注意，仍然有一个强大而活跃的社区支持它</li><li>文档可用性：Zig是一种相对较新的语言，因此文档有限，社区正在努力提高文档的可用性</li></ul><p>开发者可以在系统编程中使用Zig来构建操作系统、设备驱动程序和嵌入式系统。其还在<a href="https://cloud.tencent.com/product/cli?from_column=20065&amp;from=20065">命令行工具</a>中也有很多应用场景，可用于创建高效和快速的命令行界面，构建系统脚本，或优化现有工具的性能。</p><p>在编译器和语言开发中，Zig以其元编程能力和对简易性的追求而闻名。比较著名的开源项目是Bun，其是一个使用Zig开发的JavaScript运行时。</p><p>与Rust一样，Zig也有一些更为专业的使用场景：</p><ul><li>游戏开发，因支持高性能游戏引擎、能够实时模拟</li><li>在嵌入式系统和物联网中，用于编程微控制器、传感器和其他资源受限设备</li><li>在密码应用中，用于实现加密算法、数字签名、安全通信协议和其他安全敏感组</li></ul><p>小小的Benchmark<a href="https://zserge.com/posts/better-c-benchmark/">A “Better C” Benchmark (zserge.com)</a></p><p>我为什么会看上面这些语言的比较,主要原因还是:C++很好,但没有完善的工具链,它的标准委员会也不会管这些,而一些大厂也没有开源一些工具使用；</p><p>Go的生态位跟C/C++和Rust这类语言还不一样后者的一些东西不会拿Go来重构;Rust的上手门槛高,但目前看来是最可行的C/C++在系统编程、工具链重构甚至于一些业务处理上的可行工具.</p><p>而Zig还远远没有完善,但上手门槛相对更低,但应该还是需要沉淀,更何况c语言即使到今天也在更新,生态还是在的.</p><h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>之前一段时间有个叫Mojo的编程语言不断在宣传自己的在AI领域编程的地位:比C和Python性能更好.<a href="https://www.modular.com/max/mojo">Mojo 🔥: Programming language for all of AI (modular.com)</a></p><p>目前还在吹水建设阶段,看后续表现(其实大众看的是有没有相关大厂进局).</p><p>我常常会关注一些本身比较老但使用并不少的编程语言,因为这类编程语言有自己的生态位,文档可能不算新,官方网站也往往看起来很老,生态上也没有很大的持续发力点,但是我还是会时不时看看,毕竟其中很多可能也会用上.</p><h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><p>之前的文章我也提到过,php生态位就是web,也是为web而生.你甚至不需要特意使用某些web框架来创建应用,它本身就支持很多操作.但是php本身有些语法还需要适应(很多人说语法丑陋).而它的web框架也特别多,从相对轻量ThinkPHP、Symfony到重型的Laravel,都可以试试.Swoole框架也使得从Web到 TCP、UDP、Socket上</p><p>还有相比swoole更易学习的workerman,workerman 是纯php写的网络框架.支持TCP长连接，支持Websocket、HTTP等协议.以及基于workerman的webman,webman用于替代传统的php-fpm架构，提供超高性能可扩展的HTTP服务。你可以用webman开发网站，也可以开发HTTP接口或者微服务</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="variable">$numbers</span> = <span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;The first number is: &quot;</span> . <span class="variable">$numbers</span>[<span class="number">0</span>];</span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;The length of the array is: &quot;</span> . count(<span class="variable">$numbers</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable">$person</span> = <span class="keyword">array</span>(</span><br><span class="line">    <span class="string">&quot;name&quot;</span> =&gt; <span class="string">&quot;Alice&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age&quot;</span> =&gt; <span class="number">30</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;Name: &quot;</span> . <span class="variable">$person</span>[<span class="string">&quot;name&quot;</span>] . <span class="string">&quot;, Age: &quot;</span> . <span class="variable">$person</span>[<span class="string">&quot;age&quot;</span>];</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="variable">$name</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="variable">$age</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">__construct</span>(<span class="params"><span class="variable">$name</span>, <span class="variable">$age</span></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">$this</span>-&gt;name = <span class="variable">$name</span>;</span><br><span class="line">        <span class="keyword">$this</span>-&gt;age = <span class="variable">$age</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">greet</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">&quot;Hello, my name is &quot;</span> . <span class="keyword">$this</span>-&gt;name . <span class="string">&quot; and I&#x27;m &quot;</span> . <span class="keyword">$this</span>-&gt;age . <span class="string">&quot; years old.&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="variable">$alice</span> = <span class="keyword">new</span> Person(<span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>);</span><br><span class="line"><span class="variable">$alice</span>-&gt;greet(); <span class="comment">// 输出 &quot;Hello, my name is Alice and I&#x27;m 30 years old.&quot;</span></span><br></pre></td></tr></table></figure><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">divide</span>(<span class="params"><span class="variable">$a</span>, <span class="variable">$b</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="variable">$b</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> \<span class="built_in">Exception</span>(<span class="string">&quot;Division by zero&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="variable">$a</span> / <span class="variable">$b</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="variable">$result</span> = divide(<span class="number">10</span>, <span class="number">0</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (\<span class="built_in">Exception</span> <span class="variable">$e</span>) &#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;Error: &quot;</span> . <span class="variable">$e</span>-&gt;getMessage();</span><br><span class="line">&#125;</span><br><span class="line"><span class="variable">$greet</span> = <span class="function"><span class="keyword">function</span>(<span class="params"><span class="variable">$name</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;Hello, <span class="subst">$name</span>!&quot;</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="variable">$greet</span>(<span class="string">&quot;Alice&quot;</span>); <span class="comment">// 输出 &quot;Hello, Alice!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$numbers</span> = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>];</span><br><span class="line"><span class="variable">$doubledNumbers</span> = array_map(<span class="function"><span class="keyword">function</span>(<span class="params"><span class="variable">$x</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="variable">$x</span> * <span class="number">2</span>;</span><br><span class="line">&#125;, <span class="variable">$numbers</span>);</span><br><span class="line"></span><br><span class="line">print_r(<span class="variable">$doubledNumbers</span>); <span class="comment">// 输出 [2, 4, 6, 8, 10]</span></span><br></pre></td></tr></table></figure><p><strong>推荐学习</strong>:</p><ul><li><a href="https://docs.golaravel.com/">Laravel - 为 WEB 艺术家创造的 PHP 框架。 (golaravel.com)</a></li><li><a href="https://symfony.com/">Symfony, High Performance PHP Framework for Web Development</a></li><li><a href="https://www.workerman.net/">高性能PHP应用容器 workerman</a></li><li><a href="https://www.workerman.net/doc/webman/README.html">webman 手册 (workerman.net)</a></li></ul><h3 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h3><p>也是web生态,或者说应为rails而知名.国内相对来说没那么多使用ruby的.</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">puts <span class="string">&quot;The first number is: <span class="subst">#&#123;numbers[<span class="number">0</span>]&#125;</span>&quot;</span></span><br><span class="line">puts <span class="string">&quot;The length of the array is: <span class="subst">#&#123;numbers.length&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">person = &#123;</span><br><span class="line">  <span class="string">&quot;name&quot;</span> =&gt; <span class="string">&quot;Alice&quot;</span>,</span><br><span class="line">  <span class="string">&quot;age&quot;</span> =&gt; <span class="number">30</span></span><br><span class="line">&#125;</span><br><span class="line">puts <span class="string">&quot;Name: <span class="subst">#&#123;person[<span class="string">&quot;name&quot;</span>]&#125;</span>, Age: <span class="subst">#&#123;person[<span class="string">&quot;age&quot;</span>]&#125;</span>&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span></span><br><span class="line">  <span class="keyword">attr_accessor</span> <span class="symbol">:name</span>, <span class="symbol">:age</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(name, age)</span></span></span><br><span class="line">    <span class="variable">@name</span> = name</span><br><span class="line">    <span class="variable">@age</span> = age</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">greet</span></span></span><br><span class="line">    puts <span class="string">&quot;Hello, my name is <span class="subst">#&#123;<span class="variable">@name</span>&#125;</span> and I&#x27;m <span class="subst">#&#123;<span class="variable">@age</span>&#125;</span> years old.&quot;</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Person 对象并调用方法</span></span><br><span class="line">alice = Person.new(<span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>)</span><br><span class="line">alice.greet <span class="comment"># 输出 &quot;Hello, my name is Alice and I&#x27;m 30 years old.&quot;</span></span><br></pre></td></tr></table></figure><p><strong>推荐学习</strong>:</p><ul><li><a href="https://rubyonrails.org/">Ruby on Rails — A web-app framework that includes everything needed to create database-backed web applications according to the Model-View-Controller (MVC) pattern.</a></li></ul><h3 id="Lua"><a href="#Lua" class="headerlink" title="Lua"></a>Lua</h3><p>lua生态位是写一些游戏脚本或者一些工具的功能,比如neovim中的一些插件就会使用lua.另外一些嵌入式设备也会使用,主要是与其他语言搭配.这门语言本身非常小,</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> x = <span class="number">5</span></span><br><span class="line"><span class="keyword">local</span> y = <span class="number">10</span></span><br><span class="line"><span class="keyword">local</span> sum = x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The sum of &quot;</span> .. x .. <span class="string">&quot; and &quot;</span> .. y .. <span class="string">&quot; is &quot;</span> .. sum)</span><br><span class="line"><span class="keyword">local</span> fruits = &#123;<span class="string">&quot;apple&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;orange&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用for循环遍历</span></span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>, #fruits <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">print</span>(fruits[i])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用for-in循环遍历</span></span><br><span class="line"><span class="keyword">for</span> _, fruit <span class="keyword">in</span> <span class="built_in">ipairs</span>(fruits) <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">print</span>(fruit)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">-- 定义一个Person类</span></span><br><span class="line"><span class="keyword">local</span> Person = &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person:new</span><span class="params">(name, age)</span></span></span><br><span class="line">    <span class="keyword">local</span> obj = &#123;</span><br><span class="line">        name = name,</span><br><span class="line">        age = age</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">setmetatable</span>(obj, <span class="built_in">self</span>)</span><br><span class="line">    <span class="built_in">self</span>.<span class="built_in">__index</span> = <span class="built_in">self</span></span><br><span class="line">    <span class="keyword">return</span> obj</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person:greet</span><span class="params">()</span></span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Hello, my name is &quot;</span> .. <span class="built_in">self</span>.name .. <span class="string">&quot; and I&#x27;m &quot;</span> .. <span class="built_in">self</span>.age .. <span class="string">&quot; years old.&quot;</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建Person对象并调用方法</span></span><br><span class="line"><span class="keyword">local</span> alice = Person:new(<span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>)</span><br><span class="line">alice:greet()</span><br><span class="line"><span class="comment">-- 定义一个协程函数</span></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">count</span><span class="params">(n)</span></span></span><br><span class="line">    <span class="keyword">for</span> i=<span class="number">1</span>,n <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">coroutine</span>.<span class="built_in">yield</span>(i)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建并控制协程</span></span><br><span class="line"><span class="keyword">local</span> co = <span class="built_in">coroutine</span>.<span class="built_in">create</span>(count)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">coroutine</span>.<span class="built_in">resume</span>(co, <span class="number">5</span>)) <span class="comment">-- 输出 1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">coroutine</span>.<span class="built_in">resume</span>(co)) <span class="comment">-- 输出 2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">coroutine</span>.<span class="built_in">resume</span>(co)) <span class="comment">-- 输出 3</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">coroutine</span>.<span class="built_in">resume</span>(co)) <span class="comment">-- 输出 4</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">coroutine</span>.<span class="built_in">resume</span>(co)) <span class="comment">-- 输出 5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">coroutine</span>.<span class="built_in">resume</span>(co)) <span class="comment">-- 输出 nil</span></span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 定义一个Vector2D类</span></span><br><span class="line"><span class="keyword">local</span> Vector2D = &#123;&#125;</span><br><span class="line">Vector2D.<span class="built_in">__index</span> = Vector2D</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Vector2D:new</span><span class="params">(x, y)</span></span></span><br><span class="line">    <span class="keyword">local</span> obj = <span class="built_in">setmetatable</span>(&#123;x=x, y=y&#125;, Vector2D)</span><br><span class="line">    <span class="keyword">return</span> obj</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Vector2D:add</span><span class="params">(other)</span></span></span><br><span class="line">    <span class="keyword">return</span> Vector2D:new(<span class="built_in">self</span>.x + other.x, <span class="built_in">self</span>.y + other.y)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Vector2D:__tostring</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;(&quot;</span> .. <span class="built_in">self</span>.x .. <span class="string">&quot;, &quot;</span> .. <span class="built_in">self</span>.y .. <span class="string">&quot;)&quot;</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建和操作Vector2D对象</span></span><br><span class="line"><span class="keyword">local</span> v1 = Vector2D:new(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">local</span> v2 = Vector2D:new(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="keyword">local</span> v3 = v1:add(v2)</span><br><span class="line"><span class="built_in">print</span>(v3) <span class="comment">-- 输出 (4, 6)</span></span><br></pre></td></tr></table></figure><ul><li><a href="https://www.lua.org/">The Programming Language Lua</a></li></ul><h3 id="一些有趣的东西"><a href="#一些有趣的东西" class="headerlink" title="一些有趣的东西"></a>一些有趣的东西</h3><p>[<a href="https://www.codementor.io/blog/worst-languages-to-learn-3phycr98zk">Worst Programming Languages to Learn in 2018 (codementor.io)</a>这篇文章在2018年给出了在工作上不推荐碰的语言,其中包括Dart,Rust,Ruby,Go等,事实上从工作的角度来看,一些函数式编程语言和门槛较高的语言上榜很正常,但是另外有些更可能是因为生态还不够大,但本身是做应用的,比如Dart和Go,所以还需要官网.</p><p>这份榜单比较激进,但总体还是很有趣的.像函数时语言Clojure和Elixir就相比更老的Haskell和Erlang就更好.</p><p>在2019年<a href="https://www.codementor.io/blog/worst-languages-2019-6mvbfg3w9x">Study of Programming Languages Not to Learn in 2019 (codementor.io)</a></p><p>这份榜单变得更符合我的知觉了,当然这些东西只是看看而已,比如下面的人就说自己拿CoffeeScript写应用到AppStore上赚了很多钱,所以,还是要看生态位.</p><p><img data-src="https://s2.loli.net/2024/06/23/OM87TjbGsdWXl4E.png" alt="image-20240623122150477"></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;从C语言诞生已经五十多年了,现在已经有了许多高级语言,其中很多背靠大厂,比如Java,Go,C#,Dart,Swift等等(甲骨文,谷歌微软和苹果,这类语言通过公司更新).也有很多社区的语言,比如Python,Rust,PHP,Ruby等(这类语言往往通过早期创建者和一些核心成员更新和维护,这里面也有很多开源的语言,允许其他人修改).&lt;br&gt;相较于公司旗下的语言,社区类型的语言往往更加简洁,在使用或者生产下效率高,但也存在生态相对较差、工具链不够、更新发力不够持久、文档不够丰富的问题.&lt;/p&gt;
&lt;p&gt;而 A better C的意思就是在后面的语言中找到性能较强,使用友好并且生态持续发展的语言.TLDR:在大型项目上还是使用C++,在一些工具链或者代码重构上可以考虑Rust. &lt;/p&gt;</summary>
    
    
    
    
    <category term="programming language" scheme="https://www.sekyoro.top/tags/programming-language/"/>
    
  </entry>
  
  <entry>
    <title>从论文中看AI绘画(二)</title>
    <link href="https://www.sekyoro.top/2024/06/18/%E4%BB%8E%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9C%8BAI%E7%BB%98%E7%94%BB-%E4%BA%8C/"/>
    <id>https://www.sekyoro.top/2024/06/18/%E4%BB%8E%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9C%8BAI%E7%BB%98%E7%94%BB-%E4%BA%8C/</id>
    <published>2024-06-18T08:33:38.000Z</published>
    <updated>2024-06-18T08:36:29.095Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>接着上一篇 从论文中看AI绘画(一)写,主要关注animation甚至video级别的生成了.</p><span id="more"></span><h2 id="Animate-Anyone-Consistent-and-Controllable-Image-to-Video-Synthesis-for-Character-Animation"><a href="#Animate-Anyone-Consistent-and-Controllable-Image-to-Video-Synthesis-for-Character-Animation" class="headerlink" title="Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation"></a>Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation</h2><p>TODO:</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;接着上一篇 从论文中看AI绘画(一)写,主要关注animation甚至video级别的生成了.&lt;/p&gt;</summary>
    
    
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/tags/deep-learning/"/>
    
    <category term="generative ai" scheme="https://www.sekyoro.top/tags/generative-ai/"/>
    
  </entry>
  
  <entry>
    <title>myJourneyToAI:深度学习之旅</title>
    <link href="https://www.sekyoro.top/2024/06/12/myJourneyToAI-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85/"/>
    <id>https://www.sekyoro.top/2024/06/12/myJourneyToAI-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85/</id>
    <published>2024-06-12T11:32:09.000Z</published>
    <updated>2024-06-25T03:12:11.169Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>总结一下学习人工智能/深度学习过程中个人觉得重要的方法和经验. </p><p>主要关于模型.<br><span id="more"></span></p><h1 id="蛮荒时代"><a href="#蛮荒时代" class="headerlink" title="蛮荒时代"></a>蛮荒时代</h1><blockquote><p>大约2010年开始，那些在计算上看起来不可行的神经网络算法变得热门起来，实际上是以下两点导致的： 其一，随着互联网的公司的出现，为数亿在线用户提供服务，大规模数据集变得触手可及； 另外，廉价又高质量的传感器、廉价的数据存储（克莱德定律）以及廉价计算（摩尔定律）的普及，特别是GPU的普及，使大规模算力唾手可得。</p></blockquote><h2 id="经典CNN模型"><a href="#经典CNN模型" class="headerlink" title="经典CNN模型"></a>经典CNN模型</h2><h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><p><img data-src="https://zh.d2l.ai/_images/lenet.svg" alt="../_images/lenet.svg">每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用5×5卷积核和一个sigmoid激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个2×2池操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><p><img data-src="https://zh.d2l.ai/_images/lenet-vert.svg" alt="../_images/lenet-vert.svg"></p><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><img data-src="https://zh.d2l.ai/_images/alexnet.svg" alt="../_images/alexnet.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    <span class="comment"># 这里使用一个11*11的更大窗口来捕捉对象。</span></span><br><span class="line">    <span class="comment"># 同时，步幅为4，以减少输出的高度和宽度。</span></span><br><span class="line">    <span class="comment"># 另外，输出通道的数目远大于LeNet</span></span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 使用三个连续的卷积层和较小的卷积窗口。</span></span><br><span class="line">    <span class="comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span></span><br><span class="line">    <span class="comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span></span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    <span class="comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span></span><br><span class="line">    nn.Linear(<span class="number">6400</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p><img data-src="https://guandi1995.github.io/images/classical_cnn/vgg-16-simplified.PNG" alt="img"></p><p><img data-src="https://zh.d2l.ai/_images/vgg.svg" alt="../_images/vgg.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span>(<span class="params">conv_arch</span>):</span></span><br><span class="line">    conv_blks = []</span><br><span class="line">    in_channels = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 卷积层部分</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))</span><br><span class="line">        in_channels = out_channels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        *conv_blks, nn.Flatten(),</span><br><span class="line">        <span class="comment"># 全连接层部分</span></span><br><span class="line">        nn.Linear(out_channels * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">net = vgg(conv_arch)</span><br></pre></td></tr></table></figure><h3 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h3><p><img data-src="https://zh.d2l.ai/_images/nin.svg" alt="../_images/nin.svg" style="zoom:50%;" /></p><p>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。 相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个<em>全局平均汇聚层</em>（global average pooling layer），生成一个对数几率 （logits）。NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, strides, padding</span>):</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU())</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 标签类别数是10</span></span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">    <span class="comment"># 将四维的输出转成二维的输出，其形状为(批量大小,10)</span></span><br><span class="line">    nn.Flatten())</span><br></pre></td></tr></table></figure><h3 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h3><p><img data-src="https://zh.d2l.ai/_images/inception.svg" alt="../_images/inception.svg"></p><p>在GoogLeNet中，基本的卷积块被称为<em>Inception块</em>（Inception block）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># c1--c4是每条路径的输出通道数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># 线路1，单1x1卷积层</span></span><br><span class="line">        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线路2，1x1卷积层后接3x3卷积层</span></span><br><span class="line">        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线路3，1x1卷积层后接5x5卷积层</span></span><br><span class="line">        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 线路4，3x3最大汇聚层后接1x1卷积层</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))</span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))</span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        <span class="comment"># 在通道维度上连结输出</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><img data-src="https://zh.d2l.ai/_images/inception-full.svg" alt="../_images/inception-full.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">b2 = nn.Sequential(nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))    </span><br><span class="line">b3 = nn.Sequential(Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">                   Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))                </span><br><span class="line">b4 = nn.Sequential(Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))           </span><br><span class="line">b5 = nn.Sequential(Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                   nn.Flatten())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="number">1024</span>, <span class="number">10</span>))            X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape:\t&#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure><h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p><img data-src="https://zh.d2l.ai/_images/residual-block.svg" alt="../_images/residual-block.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">nn.Module</span>):</span>  <span class="comment">#@save</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_channels, num_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">                 use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides)</span><br><span class="line">        self.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        Y += X</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y)</span><br></pre></td></tr></table></figure><p><img data-src="https://zh.d2l.ai/_images/resnet-block.svg" alt="../_images/resnet-block.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet_block</span>(<span class="params">input_channels, num_channels, num_residuals,</span></span></span><br><span class="line"><span class="params"><span class="function">                 first_block=<span class="literal">False</span></span>):</span></span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">            blk.append(Residual(input_channels, num_channels,</span><br><span class="line">                                use_1x1conv=<span class="literal">True</span>, strides=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(Residual(num_channels, num_channels))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line">b2 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">b3 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">b4 = nn.Sequential(*resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">b5 = nn.Sequential(*resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5,</span><br><span class="line">                    nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                    nn.Flatten(), nn.Linear(<span class="number">512</span>, <span class="number">10</span>))</span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape:\t&#x27;</span>, X.shape)</span><br></pre></td></tr></table></figure><h3 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h3><p><img data-src="https://zh.d2l.ai/_images/densenet-block.svg" alt="../_images/densenet-block.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span>(<span class="params">input_channels, num_channels</span>):</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(input_channels), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(input_channels, num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DenseBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_convs, input_channels, num_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DenseBlock, self).__init__()</span><br><span class="line">        layer = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">            layer.append(conv_block(</span><br><span class="line">                num_channels * i + input_channels, num_channels))</span><br><span class="line">        self.net = nn.Sequential(*layer)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.net:</span><br><span class="line">            Y = blk(X)</span><br><span class="line">            <span class="comment"># 连接通道维度上每个块的输入和输出</span></span><br><span class="line">            X = torch.cat((X, Y), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><p>稠密网络主要由2部分构成：<em>稠密块</em>（dense block）和<em>过渡层</em>（transition layer）</p><p><img data-src="https://zh.d2l.ai/_images/densenet.svg" alt="../_images/densenet.svg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">blk = DenseBlock(<span class="number">2</span>, <span class="number">3</span>, <span class="number">10</span>)</span><br><span class="line">X = torch.randn(<span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">Y = blk(X)</span><br><span class="line">Y.shape</span><br></pre></td></tr></table></figure><p>由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。 而过渡层可以用来控制模型复杂度。 它通过1×1卷积层来减小通道数，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transition_block</span>(<span class="params">input_channels, num_channels</span>):</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(input_channels), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(input_channels, num_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">blk = transition_block(<span class="number">23</span>, <span class="number">10</span>)</span><br><span class="line">b1 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># num_channels为当前的通道数</span></span><br><span class="line">num_channels, growth_rate = <span class="number">64</span>, <span class="number">32</span></span><br><span class="line">num_convs_in_dense_blocks = [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">blks = []</span><br><span class="line"><span class="keyword">for</span> i, num_convs <span class="keyword">in</span> <span class="built_in">enumerate</span>(num_convs_in_dense_blocks):</span><br><span class="line">    blks.append(DenseBlock(num_convs, num_channels, growth_rate))</span><br><span class="line">    <span class="comment"># 上一个稠密块的输出通道数</span></span><br><span class="line">    num_channels += num_convs * growth_rate</span><br><span class="line">    <span class="comment"># 在稠密块之间添加一个转换层，使通道数量减半</span></span><br><span class="line">    <span class="keyword">if</span> i != <span class="built_in">len</span>(num_convs_in_dense_blocks) - <span class="number">1</span>:</span><br><span class="line">        blks.append(transition_block(num_channels, num_channels // <span class="number">2</span>))</span><br><span class="line">        num_channels = num_channels // <span class="number">2</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    b1, *blks,</span><br><span class="line">    nn.BatchNorm2d(num_channels), nn.ReLU(),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(num_channels, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><h3 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a>U-Net</h3><p><img data-src="https://s2.loli.net/2024/06/12/PIiVxGL71WYtqCy.png" alt="image-20240612201025297"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Parts of the U-Net model &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;(convolution =&gt; [BN] =&gt; ReLU) * 2&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, mid_channels=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mid_channels:</span><br><span class="line">            mid_channels = out_channels</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, mid_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(mid_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(mid_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Downscaling with maxpool then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Upscaling then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if bilinear, use the normal convolutions to reduce the number of channels</span></span><br><span class="line">        <span class="keyword">if</span> bilinear:</span><br><span class="line">            self.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels, in_channels // <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.up = nn.ConvTranspose2d(in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        <span class="comment"># input is CHW</span></span><br><span class="line">        diffY = x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]</span><br><span class="line">        diffX = x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x1 = F.pad(x1, [diffX // <span class="number">2</span>, diffX - diffX // <span class="number">2</span>,</span><br><span class="line">                        diffY // <span class="number">2</span>, diffY - diffY // <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        x = torch.cat([x2, x1], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OutConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(OutConv, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, bilinear=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line"></span><br><span class="line">        self.inc = (DoubleConv(n_channels, <span class="number">64</span>))</span><br><span class="line">        self.down1 = (Down(<span class="number">64</span>, <span class="number">128</span>))</span><br><span class="line">        self.down2 = (Down(<span class="number">128</span>, <span class="number">256</span>))</span><br><span class="line">        self.down3 = (Down(<span class="number">256</span>, <span class="number">512</span>))</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = (Down(<span class="number">512</span>, <span class="number">1024</span> // factor))</span><br><span class="line">        self.up1 = (Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear))</span><br><span class="line">        self.up2 = (Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear))</span><br><span class="line">        self.up3 = (Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear))</span><br><span class="line">        self.up4 = (Up(<span class="number">128</span>, <span class="number">64</span>, bilinear))</span><br><span class="line">        self.outc = (OutConv(<span class="number">64</span>, n_classes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        logits = self.outc(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><h3 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h3><p><img data-src="https://s2.loli.net/2024/06/12/XNfnA8pBt7cSZrw.png" alt="image-20240612223108822"  /></p><p><a href="https://zh.d2l.ai/chapter_computer-vision/ssd.html#id9">13.7. 单发多框检测（SSD） — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  #!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#  -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#  Copyleft (C) 2024 proanimer, Inc. All Rights Reserved</span></span><br><span class="line"><span class="comment">#   author:proanimer</span></span><br><span class="line"><span class="comment">#   createTime:2024/6/12 下午10:42</span></span><br><span class="line"><span class="comment">#   lastModifiedTime:2024/6/12 下午10:42</span></span><br><span class="line"><span class="comment">#   file:SSD.py</span></span><br><span class="line"><span class="comment">#   software: classicNets</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> vgg19</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        vgg = vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line">        vgg.<span class="built_in">eval</span>()</span><br><span class="line">        self.conv = vgg.features</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1024</span>, <span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line">        self.conv4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line">        self.conv5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line">        self.conv6 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        feat_1 = self.conv(x)</span><br><span class="line">        feat = self.conv1(feat_1)</span><br><span class="line">        feat_2 = self.conv2(feat)</span><br><span class="line">        feat_3 = self.conv3(feat_2)</span><br><span class="line">        feat_4 = self.conv4(feat_3)</span><br><span class="line">        feat_5 = self.conv5(feat_4)</span><br><span class="line">        feat_6 = self.conv6(feat_5)</span><br><span class="line">        <span class="keyword">return</span> feat_1, feat_2, feat_3, feat_4, feat_5, feat_6</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Feature-Pyramid-Networks-for-Object-Detection"><a href="#Feature-Pyramid-Networks-for-Object-Detection" class="headerlink" title="Feature Pyramid Networks for Object Detection"></a>Feature Pyramid Networks for Object Detection</h3><p><img data-src="https://s2.loli.net/2024/06/12/vBQ5meLa21hNuTW.png" alt="image-20240612201222802"></p><p><img data-src="https://upload-images.jianshu.io/upload_images/14932861-4a872d74db7a93ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/760/format/webp" alt="img" style="zoom:33%;" /></p><p>最后会将不同尺度得到的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  #!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#  -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#  Copyleft (C) 2024 proanimer, Inc. All Rights Reserved</span></span><br><span class="line"><span class="comment">#   author:proanimer</span></span><br><span class="line"><span class="comment">#   createTime:2024/6/12 下午9:13</span></span><br><span class="line"><span class="comment">#   lastModifiedTime:2024/6/12 下午9:13</span></span><br><span class="line"><span class="comment">#   file:fpn.py</span></span><br><span class="line"><span class="comment">#   software: classicNets</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##先定义ResNet基本类，或者可以说ResNet的基本砖块</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    expansion = <span class="number">4</span>  <span class="comment">##通道倍增数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_planes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        self.bottleneck = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_planes, planes, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(planes),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(planes, planes, <span class="number">3</span>, stride, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(planes),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(planes, self.expansion * planes, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(self.expansion * planes),</span><br><span class="line">        )</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        identity = x</span><br><span class="line">        out = self.bottleneck(x)</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##FPN类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FPN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, layers</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FPN, self).__init__()</span><br><span class="line">        self.inplanes = <span class="number">64</span></span><br><span class="line">        <span class="comment">###下面四句代码代表处理输入的C1模块--对应博客中的图</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">###搭建自下而上的C2,C3,C4,C5</span></span><br><span class="line">        self.layer1 = self._make_layer(<span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(<span class="number">128</span>, layers[<span class="number">1</span>], <span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(<span class="number">256</span>, layers[<span class="number">2</span>], <span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(<span class="number">512</span>, layers[<span class="number">3</span>], <span class="number">2</span>)</span><br><span class="line">        <span class="comment">###定义toplayer层，对C5减少通道数，得到P5</span></span><br><span class="line">        self.toplayer = nn.Conv2d(<span class="number">2048</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="comment">###代表3*3的卷积融合，目的是消除上采样过程带来的重叠效应，以生成最终的特征图。</span></span><br><span class="line">        self.smooth1 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.smooth2 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.smooth3 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">###横向连接，保证通道数目相同</span></span><br><span class="line">        self.latlayer1 = nn.Conv2d(<span class="number">1024</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        self.latlayer2 = nn.Conv2d(<span class="number">512</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        self.latlayer3 = nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">##作用：构建C2-C5砖块，注意stride为1和2的区别：得到C2没有经历下采样</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span>(<span class="params">self, planes, blocks, stride=<span class="number">1</span></span>):</span></span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != Bottleneck.expansion * planes:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.inplanes, Bottleneck.expansion * planes, <span class="number">1</span>, stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(Bottleneck.expansion * planes)</span><br><span class="line">            )</span><br><span class="line">        <span class="comment">###初始化需要一个list，代表左侧网络ResNet每一个阶段的Bottleneck的数量</span></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(Bottleneck(self.inplanes, planes, stride, downsample))</span><br><span class="line">        self.inplanes = planes * Bottleneck.expansion</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(Bottleneck(self.inplanes, planes))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="comment">###自上而下的上采样模块</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_upsample_add</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        _, _, H, W = y.shape</span><br><span class="line">        <span class="keyword">return</span> F.upsample(x, size=(H, W), mode=<span class="string">&#x27;bilinear&#x27;</span>) + y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment">###自下而上</span></span><br><span class="line">        c1 = self.maxpool(self.relu(self.bn1(self.conv1(x))))</span><br><span class="line">        c2 = self.layer1(c1)</span><br><span class="line">        c3 = self.layer2(c2)</span><br><span class="line">        c4 = self.layer3(c3)</span><br><span class="line">        c5 = self.layer4(c4)</span><br><span class="line">        <span class="comment">###自上而下</span></span><br><span class="line">        p5 = self.toplayer(c5)</span><br><span class="line">        p4 = self._upsample_add(p5, self.latlayer1(c4))</span><br><span class="line">        p3 = self._upsample_add(p4, self.latlayer2(c3))</span><br><span class="line">        p2 = self._upsample_add(p3, self.latlayer3(c2))</span><br><span class="line">        <span class="comment">###卷积融合，平滑处理</span></span><br><span class="line">        p4 = self.smooth1(p4)</span><br><span class="line">        p3 = self.smooth2(p3)</span><br><span class="line">        p2 = self.smooth3(p2)</span><br><span class="line">        <span class="keyword">return</span> p2, p3, p4, p5</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img data-src="https://img-blog.csdnimg.cn/img_convert/91f15dc3b7067e6ec693302399e05b0b.png" alt="img"></p><h3 id="Deformable-Conv"><a href="#Deformable-Conv" class="headerlink" title="Deformable Conv"></a>Deformable Conv</h3><p>可变形的卷积,还有可变形的attention. 即插即用类型.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeformConv2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inc, outc, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">None</span>, modulation=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            modulation (bool, optional): If True, Modulated Defomable Convolution (Deformable ConvNets v2).</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(DeformConv2d, self).__init__()</span><br><span class="line">        self.kernel_size = kernel_size</span><br><span class="line">        self.padding = padding</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.zero_padding = nn.ZeroPad2d(padding)</span><br><span class="line">        <span class="comment"># conv则是实际进行的卷积操作，注意这里步长设置为卷积核大小，因为与该卷积核进行卷积操作的特征图是由输出特征图中每个点扩展为其对应卷积核那么多个点后生成的。</span></span><br><span class="line">        self.conv = nn.Conv2d(inc, outc, kernel_size=kernel_size, stride=kernel_size, bias=bias)</span><br><span class="line">        <span class="comment"># p_conv是生成offsets所使用的卷积，输出通道数为卷积核尺寸的平方的2倍，代表对应卷积核每个位置横纵坐标都有偏移量。</span></span><br><span class="line">        self.p_conv = nn.Conv2d(inc, <span class="number">2</span>*kernel_size*kernel_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=stride)</span><br><span class="line">        nn.init.constant_(self.p_conv.weight, <span class="number">0</span>)</span><br><span class="line">        self.p_conv.register_backward_hook(self._set_lr)</span><br><span class="line"> </span><br><span class="line">        self.modulation = modulation <span class="comment"># modulation是可选参数,若设置为True,那么在进行卷积操作时,对应卷积核的每个位置都会分配一个权重。</span></span><br><span class="line">        <span class="keyword">if</span> modulation:</span><br><span class="line">            self.m_conv = nn.Conv2d(inc, kernel_size*kernel_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=stride)</span><br><span class="line">            nn.init.constant_(self.m_conv.weight, <span class="number">0</span>)</span><br><span class="line">            self.m_conv.register_backward_hook(self._set_lr)</span><br><span class="line"> </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_set_lr</span>(<span class="params">module, grad_input, grad_output</span>):</span></span><br><span class="line">        grad_input = (grad_input[i] * <span class="number">0.1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(grad_input)))</span><br><span class="line">        grad_output = (grad_output[i] * <span class="number">0.1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(grad_output)))</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        offset = self.p_conv(x)</span><br><span class="line">        <span class="keyword">if</span> self.modulation:</span><br><span class="line">            m = torch.sigmoid(self.m_conv(x))</span><br><span class="line"> </span><br><span class="line">        dtype = offset.data.<span class="built_in">type</span>()</span><br><span class="line">        ks = self.kernel_size</span><br><span class="line">        N = offset.size(<span class="number">1</span>) // <span class="number">2</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> self.padding:</span><br><span class="line">            x = self.zero_padding(x)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (b, 2N, h, w)</span></span><br><span class="line">        p = self._get_p(offset, dtype)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (b, h, w, 2N)</span></span><br><span class="line">        p = p.contiguous().permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        q_lt = p.detach().floor()</span><br><span class="line">        q_rb = q_lt + <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">        q_lt = torch.cat([torch.clamp(q_lt[..., :N], <span class="number">0</span>, x.size(<span class="number">2</span>)-<span class="number">1</span>), torch.clamp(q_lt[..., N:], <span class="number">0</span>, x.size(<span class="number">3</span>)-<span class="number">1</span>)], dim=-<span class="number">1</span>).long()</span><br><span class="line">        q_rb = torch.cat([torch.clamp(q_rb[..., :N], <span class="number">0</span>, x.size(<span class="number">2</span>)-<span class="number">1</span>), torch.clamp(q_rb[..., N:], <span class="number">0</span>, x.size(<span class="number">3</span>)-<span class="number">1</span>)], dim=-<span class="number">1</span>).long()</span><br><span class="line">        q_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], dim=-<span class="number">1</span>)</span><br><span class="line">        q_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], dim=-<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># clip p</span></span><br><span class="line">        p = torch.cat([torch.clamp(p[..., :N], <span class="number">0</span>, x.size(<span class="number">2</span>)-<span class="number">1</span>), torch.clamp(p[..., N:], <span class="number">0</span>, x.size(<span class="number">3</span>)-<span class="number">1</span>)], dim=-<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># bilinear kernel (b, h, w, N)</span></span><br><span class="line">        g_lt = (<span class="number">1</span> + (q_lt[..., :N].type_as(p) - p[..., :N])) * (<span class="number">1</span> + (q_lt[..., N:].type_as(p) - p[..., N:]))</span><br><span class="line">        g_rb = (<span class="number">1</span> - (q_rb[..., :N].type_as(p) - p[..., :N])) * (<span class="number">1</span> - (q_rb[..., N:].type_as(p) - p[..., N:]))</span><br><span class="line">        g_lb = (<span class="number">1</span> + (q_lb[..., :N].type_as(p) - p[..., :N])) * (<span class="number">1</span> - (q_lb[..., N:].type_as(p) - p[..., N:]))</span><br><span class="line">        g_rt = (<span class="number">1</span> - (q_rt[..., :N].type_as(p) - p[..., :N])) * (<span class="number">1</span> + (q_rt[..., N:].type_as(p) - p[..., N:]))</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (b, c, h, w, N)</span></span><br><span class="line">        x_q_lt = self._get_x_q(x, q_lt, N)</span><br><span class="line">        x_q_rb = self._get_x_q(x, q_rb, N)</span><br><span class="line">        x_q_lb = self._get_x_q(x, q_lb, N)</span><br><span class="line">        x_q_rt = self._get_x_q(x, q_rt, N)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (b, c, h, w, N)</span></span><br><span class="line">        x_offset = g_lt.unsqueeze(dim=<span class="number">1</span>) * x_q_lt + \</span><br><span class="line">                   g_rb.unsqueeze(dim=<span class="number">1</span>) * x_q_rb + \</span><br><span class="line">                   g_lb.unsqueeze(dim=<span class="number">1</span>) * x_q_lb + \</span><br><span class="line">                   g_rt.unsqueeze(dim=<span class="number">1</span>) * x_q_rt</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># modulation</span></span><br><span class="line">        <span class="keyword">if</span> self.modulation:</span><br><span class="line">            m = m.contiguous().permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">            m = m.unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line">            m = torch.cat([m <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(x_offset.size(<span class="number">1</span>))], dim=<span class="number">1</span>)</span><br><span class="line">            x_offset *= m</span><br><span class="line"> </span><br><span class="line">        x_offset = self._reshape_x_offset(x_offset, ks)</span><br><span class="line">        out = self.conv(x_offset)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_p_n</span>(<span class="params">self, N, dtype</span>):</span></span><br><span class="line">        <span class="comment"># 由于卷积核中心点位置是其尺寸的一半，于是中心点向左（上）方向移动尺寸的一半就得到起始点，向右（下）方向移动另一半就得到终止点</span></span><br><span class="line">        p_n_x, p_n_y = torch.meshgrid(</span><br><span class="line">            torch.arange(-(self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>, (self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>+<span class="number">1</span>),</span><br><span class="line">            torch.arange(-(self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>, (self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>+<span class="number">1</span>))</span><br><span class="line">        <span class="comment"># (2N, 1)</span></span><br><span class="line">        p_n = torch.cat([torch.flatten(p_n_x), torch.flatten(p_n_y)], <span class="number">0</span>)</span><br><span class="line">        p_n = p_n.view(<span class="number">1</span>, <span class="number">2</span>*N, <span class="number">1</span>, <span class="number">1</span>).<span class="built_in">type</span>(dtype)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> p_n</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_p_0</span>(<span class="params">self, h, w, N, dtype</span>):</span></span><br><span class="line">        <span class="comment"># p0_y、p0_x就是输出特征图每点映射到输入特征图上的纵、横坐标值。</span></span><br><span class="line">        p_0_x, p_0_y = torch.meshgrid(</span><br><span class="line">            torch.arange(<span class="number">1</span>, h*self.stride+<span class="number">1</span>, self.stride),</span><br><span class="line">            torch.arange(<span class="number">1</span>, w*self.stride+<span class="number">1</span>, self.stride))</span><br><span class="line">        </span><br><span class="line">        p_0_x = torch.flatten(p_0_x).view(<span class="number">1</span>, <span class="number">1</span>, h, w).repeat(<span class="number">1</span>, N, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        p_0_y = torch.flatten(p_0_y).view(<span class="number">1</span>, <span class="number">1</span>, h, w).repeat(<span class="number">1</span>, N, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        p_0 = torch.cat([p_0_x, p_0_y], <span class="number">1</span>).<span class="built_in">type</span>(dtype)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> p_0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输出特征图上每点（对应卷积核中心）加上其对应卷积核每个位置的相对（横、纵）坐标后再加上自学习的（横、纵坐标）偏移量。</span></span><br><span class="line">    <span class="comment"># p0就是将输出特征图每点对应到卷积核中心，然后映射到输入特征图中的位置；</span></span><br><span class="line">    <span class="comment"># pn则是p0对应卷积核每个位置的相对坐标；</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_p</span>(<span class="params">self, offset, dtype</span>):</span></span><br><span class="line">        N, h, w = offset.size(<span class="number">1</span>)//<span class="number">2</span>, offset.size(<span class="number">2</span>), offset.size(<span class="number">3</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (1, 2N, 1, 1)</span></span><br><span class="line">        p_n = self._get_p_n(N, dtype)</span><br><span class="line">        <span class="comment"># (1, 2N, h, w)</span></span><br><span class="line">        p_0 = self._get_p_0(h, w, N, dtype)</span><br><span class="line">        p = p_0 + p_n + offset</span><br><span class="line">        <span class="keyword">return</span> p</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_x_q</span>(<span class="params">self, x, q, N</span>):</span></span><br><span class="line">        <span class="comment"># 计算双线性插值点的4邻域点对应的权重</span></span><br><span class="line">        b, h, w, _ = q.size()</span><br><span class="line">        padded_w = x.size(<span class="number">3</span>)</span><br><span class="line">        c = x.size(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># (b, c, h*w)</span></span><br><span class="line">        x = x.contiguous().view(b, c, -<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (b, h, w, N)</span></span><br><span class="line">        index = q[..., :N]*padded_w + q[..., N:]  <span class="comment"># offset_x*w + offset_y</span></span><br><span class="line">        <span class="comment"># (b, c, h*w*N)</span></span><br><span class="line">        index = index.contiguous().unsqueeze(dim=<span class="number">1</span>).expand(-<span class="number">1</span>, c, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>).contiguous().view(b, c, -<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        x_offset = x.gather(dim=-<span class="number">1</span>, index=index).contiguous().view(b, c, h, w, N)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> x_offset</span><br><span class="line"> </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_reshape_x_offset</span>(<span class="params">x_offset, ks</span>):</span></span><br><span class="line">        b, c, h, w, N = x_offset.size()</span><br><span class="line">        x_offset = torch.cat([x_offset[..., s:s+ks].contiguous().view(b, c, h, w*ks) <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, N, ks)], dim=-<span class="number">1</span>)</span><br><span class="line">        x_offset = x_offset.contiguous().view(b, c, h*ks, w*ks)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> x_offset</span><br></pre></td></tr></table></figure><p>这些模型中NiN的1x1conv以及ResetNet的残差作为后面更复杂模型常用的方法,比如U-Net.而UNet,FPN这样的多尺度和残差连接又在许多目标检测等任务中使用.</p><h2 id="RNN-GRU-LSTM"><a href="#RNN-GRU-LSTM" class="headerlink" title="RNN GRU LSTM"></a>RNN GRU LSTM</h2><p><img data-src="https://zh.d2l.ai/_images/rnn.svg" alt="../_images/rnn.svg"></p><p><img data-src="https://zh.d2l.ai/_images/gru-3.svg" alt="../_images/gru-3.svg"></p><p><img data-src="https://zh.d2l.ai/_images/lstm-3.svg" alt="../_images/lstm-3.svg"></p><h1 id="黑夜前的光明"><a href="#黑夜前的光明" class="headerlink" title="黑夜前的光明"></a>黑夜前的光明</h1><blockquote><p>在transformer之前,我们认为泡沫即将吹破</p><p><a href="https://www.open-open.com/news/view/448d1219">李开复说2018年是AI泡沫破裂之年 LeCun点赞 - 李开复 - IT业界 - 深度开源 (open-open.com)</a></p><p><a href="https://www.thepaper.cn/newsDetail_forward_4103098">别吹了，AI的泡沫快被吹破了<em>澎湃号·湃客</em>澎湃新闻-The Paper</a></p></blockquote><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p><img data-src="https://zh.d2l.ai/_images/seq2seq-attention-details.svg" alt="../_images/seq2seq-attention-details.svg"></p><p><img data-src="https://zh.d2l.ai/_images/multi-head-attention.svg" alt="../_images/multi-head-attention.svg"></p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p><img data-src="https://zh.d2l.ai/_images/transformer.svg" alt="../_images/transformer.svg"></p><p><a href="https://nlp.seas.harvard.edu/annotated-transformer/#prelims">The Annotated Transformer (harvard.edu)</a></p><p>从宏观角度来看，Transformer的编码器是由多个相同的层叠加而成的，每个层都有两个子层（子层表示为sublayer）。第一个子层是<em>多头自注意力</em>（multi-head self-attention）汇聚；第二个子层是<em>基于位置的前馈网络</em>（positionwise feed-forward network）。具体来说，在计算编码器的自注意力时，查询、键和值都来自前一个编码器层的输出。受中残差网络的启发，每个子层都采用了<em>残差连接</em>（residual connection）。在Transformer中，对于序列中任何位置的任何输入𝑥∈𝑅𝑑，都要求满足sublayer(𝑥)∈𝑅𝑑，以便残差连接满足𝑥+sublayer(𝑥)∈𝑅𝑑。在残差连接的加法计算之后，紧接着应用<em>层规范化</em>（layer normalization）</p><p>因此，输入序列对应的每个位置，Transformer编码器都将输出一个𝑑维表示向量。</p><p>Transformer解码器也是由多个相同的层叠加而成的，并且层中使用了残差连接和层规范化。除了编码器中描述的两个子层之外，解码器还在这两个子层之间插入了第三个子层，称为<em>编码器－解码器注意力</em>（encoder-decoder attention）层。在编码器－解码器注意力中，查询来自前一个解码器层的输出，而键和值来自整个编码器的输出。在解码器自注意力中，查询、键和值都来自上一个解码器层的输出。但是，解码器中的每个位置只能考虑该位置之前的所有位置。这种<em>掩蔽</em>（masked）注意力保留了<em>自回归</em>（auto-regressive）属性，确保预测仅依赖于已生成的输出词元。</p><blockquote><p>transformer目前是通吃的,在cv,nlp,speech等领域的各种任务上都有实践</p><p>下面是使用transformer的通用目标检测方法</p></blockquote><h3 id="DETR"><a href="#DETR" class="headerlink" title="DETR"></a>DETR</h3><p><img data-src="https://github.com/facebookresearch/detr/raw/main/.github/DETR.png" alt="DETR"></p><p>与传统的计算机视觉技术不同，DETR 将物体检测作为一个直接的集合预测问题(a direct set prediction problem)来处理。它由一个基于集合的全局损失和一个变换器编码器-解码器架构组成，前者通过两端匹配强制进行唯一预测。</p><p>给定一个固定的小范围已学对象查询集，DETR 会对对象关系和全局图像上下文进行推理，从而直接并行输出最终的预测集。由于这种并行性，DETR 非常快速高效。</p><p><a href="https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb#scrollTo=h91rsIPl7tVl">detr_demo.ipynb - Colab (google.com)</a></p><h3 id="Deformable-DETR"><a href="#Deformable-DETR" class="headerlink" title="Deformable DETR"></a>Deformable DETR</h3><p><img data-src="https://s2.loli.net/2024/06/12/UdvnyZqNjWB51SH.png" alt="image-20240612220634309"></p><p><img data-src="https://s2.loli.net/2024/06/12/BpS6JWYKnGA5Rty.png" alt="image-20240612220643631"></p><h2 id="Diffusion-Models"><a href="#Diffusion-Models" class="headerlink" title="Diffusion Models"></a>Diffusion Models</h2><blockquote><p>在VAE,GAN之后的生成式之光.</p></blockquote><p><img data-src="https://s2.loli.net/2024/06/12/XmtBQZG31L4Wi89.png" alt="image-20240612212239385"></p><p>具体代码参看<a href="https://huggingface.co/blog/annotated-diffusion">The Annotated Diffusion Model (huggingface.co)</a></p><ul><li><a href="https://angusturner.github.io/generative_models/2021/06/29/diffusion-probabilistic-models-I.html">Diffusion Models as a kind of VAE | Angus Turner</a></li><li><a href="https://github.com/yangqy1110/Diffusion-Models?tab=readme-ov-file">yangqy1110/Diffusion-Models: 扩散模型原理和pytorch代码实现初学资料汇总 (github.com)</a></li><li><a href="https://github.com/mikonvergence/DiffusionFastForward/tree/master">mikonvergence/DiffusionFastForward: DiffusionFastForward: a free course and experimental framework for diffusion-based generative models (github.com)</a></li><li><a href="https://github.com/diff-usion/Awesome-Diffusion-Models?tab=readme-ov-file">diff-usion/Awesome-Diffusion-Models: A collection of resources and papers on Diffusion Models (github.com)</a></li></ul><h1 id="现代大模型"><a href="#现代大模型" class="headerlink" title="现代大模型"></a>现代大模型</h1><blockquote><p>目前,它是正处于统治地位. 当然,人们也希望有其他方法.</p></blockquote><h2 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h2><p><img data-src="https://s2.loli.net/2024/06/12/RHxAKYM4NFjnTpu.png" alt="image-20240612203226976"></p><p><img data-src="https://s2.loli.net/2024/06/12/pK6PTi7awbfCEBG.png" alt="image-20240612203251260"></p><p>可以考虑参考Andrej Karpathy的nanoGPT以及GPT2复现.</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>学习Pytorch<a href="https://www.learnpytorch.io/">Zero to Mastery Learn PyTorch for Deep Learning</a></p><p>学习经典<a href="https://zh.d2l.ai/">《动手学深度学习》 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p><p>学习attention与transformer</p><ul><li><a href="https://nlp.seas.harvard.edu/annotated-transformer/#prelims">The Annotated Transformer (harvard.edu)</a></li><li><p><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io)</a></p></li><li><p><a href="https://github.com/lucidrains/vit-pytorch">lucidrains/vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch (github.com)</a></p></li><li><p><a href="https://github.com/changzy00/pytorch-attention">changzy00/pytorch-attention: 🦖Pytorch implementation of popular Attention Mechanisms, Vision Transformers, MLP-Like models and CNNs.🔥🔥🔥 (github.com)</a></p></li><li><a href="https://github.com/xmu-xiaoma666/External-Attention-pytorch">xmu-xiaoma666/External-Attention-pytorch: 🍀 Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.⭐⭐⭐ (github.com)</a></li></ul><p>学习llm</p><ul><li><p><a href="https://github.com/rasbt/LLMs-from-scratch">https://github.com/rasbt/LLMs-from-scratch</a></p></li><li><p><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&amp;ab_channel=AndrejKarpathy">Let’s build GPT: from scratch, in code, spelled out. (youtube.com)</a></p></li><li><p><a href="https://github.com/naklecha/llama3-from-scratch">naklecha/llama3-from-scratch: llama3 implementation one matrix multiplication at a time (github.com)</a></p></li><li><a href="https://cyrilzakka.github.io/llm-playbook/index.html">Introduction - The Large Language Model Playbook (cyrilzakka.github.io)</a></li></ul><p>学习扩散模型和大模型的个人博客</p><ul><li><a href="https://spaces.ac.cn/">科学空间|Scientific Spaces</a></li><li><a href="https://karpathy.github.io/">Andrej Karpathy blog</a></li><li><a href="https://lilianweng.github.io/">Lil’Log (lilianweng.github.io)</a></li></ul><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;总结一下学习人工智能/深度学习过程中个人觉得重要的方法和经验. &lt;/p&gt;
&lt;p&gt;主要关于模型.&lt;br&gt;</summary>
    
    
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>modern cpp learning(三)</title>
    <link href="https://www.sekyoro.top/2024/06/10/modern-cpp-learning-%E4%B8%89/"/>
    <id>https://www.sekyoro.top/2024/06/10/modern-cpp-learning-%E4%B8%89/</id>
    <published>2024-06-10T12:18:08.000Z</published>
    <updated>2024-06-27T03:03:00.042Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>并行与并发,文件系统与一些资料分享<br><span id="more"></span></p><h2 id="并行与并发"><a href="#并行与并发" class="headerlink" title="并行与并发"></a>并行与并发</h2><h3 id="并行基础"><a href="#并行基础" class="headerlink" title="并行基础"></a>并行基础</h3><p><code>std::thread</code> 用于创建一个执行的线程实例，所以它是一切并发编程的基础，使用时需要包含 <code>&lt;thread&gt;</code> 头文件， 它提供了很多基本的线程操作，例如 <code>get_id()</code> 来获取所创建线程的线程 ID，使用 <code>join()</code> 来等待一个线程结束（与该线程汇合）等等，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::thread <span class="title">t</span><span class="params">([]()&#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        std::cout &lt;&lt; <span class="string">&quot;hello world.&quot;</span> &lt;&lt; std::endl;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line">    t.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个新线程的基本步骤如下:</p><ol><li>定义一个函数或 lambda 表达式作为线程的执行体。</li><li>使用 <code>std::thread</code> 类的构造函数创建一个新线程,并传入线程执行体。</li><li>管理线程的生命周期,通常使用 <code>join()</code> 或 <code>detach()</code> 方法</li></ol><p><code>std::thread</code> 类提供了以下常用的成员函数:</p><ol><li><code>join()</code>: <strong>阻塞当前线程</strong>,直到被关联的线程执行完毕。</li><li><code>detach()</code>: 将线程设置为分离状态,主<strong>线程不会等待子线程结束</strong>。</li><li><code>get_id()</code>: 获取线程的唯一标识符。</li><li><code>swap(other)</code>: 交换两个线程对象的底层线程。</li><li><code>native_handle()</code>: 获取底层操作系统的线程句柄。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;functional&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">longRunningTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 模拟一个耗时的任务</span></span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">5</span>));</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Long running task completed.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建并分离一个新线程</span></span><br><span class="line">    std::<span class="built_in">thread</span>(std::<span class="built_in">move</span>(longRunningTask)).<span class="built_in">detach</span>();</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Main thread continuing...&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 主线程继续执行其他任务</span></span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">2</span>));</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Main thread exiting.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="互斥量与临界区"><a href="#互斥量与临界区" class="headerlink" title="互斥量与临界区"></a>互斥量与临界区</h3><p>我们在操作系统、亦或是数据库的相关知识中已经了解过了有关并发技术的基本知识，<code>mutex</code> 就是其中的核心之一。 C++11 引入了 <code>mutex</code> 相关的类，其所有相关的函数都放在 <code>&lt;mutex&gt;</code> 头文件中。</p><p><code>std::mutex</code> 是 C++11 中最基本的互斥量类，可以<strong>通过构造 <code>std::mutex</code> 对象创建互斥量， 而通过其成员函数 <code>lock()</code> 可以进行上锁，<code>unlock()</code> 可以进行解锁</strong>。 </p><p>但是在实际编写代码的过程中，最好<strong>不去直接调用成员函数， 因为调用成员函数就需要在每个临界区的出口处调用 <code>unlock()</code></strong>，当然，还包括异常。</p><p>而 C++11 为互斥量提供了一个 RAII 机制的模板类 <code>std::lock_guard</code>。</p><p>RAII 在不失代码简洁性的同时，很好的保证了代码的异常安全性。</p><p>在 RAII 用法下，对于临界区的互斥量的创建只需要在作用域的开始部分，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> v = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">critical_section</span><span class="params">(<span class="keyword">int</span> change_v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> std::mutex mtx;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mtx)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行竞争操作</span></span><br><span class="line">    v = change_v;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 离开此作用域后 mtx 会被释放</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::thread <span class="title">t1</span><span class="params">(critical_section, <span class="number">2</span>)</span>, <span class="title">t2</span><span class="params">(critical_section, <span class="number">3</span>)</span></span>;</span><br><span class="line">    t1.<span class="built_in">join</span>();</span><br><span class="line">    t2.<span class="built_in">join</span>();</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; v &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> C++ 保证了所有栈对象在生命周期结束时会被销毁，所以这样的代码也是异常安全的。</p><ul><li>而 <code>std::unique_lock</code> 则是相对于 <code>std::lock_guard</code> 出现的，<code>std::unique_lock</code> 更加灵活， <strong><code>std::unique_lock</code> 的对象会以独占所有权（没有其他的 <code>unique_lock</code> 对象同时拥有某个 <code>mutex</code> 对象的所有权） 的方式管理 <code>mutex</code> 对象上的上锁和解锁</strong>的操作。所以在并发编程中，推荐使用 <code>std::unique_lock</code>。</li><li><strong><code>std::lock_guard</code> 不能显式的调用 <code>lock</code> 和 <code>unlock</code>， 而 <code>std::unique_lock</code> 可以在声明后的任意位置调用，</strong> 可以缩小锁的作用范围，提供更高的并发度。</li><li>如果<strong>用到了条件变量 <code>std::condition_variable::wait</code> 则必须使用 <code>std::unique_lock</code> 作为参数</strong>。</li></ul><p>使用lock_guard代替lock,unlock成员函数-&gt;使用unique_lock替代lock_guard可以独占并显式调用lock,unlock.</p><blockquote><p><code>std::lock_guard</code> 是一个非常简单的互斥锁管理器。<strong>它会在构造时自动获取互斥锁,并在析构时自动释放互斥锁</strong>。这样可以确保互斥锁的正确使用,并避免手动解锁的错误。</p><p><code>std::unique_lock</code> 提供了<strong>更多的灵活性和控制</strong>。它可以<strong>手动锁定和解锁互斥锁</strong>,并支持<strong>延迟锁定</strong>、<strong>有条件地等待</strong>等功能</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> v = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">critical_section</span><span class="params">(<span class="keyword">int</span> change_v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> std::mutex mtx;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mtx)</span></span>;</span><br><span class="line">    <span class="comment">// 执行竞争操作</span></span><br><span class="line">    v = change_v;</span><br><span class="line">    std::cout &lt;&lt; v &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// 将锁进行释放</span></span><br><span class="line">    lock.<span class="built_in">unlock</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在此期间，任何人都可以抢夺 v 的持有权</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开始另一组竞争操作，再次加锁</span></span><br><span class="line">    lock.<span class="built_in">lock</span>();</span><br><span class="line">    v += <span class="number">1</span>;</span><br><span class="line">    std::cout &lt;&lt; v &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::thread <span class="title">t1</span><span class="params">(critical_section, <span class="number">2</span>)</span>, <span class="title">t2</span><span class="params">(critical_section, <span class="number">3</span>)</span></span>;</span><br><span class="line">    t1.<span class="built_in">join</span>();</span><br><span class="line">    t2.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;condition_variable&gt;</span></span></span><br><span class="line"></span><br><span class="line">std::mutex mtx;</span><br><span class="line">std::condition_variable cv;</span><br><span class="line"><span class="keyword">bool</span> data_ready = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer_thread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(mtx)</span></span>;</span><br><span class="line">        <span class="comment">// 模拟生产数据</span></span><br><span class="line">        std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">1</span>));</span><br><span class="line">        data_ready = <span class="literal">true</span>;</span><br><span class="line">        cv.<span class="built_in">notify_one</span>();</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consumer_thread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(mtx)</span></span>;</span><br><span class="line">    cv.<span class="built_in">wait</span>(lk, [] &#123; <span class="keyword">return</span> data_ready; &#125;);</span><br><span class="line">    <span class="comment">// 消费数据</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Data consumed!&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::thread <span class="title">producer</span><span class="params">(producer_thread)</span></span>;</span><br><span class="line">    <span class="function">std::thread <span class="title">consumer</span><span class="params">(consumer_thread)</span></span>;</span><br><span class="line">    producer.<span class="built_in">join</span>();</span><br><span class="line">    consumer.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="期物-Future"><a href="#期物-Future" class="headerlink" title="期物(Future)"></a>期物(Future)</h3><p>期物（Future）表现为 <code>std::future</code>，它<strong>提供了一个访问异步操作结果的途径</strong>，这句话很不好理解。 为了理解这个特性，我们需要先理解一下在 C++11 之前的多线程行为。</p><p>试想，如果我们的<strong>主线程 A 希望新开辟一个线程 B 去执行某个我们预期的任务，并返回我一个结果。 而这时候，线程 A 可能正在忙其他的事情，无暇顾及 B 的结果， 所以我们会很自然的希望能够在某个特定的时间获得线程 B 的结果。</strong></p><p>在 C++11 的 <code>std::future</code> 被引入之前，通常的做法是： 创建一个线程 A，在线程 A 里启动任务 B，<strong>当准备完毕后发送一个事件，并将结果保存在全局变量中。 而主函数线程 A 里正在做其他的事情，当需要结果的时候，调用一个线程等待函数来获得执行的结果</strong>。</p><p>C++11 提供的 <code>std::future</code> 简化了这个流程，可以用来获取异步任务的结果。 自然地，我们很容易能够想象到把它作为一种简单的线程同步手段，即屏障（barrier）</p><p>额外使用 <code>std::packaged_task</code>，它可以用来封装任何可以调用的目标，从而用于实现异步的调用。 举例来说：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;future&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将一个返回值为7的 lambda 表达式封装到 task 中</span></span><br><span class="line">    <span class="comment">// std::packaged_task 的模板参数为要封装函数的类型</span></span><br><span class="line">    <span class="function">std::packaged_task&lt;<span class="title">int</span><span class="params">()</span>&gt; <span class="title">task</span><span class="params">([]()&#123;<span class="keyword">return</span> <span class="number">7</span>;&#125;)</span></span>;</span><br><span class="line">    <span class="comment">// 获得 task 的期物</span></span><br><span class="line">    std::future&lt;<span class="keyword">int</span>&gt; result = task.<span class="built_in">get_future</span>(); <span class="comment">// 在一个线程中执行 task</span></span><br><span class="line">    std::<span class="built_in">thread</span>(std::<span class="built_in">move</span>(task)).<span class="built_in">detach</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;waiting...&quot;</span>;</span><br><span class="line">    result.<span class="built_in">wait</span>(); <span class="comment">// 在此设置屏障，阻塞到期物的完成</span></span><br><span class="line">    <span class="comment">// 输出执行结果</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;done!&quot;</span> &lt;&lt; std:: endl &lt;&lt; <span class="string">&quot;future result is &quot;</span></span><br><span class="line">              &lt;&lt; result.<span class="built_in">get</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在封装好要调用的目标后，可以使用 <code>get_future()</code> 来获得一个 <code>std::future</code> 对象，以便之后实施线程同步。</p><blockquote><p>future对象有wait和get方法分别等待与获得结果.</p><p><code>std::promise</code> 是 C++11 标准库中提供的一个类,它用于在异步任务中设置返回值或异常。它通常与 <code>std::future</code> 配合使用,形成一种生产者-消费者的模式。</p><p>简单地说,<code>std::promise</code> 就像一个”承诺”,它代表着一个正在进行的异步操作。当这个异步操作完成时,<code>std::promise</code> 就会”兑现”这个承诺,也就是设置返回值或异常。而 <code>std::future</code> 则是用来”消费”这个承诺,也就是获取异步操作的结果.</p><p>它是一个非常有用的工具,可以帮助您在异步任务中<strong>设置返回值或异常,</strong>并与 <code>std::future</code> 一起,构建更加复杂和强大的并发程序。</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;future&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">worker_thread</span><span class="params">(std::promise&lt;<span class="keyword">int</span>&gt;&amp; prom)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 模拟一些耗时的计算</span></span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">2</span>));</span><br><span class="line">    prom.<span class="built_in">set_value</span>(<span class="number">42</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::promise&lt;<span class="keyword">int</span>&gt; promise;</span><br><span class="line">    std::future&lt;<span class="keyword">int</span>&gt; future = promise.<span class="built_in">get_future</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function">std::thread <span class="title">worker</span><span class="params">(worker_thread, std::ref(promise))</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> result = future.<span class="built_in">get</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Result: &quot;</span> &lt;&lt; result &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    worker.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;future&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建一个异步任务</span></span><br><span class="line">    std::future&lt;<span class="keyword">int</span>&gt; result = std::<span class="built_in">async</span>([] &#123;</span><br><span class="line">        std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">3</span>));</span><br><span class="line">        <span class="keyword">return</span> <span class="number">42</span>;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待异步任务完成,最多等待2秒</span></span><br><span class="line">    std::future_status status = result.<span class="built_in">wait_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (status == std::future_status::ready) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Async task completed, result: &quot;</span> &lt;&lt; result.<span class="built_in">get</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (status == std::future_status::timeout) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Async task timed out.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Async task was deferred.&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;future&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">worker_thread</span><span class="params">(std::promise&lt;<span class="keyword">int</span>&gt;&amp; prom)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 模拟一个可能抛出异常的操作</span></span><br><span class="line">        <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;Something went wrong!&quot;</span>);</span><br><span class="line">        prom.<span class="built_in">set_value</span>(<span class="number">42</span>);</span><br><span class="line">    &#125; <span class="built_in"><span class="keyword">catch</span></span> (...) &#123;</span><br><span class="line">        prom.<span class="built_in">set_exception</span>(std::<span class="built_in">current_exception</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::promise&lt;<span class="keyword">int</span>&gt; promise;</span><br><span class="line">    std::future&lt;<span class="keyword">int</span>&gt; future = promise.<span class="built_in">get_future</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function">std::thread <span class="title">worker</span><span class="params">(worker_thread, std::ref(promise))</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> result = future.<span class="built_in">get</span>();</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Result: &quot;</span> &lt;&lt; result &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="built_in"><span class="keyword">catch</span></span> (<span class="keyword">const</span> std::exception&amp; e) &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Error: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    worker.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><p>条件变量 <code>std::condition_variable</code> 是为了解决死锁而生，当互斥操作不够用而引入的。 比如，<strong>线程可能需要等待某个条件为真才能继续执行， 而一个忙等待循环中可能会导致所有其他线程都无法进入临界区使得条件为真时，就会发生死锁</strong>。</p><p> 所以，<code>condition_variable</code> 对象被创建出现主要就是用于<strong>唤醒等待线程从而避免死锁</strong>。 <strong><code>std::condition_variable</code>的 <code>notify_one()</code> 用于唤醒一个线程； <code>notify_all()</code> 则是通知所有线程</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;condition_variable&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::queue&lt;<span class="keyword">int</span>&gt; produced_nums;</span><br><span class="line">    std::mutex mtx;</span><br><span class="line">    std::condition_variable cv;</span><br><span class="line">    <span class="keyword">bool</span> notified = <span class="literal">false</span>;  <span class="comment">// 通知信号</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 生产者</span></span><br><span class="line">    <span class="keyword">auto</span> producer = [&amp;]() &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; ; i++) &#123;</span><br><span class="line">            std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">milliseconds</span>(<span class="number">900</span>));</span><br><span class="line">            <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mtx)</span></span>;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;producing &quot;</span> &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">            produced_nums.<span class="built_in">push</span>(i);</span><br><span class="line">            notified = <span class="literal">true</span>;</span><br><span class="line">            cv.<span class="built_in">notify_all</span>(); <span class="comment">// 此处也可以使用 notify_one</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// 消费者</span></span><br><span class="line">    <span class="keyword">auto</span> consumer = [&amp;]() &#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            std::unique_lock&lt;std::mutex&gt; <span class="built_in">lock</span>(mtx);</span><br><span class="line">            <span class="keyword">while</span> (!notified) &#123;  <span class="comment">// 避免虚假唤醒</span></span><br><span class="line">                cv.<span class="built_in">wait</span>(lock);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 短暂取消锁，使得生产者有机会在消费者消费空前继续生产</span></span><br><span class="line">            lock.<span class="built_in">unlock</span>();</span><br><span class="line">            <span class="comment">// 消费者慢于生产者</span></span><br><span class="line">            std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">milliseconds</span>(<span class="number">1000</span>));</span><br><span class="line">            lock.<span class="built_in">lock</span>();</span><br><span class="line">            <span class="keyword">while</span> (!produced_nums.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                std::cout &lt;&lt; <span class="string">&quot;consuming &quot;</span> &lt;&lt; produced_nums.<span class="built_in">front</span>() &lt;&lt; std::endl;</span><br><span class="line">                produced_nums.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            notified = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分别在不同的线程中运行</span></span><br><span class="line">    <span class="function">std::thread <span class="title">p</span><span class="params">(producer)</span></span>;</span><br><span class="line">    std::thread cs[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">        cs[i] = std::<span class="built_in">thread</span>(consumer);</span><br><span class="line">    &#125;</span><br><span class="line">    p.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">        cs[i].<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>值得一提的是，在生产者中我们虽然可以使用 <code>notify_one()</code>，但实际上并不建议在此处使用， 因为<strong>在多消费者的情况下，我们的消费者实现中简单放弃了锁的持有，这使得可能让其他消费者争夺此锁，从而更好的利用多个消费者之间的并发</strong>。</p><p>话虽如此，但实际上<strong>因为 <code>std::mutex</code> 的排他性， 我们根本无法期待多个消费者能真正意义上的并行消费队列的中生产的内容，我们仍需要粒度更细的手段</strong>。</p><h3 id="原子操作与内存模型"><a href="#原子操作与内存模型" class="headerlink" title="原子操作与内存模型"></a>原子操作与内存模型</h3><p>上面的例子中,编译器可能对变量 <code>notified</code> 存在优化，例如将其作为一个寄存器的值， 从而导致消费者线程永远无法观察到此值的变化.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::thread <span class="title">t1</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">while</span> (flag != <span class="number">1</span>);</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">int</span> b = a;</span></span></span><br><span class="line"><span class="params"><span class="function">        std::cout &lt;&lt; <span class="string">&quot;b = &quot;</span> &lt;&lt; b &lt;&lt; std::endl;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::thread <span class="title">t2</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        a = <span class="number">5</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">        flag = <span class="number">1</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line"></span><br><span class="line">    t1.<span class="built_in">join</span>();</span><br><span class="line">    t2.<span class="built_in">join</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从直观上看，<code>t2</code> 中 <code>a = 5;</code> 这一条语句似乎总在 <code>flag = 1;</code> 之前得到执行，而 <code>t1</code> 中 <code>while (flag != 1)</code> 似乎保证了 <code>std::cout &lt;&lt; &quot;b = &quot; &lt;&lt; b &lt;&lt; std::endl;</code> 不会再标记被改变前执行。从逻辑上看，似乎 <code>b</code> 的值应该等于 5。 <strong>但实际情况远比此复杂得多，或者说这段代码本身属于未定义的行为，因为对于 <code>a</code> 和 <code>flag</code> 而言，他们在两个并行的线程中被读写， 出现了竞争</strong>。除此之外，即便我们忽略竞争读写，仍然可能受 CPU 的乱序执行，编译器对指令的重排的影响， 导致 <code>a = 5</code> 发生在 <code>flag = 1</code> 之后。从而 <code>b</code> 可能输出 0。</p><h4 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h4><p><code>std::mutex</code> 可以解决上面出现的并发读写的问题，但<strong>互斥锁是操作系统级的功能， 这是因为一个互斥锁的实现通常包含两条基本原理：</strong></p><ol><li><strong>提供线程间自动的状态转换，即『锁住』这个状态</strong></li><li><strong>保障在互斥锁操作期间，所操作变量的内存与临界区外进行隔离</strong></li></ol><p><strong>这是一组非常强的同步条件，换句话说当最终编译为 CPU 指令时会表现为非常多的指令</strong>（我们之后再来看如何实现一个简单的互斥锁）。 这对于一个仅需原子级操作（没有中间态）的变量，似乎太苛刻了。</p><p>关于同步条件的研究有着非常久远的历史，我们在这里不进行赘述。读者应该明白，现代 CPU 体系结构提供了 CPU 指令级的原子操作， 因此在<strong>多线程下共享变量的读写这一问题上， C++11 中还引入了 <code>std::atomic</code> 模板，使得我们能实例化原子类型，并将一个原子写操作从一组指令，最小化到单个 CPU 指令</strong>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::atomic&lt;<span class="keyword">int</span>&gt; counter;</span><br></pre></td></tr></table></figure><p>其为整数或浮点数的原子类型提供了基本的数值成员函数，举例来说， 包括 <code>fetch_add</code>, <code>fetch_sub</code> 等，同时通过重载方便的提供了对应的 <code>+</code>，<code>-</code> 版本</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line">std::atomic&lt;<span class="keyword">int</span>&gt; count = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::thread <span class="title">t1</span><span class="params">([]()&#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        count.fetch_add(<span class="number">1</span>);</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line">    <span class="function">std::thread <span class="title">t2</span><span class="params">([]()&#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        count++;        <span class="comment">// 等价于 fetch_add</span></span></span></span><br><span class="line"><span class="params"><span class="function">        count += <span class="number">1</span>;     <span class="comment">// 等价于 fetch_add</span></span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;)</span></span>;</span><br><span class="line">    t1.<span class="built_in">join</span>();</span><br><span class="line">    t2.<span class="built_in">join</span>();</span><br><span class="line">    std::cout &lt;&lt; count &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并非所有的类型都能提供原子操作，这是因为原子操作的可行性取决于具体的 CPU 架构，以及所实例化的类型结构是否能够满足该 CPU 架构对内存对齐 条件的要求，因而我们总是可以通过 <code>std::atomic&lt;T&gt;::is_lock_free</code> 来检查该原子类型是否需支持原子操作.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span> &#123;</span></span><br><span class="line">    <span class="keyword">float</span> x;</span><br><span class="line">    <span class="keyword">int</span> y;</span><br><span class="line">    <span class="keyword">long</span> <span class="keyword">long</span> z;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::atomic&lt;A&gt; a;</span><br><span class="line">    std::cout &lt;&lt; std::boolalpha &lt;&lt; a.<span class="built_in">is_lock_free</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h4><p><strong>并行执行的多个线程</strong>，从某种宏观层面上讨论，可以<strong>粗略的视为一种分布式系统</strong>。 <strong>在分布式系统中，任何通信乃至本地操作都需要消耗一定时间，甚至出现不可靠的通信</strong>。</p><p>如果我们强行将一个变量 <code>v</code> 在多个线程之间的操作设为原子操作，即任何一个线程在操作完 <code>v</code> 后， 其他线程均能<strong>同步</strong>感知到 <code>v</code> 的变化，则对于变量 <code>v</code> 而言，表现为顺序执行的程序，它并没有由于引入多线程 而得到任何效率上的收益。对此有什么办法能够适当的加速呢？答案便是削弱原子操作的在进程间的同步条件。</p><p>从原理上看，每个线程可以对应为一个集群节点，而线程间的通信也几乎等价于集群节点间的通信。 削弱进程间的同步条件，通常我们会考虑四种不同的一致性模型：</p><ol><li><p>线性一致性：又称强一致性或原子一致性。它要求任何一次读操作都能读到某个数据的最近一次写的数据，并且所有线程的操作顺序与全局时钟下的顺序是一致的。</p></li><li><p>```</p><pre><code>    x.store(1)      x.load()</code></pre><p>T1 ————-+————————+———&gt;</p></li></ol><p>   T2 —————————-+——————-&gt;<br>                   x.store(2)<br>   <figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   在这种情况下线程 `T1`, `T2` 对 `x` 的两次写操作是原子的，且 `x.store(<span class="number">1</span>)` 是严格的发生在 `x.store(<span class="number">2</span>)` 之前，`x.store(<span class="number">2</span>)` 严格的发生在 `x.load()` 之前。 值得一提的是，线性一致性对全局时钟的要求是难以实现的，这也是人们不断研究比这个一致性更弱条件下其他一致性的算法的原因。</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 顺序一致性：同样要求任何一次读操作都能读到数据最近一次写入的数据，但未要求与全局时钟的顺序一致。</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>           x.store(1)  x.store(3)   x.load()<br>   T1 ————-+—————-+—————+——-&gt;</p><p>   T2 ———————-+———————————&gt;<br>                 x.store(2)</p><p>   或者</p><pre><code>       x.store(1)  x.store(3)   x.load()</code></pre><p>   T1 ————-+—————-+—————+——-&gt;</p><p>   T2 ———+———————————————-&gt;<br>         x.store(2)<br>   <figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   在顺序一致性的要求下，`x.load()` 必须读到最近一次写入的数据，因此 `x.store(<span class="number">2</span>)` 与 `x.store(<span class="number">1</span>)` 并无任何先后保障，即 只要 `T2` 的 `x.store(<span class="number">2</span>)` 发生在 `x.store(<span class="number">3</span>)` 之前即可。</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>. 因果一致性：它的要求进一步降低，只需要有因果关系的操作顺序得到保障，而非因果关系的操作顺序则不做要求。</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>         a = 1      b = 2<br>   T1 ——+—————-+——————————————&gt;</p><p>   T2 ———+——————————+————+————&gt;<br>         x.store(3)         c = a + b    y.load()</p><p>   或者</p><pre><code>     a = 1      b = 2</code></pre><p>   T1 ——+—————-+——————————————&gt;</p><p>   T2 ———+——————————+————+————&gt;<br>         x.store(3)          y.load()   c = a + b</p><p>   亦或者</p><pre><code>    b = 2       a = 1</code></pre><p>   T1 ——+—————-+——————————————&gt;</p><p>   T2 ———+——————————+————+————&gt;<br>         y.load()            c = a + b  x.store(3)<br>   <figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   上面给出的三种例子都是属于因果一致的，因为整个过程中，只有 `c` 对 `a` 和 `b` 产生依赖，而 `x` 和 `y` 在此例子中表现为没有关系（但实际情况中我们需要更详细的信息才能确定 `x` 与 `y` 确实无关）</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>. 最终一致性：是最弱的一致性要求，它只保障某个操作在未来的某个时间节点上会被观察到，但并未要求被观察到的时间。因此我们甚至可以对此条件稍作加强，例如规定某个操作被观察到的时间总是有界的。当然这已经不在我们的讨论范围之内了。</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>       x.store(3)  x.store(4)<br>   T1 ——+—————-+——————————————————————&gt;</p><p>   T2 ————-+——————+——————————+————+————&gt;<br>            x.read      x.read()           x.read()   x.read()<br>   <figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在上面的情况中，如果我们假设 x 的初始值为 <span class="number">0</span>，则 `T2` 中四次 `x.read()` 结果可能但不限于以下情况：</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>   3 4 4 4 // x 的写操作被很快观察到<br>   0 3 3 4 // x 的写操作被观察到的时间存在一定延迟<br>   0 0 0 4 // 最后一次读操作读到了 x 的最终值，但此前的变化并未观察到<br>   0 0 0 0 // 在当前时间段内 x 的写操作均未被观察到，<br>           // 但未来某个时间点上一定能观察到 x 为 4 的情况<br>   <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 内存顺序</span><br><span class="line"></span><br><span class="line">为了追求极致的性能，实现各种强度要求的一致性，C++<span class="number">11</span> 为原子操作定义了六种不同的内存顺序 `std::memory_order` 的选项，表达了四种多线程间的同步模型：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 宽松模型：在此模型下，单个线程内的原子操作都是顺序执行的，不允许指令重排，但不同线程间原子操作的顺序是任意的。类型通过 `std::memory_order_relaxed` 指定。我们来看一个例子：</span><br><span class="line"></span><br><span class="line">   ```cpp</span><br><span class="line">   std::atomic&lt;<span class="keyword">int</span>&gt; counter = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">   std::vector&lt;std::thread&gt; vt;</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">       vt.<span class="built_in">emplace_back</span>([&amp;]()&#123;</span><br><span class="line">           counter.<span class="built_in">fetch_add</span>(<span class="number">1</span>, std::memory_order_relaxed);</span><br><span class="line">       &#125;);</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; t : vt) &#123;</span><br><span class="line">       t.<span class="built_in">join</span>();</span><br><span class="line">   &#125;</span><br><span class="line">   std::cout &lt;&lt; <span class="string">&quot;current counter:&quot;</span> &lt;&lt; counter &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure></p><ol><li><p>释放/消费模型：在此模型中，我们开始限制进程间的操作顺序，如果某个线程需要修改某个值，但另一个线程会对该值的某次操作产生依赖，即后者依赖前者。具体而言，线程 A 完成了三次对 <code>x</code> 的写操作，线程 <code>B</code> 仅依赖其中第三次 <code>x</code> 的写操作，与 <code>x</code> 的前两次写行为无关，则当 <code>A</code> 主动 <code>x.release()</code> 时候（即使用 <code>std::memory_order_release</code>），选项 <code>std::memory_order_consume</code> 能够确保 <code>B</code> 在调用 <code>x.load()</code> 时候观察到 <code>A</code> 中第三次对 <code>x</code> 的写操作。我们来看一个例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化为 nullptr 防止 consumer 线程从野指针进行读取</span></span><br><span class="line"><span class="function">std::atomic&lt;<span class="keyword">int</span>*&gt; <span class="title">ptr</span><span class="params">(<span class="literal">nullptr</span>)</span></span>;</span><br><span class="line"><span class="keyword">int</span> v;</span><br><span class="line"><span class="function">std::thread <span class="title">producer</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span>* p = <span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">42</span>);</span></span></span><br><span class="line"><span class="params"><span class="function">    v = <span class="number">1024</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    ptr.store(p, std::memory_order_release);</span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span></span>;</span><br><span class="line"><span class="function">std::thread <span class="title">consumer</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span>* p;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">while</span>(!(p = ptr.load(std::memory_order_consume)));</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">    std::cout &lt;&lt; <span class="string">&quot;p: &quot;</span> &lt;&lt; *p &lt;&lt; std::endl;</span></span></span><br><span class="line"><span class="params"><span class="function">    std::cout &lt;&lt; <span class="string">&quot;v: &quot;</span> &lt;&lt; v &lt;&lt; std::endl;</span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span></span>;</span><br><span class="line">producer.<span class="built_in">join</span>();</span><br><span class="line">consumer.<span class="built_in">join</span>();</span><br></pre></td></tr></table></figure></li><li><p>释放/获取模型：在此模型下，我们可以进一步加紧对不同线程间原子操作的顺序的限制，在释放 <code>std::memory_order_release</code> 和获取 <code>std::memory_order_acquire</code> 之间规定时序，即发生在释放（release）操作之前的<strong>所有</strong>写操作，对其他线程的任何获取（acquire）操作都是可见的，亦即发生顺序（happens-before）。</p><p>可以看到，<code>std::memory_order_release</code> 确保了它之前的写操作不会发生在释放操作之后，是一个向后的屏障（backward），而 <code>std::memory_order_acquire</code> 确保了它之前的写行为不会发生在该获取操作之后，是一个向前的屏障（forward）。对于选项 <code>std::memory_order_acq_rel</code> 而言，则结合了这两者的特点，唯一确定了一个内存屏障，使得当前线程对内存的读写不会被重排并越过此操作的前后：</p><p>我们来看一个例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; v;</span><br><span class="line">std::atomic&lt;<span class="keyword">int</span>&gt; flag = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function">std::thread <span class="title">release</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    v.push_back(<span class="number">42</span>);</span></span></span><br><span class="line"><span class="params"><span class="function">    flag.store(<span class="number">1</span>, std::memory_order_release);</span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span></span>;</span><br><span class="line"><span class="function">std::thread <span class="title">acqrel</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">int</span> expected = <span class="number">1</span>; <span class="comment">// must before compare_exchange_strong</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">while</span>(!flag.compare_exchange_strong(expected, <span class="number">2</span>, std::memory_order_acq_rel))</span></span></span><br><span class="line"><span class="params"><span class="function">        expected = <span class="number">1</span>; <span class="comment">// must after compare_exchange_strong</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="comment">// flag has changed to 2</span></span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span></span>;</span><br><span class="line"><span class="function">std::thread <span class="title">acquire</span><span class="params">([&amp;]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">while</span>(flag.load(std::memory_order_acquire) &lt; <span class="number">2</span>);</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">    std::cout &lt;&lt; v.at(<span class="number">0</span>) &lt;&lt; std::endl; <span class="comment">// must be 42</span></span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span></span>;</span><br><span class="line">release.<span class="built_in">join</span>();</span><br><span class="line">acqrel.<span class="built_in">join</span>();</span><br><span class="line">acquire.<span class="built_in">join</span>();</span><br></pre></td></tr></table></figure><p>在此例中我们使用了 <code>compare_exchange_strong</code> 比较交换原语（Compare-and-swap primitive），它有一个更弱的版本，即 <code>compare_exchange_weak</code>，它允许即便交换成功，也仍然返回 <code>false</code> 失败。其原因是因为在某些平台上虚假故障导致的，具体而言，当 CPU 进行上下文切换时，另一线程加载同一地址产生的不一致。除此之外，<code>compare_exchange_strong</code> 的性能可能稍差于 <code>compare_exchange_weak</code>，但大部分情况下，鉴于其使用的复杂度而言，<code>compare_exchange_weak</code> 应该被有限考虑。</p></li><li><p>顺序一致模型：在此模型下，原子操作满足顺序一致性，进而可能对性能产生损耗。可显式的通过 <code>std::memory_order_seq_cst</code> 进行指定。最后来看一个例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">std::atomic&lt;<span class="keyword">int</span>&gt; counter = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">std::vector&lt;std::thread&gt; vt;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">    vt.<span class="built_in">emplace_back</span>([&amp;]()&#123;</span><br><span class="line">        counter.<span class="built_in">fetch_add</span>(<span class="number">1</span>, std::memory_order_seq_cst);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span>&amp; t : vt) &#123;</span><br><span class="line">    t.<span class="built_in">join</span>();</span><br><span class="line">&#125;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;current counter:&quot;</span> &lt;&lt; counter &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>这个例子与第一个宽松模型的例子本质上没有区别，仅仅只是将原子操作的内存顺序修改为了 <code>memory_order_seq_cst</code>，有兴趣的读者可以自行编写程序测量这两种不同内存顺序导致的性能差异。</p></li></ol><p>C++11 语言层提供了并发编程的相关支持，比如<code>std::thread</code>, <code>std::mutex</code>, <code>std::future</code> 这些并发编程中不可回避的重要工具。</p><p> 除此之外还介绍了 C++11 最重要的几个特性之一的『内存模型』， 它们为 C++ 在标准化高性能计算中提供了重要的基础。</p><h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><blockquote><p>文件系统库提供了文件系统、路径、常规文件、目录等等相关组件进行操作的相关功能。和正则表达式库类似，他也是最先由 boost 发起，并最终被合并为 C++ 标准的众多库之一。</p><p>C++17 引入了文件系统标准库(<code>&lt;filesystem&gt;</code>)来提供对文件系统的操作支持。该标准库定义了一组与文件系统相关的类和函数,使得在C++程序中操作文件和目录变得更加方便和跨平台</p></blockquote><ol><li><strong>文件系统</strong>:<ul><li><code>std::filesystem</code> 命名空间包含了与文件系统相关的类和函数。</li><li>主要类型包括 <code>path</code>、<code>directory_entry</code>、<code>directory_iterator</code> 和 <code>recursive_directory_iterator</code>。</li><li>这些类型允许你查询、遍历和操作文件系统中的目录和文件。</li></ul></li><li><strong>路径</strong>:<ul><li><code>std::filesystem::path</code> 类用于表示文件系统中的路径。</li><li>它可以表示绝对路径和相对路径,并提供了许多处理路径的方法,如拼接、分割等。</li><li>你可以使用 <code>operator/</code> 来拼接路径,如 <code>path1 / &quot;subdir&quot; / &quot;file.txt&quot;</code>。</li></ul></li><li><p><strong>常规文件</strong>:</p><ul><li><code>std::filesystem</code> 库提供了一些函数来操作常规文件,如 <code>std::filesystem::exists()</code>、<code>std::filesystem::file_size()</code>、<code>std::filesystem::copy_file()</code> 和 <code>std::filesystem::remove()</code>。</li><li>这些函数可以帮助你检查文件是否存在、获取文件大小、复制文件以及删除文件等。</li></ul><p><code>&lt;filesystem&gt;</code> 标准库还提供了一些与文件系统链接相关的功能</p></li><li><p><strong>硬链接和软链接</strong>:</p><ul><li><code>std::filesystem::create_hard_link()</code>函数可以创建文件的硬链接。</li><li><code>std::filesystem::create_symlink()</code>函数可以创建文件或目录的软链接(符号链接)。</li><li><code>std::filesystem::is_symlink()</code>函数可以检查某个路径是否为软链接。</li></ul></li><li><strong>文件路径规范化</strong>:<ul><li><code>std::filesystem::canonical()</code>函数可以获取某个路径的标准形式(规范路径)。</li><li>这在处理涉及软链接的路径时很有帮助,可以消除软链接带来的路径歧义。</li></ul></li><li><strong>路径比较</strong>:<ul><li><code>std::filesystem::equivalent()</code>函数可以判断两个路径是否指向同一个文件或目录。</li><li>即使路径字符串不同,如果指向同一个实体,也会返回true。</li></ul></li><li><strong>路径解析</strong>:<ul><li><code>std::filesystem::proximate()</code>函数可以获取某个路径相对于另一个路径的相对路径。</li><li>这在处理涉及多个目录的路径时很有用</li></ul></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;filesystem&gt;</span></span></span><br><span class="line"><span class="keyword">namespace</span> fs = std::filesystem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    fs::path file_path = <span class="string">&quot;example.txt&quot;</span>;</span><br><span class="line">    fs::path link_path = <span class="string">&quot;example_link.txt&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建硬链接</span></span><br><span class="line">    fs::<span class="built_in">create_hard_link</span>(file_path, link_path);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Hard link created: &quot;</span> &lt;&lt; link_path &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建软链接</span></span><br><span class="line">    fs::<span class="built_in">create_symlink</span>(file_path, <span class="string">&quot;example_symlink.txt&quot;</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Symbolic link created&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取规范路径</span></span><br><span class="line">    fs::path canonical_path = fs::<span class="built_in">canonical</span>(link_path);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Canonical path: &quot;</span> &lt;&lt; canonical_path &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断路径是否等价</span></span><br><span class="line">    <span class="keyword">if</span> (fs::<span class="built_in">equivalent</span>(file_path, canonical_path)) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Paths are equivalent&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取相对路径</span></span><br><span class="line">    fs::path relative_path = fs::<span class="built_in">proximate</span>(canonical_path, fs::<span class="built_in">current_path</span>());</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Relative path: &quot;</span> &lt;&lt; relative_path &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>C++17 文件系统标准库的一些主要组成部分:</p><h4 id="文件系统-1"><a href="#文件系统-1" class="headerlink" title="文件系统"></a>文件系统</h4><ol><li><code>std::filesystem::path</code>: 表示文件系统路径的类。可以用于创建、查询和操作路径。</li><li><code>std::filesystem::directory_entry</code>: 表示目录项的类,包含文件或目录的信息。</li><li><code>std::filesystem::directory_iterator</code>: 目录迭代器,可用于遍历目录中的内容。</li><li><code>std::filesystem::recursive_directory_iterator</code>: 递归目录迭代器,可用于遍历目录及其子目录。</li><li>一些常用函数:<ul><li><code>std::filesystem::exists()</code>: 检查路径是否存在</li><li><code>std::filesystem::is_regular_file()</code>: 检查路径是否为常规文件</li><li><code>std::filesystem::is_directory()</code>: 检查路径是否为目录</li><li><code>std::filesystem::file_size()</code>: 获取文件大小</li><li><code>std::filesystem::copy_file()</code>: 复制文件</li><li><code>std::filesystem::remove()</code>: 删除文件或目录</li><li><code>std::filesystem::create_directory()</code>: 创建目录</li></ul></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;filesystem&gt;</span></span></span><br><span class="line"><span class="keyword">namespace</span> fs = std::filesystem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取当前工作目录</span></span><br><span class="line">    fs::path current_path = fs::<span class="built_in">current_path</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Current path: &quot;</span> &lt;&lt; current_path &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历当前目录下的文件和目录</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; entry : fs::<span class="built_in">directory_iterator</span>(current_path)) &#123;</span><br><span class="line">        std::cout &lt;&lt; entry.<span class="built_in">path</span>() &lt;&lt; <span class="string">&quot; (&quot;</span>;</span><br><span class="line">        <span class="keyword">if</span> (fs::<span class="built_in">is_regular_file</span>(entry)) &#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;file, size: &quot;</span> &lt;&lt; fs::<span class="built_in">file_size</span>(entry) &lt;&lt; <span class="string">&quot; bytes&quot;</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (fs::<span class="built_in">is_directory</span>(entry)) &#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;directory&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;)&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建一个新目录</span></span><br><span class="line">    fs::path new_dir = current_path / <span class="string">&quot;new_folder&quot;</span>;</span><br><span class="line">    <span class="keyword">if</span> (fs::<span class="built_in">create_directory</span>(new_dir)) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Directory created: &quot;</span> &lt;&lt; new_dir &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="常用宏"><a href="#常用宏" class="headerlink" title="常用宏"></a>常用宏</h3><p>c++兼容c</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">funcc</span><span class="params">(<span class="keyword">int</span> a)</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;funcc&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>定义报错logger</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LOG(format, ...)                                                \</span></span><br><span class="line"><span class="meta">  fprintf(stderr, <span class="meta-string">&quot;[Date:%s|Time:%s][%s:%s:%d] &quot;</span> format <span class="meta-string">&quot;\n&quot;</span>, __DATE__, \</span></span><br><span class="line"><span class="meta">          __TIME__, __FILE__, __func__, __LINE__, ##__VA_ARGS__)</span></span><br></pre></td></tr></table></figure><p>使用</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">LOG</span>(<span class="string">&quot;Error: %d, %s&quot;</span>, <span class="number">42</span>, <span class="string">&quot;message&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h3><p><a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">C++ Core Guidelines (isocpp.github.io)</a></p><p><strong>模板编程</strong></p><p><a href="https://mq-b.github.io/Modern-Cpp-templates-tutorial/md/README">阅读须知 | 现代 C++ 模板教程 (mq-b.github.io)</a></p><p><a href="https://itlanyan.com/template-in-cpp/">C++模板编程 - tlanyan (itlanyan.com)</a></p><p><strong>并发编程</strong></p><p><a href="https://nj.gitbooks.io/c/content/">Introduction · C++并发编程实战 (gitbooks.io)</a></p><p><a href="https://mq-bai.gitbook.io/modern-cpp-concurrent-programming">首页 | 现代C++并发编程教程 (gitbook.io)</a></p><p>之后的<strong>C++20</strong><br><a href="https://en.cppreference.com/w/cpp/20">C++20 - cppreference.com</a><br><a href="https://github.com/xiaoweiChen/CXX20-The-Complete-Guide">xiaoweiChen/CXX20-The-Complete-Guide: 《C++20 The Complete Guide》的非专业个人翻译 (github.com)</a><br>虽然说了很多次,但我还是想谈谈c++本身的应用,在<strong>存储</strong>和<strong>网络</strong>上都很多,你也可以用它来造其他轮子.<br><strong>应用</strong></p><ul><li>网络编程/Linux服务器编程</li><li>计算机图形学</li><li>桌面应用编程</li><li>音视频编程</li><li>存储/数据库</li></ul><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;并行与并发,文件系统与一些资料分享&lt;br&gt;</summary>
    
    
    
    
    <category term="cpp" scheme="https://www.sekyoro.top/tags/cpp/"/>
    
  </entry>
  
  <entry>
    <title>modern cpp learning(二)</title>
    <link href="https://www.sekyoro.top/2024/06/09/modern-cpp-learning-%E4%BA%8C/"/>
    <id>https://www.sekyoro.top/2024/06/09/modern-cpp-learning-%E4%BA%8C/</id>
    <published>2024-06-09T04:46:41.000Z</published>
    <updated>2024-06-17T03:33:58.680Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>容器、智能指针与正则表达式.<br><span id="more"></span></p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>常用的容器如下:</p><ol><li><strong>std::vector</strong>:<ul><li>动态数组容器,支持随机访问。</li><li>可以动态增加或减少容器大小。</li><li>适用于需要快速随机访问的场景。</li></ul></li><li><strong>std::list</strong>:<ul><li>双向链表容器,支持高效的插入和删除操作。</li><li>不支持随机访问,但在需要频繁插入/删除的场景下性能更好。</li><li>适用于需要频繁插入/删除的数据结构,如栈、队列等。</li></ul></li><li><strong>std::deque</strong>(双端队列):<ul><li>双端队列容器,支持在头尾快速插入和删除。</li><li>实现上结合了数组和链表的优点。</li><li>适用于需要在头尾高效插入/删除的场景。</li></ul></li><li><strong>std::set</strong>/<strong>std::unordered_set</strong>:<ul><li>有序集合和无序集合容器,自动排序/散列存储元素。</li><li>支持高效的查找、插入和删除操作。</li><li>适用于需要去重和快速查找的场景。</li></ul></li><li><strong>std::map</strong>/<strong>std::unordered_map</strong>:<ul><li>关联数组容器,以键-值对的形式存储元素。</li><li>有序映射和无序映射,支持高效的查找、插入和删除。</li><li>适用于需要快速查找或存储键值对的场景。</li></ul></li><li><strong>std::stack</strong>/<strong>std::queue</strong>:<ul><li>栈和队列容器,提供先进先出(FIFO)和后进先出(LIFO)的操作。</li><li>基于其他容器(如 <code>std::deque</code>)实现。</li><li>适用于需要实现栈和队列数据结构的场景。</li></ul></li></ol><p>主要的 STL 算法:</p><ol><li><strong>排序算法</strong>:<ul><li><code>std::sort()</code>: 使用快速排序算法对元素进行排序。</li><li><code>std::stable_sort()</code>: 使用稳定排序算法(如归并排序)对元素进行排序。</li><li><code>std::partial_sort()</code>: 将前 N 个元素排序,其他元素保持原有顺序。</li><li><code>std::nth_element()</code>: 将第 N 个元素放到正确的位置,其他元素的相对顺序不变。</li></ul></li><li><strong>查找算法</strong>:<ul><li><code>std::find()</code>: 在序列中查找指定元素。</li><li><code>std::find_if()</code>: 使用自定义条件在序列中查找元素。</li><li><code>std::binary_search()</code>: 在已排序的序列中进行二分查找。</li><li><code>std::lower_bound()</code>: 返回指向序列中第一个不小于给定值的元素的迭代器。</li><li><code>std::upper_bound()</code>: 返回指向序列中第一个大于给定值的元素的迭代器。</li></ul></li><li><strong>修改算法</strong>:<ul><li><code>std::transform()</code>: 对序列中的每个元素应用给定的函数。</li><li><code>std::replace()</code>: 用新值替换序列中满足条件的元素。</li><li><code>std::reverse()</code>: 反转序列中的元素。</li><li><code>std::rotate()</code>: 将序列中的元素循环移动指定的距离。</li></ul></li><li><strong>数值算法</strong>:<ul><li><code>std::accumulate()</code>: 计算序列中元素的累加和。</li><li><code>std::inner_product()</code>: 计算两个序列的点积。</li><li><code>std::partial_sum()</code>: 计算序列中前 N 个元素的累加和。</li></ul></li><li><strong>集合算法</strong>:<ul><li><code>std::merge()</code>: 将两个有序序列合并成一个有序序列。</li><li><code>std::set_union()</code>: 计算两个集合的并集。</li><li><code>std::set_intersection()</code>: 计算两个集合的交集。</li><li><code>std::set_difference()</code>: 计算两个集合的差集。</li></ul></li></ol><p><strong>常用头文件</strong></p><ol><li>容器:<ul><li><code>std::vector</code>: <code>&lt;vector&gt;</code></li><li><code>std::list</code>: <code>&lt;list&gt;</code></li><li><code>std::deque</code>: <code>&lt;deque&gt;</code></li><li><code>std::set</code>: <code>&lt;set&gt;</code></li><li><code>std::unordered_set</code>: <code>&lt;unordered_set&gt;</code></li><li><code>std::map</code>: <code>&lt;map&gt;</code></li><li><code>std::unordered_map</code>: <code>&lt;unordered_map&gt;</code></li><li><code>std::stack</code>: <code>&lt;stack&gt;</code></li><li><code>std::queue</code>: <code>&lt;queue&gt;</code></li></ul></li><li>算法:<ul><li><code>std::sort</code>: <code>&lt;algorithm&gt;</code></li><li><code>std::find</code>: <code>&lt;algorithm&gt;</code></li><li><code>std::accumulate</code>: <code>&lt;numeric&gt;</code></li><li><code>std::transform</code>: <code>&lt;algorithm&gt;</code></li><li><code>std::copy</code>: <code>&lt;algorithm&gt;</code></li></ul></li><li>其他常用头文件:<ul><li><code>&lt;iostream&gt;</code>: 用于输入输出</li><li><code>&lt;string&gt;</code>: 用于字符串操作</li><li><code>&lt;memory&gt;</code>: 用于智能指针</li><li><code>&lt;functional&gt;</code>: 用于函数对象和 lambda 表达式</li></ul></li></ol><h3 id="线性容器"><a href="#线性容器" class="headerlink" title="线性容器"></a>线性容器</h3><h4 id="std-array"><a href="#std-array" class="headerlink" title="std::array"></a>std::array</h4><p>为什么要使用这个?</p><ul><li>节省内存</li><li>相比于普通数组更加现代化</li></ul><p>与 <code>std::vector</code> 不同，<code>std::array</code> 对象的大小是固定的，如果容器大小是固定的，那么可以优先考虑使用 <code>std::array</code> 容器。 另外由于 <code>std::vector</code> 是自动扩容的，当存入大量的数据后，并且对容器进行了删除操作， 容器并不会自动归还被删除元素相应的内存，这时候就需要手动运行 <code>shrink_to_fit()</code> 释放这部分内存</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">  std::vector&lt;<span class="keyword">int</span>&gt; v;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;size:&quot;</span> &lt;&lt; v.<span class="built_in">size</span>() &lt;&lt; std::endl;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;capacity:&quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; std::endl;</span><br><span class="line">  v.<span class="built_in">push_back</span>(<span class="number">1</span>);</span><br><span class="line">  v.<span class="built_in">push_back</span>(<span class="number">2</span>);</span><br><span class="line">  v.<span class="built_in">push_back</span>(<span class="number">3</span>);</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;size:&quot;</span> &lt;&lt; v.<span class="built_in">size</span>() &lt;&lt; std::endl;  <span class="comment">// 输出 3</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;capacity:&quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  v.<span class="built_in">clear</span>();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;size:&quot;</span> &lt;&lt; v.<span class="built_in">size</span>() &lt;&lt; std::endl;  <span class="comment">// 输出 3</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;capacity:&quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; std::endl;</span><br><span class="line">v.<span class="built_in">shrink_to_fit</span>();</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;size:&quot;</span> &lt;&lt; v.<span class="built_in">size</span>() &lt;&lt; std::endl;         <span class="comment">// 输出 0</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;capacity:&quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; std::endl; </span><br></pre></td></tr></table></figure><p>使用 <code>std::array</code> 能够让代码变得更加“现代化”，而且封装了一些操作函数，比如获取数组大小以及检查是否非空，同时还能够友好的使用标准库中的容器算法，比如 <code>std::sort</code></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">std::array&lt;<span class="keyword">int</span>, 4&gt; arr = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line">arr.<span class="built_in">empty</span>(); <span class="comment">// 检查容器是否为空</span></span><br><span class="line">arr.<span class="built_in">size</span>();  <span class="comment">// 返回容纳的元素数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 迭代器支持</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;i : arr)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用 lambda 表达式排序</span></span><br><span class="line">std::<span class="built_in">sort</span>(arr.<span class="built_in">begin</span>(), arr.<span class="built_in">end</span>(), [](<span class="keyword">int</span> a, <span class="keyword">int</span> b) &#123;</span><br><span class="line">    <span class="keyword">return</span> b &lt; a;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数组大小参数必须是常量表达式</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> len = <span class="number">4</span>;</span><br><span class="line">std::array&lt;<span class="keyword">int</span>, len&gt; arr = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 非法,不同于 C 风格数组，std::array 不会自动退化成 T*</span></span><br><span class="line"><span class="comment">// int *arr_p = arr;</span></span><br></pre></td></tr></table></figure><p>当我们开始用上了 <code>std::array</code> 时，难免会遇到要将其兼容 C 风格的接口，这里有三种做法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> *p, <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">std::array&lt;<span class="keyword">int</span>, 4&gt; arr = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// C 风格接口传参</span></span><br><span class="line"><span class="comment">// foo(arr, arr.size()); // 非法, 无法隐式转换</span></span><br><span class="line"><span class="built_in">foo</span>(&amp;arr[<span class="number">0</span>], arr.<span class="built_in">size</span>());</span><br><span class="line"><span class="built_in">foo</span>(arr.<span class="built_in">data</span>(), arr.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 `std::sort`</span></span><br><span class="line">std::<span class="built_in">sort</span>(arr.<span class="built_in">begin</span>(), arr.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure><h4 id="std-forward-list"><a href="#std-forward-list" class="headerlink" title="std::forward_list"></a>std::forward_list</h4><p><code>std::forward_list</code> 是一个列表容器，使用方法和 <code>std::list</code> 基本类似</p><p>需要知道的是，和 <code>std::list</code> 的双向链表的实现不同，<code>std::forward_list</code> <strong>使用单向链表进行实现， 提供了 <code>O(1)</code> 复杂度的元素插入，不支持快速随机访问</strong>（这也是链表的特点）， 也是标准库容器中唯一一个不提供 <code>size()</code> 方法的容器。<strong>当不需要双向迭代时，具有比 <code>std::list</code> 更高的空间利用率</strong></p><h3 id="无序容器"><a href="#无序容器" class="headerlink" title="无序容器"></a>无序容器</h3><p>我们已经熟知了传统 C++ 中的有序容器 <code>std::map</code>/<code>std::set</code>，这些元素内部通过红黑树进行实现， 插入和搜索的平均复杂度均为 <strong><code>O(log(size))</code></strong>。<strong>在插入元素时候，会根据 <code>&lt;</code> 操作符比较元素大小并判断元素是否相同， 并选择合适的位置插入到容器中。</strong>当对这个容器中的元素进行遍历时，输出结果会按照 <code>&lt;</code> 操作符的顺序来逐个遍历。</p><p>而无序容器中的元素是不进行排序的，内部通过 Hash 表实现，插入和搜索元素的平均复杂度为 <code>O(constant)</code>， 在不关心容器内部元素顺序时，能够获得显著的性能提升.</p><p>C++11 引入了的两组无序容器分别是：<code>std::unordered_map</code>/<code>std::unordered_multimap</code> 和 <code>std::unordered_set</code>/<code>std::unordered_multiset</code>,它们的用法和原有的 <code>std::map</code>/<code>std::multimap</code>/<code>std::set</code>/<code>set::multiset</code> 基本类似</p><blockquote><p>无序容器插入和搜索元素的平均复杂度O(1),所以不需要排序时可以考虑使用</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 两组结构按同样的顺序初始化</span></span><br><span class="line">    std::unordered_map&lt;<span class="keyword">int</span>, std::string&gt; u = &#123;</span><br><span class="line">        &#123;<span class="number">1</span>, <span class="string">&quot;1&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="number">3</span>, <span class="string">&quot;3&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="number">2</span>, <span class="string">&quot;2&quot;</span>&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    std::map&lt;<span class="keyword">int</span>, std::string&gt; v = &#123;</span><br><span class="line">        &#123;<span class="number">1</span>, <span class="string">&quot;1&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="number">3</span>, <span class="string">&quot;3&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="number">2</span>, <span class="string">&quot;2&quot;</span>&#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分别对两组结构进行遍历</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;std::unordered_map&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">const</span> <span class="keyword">auto</span> &amp; n : u)</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Key:[&quot;</span> &lt;&lt; n.first &lt;&lt; <span class="string">&quot;] Value:[&quot;</span> &lt;&lt; n.second &lt;&lt; <span class="string">&quot;]\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;std::map&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">const</span> <span class="keyword">auto</span> &amp; n : v)</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Key:[&quot;</span> &lt;&lt; n.first &lt;&lt; <span class="string">&quot;] Value:[&quot;</span> &lt;&lt; n.second &lt;&lt; <span class="string">&quot;]\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h3><p>纵观传统 C++ 中的容器，除了 <code>std::pair</code> 外， 似乎没有现成的结构能够用来存放不同类型的数据（通常我们会自己定义结构）。 但 <code>std::pair</code> 的缺陷是显而易见的，只能保存两个元素。</p><p><strong>核心操作</strong></p><p>关于元组的使用有三个核心的函数：</p><ol><li><code>std::make_tuple</code>: 构造元组(装包)</li><li><code>std::get</code>: 获得元组某个位置的值</li><li><code>std::tie</code>: 元组拆包</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;tuple&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">get_student</span><span class="params">(<span class="keyword">int</span> id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 返回类型被推断为 std::tuple&lt;double, char, std::string&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (id == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(<span class="number">3.8</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (id == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(<span class="number">2.9</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&quot;李四&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (id == <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(<span class="number">1.7</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&quot;王五&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(<span class="number">0.0</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&quot;null&quot;</span>);</span><br><span class="line">    <span class="comment">// 如果只写 0 会出现推断错误, 编译失败</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> student = <span class="built_in">get_student</span>(<span class="number">0</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;ID: 0, &quot;</span></span><br><span class="line">    &lt;&lt; <span class="string">&quot;GPA: &quot;</span> &lt;&lt; std::get&lt;<span class="number">0</span>&gt;(student) &lt;&lt; <span class="string">&quot;, &quot;</span></span><br><span class="line">    &lt;&lt; <span class="string">&quot;成绩: &quot;</span> &lt;&lt; std::get&lt;<span class="number">1</span>&gt;(student) &lt;&lt; <span class="string">&quot;, &quot;</span></span><br><span class="line">    &lt;&lt; <span class="string">&quot;姓名: &quot;</span> &lt;&lt; std::get&lt;<span class="number">2</span>&gt;(student) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">double</span> gpa;</span><br><span class="line">    <span class="keyword">char</span> grade;</span><br><span class="line">    std::string name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 元组进行拆包</span></span><br><span class="line">    std::<span class="built_in">tie</span>(gpa, grade, name) = <span class="built_in">get_student</span>(<span class="number">1</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;ID: 1, &quot;</span></span><br><span class="line">    &lt;&lt; <span class="string">&quot;GPA: &quot;</span> &lt;&lt; gpa &lt;&lt; <span class="string">&quot;, &quot;</span></span><br><span class="line">    &lt;&lt; <span class="string">&quot;成绩: &quot;</span> &lt;&lt; grade &lt;&lt; <span class="string">&quot;, &quot;</span></span><br><span class="line">    &lt;&lt; <span class="string">&quot;姓名: &quot;</span> &lt;&lt; name &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure><p><code>std::get</code> 除了使用常量获取元组对象外，C++14 增加了<strong>使用类型来获取元组中的对象</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::tuple&lt;std::string, <span class="keyword">double</span>, <span class="keyword">double</span>, <span class="keyword">int</span>&gt; <span class="title">t</span><span class="params">(<span class="string">&quot;123&quot;</span>, <span class="number">4.5</span>, <span class="number">6.7</span>, <span class="number">8</span>)</span></span>;</span><br><span class="line">std::cout &lt;&lt; std::get&lt;std::string&gt;(t) &lt;&lt; std::endl;</span><br><span class="line">std::cout &lt;&lt; std::get&lt;<span class="keyword">double</span>&gt;(t) &lt;&lt; std::endl; <span class="comment">// 非法, 引发编译期错误</span></span><br><span class="line">std::cout &lt;&lt; std::get&lt;<span class="number">3</span>&gt;(t) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h4 id="运行期索引"><a href="#运行期索引" class="headerlink" title="运行期索引"></a>运行期索引</h4><p>如果你仔细思考一下可能就会发现上面代码的问题，<code>std::get&lt;&gt;</code> 依赖一个编译期的常量，所以下面的方式是不合法的：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> index = <span class="number">1</span>;</span><br><span class="line">std::get&lt;index&gt;(t);</span><br></pre></td></tr></table></figure><blockquote><p>可以通过constexpr解决这个问题</p></blockquote><p>如果想通过运行期要怎么处理？答案是，使用 <code>std::variant&lt;&gt;</code>（C++ 17 引入），提供给 <code>variant&lt;&gt;</code> 的类型模板参数 可以让一个 <code>variant&lt;&gt;</code> 从而容纳提供的几种类型的变量（在其他语言，例如 Python/JavaScript 等，<strong>表现为动态类型</strong>）：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;variant&gt;</span></span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">size_t</span> n, <span class="keyword">typename</span>... T&gt;</span><br><span class="line"><span class="keyword">constexpr</span> std::variant&lt;T...&gt; _tuple_index(<span class="keyword">const</span> std::tuple&lt;T...&gt;&amp; tpl, <span class="keyword">size_t</span> i) &#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(n &gt;= <span class="keyword">sizeof</span>...(T))</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throw</span> <span class="title">std::out_of_range</span><span class="params">(<span class="string">&quot;越界.&quot;</span>)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (i == n)</span><br><span class="line">        <span class="keyword">return</span> std::variant&lt;T...&gt;&#123; std::in_place_index&lt;n&gt;, std::get&lt;n&gt;(tpl) &#125;;</span><br><span class="line">    <span class="keyword">return</span> _tuple_index&lt;(n &lt; <span class="keyword">sizeof</span>...(T)<span class="number">-1</span> ? n+<span class="number">1</span> : <span class="number">0</span>)&gt;(tpl, i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span>... T&gt;</span><br><span class="line"><span class="function"><span class="keyword">constexpr</span> std::variant&lt;T...&gt; <span class="title">tuple_index</span><span class="params">(<span class="keyword">const</span> std::tuple&lt;T...&gt;&amp; tpl, <span class="keyword">size_t</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _tuple_index&lt;<span class="number">0</span>&gt;(tpl, i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T0, <span class="keyword">typename</span> ... Ts&gt;</span><br><span class="line">std::ostream &amp; <span class="keyword">operator</span>&lt;&lt; (std::ostream &amp; s, std::variant&lt;T0, Ts...&gt; <span class="keyword">const</span> &amp; v) &#123; </span><br><span class="line">    std::<span class="built_in">visit</span>([&amp;](<span class="keyword">auto</span> &amp;&amp; x)&#123; s &lt;&lt; x;&#125;, v); </span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样我们就能：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="built_in">tuple_index</span>(t, i) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h4 id="元组合并与遍历"><a href="#元组合并与遍历" class="headerlink" title="元组合并与遍历"></a>元组合并与遍历</h4><p>还有一个常见的需求就是<strong>合并两个元组</strong>，这可以通过 <code>std::tuple_cat</code> 来实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::tuple t = std::<span class="built_in">make_tuple</span>(<span class="number">1</span>, <span class="number">2.0</span>, <span class="string">&quot;3&quot;</span>);</span><br><span class="line"> <span class="keyword">auto</span> new_tuple = std::<span class="built_in">tuple_cat</span>(<span class="built_in">get_student</span>(<span class="number">1</span>), std::<span class="built_in">move</span>(t));</span><br></pre></td></tr></table></figure><p>马上就能够发现，应该如何快速遍历一个元组？但是我们刚才介绍了如何在运行期通过非常数索引一个 <code>tuple</code> 那么遍历就变得简单了， 首先我们需要知道一个元组的长度，可以：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">tuple_len</span><span class="params">(T &amp;tpl)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> std::tuple_size&lt;T&gt;::value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就能够对元组进行迭代了：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 迭代</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i != <span class="built_in">tuple_len</span>(new_tuple); ++i)</span><br><span class="line">    <span class="comment">// 运行期索引</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">tuple_index</span>(new_tuple, i) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h2 id="智能指针和内存管理"><a href="#智能指针和内存管理" class="headerlink" title="智能指针和内存管理"></a>智能指针和内存管理</h2><p>在传统 C++ 中，『记得』手动释放资源，总不是最佳实践。因为我们很有可能就忘记了去释放资源而导致泄露。 所以通常的做法是对于一个对象而言，我们<strong>在构造函数的时候申请空间，而在析构函数（在离开作用域时调用）的时候释放空间</strong>， 也就是我们常说的 RAII 资源获取即初始化技术。</p><p>凡事都有例外，<strong>我们总会有需要将对象在自由存储上分配的需求</strong>(堆空间,指针等)，在传统 C++ 里我们只好使用 <code>new</code> 和 <code>delete</code> 去 『记得』对资源进行释放。而 C++11 引入了智能指针的概念，使用了引用计数的想法，让程序员不再需要关心手动释放内存。 这些智能指针包括 <code>std::shared_ptr</code>/<code>std::unique_ptr</code>/<code>std::weak_ptr</code>，使用它们需要包含头文件 <code>&lt;memory&gt;</code>。</p><blockquote><p>注意：<strong>引用计数不是垃圾回收，引用计数能够尽快收回不再被使用的对象</strong>，同时在回收的过程中也不会造成长时间的等待， 更能够清晰明确的表明资源的生命周期。</p></blockquote><h4 id="std-shared-ptr"><a href="#std-shared-ptr" class="headerlink" title="std::shared_ptr"></a>std::shared_ptr</h4><p><code>std::shared_ptr</code> 是一种智能指针，它能够记录多少个 <code>shared_ptr</code> 共同指向一个对象，从而消除显式的调用 <code>delete</code>，当引用计数变为零的时候就会将对象自动删除。</p><p>但还不够，因为使用 <code>std::shared_ptr</code> 仍然需要使用 <code>new</code> 来调用，这使得代码出现了某种程度上的不对称。</p><p><code>std::make_shared</code> 就能够用来消除显式的使用 <code>new</code>，所以<code>std::make_shared</code> 会分配创建传入参数中的对象， 并返回这个对象类型的<code>std::shared_ptr</code>指针。例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(std::shared_ptr&lt;<span class="keyword">int</span>&gt; i)</span> </span>&#123;</span><br><span class="line">    (*i)++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// auto pointer = new int(10); // illegal, no direct assignment</span></span><br><span class="line">    <span class="comment">// Constructed a std::shared_ptr</span></span><br><span class="line">    <span class="keyword">auto</span> pointer = std::make_shared&lt;<span class="keyword">int</span>&gt;(<span class="number">10</span>);</span><br><span class="line">    <span class="built_in">foo</span>(pointer);</span><br><span class="line">    std::cout &lt;&lt; *pointer &lt;&lt; std::endl; <span class="comment">// 11</span></span><br><span class="line">    <span class="comment">// The shared_ptr will be destructed before leaving the scope</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>std::shared_ptr</code> 可以通过 <code>get()</code> 方法来获取原始指针，通过 <code>reset()</code> 来减少一个引用计数， 并通过<code>use_count()</code>来查看一个对象的引用计数。例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> pointer = std::make_shared&lt;<span class="keyword">int</span>&gt;(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">auto</span> pointer2 = pointer; <span class="comment">// 引用计数+1</span></span><br><span class="line"><span class="keyword">auto</span> pointer3 = pointer; <span class="comment">// 引用计数+1</span></span><br><span class="line"><span class="keyword">int</span> *p = pointer.<span class="built_in">get</span>();  <span class="comment">// 这样不会增加引用计数</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer.use_count() = &quot;</span> &lt;&lt; pointer.<span class="built_in">use_count</span>() &lt;&lt; std::endl;   <span class="comment">// 3</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer2.use_count() = &quot;</span> &lt;&lt; pointer2.<span class="built_in">use_count</span>() &lt;&lt; std::endl; <span class="comment">// 3</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer3.use_count() = &quot;</span> &lt;&lt; pointer3.<span class="built_in">use_count</span>() &lt;&lt; std::endl; <span class="comment">// 3</span></span><br><span class="line"></span><br><span class="line">pointer2.<span class="built_in">reset</span>();</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;reset pointer2:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer.use_count() = &quot;</span> &lt;&lt; pointer.<span class="built_in">use_count</span>() &lt;&lt; std::endl;   <span class="comment">// 2</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer2.use_count() = &quot;</span></span><br><span class="line">          &lt;&lt; pointer2.<span class="built_in">use_count</span>() &lt;&lt; std::endl;           <span class="comment">// pointer2 已 reset; 0</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer3.use_count() = &quot;</span> &lt;&lt; pointer3.<span class="built_in">use_count</span>() &lt;&lt; std::endl; <span class="comment">// 2</span></span><br><span class="line">pointer3.<span class="built_in">reset</span>();</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;reset pointer3:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer.use_count() = &quot;</span> &lt;&lt; pointer.<span class="built_in">use_count</span>() &lt;&lt; std::endl;   <span class="comment">// 1</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer2.use_count() = &quot;</span> &lt;&lt; pointer2.<span class="built_in">use_count</span>() &lt;&lt; std::endl; <span class="comment">// 0</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;pointer3.use_count() = &quot;</span></span><br><span class="line">          &lt;&lt; pointer3.<span class="built_in">use_count</span>() &lt;&lt; std::endl;           <span class="comment">// pointer3 已 reset; 0</span></span><br></pre></td></tr></table></figure><h4 id="std-unique-ptr"><a href="#std-unique-ptr" class="headerlink" title="std::unique_ptr"></a>std::unique_ptr</h4><p><code>std::unique_ptr</code> 是一种独占的智能指针，它<strong>禁止其他智能指针与其共享同一个对象</strong>，从而保证代码的安全</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::unique_ptr&lt;<span class="keyword">int</span>&gt; pointer = std::make_unique&lt;<span class="keyword">int</span>&gt;(<span class="number">10</span>); <span class="comment">// make_unique 从 C++14 引入std::unique_ptr&lt;int&gt; pointer2 = pointer; // 非法</span></span><br></pre></td></tr></table></figure><p>C++11 没有提供 <code>std::make_unique</code>，可以自行实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> ...Args&gt;</span></span><br><span class="line"><span class="function">std::unique_ptr&lt;T&gt; <span class="title">make_unique</span><span class="params">( Args&amp;&amp; ...args )</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> std::unique_ptr&lt;T&gt;( <span class="keyword">new</span> <span class="built_in">T</span>( std::forward&lt;Args&gt;(args)... ) );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>既然是独占，换句话说就是不可复制。但是，我们可<strong>以利用 <code>std::move</code> 将其转移给其他的 <code>unique_ptr</code></strong>，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Foo</span> &#123;</span></span><br><span class="line">    <span class="built_in">Foo</span>() &#123; std::cout &lt;&lt; <span class="string">&quot;Foo::Foo&quot;</span> &lt;&lt; std::endl; &#125;</span><br><span class="line">    ~<span class="built_in">Foo</span>() &#123; std::cout &lt;&lt; <span class="string">&quot;Foo::~Foo&quot;</span> &lt;&lt; std::endl; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123; std::cout &lt;&lt; <span class="string">&quot;Foo::foo&quot;</span> &lt;&lt; std::endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(<span class="keyword">const</span> Foo &amp;)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;f(const Foo&amp;)&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;Foo&gt; <span class="title">p1</span><span class="params">(std::make_unique&lt;Foo&gt;())</span></span>;</span><br><span class="line">    <span class="comment">// p1 不空, 输出</span></span><br><span class="line">    <span class="keyword">if</span> (p1) p1-&gt;<span class="built_in">foo</span>();</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">std::unique_ptr&lt;Foo&gt; <span class="title">p2</span><span class="params">(std::move(p1))</span></span>;</span><br><span class="line">        <span class="comment">// p2 不空, 输出</span></span><br><span class="line">        <span class="built_in">f</span>(*p2);</span><br><span class="line">        <span class="comment">// p2 不空, 输出</span></span><br><span class="line">        <span class="keyword">if</span>(p2) p2-&gt;<span class="built_in">foo</span>();</span><br><span class="line">        <span class="comment">// p1 为空, 无输出</span></span><br><span class="line">        <span class="keyword">if</span>(p1) p1-&gt;<span class="built_in">foo</span>();</span><br><span class="line">        p1 = std::<span class="built_in">move</span>(p2);</span><br><span class="line">        <span class="comment">// p2 为空, 无输出</span></span><br><span class="line">        <span class="keyword">if</span>(p2) p2-&gt;<span class="built_in">foo</span>();</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;p2 被销毁&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// p1 不空, 输出</span></span><br><span class="line">    <span class="keyword">if</span> (p1) p1-&gt;<span class="built_in">foo</span>();</span><br><span class="line">    <span class="comment">// Foo 的实例会在离开作用域时被销毁</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>使用 <code>std::move(p1)</code> 将 <code>p1</code> 的所有权转移给 <code>p2</code> 时, <code>p1</code> 会变为空指针的原因如下:</p><ol><li><code>std::unique_ptr</code> 是一种独占式的智能指针,这意味着一个 <code>std::unique_ptr</code> 对象只能拥有一个动态分配的对象的所有权。</li><li>当你使用 <code>std::move(p1)</code> 时, <code>p1</code> 的所有权被转移给了 <code>p2</code>。这是因为 <code>std::move</code> 函数将 <code>p1</code> 转换为一个右值引用,从而使所有权从 <code>p1</code> 转移到 <code>p2</code>。</li><li>一旦所有权被转移,<code>p1</code> 就不再拥有任何动态分配的对象。因此, <code>p1</code> 被设置为空指针,以确保它不会被用于访问已经被转移所有权的对象。</li></ol><p>这种行为是 <code>std::unique_ptr</code> 设计的一部分,旨在确保程序员不会意外地使用已经失去所有权的指针。这样可以帮助我们避免悬空指针和内存泄漏等常见的错误</p></blockquote><p>上面代码可以看出unique_ptr存在作用域,在作用域内如果被转移到其他unque_ptr上离开作用域被销毁,同时原本的在其他作用域内不受影响.</p><h3 id="std-weak-ptr"><a href="#std-weak-ptr" class="headerlink" title="std::weak_ptr"></a>std::weak_ptr</h3><p>如果你仔细思考 <code>std::shared_ptr</code> 就会发现依然存在着资源无法释放的问题。看下面这个例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span> &#123;</span></span><br><span class="line">    std::shared_ptr&lt;B&gt; pointer;</span><br><span class="line">    ~<span class="built_in">A</span>() &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;A 被销毁&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span> &#123;</span></span><br><span class="line">    std::shared_ptr&lt;A&gt; pointer;</span><br><span class="line">    ~<span class="built_in">B</span>() &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;B 被销毁&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> a = std::make_shared&lt;A&gt;();</span><br><span class="line">    <span class="keyword">auto</span> b = std::make_shared&lt;B&gt;();</span><br><span class="line">    a-&gt;pointer = b;</span><br><span class="line">    b-&gt;pointer = a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果是 A, B 都不会被销毁，这是因为 a,b 内部的 pointer 同时又引用了 <code>a,b</code>，这使得 <code>a,b</code> 的引用计数均变为了 2，而离开作用域时，<code>a,b</code> 智能指针被析构，却只能造成这块区域的引用计数减一，这样就导致了 <code>a,b</code> 对象指向的内存区域引用计数不为零，而外部已经没有办法找到这块区域了，也就造成了内存泄露</p><p><img data-src="https://changkun.de/modern-cpp/assets/figures/pointers1.png" alt="图 5.1"></p><p>解决这个问题的办法就是使用弱引用指针 <code>std::weak_ptr</code>，<code>std::weak_ptr</code>是一种弱引用（相比较而言 <code>std::shared_ptr</code> 就是一种强引用）。<strong>弱引用不会引起引用计数增加，当换用弱引用时候</strong>，最终的释放流程如图.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">AA</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">AA</span> &#123;</span></span><br><span class="line">  std::weak_ptr&lt;B&gt; pointer;</span><br><span class="line">  ~<span class="built_in">AA</span>() &#123; std::cout &lt;&lt; <span class="string">&quot;AA::~AA&quot;</span> &lt;&lt; std::endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span> &#123;</span></span><br><span class="line">  std::weak_ptr&lt;AA&gt; pointer;</span><br><span class="line">  ~<span class="built_in">B</span>() &#123; std::cout &lt;&lt; <span class="string">&quot;B::~B&quot;</span> &lt;&lt; std::endl; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><img data-src="https://changkun.de/modern-cpp/assets/figures/pointers2.png" alt="图 5.2" style="zoom:67%;" /></p><blockquote><p><code>std::weak_ptr</code> 不会增加引用计数,使得a,b释放后原本对象没有了引用.</p></blockquote><p>最后一步只剩下 B，而 B 并没有任何智能指针引用它，因此这块内存资源也会被释放。</p><p><strong><code>std::weak_ptr</code> 没有 <code>*</code> 运算符和 <code>-&gt;</code> 运算符</strong>，所以不能够对资源进行操作，它可以用于检查 <code>std::shared_ptr</code> 是否存在，其 <strong><code>expired()</code> 方法能在资源未被释放时，会返回 <code>false</code>，否则返回 <code>true</code></strong>；除此之外，它也可以用于获取指向原始对象的 <code>std::shared_ptr</code> 指针，其 <strong><code>lock()</code> 方法在原始对象未被释放时，返回一个指向原始对象的 <code>std::shared_ptr</code> 指针，进而访问原始对象的资源，否则返回<code>nullptr</code>。</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> aa = std::make_shared&lt;AA&gt;();</span><br><span class="line"> <span class="keyword">auto</span> bb = std::make_shared&lt;B&gt;();</span><br><span class="line"> aa-&gt;pointer = bb;</span><br><span class="line"> bb-&gt;pointer = aa;</span><br><span class="line"> <span class="keyword">if</span> (!aa-&gt;pointer.<span class="built_in">expired</span>()) &#123;</span><br><span class="line">   <span class="keyword">auto</span> shared = aa-&gt;pointer.<span class="built_in">lock</span>();</span><br><span class="line">   std::cout &lt;&lt; <span class="string">&quot;shared:&quot;</span> &lt;&lt; shared.<span class="built_in">use_count</span>() &lt;&lt; std::endl;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>正则表达式描述了一种字符串匹配的模式。一般使用正则表达式主要是实现下面三个需求：</p><ol><li><strong>检查一个串是否包含</strong>某种形式的子串；</li><li>将匹配的<strong>子串替换</strong>；</li><li>从<strong>某个串中取出符合条件的子串</strong>。</li></ol><blockquote><p>检查包含,替换字串,取出字串</p></blockquote><p>正则表达式是由普通字符（例如 a 到 z）以及特殊字符组成的文字模式。模式描述在搜索文本时要匹配的一个或多个字符串。 正则表达式作为一个模板，将某个字符模式与所搜索的字符串进行匹配。</p><h4 id="普通字符"><a href="#普通字符" class="headerlink" title="普通字符"></a>普通字符</h4><p>普通字符包括没有显式指定为元字符的所有可打印和不可打印字符。这包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。</p><h4 id="特殊字符"><a href="#特殊字符" class="headerlink" title="特殊字符"></a>特殊字符</h4><p>特殊字符是正则表达式里有特殊含义的字符，也是正则表达式的核心匹配语法。参见下表：</p><div class="table-container"><table><thead><tr><th style="text-align:left">特别字符</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>$</code></td><td style="text-align:left">匹配输入字符串的结尾位置。</td></tr><tr><td style="text-align:left"><code>(</code>,<code>)</code></td><td style="text-align:left">标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。</td></tr><tr><td style="text-align:left"><code>*</code></td><td style="text-align:left">匹配前面的子表达式零次或多次。</td></tr><tr><td style="text-align:left"><code>+</code></td><td style="text-align:left">匹配前面的子表达式一次或多次。</td></tr><tr><td style="text-align:left"><code>.</code></td><td style="text-align:left">匹配除换行符 <code>\n</code> 之外的任何单字符。</td></tr><tr><td style="text-align:left"><code>[</code></td><td style="text-align:left">标记一个中括号表达式的开始。</td></tr><tr><td style="text-align:left"><code>?</code></td><td style="text-align:left">匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。</td></tr><tr><td style="text-align:left"><code>\</code></td><td style="text-align:left">将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， <code>n</code> 匹配字符 <code>n</code>。<code>\n</code> 匹配换行符。序列 <code>\\</code> 匹配 <code>&#39;\&#39;</code> 字符，而 <code>\(</code> 则匹配 <code>&#39;(&#39;</code> 字符。</td></tr><tr><td style="text-align:left"><code>^</code></td><td style="text-align:left">匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。</td></tr><tr><td style="text-align:left"><code>&#123;</code></td><td style="text-align:left">标记限定符表达式的开始。</td></tr><tr><td style="text-align:left">`</td><td style="text-align:left">`</td><td>指明两项之间的一个选择</td></tr></tbody></table></div><p>一些正则表达式示例:</p><ul><li><p><code>\s</code> 是<strong>匹配所有空白符,包括换行</strong>,\S 非空白符,不包括换行</p></li><li><p><code>\d+</code>: 匹配一个或多个数字</p></li><li><code>\b</code> 匹配一个单词边界，也就是指单词和空格间的位置.例如, ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’.</li><li><code>\w+</code>: 匹配一个或多个字母、数字或下划线字符</li><li><code>\s+</code>: 匹配一个或多个空白字符</li><li><code>[aeiou]</code>: 匹配任意一个元音字母</li><li><code>[a-zA-Z0-9_]+</code>: 匹配一个或多个字母、数字或下划线</li><li><code>\b\w+\b</code>: 匹配独立的单词</li><li><code>^[a-z]+$</code>: 匹配全部由小写字母组成的字符串.</li></ul><div class="table-container"><table><thead><tr><th>匹配</th><th>解释</th></tr></thead><tbody><tr><td>(pattern)</td><td><strong>匹配 pattern 并获取这一匹配</strong>。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ‘(‘ 或 ‘)‘。</td></tr><tr><td>(?:pattern)</td><td><strong>匹配 pattern 但不获取匹配结果</strong>，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 (\</td><td>) 来组合一个模式的各个部分是很有用。例如， ‘industr(?:y\</td><td>ies) 就是一个比 ‘industry\</td><td>industries’ 更简略的表达式。</td></tr><tr><td>(?=pattern)</td><td>正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，”Windows(?=95\</td><td>98\</td><td>NT\</td><td>2000)”能匹配”Windows2000”中的”Windows”，但不能匹配”Windows3.1”中的”Windows”。<strong>预查不消耗字符</strong>，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。</td></tr><tr><td>(?!pattern)</td><td>正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如”Windows(?!95\</td><td>98\</td><td>NT\</td><td>2000)”能匹配”Windows3.1”中的”Windows”，但不能匹配”Windows2000”中的”Windows”。<strong>预查不消耗字符</strong>，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。</td></tr><tr><td>(?&lt;=pattern)</td><td>反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，”`(?&lt;=95</td><td>98</td><td>NT</td><td>2000)Windows<code>&quot;能匹配&quot;</code>2000Windows<code>&quot;中的&quot;</code>Windows<code>&quot;，但不能匹配&quot;</code>3.1Windows<code>&quot;中的&quot;</code>Windows`”。</td></tr><tr><td>(?&lt;!pattern)</td><td>反向否定预查，与正向否定预查类似，只是方向相反。例如”`(?&lt;!95</td><td>98</td><td>NT</td><td>2000)Windows<code>&quot;能匹配&quot;</code>3.1Windows<code>&quot;中的&quot;</code>Windows<code>&quot;，但不能匹配&quot;</code>2000Windows<code>&quot;中的&quot;</code>Windows`”。</td></tr></tbody></table></div><h4 id="限定符"><a href="#限定符" class="headerlink" title="限定符"></a>限定符</h4><p>限定符用来指定<strong>正则表达式的一个给定的组件必须要出现多少次才能满足匹配</strong>。见下表：</p><div class="table-container"><table><thead><tr><th style="text-align:left">字符</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>*</code></td><td style="text-align:left">匹配前面的子表达式零次或多次。例如，<code>foo*</code> 能匹配 <code>fo</code> 以及 <code>foooo</code>。<code>*</code> 等价于<code>&#123;0,&#125;</code>。</td></tr><tr><td style="text-align:left"><code>+</code></td><td style="text-align:left">匹配前面的子表达式一次或多次。例如，<code>foo+</code> 能匹配 <code>foo</code> 以及 <code>foooo</code>，但不能匹配 <code>fo</code>。<code>+</code> 等价于 <code>&#123;1,&#125;</code>。</td></tr><tr><td style="text-align:left"><code>?</code></td><td style="text-align:left">匹配前面的子表达式零次或一次。例如，<code>Your(s)?</code> 可以匹配 <code>Your</code> 或 <code>Yours</code> 中的<code>Your</code> 。<code>?</code> 等价于 <code>&#123;0,1&#125;</code>。</td></tr><tr><td style="text-align:left"><code>&#123;n&#125;</code></td><td style="text-align:left"><code>n</code> 是一个非负整数。匹配确定的 <code>n</code> 次。例如，<code>o&#123;2&#125;</code> 不能匹配 <code>for</code> 中的 <code>o</code>，但是能匹配 <code>foo</code> 中的两个 <code>o</code>。</td></tr><tr><td style="text-align:left"><code>&#123;n,&#125;</code></td><td style="text-align:left"><code>n</code> 是一个非负整数。至少匹配 <code>n</code> 次。例如，<code>o&#123;2,&#125;</code> 不能匹配 <code>for</code> 中的 <code>o</code>，但能匹配 <code>foooooo</code> 中的所有 <code>o</code>。<code>o&#123;1,&#125;</code> 等价于 <code>o+</code>。<code>o&#123;0,&#125;</code> 则等价于 <code>o*</code>。</td></tr><tr><td style="text-align:left"><code>&#123;n,m&#125;</code></td><td style="text-align:left"><code>m</code> 和 <code>n</code> 均为非负整数，其中 <code>n</code> 小于等于 <code>m</code>。最少匹配 <code>n</code> 次且最多匹配 <code>m</code> 次。例如，<code>o&#123;1,3&#125;</code> 将匹配 <code>foooooo</code> 中的前三个 <code>o</code>。<code>o&#123;0,1&#125;</code> 等价于 <code>o?</code>。注意，在逗号和两个数之间不能有空格。</td></tr></tbody></table></div><h3 id="std-regex-及其相关"><a href="#std-regex-及其相关" class="headerlink" title="std::regex 及其相关"></a>std::regex 及其相关</h3><p>对字符串内容进行匹配的最常见手段就是使用正则表达式。 可惜<strong>在传统 C++ 中正则表达式一直没有得到语言层面的支持，没有纳入标准库</strong>， 而 C++ 作为一门高性能语言，在后台服务的开发中，对 URL 资源链接进行判断时， 使用正则表达式也是工业界最为成熟的普遍做法。</p><p>一般的解决方案就是使用 <code>boost</code> 的正则表达式库。 而 <strong>C++11 正式将正则表达式的的处理方法纳入标准库的行列</strong>，从语言级上提供了标准的支持， 不再依赖第三方。</p><p>C++11 提供的正则表达式库操作 <code>std::string</code> 对象， 模式 <code>std::regex</code> (本质是 <code>std::basic_regex</code>)进行初始化， 通过 <code>std::regex_match</code> 进行匹配， 从而产生 <code>std::smatch</code> （本质是 <code>std::match_results</code> 对象）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">std::string fnames[] = &#123;<span class="string">&quot;foot.txt&quot;</span>, <span class="string">&quot;bar.txt&quot;</span>, <span class="string">&quot;test.txt&quot;</span>, <span class="string">&quot;a0.txt&quot;</span>&#125;;</span><br><span class="line">  <span class="function">std::regex <span class="title">txt_regex</span><span class="params">(<span class="string">&quot;[a-z]+\\.txt&quot;</span>)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; fname : fnames) &#123;</span><br><span class="line">    std::cout &lt;&lt; fname &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; std::<span class="built_in">regex_match</span>(fname, txt_regex)</span><br><span class="line">              &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>另一种常用的形式就是依次传入 <code>std::string</code>/<code>std::smatch</code>/<code>std::regex</code> 三个参数， 其中 <code>std::smatch</code> 的本质其实是 <code>std::match_results</code>。 故而在标准库的实现中， <code>std::smatch</code> 被定义为了 <code>std::match_results&lt;std::string::const_iterator&gt;</code>， 也就是一个子串迭代器类型的 <code>match_results</code>。 使用 <code>std::smatch</code> 可以方便的对匹配的结果进行获取，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::regex <span class="title">base_regex</span><span class="params">(<span class="string">&quot;([a-z]+)\\.txt&quot;</span>)</span></span>;</span><br><span class="line">std::smatch base_match;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">const</span> <span class="keyword">auto</span> &amp;fname: fnames) &#123;</span><br><span class="line">    <span class="keyword">if</span> (std::<span class="built_in">regex_match</span>(fname, base_match, base_regex)) &#123;</span><br><span class="line">        <span class="comment">// std::smatch 的第一个元素匹配整个字符串</span></span><br><span class="line">        <span class="comment">// std::smatch 的第二个元素匹配了第一个括号表达式</span></span><br><span class="line">        <span class="keyword">if</span> (base_match.<span class="built_in">size</span>() == <span class="number">2</span>) &#123;</span><br><span class="line">            std::string base = base_match[<span class="number">1</span>].<span class="built_in">str</span>();</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;sub-match[0]: &quot;</span> &lt;&lt; base_match[<span class="number">0</span>].<span class="built_in">str</span>() &lt;&lt; std::endl;</span><br><span class="line">            std::cout &lt;&lt; fname &lt;&lt; <span class="string">&quot; sub-match[1]: &quot;</span> &lt;&lt; base &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;容器、智能指针与正则表达式.&lt;br&gt;</summary>
    
    
    
    
    <category term="cpp" scheme="https://www.sekyoro.top/tags/cpp/"/>
    
  </entry>
  
  <entry>
    <title>跨平台应用开发的若干解决方案</title>
    <link href="https://www.sekyoro.top/2024/06/08/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E7%9A%84%E8%8B%A5%E5%B9%B2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://www.sekyoro.top/2024/06/08/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E7%9A%84%E8%8B%A5%E5%B9%B2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</id>
    <published>2024-06-08T05:33:08.000Z</published>
    <updated>2024-06-15T06:50:55.460Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>很久没有写这类high-level的文章了,本身这类框架就一直层出不穷,但是其中历久弥坚,坚韧不拔的框架又有多少呢?<br><span id="more"></span><br>首先考虑到学习成本以及掌握一些编程语言在工作、学习生态上的价值,给这些东西适用生态划分一下.</p><h3 id="React-Native"><a href="#React-Native" class="headerlink" title="React Native"></a>React Native</h3><blockquote><p>React Native 允许了解 <strong>React 的开发人员创建原生应用程序</strong>。同时，原生开发人员可以使用 React Native 编写一次通用功能，从而获得<strong>原生平台</strong>之间的平等性。</p></blockquote><p><a href="https://reactnative.dev/docs/environment-setup">Get Started with React Native · React Native</a></p><p>使用前端技术开发移动端和web程序. 通常与Expo搭配,后者是一个生产级的 React Native 框架。Expo 提供开发人员工具，使应用程序的开发更加轻松，例如基于文件的路由、原生模块标准库等.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx create-expo-app StickerSmash --template blank &amp;&amp; <span class="built_in">cd</span> StickerSmash</span><br></pre></td></tr></table></figure><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; StyleSheet, Text, View &#125; <span class="keyword">from</span> <span class="string">&#x27;react-native&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="function"><span class="keyword">function</span> <span class="title">App</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.container&#125;</span>&gt;</span></span></span><br><span class="line"><span class="xml">      <span class="tag">&lt;<span class="name">Text</span>&gt;</span>Hello world!<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = StyleSheet.create(&#123;</span><br><span class="line">  <span class="attr">container</span>: &#123;</span><br><span class="line">    <span class="attr">flex</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">backgroundColor</span>: <span class="string">&#x27;#fff&#x27;</span>,</span><br><span class="line">    <span class="attr">alignItems</span>: <span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">    <span class="attr">justifyContent</span>: <span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用一些库的话直接就是npm,跟前端开发类似.</p><p>缺点的话就是使用前端和android studio混合搭配优点乱吧,而且可能还有一些坑. </p><p><del>如果你不喜欢React,可以试试Ionic<a href="https://ionicframework.com/">Ionic Framework - The Cross-Platform App Development Leader</a></del>其实在这里我并不想推荐其他技术了.</p><p>更多前端技术,参看<a href="https://risingstars.js.org/2023/en">2023 JavaScript Rising Stars</a></p><p>优点:</p><ul><li>强大的生态和社区(毕竟背靠折腾的厉害的前端),<strong>文档非常友善</strong></li><li>专注用户界面,呈现原生平台的用户界面组件</li><li>fast refresh,使得开发时能立即看见改动</li><li>有了debugger工具,提供log viewer, interactive layout inspector, 和network inspector.</li></ul><h3 id="Flutter"><a href="#Flutter" class="headerlink" title="Flutter"></a>Flutter</h3><p><a href="https://docs.flutter.dev/get-started/install">Install | Flutter</a></p><p>虽然前段时间听说flutter遭重,被google layoff了一些人.</p><p>广泛文档也不错,目前支持mobile, web甚至desktop(beta).</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ListView(</span><br><span class="line">  children: <span class="keyword">const</span> &lt;Widget&gt;[</span><br><span class="line">    ListTile(</span><br><span class="line">      leading: Icon(Icons.map),</span><br><span class="line">      title: Text(<span class="string">&#x27;Map&#x27;</span>),</span><br><span class="line">    ),</span><br><span class="line">    ListTile(</span><br><span class="line">      leading: Icon(Icons.photo_album),</span><br><span class="line">      title: Text(<span class="string">&#x27;Album&#x27;</span>),</span><br><span class="line">    ),</span><br><span class="line">    ListTile(</span><br><span class="line">      leading: Icon(Icons.phone),</span><br><span class="line">      title: Text(<span class="string">&#x27;Phone&#x27;</span>),</span><br><span class="line">    ),</span><br><span class="line">  ],</span><br><span class="line">),</span><br></pre></td></tr></table></figure><p>使用Dart语言的命令式UI,目前很多框架都使用这种方式了.其实也类似jsx,无非是利用编程语言层层嵌套替代原本的xml配置的方式. </p><p>Jetpack compose和Qt的qml也都类似这种了,分别替代了原本xml和widget.</p><p>利用Dart的pub.dev装一些库<a href="https://pub.dev/">The official repository for Dart and Flutter packages. (pub.dev)</a>,众所周知,提到php,ruby就是web,那么提到dart就是flutter了,因此dart的很多库也是方便flutter开发的.</p><p>缺点就是Dart也有上手门槛,不过如果你熟悉类似Kotlin,</p><p>Swift这种语言,其实它向这些语言学习了很多.</p><p>优点:</p><ul><li>Flutter 的热重载功能可让您在修改代码后立即查看应用程序的变化，而无需重新编译。</li><li>Flutter 支持谷歌的 Material Design,这是一种帮助开发人员构建数字体验的设计系统.在构建应用程序时,您可以使用多种视觉和行为小部件。</li><li>Flutter 不依赖浏览器技术.相反,它拥有自己的渲染引擎来绘制部件</li></ul><h3 id="Kotlin-Multiplatform"><a href="#Kotlin-Multiplatform" class="headerlink" title="Kotlin Multiplatform"></a>Kotlin Multiplatform</h3><p>如果你已经熟悉Jetpack Compose,那这个就是多平台下的开发框架,便于写ios,web等等. 我个人感觉它和Flutter就是这方面的leader了,如果你对desktop没有要求,那也可以使用React Native.</p><p><a href="https://www.jetbrains.com/zh-cn/lp/compose-multiplatform/">Compose Multiplatform UI 框架 | JetBrains | JetBrains: Developer Tools for Professionals and Teams</a></p><p><img data-src="https://kotlinlang.org/docs/images/kotlin-multiplatform.svg" alt="Kotlin Multiplatform"></p><p>但说实话,目前还需要再等一等.毕竟它的时间还不像前两者那么久.</p><p>首先需要<a href="https://kmp.jetbrains.com/?_gl=1*1owgdm2*_gcl_au*NTAxNzM2NDkuMTcxNjg4ODAzMA..*_ga*MTk2NDM1MDMwNS4xNzEyMDI4ODQ4*_ga_9J976DJZ68*MTcxNzgyODcyNy43LjEuMTcxNzgyODg1MS42MC4wLjA.#newProject">Kotlin Multiplatform Wizard | JetBrains</a>下载需要的库,然后进行一堆配置,目前看来还是需要再等等,先熟悉熟悉Jetpack Compose更好.</p><p>当然,前提条件都是必须要会Kotlin的基本语法.</p><h3 id="NET-MAUI"><a href="#NET-MAUI" class="headerlink" title=".NET MAUI"></a>.NET MAUI</h3><p>Flutter是谷歌的技术,React Native是Meta的技术,而MAUI就是微软的技术. 使用C#和XAML(类似xml)开发mobile和desktop程序.如果你还想要web,可以结合Blazor.</p><p><a href="https://dotnet.microsoft.com/en-us/apps/maui">.NET Multi-platform App UI (.NET MAUI) | .NET (microsoft.com)</a></p><p>目前微软正在大推,而之前的桌面开发应用比如WPF等已经没有什么大更新了,但是还是有一些公司(可能不是那么互联网的公司)正在使用.</p><p>如果你没有那么强调跨平台,我觉得WPF完全够用了.</p><p>还是使用的是利用文件配置声明UI控件,然后代码写事务逻辑.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;</span><br><span class="line">&lt;ContentPage xmlns=&quot;http://schemas.microsoft.com/dotnet/2021/maui&quot;</span><br><span class="line">             xmlns:x=&quot;http://schemas.microsoft.com/winfx/2009/xaml&quot;</span><br><span class="line">             x:Class=&quot;Notes.AboutPage&quot;&gt;</span><br><span class="line">    &lt;VerticalStackLayout Spacing=&quot;10&quot; Margin=&quot;10&quot;&gt;</span><br><span class="line">        &lt;HorizontalStackLayout Spacing=&quot;10&quot;&gt;</span><br><span class="line">            &lt;Image Source=&quot;dotnet_bot.png&quot;</span><br><span class="line">                   SemanticProperties.Description=&quot;The dot net bot waving hello!&quot;</span><br><span class="line">                   HeightRequest=&quot;64&quot; /&gt;</span><br><span class="line">            &lt;Label FontSize=&quot;22&quot; FontAttributes=&quot;Bold&quot; Text=&quot;Notes&quot; VerticalOptions=&quot;End&quot; /&gt;</span><br><span class="line">            &lt;Label FontSize=&quot;22&quot; Text=&quot;v1.0&quot; VerticalOptions=&quot;End&quot; /&gt;</span><br><span class="line">        &lt;/HorizontalStackLayout&gt;</span><br><span class="line"></span><br><span class="line">        &lt;Label Text=&quot;This app is written in XAML and C# with .NET MAUI.&quot; /&gt;</span><br><span class="line">        &lt;Button Text=&quot;Learn more...&quot; Clicked=&quot;LearnMore_Clicked&quot; /&gt;</span><br><span class="line">    &lt;/VerticalStackLayout&gt;</span><br><span class="line">&lt;/ContentPage&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">private async void LearnMore_Clicked(object sender, EventArgs e)</span><br><span class="line">&#123;</span><br><span class="line">    // Navigate to the specified URL in the system browser.</span><br><span class="line">    await Launcher.Default.OpenAsync(&quot;https://aka.ms/maui&quot;);</span><br><span class="line">&#125;private void OnCounterClicked(object sender, EventArgs e)</span><br><span class="line">&#123;</span><br><span class="line">    count++;</span><br><span class="line"></span><br><span class="line">    if (count == 1)</span><br><span class="line">        CounterBtn.Text = $&quot;Clicked &#123;count&#125; time&quot;;</span><br><span class="line">    else</span><br><span class="line">        CounterBtn.Text = $&quot;Clicked &#123;count&#125; times&quot;;</span><br><span class="line"></span><br><span class="line">    SemanticScreenReader.Announce(CounterBtn.Text);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img data-src="https://dotnet.microsoft.com/blob-assets/images/tutorials/maui/solution-explorer-mainpage.png" alt="Solution Explorer pane with MainPage.xaml file highlighted."></p><p>C#语言本身我个人还是非常喜欢的,属于历久弥坚.使用.NET开发移动程序基本上要搭配visual studio了(或者也可以使用Jetbrains的Rider),可能一些操作不熟悉.</p><p>此外也有第三方的Avalonia<a href="https://docs.avaloniaui.net/zh-Hans/docs/welcome">欢迎 | Avalonia Docs (avaloniaui.net)</a>和Uno,也是可以考虑的. 但目前可能仍然存在一些坑,生态上资源可能也没有那么丰富.</p><p>优点:</p><ul><li>.NET MAUI 提供跨平台 API，用于访问本地设备功能，如 GPS、加速计、电池和网络状态。</li><li>它有一个单一的项目系统，可使用多目标功能针对 Android、iOS、macOS 和 Windows 启用。</li><li>由于支持 .NET hot reload，开发人员可以在应用程序运行时修改托管源代码</li></ul><p>这可能不太互联网和开源,但我还是想说说:</p><h3 id="Qt"><a href="#Qt" class="headerlink" title="Qt"></a>Qt</h3><p>Qt最新已经到了6.x版本,官方也推荐Quick application,另外还有design studio方便界面设计. 官方文旦也很不错.</p><p><a href="https://doc.qt.io/qt-5/gettingstarted.html"><a href="https://doc.qt.io/">Qt Documentation | Home</a></a></p><p><a href="https://doc.qt.io/qt.html">Qt Documentation | Modules</a></p><p><img data-src="https://s2.loli.net/2024/06/08/Dv4qziapdwCQVOA.png" alt="image-20240608144743992"></p><p>随便新建一个项目,设置允许使用design studio打开的格式,这样下面文件会多一些东西.</p><p><img data-src="https://s2.loli.net/2024/06/08/ZQywH4stDL69rXu.png" alt="image-20240608150703433"></p><p>可以看到使用qml和cpp进行开发,qml里可以写UI也可以写一些简单逻辑,类似MAUI和WPF.</p><p> Qt目前支持桌面和android等<a href="https://blog.csdn.net/csdnofhaner/article/details/135733657">【Qt】如何从零配置Qt Android安卓环境_qt 安卓环境搭建</a>,但我也不推荐使用qt开发移动应用。</p><p>而是使用qml技术开发跨平台桌面应用(毕竟针对不同IDE设置一个android模拟器还是挺麻烦的).</p><p>否则跟下面一样</p><p><img data-src="https://s2.loli.net/2024/06/08/yLbGiplSnVNXr45.png" alt="image-20240608155750208"></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;QGuiApplication&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;QQmlApplicationEngine&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">QGuiApplication <span class="title">app</span><span class="params">(argc, argv)</span></span>;</span><br><span class="line"></span><br><span class="line">    QQmlApplicationEngine engine;</span><br><span class="line">    <span class="function"><span class="keyword">const</span> QUrl <span class="title">url</span><span class="params">(<span class="string">u&quot;qrc:/ada/Main.qml&quot;</span>_qs)</span></span>;</span><br><span class="line">    QObject::<span class="built_in">connect</span>(</span><br><span class="line">        &amp;engine,</span><br><span class="line">        &amp;QQmlApplicationEngine::objectCreationFailed,</span><br><span class="line">        &amp;app,</span><br><span class="line">        []() &#123; QCoreApplication::<span class="built_in">exit</span>(<span class="number">-1</span>); &#125;,</span><br><span class="line">        Qt::QueuedConnection);</span><br><span class="line">    engine.<span class="built_in">load</span>(url);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> app.<span class="built_in">exec</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight qml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> QtQuick</span><br><span class="line"><span class="keyword">import</span> QtQuick.Controls</span><br><span class="line"></span><br><span class="line"><span class="title">Window</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">640</span></span><br><span class="line">    <span class="attribute">height</span>: <span class="number">480</span></span><br><span class="line">    <span class="attribute">visible</span>: <span class="literal">true</span></span><br><span class="line">    <span class="attribute">title</span>: qsTr(<span class="string">&quot;Hello World&quot;</span>)</span><br><span class="line">    <span class="title">Rectangle</span> &#123;</span><br><span class="line">        <span class="attribute">anchors.fill</span>: <span class="built_in">parent</span></span><br><span class="line">        <span class="attribute">color</span>: <span class="string">&quot;red&quot;</span></span><br><span class="line">        <span class="title">Column</span> &#123;</span><br><span class="line">            <span class="attribute">spacing</span>: <span class="number">20</span></span><br><span class="line">            <span class="title">Text</span> &#123;</span><br><span class="line">                <span class="attribute">text</span>: qsTr(<span class="string">&quot;Hello World&quot;</span>)</span><br><span class="line">                <span class="attribute">font.pixelSize</span>: <span class="number">254</span></span><br><span class="line">                <span class="attribute">font.bold</span>: <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="title">Button</span> &#123;</span><br><span class="line">                <span class="attribute">text</span>: qsTr(<span class="string">&quot;Hi, press me!&quot;</span>)</span><br><span class="line">                <span class="attribute">onClicked</span>: <span class="built_in">console</span>.log(<span class="string">&quot;Button clicked!&quot;</span>)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="title">Button</span> &#123;</span><br><span class="line">                <span class="attribute">text</span>: qsTr(<span class="string">&quot;Hi, press me!&quot;</span>)</span><br><span class="line">                <span class="attribute">onClicked</span>: <span class="built_in">console</span>.log(<span class="string">&quot;Button clicked!&quot;</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>而且Qt不只是一个UI库,它包括cpp的各种封装与工具,qml也支持js执行.</p><p>不过开发上qt本身并不支持热重载,每次改完还要重新运行.</p><p>我不会说c++很难,但这是个事实,不过Qt已经方便你很多了.构建工具也从原本Qt自己的qmake变成了cmake优先.</p><p>另外Qt和visual studio也是我很喜欢的c++的IDE,最近jetbrains又发力搞了clion nova据说占用内存小了,也可以试试.</p><p>但可能由于各种原因,Qt的生态跟前面几者不太相同,这里引用一句.</p><blockquote><p>以往QT需求比较强烈的领域主要集中于军工、安防、车联网、工业控制、电力等相对偏传统的行业领域，整体需求比较稳定。但是近年来由于…，采用….，实现…。这也就意味着，像QT这种GUI框架必然会越受青睐。</p><p>作者：飞援<br>链接：<a href="https://juejin.cn/post/7076273798311313439">https://juejin.cn/post/7076273798311313439</a><br>来源：稀土掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p></blockquote><p>我并不是觉得Qt需要有多么受青睐,但是它的需求确实如上面所说,导致很多人拿来工作的并不多.</p><h3 id="One-more-thing"><a href="#One-more-thing" class="headerlink" title="One more thing"></a>One more thing</h3><p>事实上很多时候并不需要跨平台开发,引入跨平台开发会毫无疑问地增加负担. 如果只是跨桌面的话也可以考虑electron,tauri(本质上是webview前端技术)等.</p><p><strong>当你只需要单个平台时,可以有更多选择</strong>. 比如在Windows或者微软的一些平台上,使用WPF,winui3等. 比如单独的安卓开发使用kotlin compose. 减少了跨平台开发带来的不一致性问题.</p><p><img data-src="https://github.com/robloo/PublicDocs/raw/master/XAMLFrameworkEvolution.png?raw=true" alt="img"></p><p>关于windows上的UI框架,微软还是有点多变了(微软的东西还是要等它更成熟再用,比如WPF),具体可以看看下面介绍</p><ul><li><a href="https://github.com/microsoft/microsoft-ui-xaml/blob/main/docs/roadmap.md#benefits-of-winui">microsoft-ui-xaml/docs/roadmap.md at main · microsoft/microsoft-ui-xaml (github.com)</a></li><li><a href="https://github.com/robloo/PublicDocs/blob/master/UWPvsWPF.md">PublicDocs/UWPvsWPF.md at master · robloo/PublicDocs (github.com)</a></li></ul><p>另外参考某些大佬的建议</p><blockquote><p>QtWidgets 对标 WinForm，QtQuick 对标 WPF，QtWebEngine 对标 cef/electron/react native，可以在同一个里同时使用多种开发模式混合开发</p><p>比如主界面用 QtWidgets 做，而各种快速迭代的界面用 QtWebEngine + web 技术开发，而不是单一的只提供一种。</p></blockquote><p><a href="https://www.zhihu.com/question/476748969">独立开发桌面程序（Windows）UI框架选择哪个更好？ - 知乎 (zhihu.com)</a></p><h3 id="FYI"><a href="#FYI" class="headerlink" title="FYI"></a>FYI</h3><ol><li><a href="https://www.jetbrains.com/help/kotlin-multiplatform-dev/cross-platform-frameworks.html#what-is-a-cross-platform-app-development-framework">The Six Most Popular Cross-Platform App Development Frameworks | Kotlin Multiplatform Development Documentation (jetbrains.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;很久没有写这类high-level的文章了,本身这类框架就一直层出不穷,但是其中历久弥坚,坚韧不拔的框架又有多少呢?&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>modern cpp learning(一)</title>
    <link href="https://www.sekyoro.top/2024/06/02/modern-cpp-learning(%E4%B8%80)/"/>
    <id>https://www.sekyoro.top/2024/06/02/modern-cpp-learning(%E4%B8%80)/</id>
    <published>2024-06-02T14:31:56.000Z</published>
    <updated>2024-06-09T07:38:46.946Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>cpp,古老又传统的语言,但它依然是许多语言希望替代战胜的.这里介绍一些新特性.<br><span id="more"></span></p><p>由于cpp只有语言标准,不同编译器具体实现不同,这里使用的是clang.</p><p>预备知识:C++98 主要包括指针(对于c/c++很重要的东西),结构体,类(尤其是<strong>不同的构造函数</strong>),<strong>lambda函数</strong>,STL,引用,命名空间以及<strong>模板编程</strong>.</p><p><a href="https://www.runoob.com/cplusplus/cpp-tutorial.html">C++ 教程 | 菜鸟教程 (runoob.com)</a></p><p><a href="https://www.learncpp.com/">Learn C++ – Skill up with our free tutorials (learncpp.com)</a></p><p><a href="https://zh.cppreference.com/w/">cppreference.com</a></p><p><a href="http://staff.ustc.edu.cn/~lgliu/Courses/ComputerGraphics_2020_spring-summer/default.htm#课程作业">刘利刚《计算机图形学》2020 (ustc.edu.cn)</a></p><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在学习现代 C++ 之前，我们先了解一下从 C++11 开始，被弃用的主要特性：</p><blockquote><p><strong>注意</strong>：弃用并非彻底不能用，只是用于暗示程序员这些特性将从未来的标准中消失，应该尽量避免使用。但是，已弃用的特性依然是标准库的一部分，并且出于兼容性的考虑，大部分特性其实会『永久』保留。</p></blockquote><ul><li><p><strong>不再允许字符串字面值常量赋值给一个 <code>char \*</code>。如果需要用字符串字面值常量赋值和初始化一个 <code>char \*</code>，应该使用 <code>const char \*</code> 或者 <code>auto</code>。</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *str = <span class="string">&quot;hello world!&quot;</span>; <span class="comment">// 将出现弃用警告</span></span><br></pre></td></tr></table></figure></li><li><p><strong>C++98 异常说明、 <code>unexpected_handler</code>、<code>set_unexpected()</code> 等相关特性被弃用，应该使用 <code>noexcept</code>。</strong></p></li><li><p><strong><code>auto_ptr</code> 被弃用，应使用 <code>unique_ptr</code>。</strong></p></li><li><p><strong><code>register</code> 关键字被弃用，可以使用但不再具备任何实际含义。</strong></p></li><li><p><strong><code>bool</code> 类型的 <code>++</code> 操作被弃用。</strong></p></li><li><p><strong>如果一个类有析构函数，为其生成拷贝构造函数和拷贝赋值运算符的特性被弃用了。</strong></p></li><li><p><strong>C 语言风格的类型转换被弃用（即在变量前使用 <code>(convert_type)</code>），应该使用 <code>static_cast</code>、<code>reinterpret_cast</code>、<code>const_cast</code> 来进行类型转换。</strong></p></li><li><p><strong>特别地，在最新的 C++17 标准中弃用了一些可以使用的 C 标准库，例如 <code>&lt;ccomplex&gt;</code>、<code>&lt;cstdalign&gt;</code>、<code>&lt;cstdbool&gt;</code> 与 <code>&lt;ctgmath&gt;</code> 等</strong></p></li></ul><p><strong>C++ 不是 C 的一个超集</strong></p><p>在编写 C++ 时，也应该尽可能的避免使用诸如 <code>void*</code> 之类的程序风格。而在不得不使用 C 时，应该注意使用 <code>extern &quot;C&quot;</code> 这种特性，将 C 语言的代码与 C++代码进行分离编译，再统一链接这种做法，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foo.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// foo.c</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x+y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.1.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;foo.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;functional&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    [out = std::<span class="built_in">ref</span>(std::cout &lt;&lt; <span class="string">&quot;Result from C code: &quot;</span> &lt;&lt; <span class="built_in">add</span>(<span class="number">1</span>, <span class="number">2</span>))]()&#123;</span><br><span class="line">        out.<span class="built_in">get</span>() &lt;&lt; <span class="string">&quot;.\n&quot;</span>;</span><br><span class="line">    &#125;();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>应先使用 <code>gcc</code> 编译 C 语言的代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c foo.c</span><br></pre></td></tr></table></figure><p>编译出 <code>foo.o</code> 文件，再使用 <code>clang++</code> 将 C++ 代码和 <code>.o</code> 文件链接起来（或者都编译为 <code>.o</code> 再统一链接）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clang++ 1.1.cpp foo.o -std=c++2a -o 1.1</span><br></pre></td></tr></table></figure><p>也可以使用 <code>Makefile</code> 来编译上面的代码：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">C = gcc</span><br><span class="line">CXX = clang++</span><br><span class="line"></span><br><span class="line">SOURCE_C = foo.c</span><br><span class="line">OBJECTS_C = foo.o</span><br><span class="line"></span><br><span class="line">SOURCE_CXX = 1.1.cpp</span><br><span class="line"></span><br><span class="line">TARGET = 1.1</span><br><span class="line">LDFLAGS_COMMON = -std=c++2a</span><br><span class="line"></span><br><span class="line"><span class="section">all:</span></span><br><span class="line"><span class="variable">$(C)</span> -c <span class="variable">$(SOURCE_C)</span></span><br><span class="line"><span class="variable">$(CXX)</span> <span class="variable">$(SOURCE_CXX)</span> <span class="variable">$(OBJECTS_C)</span> <span class="variable">$(LDFLAGS_COMMON)</span> -o <span class="variable">$(TARGET)</span></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">rm -rf *.o <span class="variable">$(TARGET)</span></span><br></pre></td></tr></table></figure><p>C++98标准: 会生成默认构造函数, 析构函数, 复制构造函数, 复制赋值运算符</p><p>C++11标准: 除了C++98标准中生成的函数外, 还会生成移动构造函数和移动赋值运算符</p><p>以类A为例, 上述函数表示如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">A</span>() = <span class="keyword">default</span>;                    <span class="comment">// 构造函数</span></span><br><span class="line">  ~<span class="built_in">A</span>() = <span class="keyword">default</span>;                   <span class="comment">// 析构函数</span></span><br><span class="line">  <span class="built_in">A</span>(<span class="keyword">const</span> A&amp;) = <span class="keyword">default</span>;            <span class="comment">// 复制构造函数</span></span><br><span class="line">  A&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> A&amp;) = <span class="keyword">default</span>; <span class="comment">// 复制赋值运算符</span></span><br><span class="line">  <span class="built_in">A</span>(A&amp;&amp;) = <span class="keyword">default</span>;                 <span class="comment">// 移动构造函数</span></span><br><span class="line">  A&amp; <span class="keyword">operator</span>=(A&amp;&amp;) = <span class="keyword">default</span>;      <span class="comment">// 移动赋值运算符</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>C++11标准中上述函数的生成规律:</p><ul><li><p>只要指定了一个要求传参的构造函数, 就会阻止编译器生成默认构造函数</p></li><li><p>两种复制操作是彼此独立的, 即显式声明了其中一个, 不会阻止编译器默认生成另一个</p></li><li><p>两种移动操作并不彼此独立, 即显式声明了其中一个, 就会阻止编译器默认生成另一个</p></li><li><p>一旦<strong>显式声明了复制操作, 就会阻止编译器默认生成移动操作</strong></p></li><li><p>一旦<strong>显式声明了移动操作, 就会阻止编译器默认生成复制操作</strong></p></li><li><p>一旦<strong>显式申明了析构函数, 就会阻止编译器默认生成移动操作</strong></p></li></ul><p>如果编译器默认生成的上述函数能满足你的需求, 但由于各个规则被抑制生成的话, 可以<strong>通过= default来显式表达这个想法</strong>, 如上述A类所示</p><p>大三律 (Rule of Three)<br><strong>如果你声明了复制构造函数, 复制赋值运算符, 或析构函数的任何一个, 你就得同时声明所有这三个</strong>。这个思想源于: 如果有改写复制操作的需求, 往往意味着该类需要执行某种资源管理, 而这就意味着:</p><ul><li><p>在一种复制操作中进行的任何资源管理, 也极有可能在另一种复制操作中也需要进行</p></li><li><p>该类的析构函数也会参与到该资源的管理中(通常是释放)</p></li></ul><h2 id="可用性的增强"><a href="#可用性的增强" class="headerlink" title="可用性的增强"></a>可用性的增强</h2><h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><h4 id="NULL与nullptr"><a href="#NULL与nullptr" class="headerlink" title="NULL与nullptr"></a>NULL与nullptr</h4><p>NULL在不同编译器中实现不同,通常是0或者((void<em>)0).但是:C++ <strong>不允许</strong>直接将 `void </em><code>隐式转换到其他类型，从而</code>((void*)0)<code>不是</code>NULL` 的合法实现。</p><p>没有了 <code>void *</code> 隐式转换的 C++ 只好将 <code>NULL</code> 定义为 <code>0</code>。而这依然会产生新的问题，将 <code>NULL</code> 定义成 <code>0</code> 将导致 <code>C++</code> 中重载特性发生混乱</p><p>直接使用nullptr.</p><h4 id="constexpr"><a href="#constexpr" class="headerlink" title="constexpr"></a>constexpr</h4><p>C++ 本身已经具备了常量表达式的概念，比如 <code>1+2</code>, <code>3*4</code> 这种表达式总是会产生相同的结果并且没有任何副作用。如果编译器能够在编译时就把这些表达式直接优化并植入到程序运行时，将能增加程序的性能。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> arr_1[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">char</span> arr_2[LEN];</span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> len2_constexpr = <span class="number">1</span> + <span class="number">2</span> + <span class="number">3</span>;</span><br><span class="line"><span class="keyword">char</span> arr_4[len2_constexpr]</span><br></pre></td></tr></table></figure><h3 id="变量初始化"><a href="#变量初始化" class="headerlink" title="变量初始化"></a>变量初始化</h3><h4 id="在if-switch中初始化变量"><a href="#在if-switch中初始化变量" class="headerlink" title="在if/switch中初始化变量"></a>在if/switch中初始化变量</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将临时变量放到 if 语句内</span></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">const</span> std::vector&lt;<span class="keyword">int</span>&gt;::iterator itr = std::<span class="built_in">find</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), <span class="number">3</span>);</span><br><span class="line">    itr != vec.<span class="built_in">end</span>()) &#123;</span><br><span class="line">    *itr = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="初始化列表"><a href="#初始化列表" class="headerlink" title="初始化列表"></a>初始化列表</h4><p>初始化是一个非常重要的语言特性，最常见的就是在对象进行初始化时进行使用。 在传统 C++ 中，不同的对象有着不同的初始化方法，例如<strong>普通数组</strong>、 POD （<strong>P</strong>lain <strong>O</strong>ld <strong>D</strong>ata，即<strong>没有构造、析构和虚函数的类或结构体</strong>） 类型都可以使用 <code>&#123;&#125;</code> 进行初始化，也就是我们所说的初始化列表。 </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span>* ch = &#123;<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p>对于<strong>类对象的初始化</strong>，要么需要通过<strong>拷贝构造</strong>、要么就需要<strong>使用 <code>()</code> 进行</strong></p><p>这些不同方法都针对各自对象，<strong>不能通用</strong></p><p>为解决这个问题，C++11 首先把初始化列表的概念绑定到类型上，称其为 <code>std::initializer_list</code>，允许构造函数或其他函数像参数一样使用初始化列表，这就为类对象的初始化与普通数组和 POD 的初始化方法提供了统一的桥梁</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MagicFoo</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  std::vector&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">  <span class="built_in">MagicFoo</span>() = <span class="keyword">default</span>;</span><br><span class="line">  <span class="built_in">MagicFoo</span>(std::initializer_list&lt;<span class="keyword">int</span>&gt; list) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> it = list.<span class="built_in">begin</span>(); it != list.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">      vec.<span class="built_in">push_back</span>(*it);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">  MagicFoo magicFoo = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>初始化列表除了用在对象构造上，还能将其作为普通函数的形参</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span>:    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(std::initializer_list&lt;<span class="keyword">int</span>&gt; list)</span> </span>&#123;        <span class="keyword">for</span> (std::initializer_list&lt;<span class="keyword">int</span>&gt;::iterator it = list.<span class="built_in">begin</span>();            it != list.<span class="built_in">end</span>(); ++it) vec.<span class="built_in">push_back</span>(*it);    &#125;magicFoo.<span class="built_in">foo</span>(&#123;<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&#125;);</span><br></pre></td></tr></table></figure><p>考虑可以替代麻烦的va_list?</p><p>C++11还提供了统一的语法来初始化任意的对象</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MagicFoo magicFoo  &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br></pre></td></tr></table></figure><h4 id="结构化绑定"><a href="#结构化绑定" class="headerlink" title="结构化绑定"></a>结构化绑定</h4><p>结构化绑定提供了类似其他语言中提供的多返回值的功能。在容器一章中，我们会学到 C++11 新增了 <code>std::tuple</code> 容器用于构造一个元组，进而囊括多个返回值。但缺陷是，C++11/14 并没有提供一种简单的方法直接从元组中拿到并定义元组中的元素，尽管我们可以使用 <code>std::tie</code> 对元组进行拆包，但我们依然必须非常清楚这个元组包含多少个对象，各个对象是什么类型，非常麻烦。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::tuple&lt;<span class="keyword">int</span>, <span class="keyword">double</span>, std::string&gt; <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">make_tuple</span>(<span class="number">1</span>, <span class="number">2.3</span>, <span class="string">&quot;456&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">  <span class="keyword">auto</span> [x,y,z] = <span class="built_in">f</span>();</span><br><span class="line">  std::cout &lt;&lt; x &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; z &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><blockquote><p>其实就是方便了返回值的获取.</p></blockquote><p>在传统 C 和 C++ 中，参数的类型都必须明确定义，这其实对我们快速进行编码没有任何帮助，尤其是<strong>当我们面对一大堆复杂的模板类型时，必须明确的指出变量的类型才能进行后续的编码，这不仅拖慢我们的开发效率，也让代码变得又臭又长</strong>。</p><p>C++11 引入了 <code>auto</code> 和 <code>decltype</code> 这两个关键字实现了类型推导，让编译器来操心变量的类型。这使得 C++ 也具有了和其他现代编程语言一样，某种意义上提供了无需操心变量类型的使用习惯。</p><h3 id="类型推导"><a href="#类型推导" class="headerlink" title="类型推导"></a>类型推导</h3><h4 id="auto"><a href="#auto" class="headerlink" title="auto"></a>auto</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> i = <span class="number">5</span>;              <span class="comment">// i 被推导为 int</span></span><br><span class="line"><span class="keyword">auto</span> arr = <span class="keyword">new</span> <span class="built_in"><span class="keyword">auto</span></span>(<span class="number">10</span>); <span class="comment">// arr 被推导为 int *</span></span><br></pre></td></tr></table></figure><p>从 C++ 14 起，<code>auto</code> 能用于 lambda 表达式中的函数传参</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> add14 = [](<span class="keyword">auto</span> x, <span class="keyword">auto</span> y) -&gt; <span class="keyword">int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x+y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add20</span><span class="params">(<span class="keyword">auto</span> x, <span class="keyword">auto</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x+y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> i = <span class="number">5</span>; <span class="comment">// type int</span></span><br><span class="line"><span class="keyword">auto</span> j = <span class="number">6</span>; <span class="comment">// type int</span></span><br><span class="line">std::cout &lt;&lt; <span class="built_in">add14</span>(i, j) &lt;&lt; std::endl;</span><br><span class="line">std::cout &lt;&lt; <span class="built_in">add20</span>(i, j) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h4 id="decltype"><a href="#decltype" class="headerlink" title="decltype"></a>decltype</h4><p><code>decltype</code> 关键字是为了解决 <code>auto</code> 关键字只能对变量进行类型推导的缺陷而出现的。它的用法和 <code>typeof</code> 很相似</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> x = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">auto</span> y = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">decltype</span>(x+y) z; <span class="comment">// 利用其它变量类型声明变量</span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (std::is_same&lt;<span class="keyword">decltype</span>(x), <span class="keyword">int</span>&gt;::value)</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;type x == int&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="keyword">if</span> (std::is_same&lt;<span class="keyword">decltype</span>(x), <span class="keyword">float</span>&gt;::value)</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;type x == float&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"><span class="keyword">if</span> (std::is_same&lt;<span class="keyword">decltype</span>(x), <span class="keyword">decltype</span>(z)&gt;::value)</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;type z == type x&quot;</span> &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>判断类型是否相同</p><h4 id="尾返回类型推导"><a href="#尾返回类型推导" class="headerlink" title="尾返回类型推导"></a>尾返回类型推导</h4><p>来看下面代码的进化.一开始,这样的代码很丑陋，因为程序员在使用这个模板函数的时候，必须明确指出返回类型。但事实上我们并不知道 <code>add()</code> 这个函数会做什么样的操作，以及获得一个什么样的返回类型</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="function">R <span class="title">add</span><span class="params">(T x, U y)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">add</span><span class="params">(T x, U y)</span>-&gt;<span class="title">decltype</span><span class="params">(x + y)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">add</span><span class="params">(T x, U y)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 C++11 中这个问题得到解决。虽然你可能马上会反应出来使用 <code>decltype</code> 推导 <code>x+y</code> 的类型，写出这样的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">decltype</span>(x+y) <span class="built_in">add</span>(T x, U y)</span><br></pre></td></tr></table></figure><p>但事实上这样的写法并不能通过编译。这是因为在编译器读到 decltype(x+y) 时，<code>x</code> 和 <code>y</code> 尚未被定义。为了解决这个问题，C++11 还引入了一个叫做尾返回类型（trailing return type），利用 <code>auto</code> 关键字将返回类型后置.</p><p>从 C++14 开始是可以直接让普通函数具备返回值推导，因此第三种写法也正确.</p><blockquote><p>typename 和 class 在模板参数列表中没有区别，在 typename 这个关键字出现之前，都是使用 class 来定义模板参数的。但在模板中定义有<a href="https://en.cppreference.com/w/cpp/language/dependent_name#The_typename_disambiguator_for_dependent_names">嵌套依赖类型</a>的变量时，需要用 typename 消除歧义</p></blockquote><p>嵌套依赖类型的例子如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">int</span> value_type;</span><br><span class="line">    value_type x;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span> :</span> <span class="keyword">public</span> Base&lt;T&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 在这里,Derived类需要告诉编译器 value_type 是一个类型,而不是变量</span></span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">typename</span> Base&lt;T&gt;::value_type value_type;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 这里可以直接使用 value_type,因为已经在上面声明了</span></span><br><span class="line">        value_type y = <span class="number">42</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Derived&lt;<span class="keyword">double</span>&gt; d;</span><br><span class="line">    d.<span class="built_in">foo</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">int</span> value_type;</span><br><span class="line">    value_type x;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span> :</span> <span class="keyword">public</span> Base&lt;T&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 在成员函数中使用基类的成员类型,需要使用 typename 关键字</span></span><br><span class="line">        <span class="keyword">typename</span> Base&lt;T&gt;::value_type y = <span class="number">42</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="decltype-auto"><a href="#decltype-auto" class="headerlink" title="decltype(auto)"></a>decltype(auto)</h4><p> C++14 开始提供的一个略微复杂的用法</p><p>简单来说，<code>decltype(auto)</code> 主要<strong>用于对转发函数或封装的返回类型进行推导</strong>，它使我们<strong>无需显式的指定 <code>decltype</code> 的参数表达式</strong>.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string  <span class="title">lookup1</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">std::string&amp; <span class="title">lookup2</span><span class="params">()</span></span>;</span><br><span class="line">\\在 C++<span class="number">11</span> 中，封装实现是如下形式：</span><br><span class="line"></span><br><span class="line"><span class="function">std::string <span class="title">look_up_a_string_1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">lookup1</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">std::string&amp; <span class="title">look_up_a_string_2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">lookup2</span>();</span><br><span class="line">&#125;</span><br><span class="line">而有了 <span class="keyword">decltype</span>(<span class="keyword">auto</span>)，我们可以让编译器完成这一件烦人的参数转发：</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) <span class="title">look_up_a_string_1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">lookup1</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) <span class="title">look_up_a_string_2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">lookup2</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a>控制流</h3><h4 id="if-constexpr"><a href="#if-constexpr" class="headerlink" title="if constexpr"></a>if constexpr</h4><p>constexpr将表达式或函数编译为常量结果.如果我们把这一特性引入到条件判断中去，让代码在编译时就完成分支判断，岂不是能让程序效率更高？C++17 将 <code>constexpr</code> 这个关键字引入到 <code>if</code> 语句中，允许在代码中声明常量表达式的判断条件</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">print_type_info</span><span class="params">(<span class="keyword">const</span> T&amp; t)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_integral&lt;T&gt;::value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> t + <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> t + <span class="number">0.001</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">print_type_info</span>(<span class="number">5</span>) &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">print_type_info</span>(<span class="number">3.14</span>) &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="区间for迭代"><a href="#区间for迭代" class="headerlink" title="区间for迭代"></a>区间for迭代</h4><p>C++11 引入了基于范围的迭代写法，我们拥有了能够写出像 Python 一样简洁的循环语句</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">auto</span> itr = std::<span class="built_in">find</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), <span class="number">3</span>); itr != vec.<span class="built_in">end</span>()) *itr = <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> element : vec)</span><br><span class="line">        std::cout &lt;&lt; element &lt;&lt; std::endl; <span class="comment">// read only</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;element : vec) &#123;</span><br><span class="line">        element += <span class="number">1</span>;                      <span class="comment">// writeable</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> element : vec)</span><br><span class="line">        std::cout &lt;&lt; element &lt;&lt; std::endl; <span class="comment">// read only</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h3><p>C++ 的模板一直是这门语言的一种特殊的艺术，模板甚至可以独立作为一门新的语言来进行使用。<strong>模板的哲学在于将一切能够在编译期处理的问题丢到编译期进行处理</strong>，<strong>仅在运行时处理那些最核心的动态服务</strong>，进而大幅优化运行期的性能。因此模板也被很多人视作 C++ 的黑魔法之一</p><h4 id="外部模板"><a href="#外部模板" class="headerlink" title="外部模板"></a>外部模板</h4><p>传统 C++ 中，模板只有在使用时才会被编译器实例化。换句话说，只要在每个编译单元（文件）中编译的代码中遇到了被完整定义的模板，都会实例化。这就产生了重复实例化而导致的编译时间的增加。并且，我们没有办法通知编译器不要触发模板的实例化。</p><p>为此，C++11 引入了外部模板，扩充了原来的强制编译器在特定位置实例化模板的语法，使我们能够显式的通知编译器何时进行模板的实例化</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> <span class="class"><span class="keyword">class</span> <span class="title">std</span>:</span>:vector&lt;<span class="keyword">bool</span>&gt;;          <span class="comment">// 强行实例化</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">template</span> <span class="class"><span class="keyword">class</span> <span class="title">std</span>:</span>:vector&lt;<span class="keyword">double</span>&gt;; <span class="comment">// 不在该当前编译文件中实例化模板</span></span><br></pre></td></tr></table></figure><blockquote><p>也就是在编译多个单元式使得相同实例化模板只编译一次</p></blockquote><h4 id="尖括号”-gt-”"><a href="#尖括号”-gt-”" class="headerlink" title="尖括号”&gt;”"></a>尖括号”&gt;”</h4><p>在传统 C++ 的编译器中，<code>&gt;&gt;</code>一律被当做右移运算符来进行处理。但实际上我们很容易就写出了嵌套模板的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;std::vector&lt;<span class="keyword">int</span>&gt;&gt; matrix;</span><br></pre></td></tr></table></figure><p>这在传统 C++ 编译器下是不能够被编译的，而 C++11 开始，连续的右尖括号将变得合法，并且能够顺利通过编译。甚至于像下面这种写法都能够通过编译：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">bool</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MagicType</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> magic = T;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// in main function:</span></span><br><span class="line">std::vector&lt;MagicType&lt;(1&gt;<span class="number">2</span>)&gt;&gt; magic; <span class="comment">// 合法, 但不建议写出这样的代码</span></span><br></pre></td></tr></table></figure><h4 id="类型别名模板"><a href="#类型别名模板" class="headerlink" title="类型别名模板"></a>类型别名模板</h4><p><strong>模板是用来产生类型的。</strong>在传统 C++ 中，<code>typedef</code> 可以为类型定义一个新的名称，但是却没有办法为模板定义一个新的名称。因为，模板不是类型.</p><p>使用using替代typedef</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename T, typename U&gt;</span><br><span class="line">class MagicType &#123;</span><br><span class="line"> public:</span><br><span class="line">  T dark;</span><br><span class="line">  U magic;</span><br><span class="line">&#125;;</span><br><span class="line">template &lt;typename T&gt;</span><br><span class="line">using NewProcess = MagicType&lt;std::vector&lt;T&gt;, std::string&gt;;</span><br></pre></td></tr></table></figure><blockquote><p>通常我们使用 <code>typedef</code> 定义别名的语法是：<code>typedef 原名称 新名称;</code>，但是对函数指针等别名的定义语法却不相同，这通常给直接阅读造成了一定程度的困难。</p></blockquote><h4 id="变长参数模板"><a href="#变长参数模板" class="headerlink" title="变长参数模板"></a>变长参数模板</h4><p>C++11 加入了新的表示方法， <strong>允许任意个数、任意类别的模板参数，同时也不需要在定义时将参数的个数固定</strong>。</p><p><strong>变长参数模板也能被直接调整到到模板函数上</strong>。传统 C 中的 <code>printf</code> 函数， 虽然也能达成不定个数的形参的调用，但其并非类别安全。 而 C++11 除了能定义类别安全的变长参数函数外， 还可以使类似 <code>printf</code> 的函数能自然地处理非自带类别的对象。 除了<strong>在模板参数中能使用 <code>...</code> 表示不定长模板参数外</strong>， <strong>函数参数也使用同样的表示法代表不定长参数</strong>， 这也就为我们简单编写变长参数函数提供了便捷的手段，</p><p>定义了变长的模板参数，如何对参数进行解包呢？</p><p>首先可以使用 <code>sizeof...</code> 来计算参数的个数，：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span>... Ts&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">magic</span><span class="params">(Ts... args)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="keyword">sizeof</span>...(args) &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对参数进行解包，到目前为止还没有一种简单的方法能够处理参数包，但有两种经典的处理手法,一种使用递归(c++17之后可以使用变参模板展开)另一种使用初始化列表展开.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T0&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printf1</span><span class="params">(T0 value)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span>... Ts&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printf1</span><span class="params">(T value, Ts... args)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">printf1</span>(args...);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf1</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="string">&quot;123&quot;</span>, <span class="number">1.1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 C++17 中增加了<strong>变参模板展开</strong>的支持，于是你可以在一个函数中完成 <code>printf</code> 的编写：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">template&lt;typename T0, typename<span class="params">...</span> T&gt;</span><br><span class="line"><span class="literal">void</span> printf2(T0 t0, T<span class="params">...</span> t) &#123;</span><br><span class="line">    std<span class="type">::cout</span> &lt;&lt; t0 &lt;&lt; std<span class="type">::endl</span>;</span><br><span class="line">    <span class="keyword">if</span> constexpr (sizeof<span class="params">...</span>(t) &gt; <span class="number">0</span>) printf2(t<span class="params">...</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>事实上，有时候我们虽然使用了变参模板，却不一定需要对参数做逐个遍历，我们可以<strong>利用 <code>std::bind</code> 及完美转发等特性实现对函数和参数的绑定</strong>，从而达到成功调用的目的。</p></blockquote><p>递归模板函数是一种标准的做法，但缺点显而易见的在于必须定义一个终止递归的函数。</p><p>这里介绍一种使用<strong>初始化列表展开</strong>的黑魔法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span>... Ts&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">printf3</span><span class="params">(T value, Ts... args)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">    (<span class="keyword">void</span>) std::initializer_list&lt;T&gt;&#123;([&amp;args] &#123;</span><br><span class="line">        std::cout &lt;&lt; args &lt;&lt; std::endl;</span><br><span class="line">    &#125;(), value)...&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个代码中，额外使用了 C++11 中提供的初始化列表以及 Lambda 表达式的特性.</p><p>通过初始化列表，<code>(lambda 表达式, value)...</code> 将会被展开。由于逗号表达式的出现，首先会执行前面的 lambda 表达式，完成参数的输出。 为了避免编译器警告，我们可以将 <code>std::initializer_list</code> 显式的转为 <code>void</code></p><h4 id="折叠表达式"><a href="#折叠表达式" class="headerlink" title="折叠表达式"></a>折叠表达式</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> ... T&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">sum</span><span class="params">(T ... t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (t + ...);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>) &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="非类型模板参数推导"><a href="#非类型模板参数推导" class="headerlink" title="非类型模板参数推导"></a>非类型模板参数推导</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">int</span> BufSize&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">buffer_t</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">T&amp; <span class="title">alloc</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">(T&amp; item)</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T data[BufSize];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">buffer_t</span>&lt;<span class="keyword">int</span>, <span class="number">100</span>&gt; buf; <span class="comment">// 100 作为模板参数</span></span><br></pre></td></tr></table></figure><p>既然此处的模板参数 以具体的字面量进行传递，能否让编译器辅助我们进行类型推导， 通过使用占位符 <code>auto</code> 从而不再需要明确指明类型？ 幸运的是，C++17 引入了这一特性，我们的确可以 <code>auto</code> 关键字，让编译器辅助完成具体类型的推导， 例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">auto</span> value&gt; <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    foo&lt;<span class="number">10</span>&gt;();  <span class="comment">// value 被推导为 int 类型</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h3><p>C++11 引入了委托构造的概念，这使得构造函数可以在同一个类中一个构造函数调用另一个构造函数，从而达到简化代码的目的</p><h4 id="委托构造"><a href="#委托构造" class="headerlink" title="委托构造"></a>委托构造</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> value1;</span><br><span class="line">    <span class="keyword">int</span> value2;</span><br><span class="line">    <span class="built_in">Base</span>() &#123;</span><br><span class="line">        value1 = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">Base</span>(<span class="keyword">int</span> value) : <span class="built_in">Base</span>() &#123; <span class="comment">// 委托 Base() 构造函数</span></span><br><span class="line">        value2 = value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">Base <span class="title">b</span><span class="params">(<span class="number">2</span>)</span></span>;</span><br><span class="line">    std::cout &lt;&lt; b.value1 &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; b.value2 &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="继承构造"><a href="#继承构造" class="headerlink" title="继承构造"></a>继承构造</h4><p>在传统 C++ 中，<strong>构造函数如果需要继承是需要将参数一一传递的，这将导致效率低下</strong>。C++11 利用关键字 <code>using</code> 引入了继承构造函数的概念</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> value1;</span><br><span class="line">    <span class="keyword">int</span> value2;</span><br><span class="line">    <span class="built_in">Base</span>() &#123;</span><br><span class="line">        value1 = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">Base</span>(<span class="keyword">int</span> value) : <span class="built_in">Base</span>() &#123; <span class="comment">// 委托 Base() 构造函数</span></span><br><span class="line">        value2 = value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Subclass</span> :</span> <span class="keyword">public</span> Base &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">using</span> Base::Base; <span class="comment">// 继承构造</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">Subclass <span class="title">s</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">    std::cout &lt;&lt; s.value1 &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; s.value2 &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="显示虚函数重载"><a href="#显示虚函数重载" class="headerlink" title="显示虚函数重载"></a>显示虚函数重载</h4><p>在c++中通过virtual声明可重载的方法,称为虚函数,但只要不是纯虚函数,子类就可以不用去重载实现.</p><p>但是如果实现了一个同名方法,通过override看有没有对应的基类方法.</p><p>通过final让类或者方法不能被继承和重载.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Base</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SubClass</span>:</span> Base &#123;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span>)</span> <span class="keyword">override</span></span>; <span class="comment">// 合法</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">float</span>)</span> <span class="keyword">override</span></span>; <span class="comment">// 非法, 父类没有此虚函数</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>final</code> 则是为了防止类被继续继承以及终止虚函数继续重载引入的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Base</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> <span class="keyword">final</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SubClass1</span> <span class="keyword">final</span>:</span> Base &#123;</span><br><span class="line">&#125;; <span class="comment">// 合法</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SubClass2</span> :</span> SubClass1 &#123;</span><br><span class="line">&#125;; <span class="comment">// 非法, SubClass1 已 final</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SubClass3</span>:</span> Base &#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span>; <span class="comment">// 非法, foo 已 final</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="显示禁用默认函数"><a href="#显示禁用默认函数" class="headerlink" title="显示禁用默认函数"></a>显示禁用默认函数</h4><p>在传统 C++ 中，如果程序员没有提供，<strong>编译器会默认为对象生成默认构造函数、 复制构造、赋值算符以及析构函数</strong>。 另外，C++ 也为所有类定义了诸如 <code>new</code> <code>delete</code> 这样的运算符。 当程序员有需要时，可以重载这部分函数</p><p>这就引发了一些需求：<strong>无法精确控制默认函数的生成行为</strong>。 例如<strong>禁止类的拷贝时，必须将复制构造函数与赋值算符声明为 <code>private</code></strong>。 尝试使用这些未定义的函数将导致编译或链接错误，则是一种非常不优雅的方式。</p><p>编译器产生的默认构造函数与用户定义的构造函数无法同时存在。 若用户定义了任何构造函数，编译器将不再生成默认构造函数.</p><p>C++11 提供了上述需求的解决方案，允许显式的声明采用或拒绝编译器自带的函数， 但<strong>有时候我们却希望同时拥有这两种构造函数</strong>，这就造成了尴尬</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Magic &#123;</span><br><span class="line">    public:</span><br><span class="line">    Magic() = default; // 显式声明使用编译器生成的构造</span><br><span class="line">    Magic&amp; operator=(const Magic&amp;) = delete; // 显式声明拒绝编译器生成构造</span><br><span class="line">    Magic(int magic_number);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="强类型枚举"><a href="#强类型枚举" class="headerlink" title="强类型枚举"></a>强类型枚举</h4><p>在传统 C++中，枚举类型并非类型安全，枚举类型会被视作整数，则会让两种完全不同的枚举类型可以进行直接的比较（虽然编译器给出了检查，但并非所有），<strong>甚至同一个命名空间中的不同枚举类型的枚举值名字不能相同</strong>，这通常不是我们希望看到的结果。</p><blockquote><p>enum class替代enum</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="keyword">class</span> <span class="title">Color</span> :</span> <span class="keyword">uint8_t</span> &#123; RED = <span class="number">1</span>, GREEN = <span class="number">2</span>, BLUE = <span class="number">3</span> &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样定义的枚举<strong>实现了类型安全</strong>，首先<strong>他不能够被隐式的转换为整数</strong>，同时<strong>也不能够将其与整数数字进行比较</strong>， <strong>更不可能对不同的枚举类型的枚举值进行比较</strong>。<strong>但相同枚举值之间如果指定的值相同，那么可以进行比较</strong></p><p>我们希望获得枚举值的值时，将必须显式的进行类型转换，不过我们可以通过重载 <code>&lt;&lt;</code> 这个算符来进行输出</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">std::ostream&amp; <span class="keyword">operator</span>&lt;&lt;(</span><br><span class="line">    <span class="keyword">typename</span> std::enable_if&lt;std::is_enum&lt;T&gt;::value, std::ostream&gt;::type&amp; stream,</span><br><span class="line">    <span class="keyword">const</span> T&amp; e) &#123;</span><br><span class="line">  <span class="keyword">return</span> stream &lt;&lt; <span class="keyword">static_cast</span>&lt;<span class="keyword">typename</span> std::underlying_type&lt;T&gt;::type&gt;(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>作业</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">typename</span> Value, <span class="keyword">typename</span> F&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">update</span><span class="params">(std::map&lt;Key, Value&gt;&amp; m, F foo)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span></span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp;&amp; [key, value] : m) &#123;</span><br><span class="line">    value = <span class="built_in">foo</span>(key);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span>... T&gt;</span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">average</span><span class="params">(T... t)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (t + ...) / <span class="keyword">sizeof</span>...(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>重点</strong></p><ol><li><code>auto</code> 类型推导</li><li>范围 <code>for</code> 迭代</li><li>初始化列表</li><li>变参模板</li></ol><h2 id="运行期的强化"><a href="#运行期的强化" class="headerlink" title="运行期的强化"></a>运行期的强化</h2><h3 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h3><p>Lambda 表达式是现代 C++ 中最重要的特性之一，而 Lambda 表达式，<strong>实际上就是提供了一个类似匿名函数的特性， 而匿名函数则是在需要一个函数，但是又不想费力去命名一个函数的情况下去使用的。</strong>这样的场景其实有很多很多， 所以匿名函数几乎是现代编程语言的标配。</p><p>Lambda 表达式的基本语法如下：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[捕获列表]</span>(参数列表) <span class="selector-tag">mutable</span>(可选) 异常属性 <span class="selector-tag">-</span>&gt; 返回类型 &#123;</span><br><span class="line"><span class="comment">// 函数体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所谓捕获列表，其实可以理解为参数的一种类型，Lambda 表达式内部函数体在默认情况下是不能够使用函数体外部的变量的， 这时候捕获列表可以起到传递外部数据的作用</p><h4 id="值捕获"><a href="#值捕获" class="headerlink" title="值捕获"></a>值捕获</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lambda_value_capture</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> value = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">auto</span> copy_value = [value] &#123;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;;</span><br><span class="line">    value = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">auto</span> stored_value = <span class="built_in">copy_value</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;stored_value = &quot;</span> &lt;&lt; stored_value &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// 这时, stored_value == 1, 而 value == 100.</span></span><br><span class="line">    <span class="comment">// 因为 copy_value 在创建时就保存了一份 value 的拷贝</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="引用捕获"><a href="#引用捕获" class="headerlink" title="引用捕获"></a>引用捕获</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lambda_reference_capture</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> value = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">auto</span> copy_value = [&amp;value] &#123;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;;</span><br><span class="line">    value = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">auto</span> stored_value = <span class="built_in">copy_value</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;stored_value = &quot;</span> &lt;&lt; stored_value &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// 这时, stored_value == 100, value == 100.</span></span><br><span class="line">    <span class="comment">// 因为 copy_value 保存的是引用</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="隐式捕获"><a href="#隐式捕获" class="headerlink" title="隐式捕获"></a>隐式捕获</h4><p>手动书写捕获列表有时候是非常复杂的，这种机械性的工作可以交给编译器来处理，这时候可以在捕获列表中写一个 <code>&amp;</code> 或 <code>=</code> 向编译器声明采用引用捕获或者值捕获.</p><p>总结一下，捕获提供了 Lambda 表达式对外部值进行使用的功能，捕获列表的最常用的四种形式可以是：</p><ul><li>[] 空捕获列表</li><li>[name1, name2, …] 捕获一系列变量</li><li>[&amp;] 引用捕获, 从函数体内的使用确定引用捕获列表</li><li>[=] 值捕获, 从函数体内的使用确定值捕获列表</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[]      <span class="comment">// 沒有定义任何变量。使用未定义变量会引发错误。</span></span><br><span class="line">[x, &amp;y] <span class="comment">// x以传值方式传入（默认），y以引用方式传入。</span></span><br><span class="line">[&amp;]     <span class="comment">// 任何被使用到的外部变量都隐式地以引用方式加以引用。</span></span><br><span class="line">[=]     <span class="comment">// 任何被使用到的外部变量都隐式地以传值方式加以引用。</span></span><br><span class="line">[&amp;, x]  <span class="comment">// x显式地以传值方式加以引用。其余变量以引用方式加以引用。</span></span><br><span class="line">[=, &amp;z] <span class="comment">// z显式地以引用方式加以引用。其余变量以传值方式加以引用。</span></span><br></pre></td></tr></table></figure><h4 id="表达式捕获"><a href="#表达式捕获" class="headerlink" title="表达式捕获"></a>表达式捕获</h4><p>上面提到的值捕获、引用捕获都是已经在外层作用域声明的变量，因此这些捕获方式<strong>捕获的均为左值，而不能捕获右值</strong>。</p><blockquote><p>它表示一个即将被销毁的临时对象或表达式的结果。与之相对应的是左值(lvalue)，它表示一个可以取地址的对象。下面让我们详细解释一下右值的概念:</p><ol><li><strong>临时对象</strong>:<ul><li>右值通常指的是临时对象,这些对象是表达式的结果,在表达式结束后就会被销毁。</li><li>例如: <code>std::string(&quot;hello&quot;)</code> 是一个临时的 <code>std::string</code> 对象,它是一个右值。</li></ul></li><li><strong>表达式结果</strong>:<ul><li>任何表达式的结果都是一个右值,除非该表达式的结果是一个可以取地址的对象(即左值)。</li><li>例如: <code>1 + 2</code> 的结果是一个右值,因为它只是一个临时的数值。</li></ul></li><li><strong>无名对象</strong>:<ul><li>在 C++ 中,无名对象也是右值。无名对象是没有变量名称的临时对象。</li><li>例如: <code>MyClass()</code> 创建的是一个无名的 <code>MyClass</code> 对象,它是一个右值。</li></ul></li><li><strong>移动语义</strong>:<ul><li>在 C++11 中引入了移动语义的概念,它利用了右值的特性来优化性能。</li><li>当一个对象作为右值传递时,我们可以”移动”它的资源,而不是复制它,从而避免不必要的内存分配和复制操作。</li></ul></li></ol></blockquote><p>C++14 给与了我们方便，<strong>允许捕获的成员用任意的表达式进行初始化，这就允许了右值的捕获</strong>， 被声明的捕获变量类型会根据表达式进行判断，判断方式与使用 <code>auto</code> 本质上是相同的</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span>  <span class="comment">// std::make_unique</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span> <span class="comment">// std::move</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lambda_expression_capture</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> important = std::make_unique&lt;<span class="keyword">int</span>&gt;(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">auto</span> add = [v1 = <span class="number">1</span>, v2 = std::<span class="built_in">move</span>(important)](<span class="keyword">int</span> x, <span class="keyword">int</span> y) -&gt; <span class="keyword">int</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> x+y+v1+(*v2);</span><br><span class="line">    &#125;;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">add</span>(<span class="number">3</span>,<span class="number">4</span>) &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的代码中<strong>，important 是一个独占指针，是不能够被 “=” 值捕获到，这时候我们可以将其转移为右值</strong>，在表达式中初始化</p><h4 id="泛型lambda"><a href="#泛型lambda" class="headerlink" title="泛型lambda"></a>泛型lambda</h4><p><code>auto</code> 关键字不能够用在参数表里，这是因为这样的写法会与模板的功能产生冲突。 但是 Lambda 表达式并不是普通函数，所以在没有明确指明参数表类型的情况下，Lambda 表达式并不能够模板化。 幸运的是，这种麻烦只存在于 C++11 中，从 C++14 开始，Lambda 函数的形式参数可以使用 <code>auto</code> 关键字来产生意义上的泛型</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> add = [](<span class="keyword">auto</span> x, <span class="keyword">auto</span> y) &#123;</span><br><span class="line">    <span class="keyword">return</span> x+y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">add</span>(<span class="number">1</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">add</span>(<span class="number">1.1</span>, <span class="number">2.2</span>);</span><br></pre></td></tr></table></figure><h3 id="函数对象包装器"><a href="#函数对象包装器" class="headerlink" title="函数对象包装器"></a>函数对象包装器</h3><h4 id="std-function"><a href="#std-function" class="headerlink" title="std::function"></a>std::function</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> foo = <span class="built_in"><span class="keyword">void</span></span>(<span class="keyword">int</span>); <span class="comment">// 定义函数类型, using 的使用见上一节中的别名语法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">functional</span><span class="params">(foo f)</span> </span>&#123; <span class="comment">// 参数列表中定义的函数类型 foo 被视为退化后的函数指针类型 foo*</span></span><br><span class="line">    <span class="built_in">f</span>(<span class="number">1</span>); <span class="comment">// 通过函数指针调用函数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> f = [](<span class="keyword">int</span> value) &#123;</span><br><span class="line">        std::cout &lt;&lt; value &lt;&lt; std::endl;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">functional</span>(f); <span class="comment">// 传递闭包对象，隐式转换为 foo* 类型的函数指针值</span></span><br><span class="line">    <span class="built_in">f</span>(<span class="number">1</span>); <span class="comment">// lambda 表达式调用</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>种是将 Lambda 作为函数类型传递进行调用， 而另一种则是直接调用 Lambda 表达式，在 C++11 中，统一了这些概念，将能够被调用的对象的类型， 统一称之为可调用类型。而这种类型，便是通过 <code>std::function</code> 引入的。</p><p>C++11 <code>std::function</code> 是一种通用、多态的函数封装， 它的实例可以对任何可以调用的目标实体进行存储、复制和调用操作， 它也是对 C++ 中现有的可调用实体的一种类型安全的包裹（相对来说，函数指针的调用不是类型安全的）， 换句话说，<strong>就是函数的容器。当我们有了函数的容器之后便能够更加方便的将函数、函数指针作为对象进行处理</strong>。 例如</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> para)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> para;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// std::function 包装了一个返回值为 int, 参数为 int 的函数</span></span><br><span class="line">    std::function&lt;<span class="built_in"><span class="keyword">int</span></span>(<span class="keyword">int</span>)&gt; func = foo;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> important = <span class="number">10</span>;</span><br><span class="line">    std::function&lt;<span class="built_in"><span class="keyword">int</span></span>(<span class="keyword">int</span>)&gt; func2 = [&amp;](<span class="keyword">int</span> value) -&gt; <span class="keyword">int</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>+value+important;</span><br><span class="line">    &#125;;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">func</span>(<span class="number">10</span>) &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">func2</span>(<span class="number">10</span>) &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="std-bind和std-placeholder"><a href="#std-bind和std-placeholder" class="headerlink" title="std::bind和std::placeholder"></a>std::bind<code>和</code>std::placeholder</h4><p>而 <code>std::bind</code> 则是用来绑定函数调用的参数的， 它解决的需求是我们有时候可能并不一定能够一次性获得调用某个函数的全部参数，通过这个函数， 我们可以将部分调用参数提前绑定到函数身上成为一个新的对象，然后在参数齐全后，完成调用。 例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b, <span class="keyword">int</span> c)</span> </span>&#123;</span><br><span class="line">    ;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将参数1,2绑定到函数 foo 上，</span></span><br><span class="line">    <span class="comment">// 但使用 std::placeholders::_1 来对第一个参数进行占位</span></span><br><span class="line">    <span class="keyword">auto</span> bindFoo = std::<span class="built_in">bind</span>(foo, std::placeholders::_1, <span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">    <span class="comment">// 这时调用 bindFoo 时，只需要提供第一个参数即可</span></span><br><span class="line">    <span class="built_in">bindFoo</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="右值引用"><a href="#右值引用" class="headerlink" title="右值引用"></a>右值引用</h3><p>右值引用是 C++11 引入的<strong>与 Lambda 表达式齐名的重要特性之一</strong>。它的<strong>引入解决了 C++ 中大量的历史遗留问题， 消除了诸如 <code>std::vector</code>、<code>std::string</code> 之类的额外开销</strong>， 也才使得函数对象容器 <code>std::function</code> 成为了可能</p><p>左值引用 左值  右值</p><p><strong>左值</strong> (lvalue, left value)，顾名思义就是赋值符号左边的值。准确来说， <strong>左值是表达式（不一定是赋值表达式）后依然存在的持久对象</strong>。</p><p> C++11 中为了引入强大的右值引用，将右值的概念进行了进一步的划分，分为：纯右值、将亡值。</p><p><strong>纯右值</strong> (prvalue, pure rvalue)，纯粹的右值，要么是纯粹的字面量，例如 <code>10</code>, <code>true</code>； 要么是求值结果相当于字面量或匿名临时对象，例如 <code>1+2</code>。非引用返回的临时变量、<strong>运算表达式产生的临时变量</strong>、 原<strong>始字面量</strong>、<strong>Lambda 表达式都属于纯右值</strong>。</p><p>字面量除了字符串字面量以外，均为纯右值。而<strong>字符串字面量是一个左值</strong>，类型为 <code>const char</code> 数组</p><p>将亡值可能稍有些难以理解，我们来看这样的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::vector&lt;<span class="keyword">int</span>&gt; <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; temp = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">return</span> temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; v = <span class="built_in">foo</span>();</span><br></pre></td></tr></table></figure><p>在这样的代码中，就传统的理解而言，函数 <code>foo</code> 的返回值 <code>temp</code> 在内部创建然后被赋值给 <code>v</code>， 然而 <code>v</code> 获得这个对象时，会将整个 <code>temp</code> 拷贝一份，然后把 <code>temp</code> 销毁，如果这个 <code>temp</code> 非常大， 这将造成大量额外的开销（这也就是传统 C++ 一直被诟病的问题）。在最后一行中，<code>v</code> 是左值、 <code>foo()</code> 返回的值就是右值（也是纯右值）。但是，<code>v</code> 可以被别的变量捕获到， 而 <code>foo()</code> 产生的那个返回值作为一个临时值，一旦被 <code>v</code> 复制后，将立即被销毁，无法获取、也不能修改。 而将亡值就定义了这样一种行为：临时的值能够被识别、同时又能够被移动。</p><p>在 C++11 之后，编译器为我们做了一些工作，<strong>此处的左值 <code>temp</code> 会被进行此隐式右值转换， 等价于 <code>static_cast&lt;std::vector&lt;int&gt; &amp;&amp;&gt;(temp)</code>，进而此处的 <code>v</code> 会将 <code>foo</code> 局部返回的值进行移动</strong>。 也就是后面我们将会提到的移动语义。</p><p>要拿到一个将亡值，就需要用到右值引用：<code>T &amp;&amp;</code>，其中 <code>T</code> 是类型。 右值引用的声明让这个临时值的生命周期得以延长、只要变量还活着，那么将亡值将继续存活。</p><p>C++11 提供了 <code>std::move</code> 这个方法将左值参数无条件的转换为右值， 有了它我们就能够方便的获得一个右值临时对象，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reference</span><span class="params">(std::string&amp; str)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;左值&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reference</span><span class="params">(std::string&amp;&amp; str)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;右值&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::string lv1 = <span class="string">&quot;string,&quot;</span>; <span class="comment">// lv1 是一个左值</span></span><br><span class="line">    <span class="comment">// std::string&amp;&amp; r1 = lv1; // 非法, 右值引用不能引用左值</span></span><br><span class="line">    std::string&amp;&amp; rv1 = std::<span class="built_in">move</span>(lv1); <span class="comment">// 合法, std::move可以将左值转移为右值</span></span><br><span class="line">    std::cout &lt;&lt; rv1 &lt;&lt; std::endl; <span class="comment">// string,</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> std::string&amp; lv2 = lv1 + lv1; <span class="comment">// 合法, 常量左值引用能够延长临时变量的生命周期</span></span><br><span class="line">    <span class="comment">// lv2 += &quot;Test&quot;; // 非法, 常量引用无法被修改</span></span><br><span class="line">    std::cout &lt;&lt; lv2 &lt;&lt; std::endl; <span class="comment">// string,string,</span></span><br><span class="line"></span><br><span class="line">    std::string&amp;&amp; rv2 = lv1 + lv2; <span class="comment">// 合法, 右值引用延长临时对象生命周期</span></span><br><span class="line">    rv2 += <span class="string">&quot;Test&quot;</span>; <span class="comment">// 合法, 非常量引用能够修改临时变量</span></span><br><span class="line">    std::cout &lt;&lt; rv2 &lt;&lt; std::endl; <span class="comment">// string,string,string,Test</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">reference</span>(rv2); <span class="comment">// 输出左值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>历史遗留问题:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// int &amp;a = std::move(1);    // 不合法，非常量左引用无法引用右值</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> &amp;b = std::<span class="built_in">move</span>(<span class="number">1</span>); <span class="comment">// 合法, 常量左引用允许引用右值</span></span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; a &lt;&lt; b &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一个问题，为什么不允许非常量引用绑定到非左值？这是因为这种做法存在逻辑错误：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increase</span><span class="params">(<span class="keyword">int</span> &amp; v)</span> </span>&#123;</span><br><span class="line">    v++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> s = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">increase</span>(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于 <code>int&amp;</code> 不能引用 <code>double</code> 类型的参数，因此必须产生一个临时值来保存 <code>s</code> 的值， 从而当 <code>increase()</code> 修改这个临时值时，调用完成后 <code>s</code> 本身并没有被修改。</p><p>第二个问题，为什么常量引用允许绑定到非左值？原因很简单，因为 Fortran 需要</p><p>总结一下,非常量左值引用能够引用左值以及右值.左值引用作为函数的参数，能够减少拷贝, 左值引用可以引用函数返回值，也可以减少拷贝构造</p><p><strong>右值是不能取出地址的</strong>，但是当右值取别名后，这个右值会被存到特定的位置，且可以取到该值的地址，也就是说右值引用值是一个左值。</p><p>右值引用只能引用右值.  <code>std::move</code>能将左值/右值都转为右值引用</p><p>拿到右值引用后就能使用移动构造和赋值进行节省内存了.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Vector&amp; <span class="title">func1</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">Vector&amp;&amp; <span class="title">func2</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">Vector <span class="title">func3</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Vector a;</span><br><span class="line">a;              <span class="comment">//左值表达式</span></span><br><span class="line"><span class="built_in">func1</span>();        <span class="comment">//左值表达式，返还值是临时的，返还类型是左值引用，因此被认为不可移动。</span></span><br><span class="line"><span class="built_in">func2</span>();        <span class="comment">//将亡值表达式，返还值是临时的，返还类型是右值引用，因此指代的对象即使非临时也会被认为可移动。</span></span><br><span class="line"><span class="built_in">func3</span>();        <span class="comment">//纯右值表达式，返还值为临时值。</span></span><br><span class="line">std::<span class="built_in">move</span>(a)；  <span class="comment">//将亡值表达式，std::move本质也是个函数，同上。</span></span><br><span class="line"><span class="built_in">Vector</span>();       <span class="comment">//纯右值表达式</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>右值引用&amp;&amp;类似一种标记,主要用于移动构造和赋值节省拷贝操作,否则拷贝构造和赋值会将函数返回值先拷贝到临时值,临时值再拷贝到到函数接收值上造成浪费(编译器不优化的情况下).</p><p>std::move就是一种方便操作将左右值都转为右值引用.</p><p>std::forward进行完美转发,也就是将左值得到左值,右值依然是右值.</p></blockquote><p>tips:</p><ul><li><strong>右值引用类型只是用于匹配右值，而并非表示一个右值。因此，尽量不要声明右值引用类型的变量，而只在函数形参使用它以匹配右值</strong></li><li>实参传递给形参，即形参会根据实参来构造。其结果是调用了移动构造函数；函数结束时则释放形参。</li></ul><p><strong>拷贝构造与移动构造</strong></p><p>拷贝构造函数，又称复制构造函数，是一种特殊的构造函数，它由编译器调用来完成一些基于同一类的其他对象的构建及初始化。其形参必须是引用，但并不限制为const，一般普遍的会加上const限制.</p><p>此函数经常用在<strong>函数调用时用户定义类型的值传递及返回</strong>。拷贝构造函数要调用基类的拷贝构造函数和成员函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CExample</span>(<span class="keyword">const</span> CExample &amp; c)</span><br><span class="line">  &#123;</span><br><span class="line">      a=c.a;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;copy constructor is called\n&quot;</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>移动构造（Move Constructor）是一种特殊的构造函数，它通过<strong>接收一个右值引用参数来创建新对象，并从传入的对象中“移动”资源而不是执行深拷贝</strong>。</p><p>移动构造的使用场景：</p><ul><li><p>在函数中返回临时对象时，可以通过移动构造函数避免不必要的拷贝操作。</p></li><li><p>在容器中插入临时对象时，可以通过移动构造函数实现高效插入和删除操作。</p></li><li><p>在进行资源管理时，通过移动构造函数可以从一个对象转移资源所有权，提高性能</p></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 移动构造函数</span></span><br><span class="line">    <span class="built_in">MyClass</span>(MyClass&amp;&amp; other) &#123;</span><br><span class="line">        <span class="comment">// 资源的转移或交换操作</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>实现的 拷贝构造 的参数是<strong>const 类型</strong>，所以<strong>既可以进行左值引用也可以进行右值引用</strong> <strong>当存在移动构造时，传入右值优先调用移动构造</strong>，否则构造此时的拷贝构造。</p><p><strong>拷贝赋值与移动赋值</strong></p><p><strong>赋值操作符则是处理一个已经存在的对象。对一个对象赋值，当它一次出现时，它将调用复制构造函数，以后每次出现，都调用赋值操作符</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">string&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> string &amp;s);</span><br></pre></td></tr></table></figure><p>移动赋值（Move Assignment）是一种在编程语言中用于<strong>将一个对象的资源（如内存空间）转移到另一个对象</strong>的操作</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 移动赋值</span></span><br><span class="line">string&amp; <span class="keyword">operator</span>=(string&amp;&amp; s)</span><br><span class="line">&#123;</span><br><span class="line">cout &lt;&lt; <span class="string">&quot;string&amp; operator=(string&amp;&amp; s) &lt;---&gt; 移动赋值(资源移动)&quot;</span> &lt;&lt; endl;</span><br><span class="line"><span class="built_in">swap</span>(s);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="移动语义"><a href="#移动语义" class="headerlink" title="移动语义"></a>移动语义</h4><p>传统 C++ 通过拷贝构造函数和赋值操作符为类对象设计了拷贝/复制的概念，但为了实现对资源的移动操作， 调用者必须使用先复制、再析构的方式，否则就需要自己实现移动对象的接口。 试想，搬家的时候是把家里的东西直接搬到新家去，而不是将所有东西复制一份（重买）再放到新家、 再把原来的东西全部扔掉（销毁），这是非常反人类的一件事情。</p><p>传统的 C++ 没有区分『移动』和『拷贝』的概念，造成了大量的数据拷贝，浪费时间和空间。 右值引用的出现恰好就解决了这两个概念的混淆问题，</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> *pointer;</span><br><span class="line">    <span class="built_in">A</span>():<span class="built_in">pointer</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(<span class="number">1</span>)) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;构造&quot;</span> &lt;&lt; pointer &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">A</span>(A&amp; a):<span class="built_in">pointer</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(*a.pointer)) &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;拷贝&quot;</span> &lt;&lt; pointer &lt;&lt; std::endl;</span><br><span class="line">    &#125; <span class="comment">// 无意义的对象拷贝</span></span><br><span class="line">    <span class="built_in">A</span>(A&amp;&amp; a):<span class="built_in">pointer</span>(a.pointer) &#123;</span><br><span class="line">        a.pointer = <span class="literal">nullptr</span>;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;移动&quot;</span> &lt;&lt; pointer &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">A</span>()&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;析构&quot;</span> &lt;&lt; pointer &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">delete</span> pointer;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 防止编译器优化</span></span><br><span class="line"><span class="function">A <span class="title">return_rvalue</span><span class="params">(<span class="keyword">bool</span> test)</span> </span>&#123;</span><br><span class="line">    A a,b;</span><br><span class="line">    <span class="keyword">if</span>(test) <span class="keyword">return</span> a; <span class="comment">// 等价于 static_cast&lt;A&amp;&amp;&gt;(a);</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> b;     <span class="comment">// 等价于 static_cast&lt;A&amp;&amp;&gt;(b);</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    A obj = <span class="built_in">return_rvalue</span>(<span class="literal">false</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;obj:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; obj.pointer &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; *obj.pointer &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="完美转发"><a href="#完美转发" class="headerlink" title="完美转发"></a>完美转发</h4><p>当我们使用了万能引用时，即使可以同时匹配左值、右值，但需要转发参数给其他函数时，会丢失引用性质（形参是个左值，从而无法判断到底匹配的是个左值还是右值）.一个声明的右值引用其实是一个左值。这就为我们进行参数转发（传递）造成了问题</p><p>完美转发函数 <strong>std:forward<T></strong> 。它可以在模板函数内给另一个函数传递参数时，将参数类型保持原本状态传入（如果形参推导出是右值引用则作为右值传入，如果是左值引用则作为左值传入）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reference</span><span class="params">(<span class="keyword">int</span>&amp; v)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;左值&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reference</span><span class="params">(<span class="keyword">int</span>&amp;&amp; v)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;右值&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">pass</span><span class="params">(T&amp;&amp; v)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;普通传参:&quot;</span>;</span><br><span class="line">    <span class="built_in">reference</span>(v); <span class="comment">// 始终调用 reference(int&amp;)</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;传递右值:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">pass</span>(<span class="number">1</span>); <span class="comment">// 1是右值, 但输出是左值</span></span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;传递左值:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">int</span> l = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">pass</span>(l); <span class="comment">// l 是左值, 输出左值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于 <code>pass(1)</code> 来说，虽然传递的是右值，但由于 <code>v</code> 是一个引用，所以同时也是左值。 因此 <code>reference(v)</code> 会调用 <code>reference(int&amp;)</code>，输出『左值』。 而对于<code>pass(l)</code>而言，<code>l</code>是一个左值，为什么会成功传递给 <code>pass(T&amp;&amp;)</code> 呢？</p><p>这是基于<strong>引用坍缩规则</strong>的：在传统 C++ 中，我们不能够对一个引用类型继续进行引用， 但 C++ 由于右值引用的出现而放宽了这一做法，从而产生了引用坍缩规则，允许我们对引用进行引用， 既能左引用，又能右引用。但是却遵循如下规则：</p><div class="table-container"><table><thead><tr><th style="text-align:left">函数形参类型</th><th style="text-align:left">实参参数类型</th><th style="text-align:left">推导后函数形参类型</th></tr></thead><tbody><tr><td style="text-align:left">T&amp;</td><td style="text-align:left">左引用</td><td style="text-align:left">T&amp;</td></tr><tr><td style="text-align:left">T&amp;</td><td style="text-align:left">右引用</td><td style="text-align:left">T&amp;</td></tr><tr><td style="text-align:left">T&amp;&amp;</td><td style="text-align:left">左引用</td><td style="text-align:left">T&amp;</td></tr><tr><td style="text-align:left">T&amp;&amp;</td><td style="text-align:left">右引用</td><td style="text-align:left">T&amp;&amp;</td></tr></tbody></table></div><p>因此，模板函数中使用 <code>T&amp;&amp;</code> 不一定能进行右值引用，当传入左值时，此函数的引用将被推导为左值。 更准确的讲，<strong>无论模板参数是什么类型的引用，当且仅当实参类型为右引用时，模板参数才能被推导为右引用类型</strong>。 这才使得 <code>v</code> 作为左值的成功传递。</p><p>谓完美转发，就是为了让我们在传递参数的时候， 保持原来的参数类型（左引用保持左引用，右引用保持右引用）。 为了解决这个问题，我们应该使用 <code>std::forward</code> 来进行参数的转发（传递）：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reference</span><span class="params">(<span class="keyword">int</span>&amp; v)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;左值引用&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reference</span><span class="params">(<span class="keyword">int</span>&amp;&amp; v)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;右值引用&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">pass</span><span class="params">(T&amp;&amp; v)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;              普通传参: &quot;</span>;</span><br><span class="line">    <span class="built_in">reference</span>(v);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;       std::move 传参: &quot;</span>;</span><br><span class="line">    <span class="built_in">reference</span>(std::<span class="built_in">move</span>(v));</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;    std::forward 传参: &quot;</span>;</span><br><span class="line">    <span class="built_in">reference</span>(std::forward&lt;T&gt;(v));</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;static_cast&lt;T&amp;&amp;&gt; 传参: &quot;</span>;</span><br><span class="line">    <span class="built_in">reference</span>(<span class="keyword">static_cast</span>&lt;T&amp;&amp;&gt;(v));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;传递右值:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">pass</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;传递左值:&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">int</span> v = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">pass</span>(v);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">传递右值:</span><br><span class="line">              普通传参: 左值引用</span><br><span class="line">       std::move 传参: 右值引用</span><br><span class="line">    std::forward 传参: 右值引用</span><br><span class="line"><span class="keyword">static_cast</span>&lt;T&amp;&amp;&gt; 传参: 右值引用</span><br><span class="line">传递左值:</span><br><span class="line">              普通传参: 左值引用</span><br><span class="line">       std::move 传参: 右值引用</span><br><span class="line">    std::forward 传参: 左值引用</span><br><span class="line"><span class="keyword">static_cast</span>&lt;T&amp;&amp;&gt; 传参: 左值引用</span><br></pre></td></tr></table></figure><p>无论传递参数为左值还是右值，普通传参都会将参数作为左值进行转发； 由于类似的原因，<code>std::move</code> 总会接受到一个左值，从而转发调用了<code>reference(int&amp;&amp;)</code> 输出右值引用。</p><p>唯独 <code>std::forward</code> 即没有造成任何多余的拷贝，同时<strong>完美转发</strong>(传递)了函数的实参给了内部调用的其他函数。</p><p><code>std::forward</code> 和 <code>std::move</code> 一样，没有做任何事情，<code>std::move</code> 单纯的将左值转化为右值， <code>std::forward</code> 也只是单纯的将参数做了一个类型的转换，从现象上来看， <code>std::forward&lt;T&gt;(v)</code> 和 <code>static_cast&lt;T&amp;&amp;&gt;(v)</code> 是完全一样的。</p><p><strong>1. 我们应该首先把编写右值引用类型相关的任务重点放在对象的构造、赋值函数上。从源头上出发，在编写其它代码时会自然而然享受到了移动构造、移动赋值的优化效果。</strong></p><p><strong>2. 形参：从优化的角度上看，若参数有支持移动构造（或移动赋值）的类型，应提供左值引用和右值引用的重载版本。移动开销很低时，只提供一个非引用类型的版本也是可以接受的。</strong></p><p><strong>3. 返还值：不要且没必要编写返还右值引用类型的函数，除非有特殊用途。</strong></p><h2 id="可能遇到的报错"><a href="#可能遇到的报错" class="headerlink" title="可能遇到的报错"></a>可能遇到的报错</h2><ol><li>非常量引用的初始值必须为左值</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span>&amp; ref = x; <span class="comment">// x 是一个左值表达式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> y = <span class="number">20</span>;</span><br><span class="line"><span class="keyword">int</span> z = y + <span class="number">5</span>; <span class="comment">// y + 5 是一个右值表达式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> x = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span>&amp; ref1 = x;  <span class="comment">// 正确,x 是一个左值</span></span><br><span class="line"><span class="keyword">int</span> y = <span class="number">20</span>;</span><br><span class="line"><span class="keyword">int</span>&amp; ref2 = y + <span class="number">5</span>; <span class="comment">// 错误,y + 5 是一个右值表达式</span></span><br></pre></td></tr></table></figure><p>这个规则的目的是为了确保引用变量在初始化后能够继续指向一个可修改的对象。如果允许引用绑定到一个临时的右值表达式,那么当这个临时对象被销毁后,引用就会悬空(dangle),这会导致程序出现错误</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://changkun.de/modern-cpp/zh-cn/01-intro/">第 1 章 迈向现代 C++ 现代 C++ 教程: 高速上手 C++ 11/14/17/20 - Modern C++ Tutorial: C++ 11/14/17/20 On the Fly (changkun.de)</a></li><li><a href="https://www.cnblogs.com/KillerAery/p/12802771.html">透彻理解C++11 移动语义：右值、右值引用、std::move、std::forward - KillerAery - 博客园 (cnblogs.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;cpp,古老又传统的语言,但它依然是许多语言希望替代战胜的.这里介绍一些新特性.&lt;br&gt;</summary>
    
    
    
    
    <category term="cpp" scheme="https://www.sekyoro.top/tags/cpp/"/>
    
  </entry>
  
  <entry>
    <title>深度学习可解释性分析</title>
    <link href="https://www.sekyoro.top/2024/05/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E5%88%86%E6%9E%90/"/>
    <id>https://www.sekyoro.top/2024/05/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E5%88%86%E6%9E%90/</id>
    <published>2024-05-29T07:37:15.000Z</published>
    <updated>2024-05-31T09:37:20.532Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这种分析貌似在大模型时代没有使用那么多了,所以这里大概了解一下.<br><span id="more"></span></p><p>主要了解CAM,Grad-CAM可视化方法以及Sillancy map的概念</p><h3 id="Learning-Deep-Features-for-Discriminative-Localization"><a href="#Learning-Deep-Features-for-Discriminative-Localization" class="headerlink" title="Learning Deep Features for Discriminative Localization"></a>Learning Deep Features for Discriminative Localization</h3><p><img data-src="https://s2.loli.net/2024/05/31/yOYfGdwV7c8JhmW.png" alt="image-20240531153653129" style="zoom:50%;" /></p><p>对于给定的图像,令f~k~( x , y)表示空间位置( x , y)处最后一个卷积层中单元k的激活值.然后,对于单元k,执行全局平均池化的结果F^k^为∑~x,y~ f~k~( x ,y).因此,对于给定的类c,softmax的输入S~c~=∑~k~ w^c^ ~k~F~k~,其中w^c^~k~是单位k对应于类c的权重.本质上,w^c^~k~表示F~k~对c类的重要性.</p><p>最后通过exp(S~c~ )/∑~c~ exp(S~c~ )给出类c,P~c~的softmax的输出.</p><p><img data-src="https://s2.loli.net/2024/05/31/1yp7RFxnXhuAbaN.png" alt="image-20240531154551531"></p><p>通过将F~k~ =∑~x,y~f~k~( x,y)插入类得分S~c~,得到</p><script type="math/tex; mode=display">\begin{aligned}S_{c}& =\sum_kw_k^c\sum_{x,y}f_k(x,y)  \\&=\sum_{x,y}\sum_{k}w_{k}^{c}f_{k}(x,y).\end{aligned}</script><p>将M~c~定义为c类的类激活映射,其中每个空间元素由S~c~ =∑~x,y~M~c~( x ,y),因此M~c~( x , y)直接表明空间网格( x , y)上的激活导致图像分类到c类的重要性.</p><p>所以这里的class activation map是根据卷积层特征来的,权重值计算依赖于global pooling.</p><h3 id="Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization"><a href="#Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization" class="headerlink" title="Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"></a>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</h3><blockquote><p>CAM对于网络结构有要求，不采用GAP方法不能使用；且只能可视化最后一层的卷积</p></blockquote><p>提出了一种从基于卷积神经网络( Convolutional Neural Network，CNN )的一大类模型中为决策产生”视觉解释”的技术,使其更加透明和可解释.</p><p>我们的方法- -梯度加权类激活映射( Gradient-weighted Class Activation Mapping，Grad-CAM )，利用任意目标概念(在分类网络中说’狗’ ,或者在描述网络中说词序列)流入最终卷积层的梯度，产生一个粗略的定位图，突出图像中的重要区域，用于预测概念</p><p>与以前的方法不同，Grad - CAM适用于各种各样的CNN模型家族：( 1 )具有全连接层的CNN (例如. VGG ),( 2 )用于结构化输出的CNNs (如字幕),( 3 )用于具有多模态输入(例如,视觉问答)或强化学习的任务的CNNs，都没有架构变化或重新训练.</p><p><img data-src="https://s2.loli.net/2024/05/31/btfxHFEojOwuhAy.png" alt="image-20240531162540520"></p><script type="math/tex; mode=display">\alpha_k^c=\overbrace{\frac1Z\sum_i\sum_j}^{\text{global average pooling}}\underbrace{\frac{\partial y^c}{\partial A_{ij}^k}}_{\text{gradients via backprop}}</script><script type="math/tex; mode=display">L_{\text{Grad-CAM}}^c=ReLU\underbrace{\left(\sum\alpha_k^cA^k\right)}_{\text{linear combination}}</script><p>其中A^k^是特征图的值,权重由自己定变成了梯度.</p><p><img data-src="https://s2.loli.net/2024/05/31/rjbTCeuOVwna2h9.png" alt="image-20240531162743950"></p><p>为了得到对任意类c的宽u和高v的类判别局部化映射Grad - CAM Lc Grad-CAM∈R^u×v^，我们首先计算类c的得分y~c~ (在softmax之前)关于卷积层的特征图激活A~k~的梯度，即∑y~c~∑A~k~。</p><h3 id="Grad-CAM-Generalized-Gradient-based-Visual-Explanations-for-Deep-Convolutional-Networks"><a href="#Grad-CAM-Generalized-Gradient-based-Visual-Explanations-for-Deep-Convolutional-Networks" class="headerlink" title="Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks"></a>Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks</h3><p>本文的工作主要受到两种算法的启发，即CAM和Grad - CAM,这两种算法在当今被广泛使用.</p><p>CAM和Grad - CAM都基于一个基本假设,即<strong>对于特定类别c的最终得分Y~c~可以写成其全局平均池化最后一个卷积层特征图A~k~的线性组合</strong></p><p><img data-src="https://s2.loli.net/2024/05/31/yXqhk83Tb4KQIsR.png" alt="image-20240531170624521"></p><script type="math/tex; mode=display">Y^c=\sum_kw_k^c.\sum_i\sum_jA_{ij}^k</script><p>在Grad - CAM和CAM中基于梯度的可视化技术的基础上提出了一种广义的方法，称为Grad - CAM + +，它是通过显式地建模CNN特征图中每个像素对最终输出的贡献来制定的。</p><script type="math/tex; mode=display">w_k^c=\sum_i\sum_j\alpha_{ij}^{kc}.relu(\frac{\partial Y^c}{\partial A_{ij}^k})</script><p><img data-src="https://s2.loli.net/2024/05/31/HQbnsrTIEe8o7Gd.png" alt="image-20240531172032414"></p><script type="math/tex; mode=display">Y^{c}=\sum_{k}[\sum_{i}\sum_{j}\{\sum_{a}\sum_{b}\alpha_{ab}^{kc}.relu(\frac{\partial Y^{c}}{\partial A_{ab}^{k}})\}A_{ij}^{k}]</script><h3 id="Smooth-Grad-CAM-An-Enhanced-Inference-Level-Visualization-Technique-for-Deep-Convolutional-Neural-Network-Models"><a href="#Smooth-Grad-CAM-An-Enhanced-Inference-Level-Visualization-Technique-for-Deep-Convolutional-Neural-Network-Models" class="headerlink" title="Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models"></a>Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models</h3><p>加入噪声</p><script type="math/tex; mode=display">M_c(I)=\frac1n\sum_1^nM_c(I+\mathcal{N}(0,\sigma^2))</script><script type="math/tex; mode=display">M_c(x,y)=\sum_kw_c^kf^k(x,y)=\sum_kw_c^k\cdot\frac1n\sum_1^n(f_{x,y|I+\mathcal{N}(0,\sigma^2)}^k)</script><blockquote><p>由于添加了噪声，所以更能够突出特征图在噪声中robust的部分，这部分被认为更重要；此方法可以用来比较图片不同位置对神经元的激活强度，所以可以进行choosing neurons的操作</p></blockquote><h3 id="Saliency-map"><a href="#Saliency-map" class="headerlink" title="Saliency map"></a>Saliency map</h3><p>表示显著性.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">image</span>):</span></span><br><span class="line">  <span class="keyword">return</span> (image - image.<span class="built_in">min</span>()) / (image.<span class="built_in">max</span>() - image.<span class="built_in">min</span>())</span><br><span class="line">  <span class="comment"># return torch.log(image)/torch.log(image.max())</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_saliency_maps</span>(<span class="params">x, y, model</span>):</span></span><br><span class="line">  model.<span class="built_in">eval</span>()</span><br><span class="line">  x = x.cuda()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># we want the gradient of the input x</span></span><br><span class="line">  x.requires_grad_()</span><br><span class="line">  </span><br><span class="line">  y_pred = model(x)</span><br><span class="line">  loss_func = torch.nn.CrossEntropyLoss()</span><br><span class="line">  loss = loss_func(y_pred, y.cuda())</span><br><span class="line">  loss.backward()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># saliencies = x.grad.abs().detach().cpu()</span></span><br><span class="line">  saliencies, _ = torch.<span class="built_in">max</span>(x.grad.data.<span class="built_in">abs</span>().detach().cpu(),dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># We need to normalize each image, because their gradients might vary in scale</span></span><br><span class="line">  saliencies = torch.stack([normalize(item) <span class="keyword">for</span> item <span class="keyword">in</span> saliencies])</span><br><span class="line">  <span class="keyword">return</span> saliencies</span><br><span class="line">  <span class="comment"># images, labels = train_set.getbatch(img_indices)</span></span><br><span class="line">saliencies = compute_saliency_maps(images, labels, model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># visualize</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="built_in">len</span>(img_indices), figsize=(<span class="number">15</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> row, target <span class="keyword">in</span> <span class="built_in">enumerate</span>([images, saliencies]):</span><br><span class="line">  <span class="keyword">for</span> column, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(target):</span><br><span class="line">    <span class="keyword">if</span> row==<span class="number">0</span>:</span><br><span class="line">      axs[row][column].imshow(img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).numpy())</span><br><span class="line">      <span class="comment"># What is permute?</span></span><br><span class="line">      <span class="comment"># In pytorch, the meaning of each dimension of image tensor is (channels, height, width)</span></span><br><span class="line">      <span class="comment"># In matplotlib, the meaning of each dimension of image tensor is (height, width, channels)</span></span><br><span class="line">      <span class="comment"># permute is a tool for permuting dimensions of tensors</span></span><br><span class="line">      <span class="comment"># For example, img.permute(1, 2, 0) means that,</span></span><br><span class="line">      <span class="comment"># - 0 dimension is the 1 dimension of the original tensor, which is height</span></span><br><span class="line">      <span class="comment"># - 1 dimension is the 2 dimension of the original tensor, which is width</span></span><br><span class="line">      <span class="comment"># - 2 dimension is the 0 dimension of the original tensor, which is channels</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      axs[row][column].imshow(img.numpy(), cmap=plt.cm.hot)</span><br><span class="line">    </span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/inseq-team/inseq?tab=readme-ov-file">inseq-team/inseq: Interpretability for sequence generation models 🐛 🔍 (github.com)</a></li><li><a href="https://www.youtube.com/watch?v=WQY85vaQfTI&amp;ab_channel=Hung-yiLee">【機器學習2021】機器學習模型的可解釋性 (Explainable ML) (上) – 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？ (youtube.com)</a></li><li><a href="https://www.youtube.com/watch?v=RRGZs5qTeuQ&amp;ab_channel=Hung-yiLee">【機器學習2023】 HW9 - Explainable AI (youtube.com)</a></li><li><a href="https://weichengan.com/2020/11/30/paper_notes/cam_notes/">论文笔记：CAM、Grad-CAM、Grad-CAM++和Smooth Grad-CAM++ | CassiniWei’s Blog (weichengan.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;这种分析貌似在大模型时代没有使用那么多了,所以这里大概了解一下.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>协同感知数据集和代码库介绍</title>
    <link href="https://www.sekyoro.top/2024/05/23/%E5%8D%8F%E5%90%8C%E6%84%9F%E7%9F%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/"/>
    <id>https://www.sekyoro.top/2024/05/23/%E5%8D%8F%E5%90%8C%E6%84%9F%E7%9F%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-05-23T02:10:14.000Z</published>
    <updated>2024-07-11T08:58:42.607Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>目前深度学习的方法都是数据驱动的,在协同感知方面,数据集目前不算特别多,主要存在1)真实数据较少2)不同数据集之间配置差异较大,需要自行修改等.</p><span id="more"></span><h2 id="协同感知数据集"><a href="#协同感知数据集" class="headerlink" title="协同感知数据集"></a>协同感知数据集</h2><p><img data-src="https://s2.loli.net/2024/05/28/XfzY8nQyI3adCNM.png" alt="image-20240528181153135"></p><p>目前找到的数据集还是不少的.</p><h3 id="OPV2V-2022"><a href="#OPV2V-2022" class="headerlink" title="OPV2V 2022"></a>OPV2V 2022</h3><p>推出了首个大规模开放式车对车感知模拟数据集。该数据集包含 <strong>70 多个场景、11,464 个帧和 232,913 个注释三维车辆边界框</strong>，<strong>收集自 CARLA 的 8 个城镇和洛杉矶卡尔弗城的一个数字城镇</strong>。然后构建了一个包含 16 个实施模型的综合基准，以评估几种信息融合策略（即早期、后期和中间融合）与最先进的激光雷达检测算法。</p><h3 id="V2XSet-2022"><a href="#V2XSet-2022" class="headerlink" title="V2XSet 2022"></a>V2XSet 2022</h3><p>研究了如何应用 “车对物”（V2X）通信来提高自动驾驶汽车的感知性能。我们利用新颖的视觉转换器（Vision Transformer）提出了一个具有 V2X 通信功能的稳健合作感知框架。具体来说，我们建立了一个整体注意力模型，即 V2X-ViT，以有效融合道路代理（即车辆和基础设施）之间的信息。V2X-ViT 由异构多代理自我注意和多尺度窗口自我注意交替层组成，可捕捉代理间的交互和每个代理的空间关系。这些关键模块采用统一的 Transformer 架构设计，以应对常见的 V2X 挑战，包括异步信息共享、姿势错误和 V2X 组件的异构性。</p><p><img data-src="https://s2.loli.net/2024/03/22/3dLmHN96vbuVBtY.png" alt="image-20240322144729411"></p><p>车与道路  CARLA和OPENCDA创建的模拟数据集</p><h3 id="DAIR-V2X-2022"><a href="#DAIR-V2X-2022" class="headerlink" title="DAIR-V2X 2022"></a>DAIR-V2X 2022</h3><p>为了加速车辆-基础设施协同自动驾驶（VICAD）的计算机视觉研究和创新，我们发布了 DAIR-V2X 数据集，这是<strong>首个用于 VICAD 的大规模、多模态、多视角真实场景数据集</strong>。</p><h3 id="V2X-Sim-2022"><a href="#V2X-Sim-2022" class="headerlink" title="V2X-Sim 2022"></a>V2X-Sim 2022</h3><p>车对物（V2X）通信技术实现了车辆与邻近环境中许多其他实体之间的协作，可以从根本上改善自动驾驶的感知系统。然而，公共数据集的缺乏极大地限制了协同感知的研究进展。为了填补这一空白，我们提出了 V2X-Sim—一个<strong>用于 V2X 辅助自动驾驶的综合模拟多代理感知数据集</strong>。V2XSim 提供：（1）来自路边装置（RSU）和多辆车的多代理传感器记录，可实现协同感知；（2）多模态传感器流，可促进多模态感知；以及（3）多种地面实况，可支持各种感知任务。同时，我们建立了一个开源测试平台，并在检测、跟踪和分割等三个任务上为最先进的协同感知算法提供了基准。V2X-Sim 试图在现实数据集广泛可用之前，促进自动驾驶的协同感知研究。</p><h3 id="V2V4Real-2023"><a href="#V2V4Real-2023" class="headerlink" title="V2V4Real 2023"></a>V2V4Real 2023</h3><p>最近的研究表明，车对车（V2V）协同感知系统在彻底改变自动驾驶行业方面具有巨大潜力。然而，真实世界数据集的缺乏阻碍了这一领域的发展。为了促进协同感知的发展，我们提出了 V2V4Real，这是首个<strong>大规模真实世界多模态 V2V 感知数据集</strong>。</p><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>现代自动驾驶感知协同对于遮挡敏感并且缺乏长范围感知能力,这是阻碍五级自动驾驶的关键瓶颈之一.</p><p>最近的研究表明，<strong>车对车（V2V）协作感知系统具有彻底改变自动驾驶行业的巨大潜力</strong>。然而，<strong>缺乏真实世界的数据集阻碍了该领域的进步。为了促进合作感知的发展，我们提出了 V2V4Real</strong>，这是第一个用于 V2V 感知的大规模现实世界多模态数据集。这些数据是由两辆配备多模态传感器的车辆在不同场景中一起行驶收集的。我们的 V2V4Real 数据集覆盖了 <strong>410 公里的驾驶区域，包括 20K LiDAR 帧、40K RGB 帧、240K 5 个类别的带注释 3D 边界框以及覆盖所有驾驶路线的 HDMap</strong>。</p><blockquote><p>自动驾驶技术在国际上有一个严格的分级标准，而美国交通部选择的是美国汽车工程师学会(Society of Automotive Engineers)给出的评定标准，其主要内容是：</p><p>0级：无自动驾驶，由人类驾驶员全权操控汽车，可以得到警告或干预系统的辅助;</p><p>1级：驾驶支援，通过驾驶环境对方向盘和加减速中的一项操作提供驾驶支持，其他的驾驶动作都由人类驾驶员进行操作;</p><p>2级：部分自动化，通过驾驶环境对方向盘和加减速中的多项操作提供驾驶支持，其他的驾驶动作都由人类驾驶员进行操作。</p><p>3级：有条件自动化，由自动驾驶系统完成所有的驾驶操作。根据系统要求，人类驾驶者需要在适当的时候提供应答。</p><p>4级：高度自动化，由自动驾驶系统完成所有的驾驶操作。根据系统要求，人类驾驶者不一定需要对所有的系统请求做出应答，包括限定道路和环境条件等。</p><p>5级：完全自动化，在所有人类驾驶者可以应付的道路和环境条件下，均可以由自动驾驶系统自主完成所有的驾驶操作。</p></blockquote><p>V2V4Real 引入了三个感知任务，包括协作 3D 对象检测、协作 3D 对象跟踪和用于协作感知的 Sim2Real 域自适应。我们提供了近期协作感知算法在三个任务上的综合基准。 V2V4Real 数据集和代码库可以在 Research.seas.ucla.edu/mobility-lab/v2v4real 上找到。</p><p>我们收集了 19 个小时的 310K 帧的驾驶数据。我们手动选择最具代表性的 67 个场景，每个场景时长 10-20 秒。我们以 10Hz 的频率对帧进行采样，得到总共 20K 帧的 LiDAR 点云和 40K 帧的 RGB 图像。对于每个场景，我们确保两辆车传感器系统之间的异步小于 50 毫秒。所有场景都与包含可行驶区域、道路边界以及虚线的地图对齐。</p><ul><li>协作者的相对位姿存在不可避免的误差，这在将数据转换到统一坐标系时会产生全局错位。</li><li>协作者的传感器测量通常不同步，这是由不同传感器系统的异步以及数据传输过程中的通信延迟造成的</li><li>典型的V2V通信技术需要有限的带宽，这限制了传输数据的大小[31,40,49]。因此，协作检测算法必须考虑精度和带宽要求之间的权衡</li></ul><p><strong>训练细节.</strong>对于所有三个任务，数据集分为训练/验证/测试集，分别具有 <strong>14,210/2,000/3,986 帧</strong>。所有检测模型均采用 PointPillar  作为骨干从点云中提取 2D 特征。我们用 60 个 epoch 训练所有模型，每个 GPU (RTX3090) 的批量大小为 4，学习率为 0.001，并通过余弦退火来衰减学习率。早期停止用于寻找最佳时期。我们还为所有实验添加了正常的点云数据增强，包括缩放、旋转和翻转。我们使用权重衰减为 1×10−2 的 AdamW来优化我们的模型。对于跟踪任务，我们将前 3 帧和当前帧一起作为输入.</p><h3 id="RCooper-A-Real-world-Large-scale-Dataset-for-Roadside-Cooperative-Perception-2024"><a href="#RCooper-A-Real-world-Large-scale-Dataset-for-Roadside-Cooperative-Perception-2024" class="headerlink" title="RCooper: A Real-world Large-scale Dataset for Roadside Cooperative Perception 2024"></a>RCooper: A Real-world Large-scale Dataset for Roadside Cooperative Perception 2024</h3><p>近年来，路侧感知的价值逐渐凸显并得到认可，它可以延伸自动驾驶和交通管理的边界。</p><p>然而，现有的路侧感知方法仅针对单一基础设施的传感器系统，由于感知范围和盲区的限制，无法实现对交通区域的全面理解。面向高质量的路侧感知，我们需要路侧协同感知( Roadside Cooperative Perception，RCooper )来实现面向受限交通区域的实际区域覆盖路侧感知。Rcooper有其特定领域的挑战，但由于缺乏数据集而阻碍了进一步的探索。</p><p><img data-src="https://s2.loli.net/2024/05/24/43wQjzbeqUEdXTs.png" alt="image-20240524101039784"></p><p>因此，我们发布了第一个真实世界的大规模RCooper数据集，以启动对实际路边协作感知的研究，包括检测和跟踪。人工标注的数据集包括50k幅图像和30k个点云，其中包含两个具有代表性的交通场景(即,交叉口和走廊)。所构建的基准证明了路侧合作感知的有效性，并展示了进一步研究的方向。</p><h3 id="TUMTraf-V2X-2024"><a href="#TUMTraf-V2X-2024" class="headerlink" title="TUMTraf-V2X 2024"></a>TUMTraf-V2X 2024</h3><p>协作感知为增强自动驾驶车辆的能力和改善道路安全提供了许多好处。除了车载传感器外，使用路边传感器增加了可靠性，并扩展了传感器的范围。</p><p>数据集包含2，000个标记点云和5，000张来自5个路侧和4个机载传感器的标记图像。它包括30k个带有轨道ID和精确的GPS和IMU数据的3D盒子。标注了八个类别，涵盖了具有挑战性的驾驶操作的遮挡场景，如交通违规、接近失误事件、超车和掉头。</p><h3 id="V2X-Real-2024"><a href="#V2X-Real-2024" class="headerlink" title="V2X-Real 2024"></a>V2X-Real 2024</h3><p>近年来，随着车联网( Vehicle-to-Ething，V2X )技术的发展，自动驾驶车辆能够共享感知信息以穿透遮挡，极大地提升了感知能力。</p><p>在本文中，我们提出了一个同时具有多种车辆和智能基础设施的混合数据集，以促进具有多模态感知数据的V2X协作感知开发。我们的V2X - Real使用两个连接的自动化车辆和两个智能基础设施进行采集，这些基础设施都配备了包括激光雷达传感器和多视角相机在内的多模态传感器。</p><p>整个数据集包含33K个LiDAR帧和171K个相机数据，在非常具有挑战性的城市场景中，有超过1.2 M的10个类别的注释边界框。根据协作模式和自我视角，我们推导出车辆中心、基础设施中心、车辆到车辆和基础设施到基础设施协作感知的四类数据集。 主要是包含了I2I的场景.</p><blockquote><p>上面三个数据集都是V2X的真实环境数据</p></blockquote><h2 id="CodeBase"><a href="#CodeBase" class="headerlink" title="CodeBase"></a>CodeBase</h2><p>我常用的就是OpenCOOD <a href="https://github.com/DerrickXuNu/OpenCOOD?tab=readme-ov-file">ICRA 2022] An opensource framework for cooperative detection. Official implementation for OPV2V. (github.com)</a>的代码库,但也有其他看起来还行的,包括:</p><ul><li><a href="https://github.com/ucla-mobility/V2V4Real">CVPR2023 Highlight] The official codebase for paper “V2V4Real: A large-scale real-world dataset for Vehicle-to-Vehicle Cooperative Perception” (github.com)</a></li><li><a href="https://github.com/yifanlu0227/HEAL">ICLR2024] HEAL: An Extensible Framework for Open Heterogeneous Collaborative Perception ➡️ All You Need for Multi-Modality Collaborative Perception! (github.com)</a></li><li><a href="https://github.com/yifanlu0227/CoAlign/tree/main">ICRA2023] CoAlign: Robust Collaborative 3D Object Detection in Presence of Pose Errors (github.com)</a></li><li><a href="https://github.com/AIR-THU/DAIR-V2X">AIR-THU/DAIR-V2X (github.com)</a></li><li><a href="https://github.com/coperception/coperception">coperception/coperception: An SDK for multi-agent collaborative perception. (github.com)</a> 这个仓库代码其实不太行 😅</li></ul><p>这里对其中一些代码做简单介绍.</p><h3 id="BaseDataset"><a href="#BaseDataset" class="headerlink" title="BaseDataset"></a>BaseDataset</h3><p>不同时期不同类型数据进行融合的父类.数据中通过idx得到对应的场景中数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">retrieve_base_data</span>(<span class="params">self, idx, cur_ego_pose_flag=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="comment"># we loop the accumulated length list to see get the scenario index</span></span><br><span class="line">        scenario_index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, ele <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.len_record):</span><br><span class="line">            <span class="keyword">if</span> idx &lt; ele:</span><br><span class="line">                scenario_index = i</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        scenario_database = self.scenario_database[scenario_index]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># check the timestamp index</span></span><br><span class="line">        timestamp_index = idx <span class="keyword">if</span> scenario_index == <span class="number">0</span> <span class="keyword">else</span> \</span><br><span class="line">            idx - self.len_record[scenario_index - <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># retrieve the corresponding timestamp key</span></span><br><span class="line">        timestamp_key = self.return_timestamp_key(scenario_database,</span><br><span class="line">                                                  timestamp_index)</span><br><span class="line">        <span class="comment"># calculate distance to ego for each cav</span></span><br><span class="line">        ego_cav_content = \</span><br><span class="line">            self.calc_dist_to_ego(scenario_database, timestamp_key)</span><br><span class="line"></span><br><span class="line">        data = OrderedDict()</span><br><span class="line">        <span class="comment"># load files for all CAVs</span></span><br><span class="line">        <span class="keyword">for</span> cav_id, cav_content <span class="keyword">in</span> scenario_database.items():</span><br><span class="line">            data[cav_id] = OrderedDict()</span><br><span class="line">            data[cav_id][<span class="string">&#x27;ego&#x27;</span>] = cav_content[<span class="string">&#x27;ego&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># calculate delay for this vehicle</span></span><br><span class="line">            timestamp_delay = \</span><br><span class="line">                self.time_delay_calculation(cav_content[<span class="string">&#x27;ego&#x27;</span>])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> timestamp_index - timestamp_delay &lt;= <span class="number">0</span>:</span><br><span class="line">                timestamp_delay = timestamp_index</span><br><span class="line">            timestamp_index_delay = <span class="built_in">max</span>(<span class="number">0</span>, timestamp_index - timestamp_delay)</span><br><span class="line">            timestamp_key_delay = self.return_timestamp_key(scenario_database,</span><br><span class="line">                                                            timestamp_index_delay)</span><br><span class="line">            <span class="comment"># add time delay to vehicle parameters</span></span><br><span class="line">            data[cav_id][<span class="string">&#x27;time_delay&#x27;</span>] = timestamp_delay</span><br><span class="line">            <span class="comment"># load the corresponding data into the dictionary</span></span><br><span class="line">            data[cav_id][<span class="string">&#x27;params&#x27;</span>] = self.reform_param(cav_content,</span><br><span class="line">                                                       ego_cav_content,</span><br><span class="line">                                                       timestamp_key,</span><br><span class="line">                                                       timestamp_key_delay,</span><br><span class="line">                                                       cur_ego_pose_flag)</span><br><span class="line">            data[cav_id][<span class="string">&#x27;lidar_np&#x27;</span>] = \</span><br><span class="line">                pcd_utils.pcd_to_np(cav_content[timestamp_key_delay][<span class="string">&#x27;lidar&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><h3 id="不同数据类型融合"><a href="#不同数据类型融合" class="headerlink" title="不同数据类型融合"></a>不同数据类型融合</h3><h4 id="早期"><a href="#早期" class="headerlink" title="早期"></a>早期</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">projected_lidar_stack = []</span><br><span class="line">       object_stack = []</span><br><span class="line">       object_id_stack = []</span><br><span class="line"></span><br><span class="line">       <span class="comment"># loop over all CAVs to process information</span></span><br><span class="line">       <span class="keyword">for</span> cav_id, selected_cav_base <span class="keyword">in</span> base_data_dict.items():</span><br><span class="line">           <span class="comment"># check if the cav is within the communication range with ego</span></span><br><span class="line">           distance = \</span><br><span class="line">               math.sqrt((selected_cav_base[<span class="string">&#x27;params&#x27;</span>][<span class="string">&#x27;lidar_pose&#x27;</span>][<span class="number">0</span>] -</span><br><span class="line">                          ego_lidar_pose[<span class="number">0</span>]) ** <span class="number">2</span> + (</span><br><span class="line">                                 selected_cav_base[<span class="string">&#x27;params&#x27;</span>][</span><br><span class="line">                                     <span class="string">&#x27;lidar_pose&#x27;</span>][<span class="number">1</span>] - ego_lidar_pose[</span><br><span class="line">                                     <span class="number">1</span>]) ** <span class="number">2</span>)</span><br><span class="line">           <span class="keyword">if</span> distance &gt; opencood.data_utils.datasets.COM_RANGE:</span><br><span class="line">               <span class="keyword">continue</span></span><br><span class="line">           selected_cav_processed = self.get_item_single_car(</span><br><span class="line">               selected_cav_base,</span><br><span class="line">               ego_lidar_pose)</span><br><span class="line">           <span class="comment"># all these lidar and object coordinates are projected to ego</span></span><br><span class="line">           <span class="comment"># already.</span></span><br><span class="line">           projected_lidar_stack.append(</span><br><span class="line">               selected_cav_processed[<span class="string">&#x27;projected_lidar&#x27;</span>])</span><br><span class="line">           object_stack.append(selected_cav_processed[<span class="string">&#x27;object_bbx_center&#x27;</span>])</span><br><span class="line">           object_id_stack += selected_cav_processed[<span class="string">&#x27;object_ids&#x27;</span>]</span><br></pre></td></tr></table></figure><p>上面得到了三个数组 projected_lidar_stack,object_stack ,object_id_stack.</p><p>分别是通过<code>project_world_objects</code>得到的bbx的中心,物体id以及lidar数据(投影到ego坐标系上),</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">object_bbx_center, object_bbx_mask, object_ids = \</span><br><span class="line">          self.post_processor.generate_object_center([selected_cav_base],</span><br><span class="line">                                                     ego_pose)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># filter lidar</span></span><br><span class="line">      lidar_np = selected_cav_base[<span class="string">&#x27;lidar_np&#x27;</span>]</span><br><span class="line">      lidar_np = shuffle_points(lidar_np)</span><br><span class="line">      <span class="comment"># remove points that hit itself</span></span><br><span class="line">      lidar_np = mask_ego_points(lidar_np)</span><br><span class="line">      <span class="comment"># project the lidar to ego space</span></span><br><span class="line">      lidar_np[:, :<span class="number">3</span>] = \</span><br><span class="line">          box_utils.project_points_by_matrix_torch(lidar_np[:, :<span class="number">3</span>],</span><br><span class="line">                                                   transformation_matrix)</span><br><span class="line"></span><br><span class="line">      selected_cav_processed.update(</span><br><span class="line">          &#123;<span class="string">&#x27;object_bbx_center&#x27;</span>: object_bbx_center[object_bbx_mask == <span class="number">1</span>],</span><br><span class="line">           <span class="string">&#x27;object_ids&#x27;</span>: object_ids,</span><br><span class="line">           <span class="string">&#x27;projected_lidar&#x27;</span>: lidar_np&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_object_center</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                           cav_contents,</span></span></span><br><span class="line"><span class="params"><span class="function">                           reference_lidar_pose</span>):</span></span><br><span class="line">    <span class="keyword">from</span> opencood.data_utils.datasets <span class="keyword">import</span> GT_RANGE</span><br><span class="line"></span><br><span class="line">    tmp_object_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> cav_content <span class="keyword">in</span> cav_contents:</span><br><span class="line">        tmp_object_dict.update(cav_content[<span class="string">&#x27;params&#x27;</span>][<span class="string">&#x27;vehicles&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    output_dict = &#123;&#125;</span><br><span class="line">    filter_range = self.params[<span class="string">&#x27;anchor_args&#x27;</span>][<span class="string">&#x27;cav_lidar_range&#x27;</span>] \</span><br><span class="line">        <span class="keyword">if</span> self.train <span class="keyword">else</span> GT_RANGE</span><br><span class="line"></span><br><span class="line">    box_utils.project_world_objects(tmp_object_dict,</span><br><span class="line">                                    output_dict,</span><br><span class="line">                                    reference_lidar_pose,</span><br><span class="line">                                    filter_range,</span><br><span class="line">                                    self.params[<span class="string">&#x27;order&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    object_np = np.zeros((self.params[<span class="string">&#x27;max_num&#x27;</span>], <span class="number">7</span>))</span><br><span class="line">    mask = np.zeros(self.params[<span class="string">&#x27;max_num&#x27;</span>])</span><br><span class="line">    object_ids = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (object_id, object_bbx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(output_dict.items()):</span><br><span class="line">        object_np[i] = object_bbx[<span class="number">0</span>, :]</span><br><span class="line">        mask[i] = <span class="number">1</span></span><br><span class="line">        object_ids.append(object_id)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> object_np, mask, object_ids</span><br></pre></td></tr></table></figure><p>后面对点云数据去掉一些范围的值,增强,然后将点云数据通过voxel或者bev得到对应的体素得到lidar_dict</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pre-process the lidar to voxel/bev/downsampled lidar</span></span><br><span class="line">       lidar_dict = self.pre_processor.preprocess(projected_lidar_stack)</span><br></pre></td></tr></table></figure><p>最后的返回数据,包括object_bbx_center,mask,object_ids前面三个通过get_item_single_car得到lidar,center和ids,将周围车的lidar放在一起通过与处理得到lidar_dict,anchor_box和label_dict通过postprocess得到.可视化数据包括没有通过预处理的点云的列表origin_lidar以及通过列表vstack后的结果.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">processed_data_dict[<span class="string">&#x27;ego&#x27;</span>].update(</span><br><span class="line">         &#123;<span class="string">&#x27;object_bbx_center&#x27;</span>: object_bbx_center,</span><br><span class="line">          <span class="string">&#x27;object_bbx_mask&#x27;</span>: mask,</span><br><span class="line">          <span class="string">&#x27;object_ids&#x27;</span>: [object_id_stack[i] <span class="keyword">for</span> i <span class="keyword">in</span> unique_indices],</span><br><span class="line">          <span class="string">&#x27;anchor_box&#x27;</span>: anchor_box,</span><br><span class="line">          <span class="string">&#x27;processed_lidar&#x27;</span>: lidar_dict,</span><br><span class="line">          <span class="string">&#x27;label_dict&#x27;</span>: label_dict&#125;)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span> self.visualize:</span><br><span class="line">         processed_data_dict[<span class="string">&#x27;ego&#x27;</span>].update(&#123;<span class="string">&#x27;origin_lidar&#x27;</span>:projected_lidar_stack,</span><br><span class="line">                                           <span class="string">&#x27;split_lidar&#x27;</span>:ind_lidar&#125;)</span><br><span class="line">     <span class="keyword">return</span> processed_data_dict</span><br></pre></td></tr></table></figure><p>在<code>get_item_single_car</code>通过得到的车的数据和ego数据计算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_item_single_car</span>(<span class="params">self, selected_cav_base, ego_pose</span>):</span></span><br><span class="line">     <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     Project the lidar and bbx to ego space first, and then do clipping.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     Parameters</span></span><br><span class="line"><span class="string">     ----------</span></span><br><span class="line"><span class="string">     selected_cav_base : dict</span></span><br><span class="line"><span class="string">         The dictionary contains a single CAV&#x27;s raw information.</span></span><br><span class="line"><span class="string">     ego_pose : list</span></span><br><span class="line"><span class="string">         The ego vehicle lidar pose under world coordinate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     Returns</span></span><br><span class="line"><span class="string">     -------</span></span><br><span class="line"><span class="string">     selected_cav_processed : dict</span></span><br><span class="line"><span class="string">         The dictionary contains the cav&#x27;s processed information.</span></span><br><span class="line"><span class="string">     &quot;&quot;&quot;</span></span><br><span class="line">     selected_cav_processed = &#123;&#125;</span><br><span class="line"></span><br><span class="line">     <span class="comment"># calculate the transformation matrix</span></span><br><span class="line">     transformation_matrix = \</span><br><span class="line">         x1_to_x2(selected_cav_base[<span class="string">&#x27;params&#x27;</span>][<span class="string">&#x27;lidar_pose&#x27;</span>],</span><br><span class="line">                  ego_pose)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># retrieve objects under ego coordinates</span></span><br><span class="line">     object_bbx_center, object_bbx_mask, object_ids = \</span><br><span class="line">         self.post_processor.generate_object_center([selected_cav_base],</span><br><span class="line">                                                    ego_pose)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># filter lidar</span></span><br><span class="line">     lidar_np = selected_cav_base[<span class="string">&#x27;lidar_np&#x27;</span>]</span><br><span class="line">     lidar_np = shuffle_points(lidar_np)</span><br><span class="line">     <span class="comment"># remove points that hit itself</span></span><br><span class="line">     lidar_np = mask_ego_points(lidar_np)</span><br><span class="line">     <span class="comment"># project the lidar to ego space</span></span><br><span class="line">     lidar_np[:, :<span class="number">3</span>] = \</span><br><span class="line">         box_utils.project_points_by_matrix_torch(lidar_np[:, :<span class="number">3</span>],</span><br><span class="line">                                                  transformation_matrix)</span><br><span class="line"></span><br><span class="line">     selected_cav_processed.update(</span><br><span class="line">         &#123;<span class="string">&#x27;object_bbx_center&#x27;</span>: object_bbx_center[object_bbx_mask == <span class="number">1</span>],</span><br><span class="line">          <span class="string">&#x27;object_ids&#x27;</span>: object_ids,</span><br><span class="line">          <span class="string">&#x27;projected_lidar&#x27;</span>: lidar_np&#125;)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">return</span> selected_cav_processed</span><br></pre></td></tr></table></figure><p>在读取yaml文件时,通过load_point_pillar_params加载了一些参数.首先获取lidar范围,然后是体素大小,就通过划分体素获得了grid,也就是一个个网格,然后处理anchor,根据每个anchor的长宽高,再根据lidar_range得到一个范围内的anchor数目.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_point_pillar_params</span>(<span class="params">param</span>):</span></span><br><span class="line">    cav_lidar_range = param[<span class="string">&#x27;preprocess&#x27;</span>][<span class="string">&#x27;cav_lidar_range&#x27;</span>]</span><br><span class="line">    voxel_size = param[<span class="string">&#x27;preprocess&#x27;</span>][<span class="string">&#x27;args&#x27;</span>][<span class="string">&#x27;voxel_size&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    grid_size = (np.array(cav_lidar_range[<span class="number">3</span>:<span class="number">6</span>]) - np.array(</span><br><span class="line">        cav_lidar_range[<span class="number">0</span>:<span class="number">3</span>])) / \</span><br><span class="line">                np.array(voxel_size)</span><br><span class="line">    grid_size = np.<span class="built_in">round</span>(grid_size).astype(np.int64)</span><br><span class="line">    param[<span class="string">&#x27;model&#x27;</span>][<span class="string">&#x27;args&#x27;</span>][<span class="string">&#x27;point_pillar_scatter&#x27;</span>][<span class="string">&#x27;grid_size&#x27;</span>] = grid_size</span><br><span class="line">    anchor_args = param[<span class="string">&#x27;postprocess&#x27;</span>][<span class="string">&#x27;anchor_args&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    vw = voxel_size[<span class="number">0</span>]</span><br><span class="line">    vh = voxel_size[<span class="number">1</span>]</span><br><span class="line">    vd = voxel_size[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    anchor_args[<span class="string">&#x27;vw&#x27;</span>] = vw</span><br><span class="line">    anchor_args[<span class="string">&#x27;vh&#x27;</span>] = vh</span><br><span class="line">    anchor_args[<span class="string">&#x27;vd&#x27;</span>] = vd</span><br><span class="line"></span><br><span class="line">    anchor_args[<span class="string">&#x27;W&#x27;</span>] = math.ceil((cav_lidar_range[<span class="number">3</span>] - cav_lidar_range[<span class="number">0</span>]) / vw)</span><br><span class="line">    anchor_args[<span class="string">&#x27;H&#x27;</span>] = math.ceil((cav_lidar_range[<span class="number">4</span>] - cav_lidar_range[<span class="number">1</span>]) / vh)</span><br><span class="line">    anchor_args[<span class="string">&#x27;D&#x27;</span>] = math.ceil((cav_lidar_range[<span class="number">5</span>] - cav_lidar_range[<span class="number">2</span>]) / vd)</span><br><span class="line"></span><br><span class="line">    param[<span class="string">&#x27;postprocess&#x27;</span>].update(&#123;<span class="string">&#x27;anchor_args&#x27;</span>: anchor_args&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> param</span><br></pre></td></tr></table></figure><h3 id="常用工具类"><a href="#常用工具类" class="headerlink" title="常用工具类"></a>常用工具类</h3><p>从(N,C,H,W)也就是多个batch的cav数据放在一起,但是后面需要处理每个batch的数据,就通过regroup得到.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regroup</span>(<span class="params">dense_feature, record_len, max_len</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Regroup the data based on the record_len.</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    dense_feature : torch.Tensor</span></span><br><span class="line"><span class="string">        N, C, H, W</span></span><br><span class="line"><span class="string">    record_len : list</span></span><br><span class="line"><span class="string">        [sample1_len, sample2_len, ...]</span></span><br><span class="line"><span class="string">    max_len : int</span></span><br><span class="line"><span class="string">        Maximum cav number</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    regroup_feature : torch.Tensor</span></span><br><span class="line"><span class="string">        B, L, C, H, W</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cum_sum_len = <span class="built_in">list</span>(np.cumsum(torch_tensor_to_numpy(record_len)))</span><br><span class="line">    <span class="comment"># [sample1_len, sample2_len+sample1_len, ...]</span></span><br><span class="line">    split_features = torch.tensor_split(dense_feature,</span><br><span class="line">                                        cum_sum_len[:-<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 利用tensor_split划分每个batch的数据de&#x27;dao</span></span><br><span class="line">    regroup_features = []</span><br><span class="line">    mask = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> split_feature <span class="keyword">in</span> split_features:</span><br><span class="line">        <span class="comment"># M, C, H, W</span></span><br><span class="line">        feature_shape = split_feature.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># the maximum M is 5 as most 5 cavs</span></span><br><span class="line">        padding_len = max_len - feature_shape[<span class="number">0</span>]</span><br><span class="line">        mask.append([<span class="number">1</span>] * feature_shape[<span class="number">0</span>] + [<span class="number">0</span>] * padding_len)</span><br><span class="line"></span><br><span class="line">        padding_tensor = torch.zeros(padding_len, feature_shape[<span class="number">1</span>],</span><br><span class="line">                                     feature_shape[<span class="number">2</span>], feature_shape[<span class="number">3</span>])</span><br><span class="line">        padding_tensor = padding_tensor.to(split_feature.device)</span><br><span class="line"></span><br><span class="line">        split_feature = torch.cat([split_feature, padding_tensor],</span><br><span class="line">                                  dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1, 5C, H, W</span></span><br><span class="line">        split_feature = split_feature.view(-<span class="number">1</span>,</span><br><span class="line">                                           feature_shape[<span class="number">2</span>],</span><br><span class="line">                                           feature_shape[<span class="number">3</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        regroup_features.append(split_feature)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># B, 5C, H, W</span></span><br><span class="line">    regroup_features = torch.cat(regroup_features, dim=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># B, L, C, H, W</span></span><br><span class="line">    regroup_features = rearrange(regroup_features,</span><br><span class="line">                                 <span class="string">&#x27;b (l c) h w -&gt; b l c h w&#x27;</span>,</span><br><span class="line">                                 l=max_len)</span><br><span class="line">    mask = torch.from_numpy(np.array(mask)).to(regroup_features.device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> regroup_features, mask</span><br></pre></td></tr></table></figure><h2 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h2><ol><li>arXiv:2404.14022</li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;目前深度学习的方法都是数据驱动的,在协同感知方面,数据集目前不算特别多,主要存在1)真实数据较少2)不同数据集之间配置差异较大,需要自行修改等.&lt;/p&gt;</summary>
    
    
    
    
    <category term="collaborative perception" scheme="https://www.sekyoro.top/tags/collaborative-perception/"/>
    
  </entry>
  
  <entry>
    <title>Domain Adaptation Method</title>
    <link href="https://www.sekyoro.top/2024/05/21/Domain-Adaptation-Method/"/>
    <id>https://www.sekyoro.top/2024/05/21/Domain-Adaptation-Method/</id>
    <published>2024-05-21T01:47:55.000Z</published>
    <updated>2024-07-09T03:15:45.612Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这个方向的技术目前没有那么火了,但是能应用的场景非常之多.<br><span id="more"></span></p><h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><h2 id="Deep-Unsupervised-Domain-Adaptation-A-Review-of-Recent-Advances-and-Perspectives"><a href="#Deep-Unsupervised-Domain-Adaptation-A-Review-of-Recent-Advances-and-Perspectives" class="headerlink" title="Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives"></a>Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives</h2><p>深度学习已经成为解决不同领域现实问题的首选方法，部分原因是它能够从数据中学习,并在广泛的应用中取得了令人印象深刻的性能。</p><p>然而，它的成功通常依赖于两个假设：( i )<strong>精确的模型拟合需要大量有标签的数据集</strong>,( ii )<strong>训练和测试数据是独立同分布的.因此,它在看不见的目标域上的性能得不到保证,特别是在适应阶段遇到分布外数据时</strong>。</p><p>在目标域数据上的性能下降是部署在源域数据上成功训练的深度神经网络的一个关键问题.</p><p>无监督域适应( Unsupervised Domain Adaptation，UDA )正是针对这一问题提出的,通过同时利用已标记的源域数据和未标记的目标域数据,在目标域中执行各种任务</p><p><img data-src="https://s2.loli.net/2024/05/21/yksHCLQcPdOrERa.png" alt="image-20240521102852946"></p><blockquote><p>Although supervised deep learning is the most prevalent and successful approach for a variety of tasks, its success hinges on (i) vast troves of labeled training data and (ii) the assumption of independent and identically distributed (i.i.d.) training and testing datasets.</p></blockquote><p>Because reliable labeling of massive datasets for various application domains is often expensive and prohibitive, for a task without sufficient labeled datasets in a target domain, there is strong demand to apply trained models, by leveraging rich labeled data from a source domain</p><p><img data-src="https://s2.loli.net/2024/05/21/R2xdyXHQJp38nNj.png" alt="image-20240521110351381"></p><script type="math/tex; mode=display">\begin{aligned}&\mathcal{L}_t(h)\leq\mathcal{L}_s(h)+d[p_\mathcal{S},p_\mathcal{T}]+\\&\min[\mathbb{E}_{x\sim p_s}|p_s(y|x)-p_t(y|x)|,\mathbb{E}_{x\sim p_t}|p_s(y|x)-p_t(y|x)|]\end{aligned}</script><p><img data-src="https://s2.loli.net/2024/05/23/ZAvaHCuiyK78RpW.png" alt="image-20240523110706500"></p><p>常用的方法分类如图.</p><h4 id="Statistic-Divergence-Alignment"><a href="#Statistic-Divergence-Alignment" class="headerlink" title="Statistic Divergence Alignment"></a>Statistic Divergence Alignment</h4><p>学习领域不变特征表示是许多深度UDA方法中应用最广泛的思想,其关键在于最小化潜在特征空间中的领域差异.<strong>为了实现这一目标,选择合适的divergence measure是这些方法的核心</strong>。</p><h2 id="Deep-visual-domain-adaptation-A-survey"><a href="#Deep-visual-domain-adaptation-A-survey" class="headerlink" title="Deep visual domain adaptation: A survey"></a>Deep visual domain adaptation: A survey</h2><p>深度域适应已经成为一种新的学习技术，以解决缺乏大量标记数据的问题。与传统的学习共享特征子空间或重用具有浅层表示的重要源实例的方法相比，深度域适应方法通过将域适应嵌入到深度学习的流水线中，利用深度网络来学习更多的可迁移表示。已有针对浅域自适应的全面调查，但很少有人及时评论基于深度学习的新兴方法。在本文中，我们对计算机视觉应用中的深度域自适应方法进行了全面调查，主要有四大贡献。首先，我们根据定义两个域如何偏离的数据属性，提出了不同深度域适配场景的分类法。其次，我们根据训练损失将深域适应方法归纳为几个类别，并简要分析和比较了这些类别下的最先进方法。第三，我们概述了图像分类之外的计算机视觉应用，如人脸识别、语义分割和物体检测。第四，重点介绍当前方法的一些潜在不足和未来的几个发展方向。</p><p><img data-src="https://s2.loli.net/2024/06/18/rWKxDdeUG4nSJRO.png" alt="image-20240618230157030"></p><p>域 D 由特征空间 X 和边际概率分布 P(X) 组成，其中 X = {x1, ., xn}∈ X。给定一个特定的域 D = {X , P(X )}，任务 T 由一个特征空间 Y 和一个客观预测函数 f( - ) 组成，从概率论的角度来看，f( - ) 也可以看作是条件概率分布 P(Y|X)。一般来说，我们可以从标注数据 {xi, yi}（其中 xi∈X 和 yi∈Y ）中以有监督的方式学习 P(Y|X)。</p><p>假设有两个域：有足够标注数据的训练数据集是源域 Ds = {X s, P(X )s}, 有<strong>少量标注数据或无标注数据的测试数据集是目标域 Dt = {X t , P(X )t }</strong>。部分标注的部分 Dtl 和未标注的部分 Dtu 构成了整个目标域，即 Dt = Dtl ∪ Dtu。每个域都有其任务：前者为 T s = {Ys, P(Y s|Xs )}, 后者为 T t = {Yt , P(Y t |Xt )} 。</p><p>同样，P(Ys|Xs) 可以从源标签数据 {xs i , ys i } 中学习，而 P(Yt|Xt) 可以从标签目标数据 {xtl i , ytl i } 和非标签数据 {xtu i } 中学习。</p><p>对DA方法进行分类</p><blockquote><p>在同质数据中，源域和目标域之间的特征空间是相同的（X s = X t），维度也相同（ds = dt）。因此，源数据集和目标数据集的数据分布一般是不同的（P(X)s = P(X)t）。</p><p>在异构数据中，源域和目标域之间的特征空间是不等同的（X s = X t），维度一般也可能不同（ds = dt）。</p></blockquote><p>此外，我们还可以将同质 DA 设置进一步分为三种情况：</p><ol><li><p>在有监督的 DA 中，存在少量有标签的目标数据（D^tl^）。然而，标签数据通常不足以完成任务。</p></li><li><p>在半监督 DA 中，训练阶段既有有限的目标域标记数据（D^tl^），也有冗余的非标记数据（D^tu^），这使得网络可以学习目标域的结构信息。</p></li><li><p>在无监督 DA 中，训练网络时无法观察到有标签但足够多的无标签目标域数据（D^tu^）</p></li></ol><p>与同质类似，异质也可分为有监督、半监督和无监督。</p><p>上述所有 DA 设置都假定源领域和目标领域直接相关，因此，知识转移只需一步即可完成。我们称其为一步式设计。</p><p><img data-src="https://s2.loli.net/2024/06/30/sP3IEinJu1cg2tm.png" alt="image-20240630194001836"></p><p>然而，在现实中，这一假设偶尔也会落空。两个域之间几乎没有重叠，因此执行单步 DA 将不会有效。幸运的是，有一些中间域能够拉近源域和目标域之间的距离。使用一系列中间桥梁来连接两个看似不相关的域，然后通过该桥梁执行一步式 DA,这就是多步式（或反式）DA .例如,人脸图像和车辆图像由于形状或其他方面的不同而互不相似,因此单步检测会失败.但是,可以引入一些中间图像，如 “足球头盔”,作为中间域,从而顺利实现知识转移.</p><p>从广义上讲，深度 DA 是一种利用深度网络提高 DA 性能的方法。根据这一定义，具有深度特征的浅层方法可视为深度 DA 方法。浅层方法采用 DA，而深度网络只能提取矢量特征，无助于直接传递知识。例如，Lu 等人从 CNN 中提取卷积激活作为张量表示，然后进行张量对齐。</p><p>从狭义上讲，深度 DA 基于专为 DA 设计的深度学习架构，可以通过反向传播从深度网络中获得第一手效果。其直观思路是<strong>将 DA 嵌入到学习表征的过程中，学习一种既有语义意义又有领域不变性的深度特征表征。有了 “好 “的特征表示，目标任务的性能就会显著提高</strong>。</p><p>一步式数据采集的深度方法可归纳为三种情况.</p><p>第一种情况是<strong>基于差异(Discrepancy-based)</strong>的深度数据挖掘方法,该方法<strong>假定用标注或未标注的目标数据微调深度网络模型可以减少两个域之间的偏移</strong>.类判据(class criterion)、统计判据(statistic criterion)、架构判据(architecture criterion)和几何判据(geometric criterion)是进行微调的四种主要技术。</p><p><strong>class criterion</strong>:使用类标签信息作为在不同领域间转移知识的指南.在有监督的数据分析中,当目标领域的标签样本可用时,软标签和度量学习总是有效的.当无法获得此类样本时,可采用其他一些技术来替代类标签数据,如伪标签和属性表示法.</p><p><strong>statistic criterion</strong>:利用某些机制对源域和目标域之间的统计分布偏移进行配准。最常用的比较和减少分布偏移的方法有最大均值差异（MMD）、相关对齐（CORAL）、KullbackLeibler发散和 H 发散等。</p><p><strong>Architecture criterion</strong>:这些技术旨在通过调整深度网络的架构，提高学习更多可迁移特征的能力。已被证明具有成本效益的技术包括自适应批量归一化（BN）、弱相关权重、域引导剔除等。</p><p><strong>Geometric criterion</strong>:根据源域和目标域的几何特性将其连接起来。这一标准假定几何结构的关系可以减少域的偏移.</p><p>第二种情况可称为<strong>基于对抗(Adversarial-based)的深度 DA 方法</strong>。在这种情况下，<strong>会使用一个领域判别器来对数据点是来自源领域还是目标领域进行分类</strong>，通过对抗目标来鼓励领域混淆，从而使经验源映射分布和目标映射分布之间的距离最小化。</p><p>此外，根据是否存在生成模型，基于对抗的深度数据挖掘方法可分为两种情况。</p><p><strong>生成模型</strong>：将判别模型与一般基于生成对抗网络（GAN）的生成组件相结合。其中一种典型情况是使用源图像、噪声矢量或两者生成与目标样本相似的模拟样本，并保留源域的注释信息。</p><p><strong>非生成模型</strong>：特征提取器不是利用输入图像分布生成模型，而是利用源域中的标签学习判别表征，并通过域混淆损失将目标数据映射到同一空间，从而得到域不变表征.</p><p>第三种情况可称为<strong>基于重构(Reconstruction-based)</strong>的 DA 方法，它假定源样本或目标样本的数据重构有助于提高 DA 的性能。重构器既能确保域内表征的特异性，又能确保域间表征的不可分性。</p><ul><li>编码器-解码器重构：通过使用堆叠自动编码器（SAE），编码器-解码器重构方法将用于表征学习的编码器网络与用于数据重构的解码器网络结合起来.</li><li>对抗重构：重构误差是通过 GAN 识别器（如 dual GAN、cycle GAN和 disco GAN）获得的循环映射测量的每个图像域内重构图像与原始图像之间的差异。</li></ul><p>在多步骤 DA 中，<strong>我们首先要确定与源域和目标域的关系比直接联系更密切的中间域。其次，知识转移过程将在源域、中间域和目标域之间以较少信息损失的方式通过一步 DA 完成</strong>。因此，多步骤 DA 的关键在于如何选择和利用中间域；此外，根据文献，它可以分为三类：手工选择机制、基于特征的选择机制和基于表征的选择机制。</p><p><strong>Hand-crafted</strong>：用户根据经验确定中间域</p><p><strong>Instance-based</strong>：从辅助数据集中选择某些部分的数据来组成中间域，以训练深度网络</p><p><strong>Representation-based</strong>：通过冻结先前训练好的网络,并将其中间表征作为新网络的输入,可以实现转移</p><h4 id="Discrepancy-based-approaches"><a href="#Discrepancy-based-approaches" class="headerlink" title="Discrepancy-based approaches"></a>Discrepancy-based approaches</h4><p>Yosinski 等人证明,由于脆弱的共适应性和表征特异性,深度网络学习到的可迁移特征具有局限性,而微调可以提高泛化性能.微调（也可视为基于差异的深度数据挖掘方法）是<strong>用源数据训练基础网络,然后直接重用前 n 层来构建目标网络</strong>.<strong>目标网络的其余层是随机初始化的,并根据差异损失进行训练</strong>.在训练过程中,可以根据目标数据集的大小及其与源数据集的相似度,对目标网络的前 n 层进行微调或冻结。</p><h5 id="class-criterion"><a href="#class-criterion" class="headerlink" title="class criterion"></a>class criterion</h5><p>类标准是深度 DA 中最基本的训练损耗。<strong>在使用源数据对网络进行预训练后，目标模型的其余各层将类标签信息作为训练网络的指南</strong>。因此，假定可以从目标数据集中获得少量带标签的样本。理想情况下，类标签信息在有监督的数据分析中直接给出。大多数工作通常使用地面真实类的负对数似然与 softmax 作为训练损失，即 L = - ∑N i=0 yi log ˆ yi（ˆ yi 是模型的 softmax 预测，代表类概率）</p><p><img data-src="https://s2.loli.net/2024/06/30/5U4korDjOX1diuP.png" alt="image-20240630221825042"></p><p>受 Tzeng 等人的启发， 通过同时最小化领域混淆损失（属于基于对抗的方法）和软标签损失，对网络进行了微调。使用软标签而不是硬标签可以保持跨域类之间的关系。Gebru 等人在的基础上修改了现有的适应算法，在细粒度的类级别 Lcsoft 和属性级别 Lasoft 上使用了软标签损失。</p><p>除了 softmax 损失外，还有其他方法可用作训练损失，以微调有监督 DA 中的目标模型。深度网络中的嵌入度量学习是另一种方法，它可以使来自不同领域、具有相同标签的样本距离更近，而具有不同标签的样本距离更远。基于这一思想构建了<strong>相应的语义对齐损失和分离损失</strong>。Hu 等人提出了深度转移度量学习，它应用了边际费雪分析准则和 MMD 准则.</p><p>然而，如果目标域中没有直接的类标签信息，我们该怎么办呢？众所周知，人类可以仅凭高层次的描述来识别未见过的类。例如，当我们得到 “高大的棕色长颈动物 “的描述时，我们就能识别出长颈鹿。为了模仿人类的能力，为每个类引入了高级语义属性。假设 a^c^ = (a^c^~1~, … , a^c^~m~ ) 是 c 类的属性表示，它具有固定长度的二进制值，在所有类中有 m 个属性.分类器为每个属性 a^m^ 提供 p(a^m^|x) 的估计值</p><p><strong>Statistic criterion</strong></p><p>虽然有些基于差异的方法会<strong>寻找伪标签、属性标签或其他标签目标数据的替代品</strong>，但更多的工作侧重于在<strong>无监督 DA 中通过最小化域分布差异来学习域不变表示</strong>。MMD 是通过核双样本测试比较两个数据集分布的有效指标。</p><script type="math/tex; mode=display">MMD^{2}(s,t)=\sup_{\|\phi\|_{\mathcal{H}}\leq1}\left\|E_{x^{s}\sim s}[\phi(x^{s})]-E_{x^{t}\sim s}[\phi(x^{t})]\right\|_{\mathcal{H}}^{2}</script><p>在此基础上，Ghifary 等人提出了一种模型，在单隐层前馈神经网络中引入 MMD 指标。MMD 指标在每个域的表征之间进行计算，以减少潜在空间中的分布失配。</p><script type="math/tex; mode=display">MMD^2(D_s,D_t)=\left\|\frac{1}{M}\sum_{i=1}^M\phi(x_i^s)-\frac{1}{N}\sum_{j=1}^N\phi(x_j^t)\right\|_H^2</script><p>Long 等人没有使用单层和线性 MMD，而是提出了深度适应网络 (DAN)，通过添加多个适应层和探索多个内核来匹配跨域边际分布的变化，同时假设条件分布保持不变（图 6）。然而，在实际应用中，这一假设相当强；换句话说，源分类器不能直接用于目标域。为了使其更具通用性，联合适应网络（JAN）基于联合最大均值差异（JMMD）准则，在多个特定领域层中调整输入特征和输出标签联合分布的偏移。Zhang 等人提出了 DTN，其中边际分布和条件分布都根据 MMD 进行匹配。</p><p>如果 φ 是特征核（即高斯核或拉普拉斯核），MMD 将比较所有阶次的统计量矩。与 MMD 不同，CORAL学习的是一种线性变换，它能使域之间的二阶统计量保持一致。Sun 和 Saenko 利用非线性变换将 CORAL 扩展到深度神经网络（深度 CORAL）。</p><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{CORAL}}=\frac{1}{4d^{2}}\|C_{S}-C_{T}\|_{F}^{2}</script><p>其中，‖-‖F^2^ 表示矩阵弗罗贝尼斯准则平方。C~S~ 和 C~T~ 分别表示源数据和目标数据的协方差矩阵。</p><p><strong>Architecture criterion</strong></p><p>其他一些方法则会优化网络架构，使分布差异最小化。这种适应行为可以在大多数深度 DA 模型中实现，如监督和非监督设置。Rozantsev 等人认为，对应层的权重不是共享的，而是通过权重正则化器 rw( - ) 进行关联，以考虑两个域的差异。</p><p><img data-src="https://s2.loli.net/2024/06/30/V3uX2QpSghyj8Bz.png" alt="image-20240630223652513"></p><p><strong>Geometric criterion</strong></p><p>几何准则通过整合从源域到目标域的路径上的中间子空间来减轻域偏移。</p><h4 id="Adversarial-based-approaches"><a href="#Adversarial-based-approaches" class="headerlink" title="Adversarial-based approaches"></a>Adversarial-based approaches</h4><p>GAN这里就不细说了.</p><h5 id="Non-generative-models"><a href="#Non-generative-models" class="headerlink" title="Non-generative models"></a>Non-generative models</h5><p>深度DA的关键在于从源样本和目标样本中学习与领域无关的表征。有了这些表征，两个领域的分布就会足够相似，这样分类器就会被骗过，即使它是在源样本上训练出来的，也能直接用于目标领域。因此，表征是否存在领域混淆对于知识迁移至关重要。受 GAN 的启发引入了由判别器产生的领域混淆损失，以提高无生成器的深度 DA 性能。</p><p>域对抗神经网络（DANN）将梯度反转层（GRL）集成到标准架构中，以确保两个域的特征分布相似）。该网络由共享特征提取层和两个分类器组成。</p><p>DANN 通过使用 GRL 使域混淆损失（所有样本）和标签预测损失（源样本）最小化，同时使域混淆损失最大化。</p><p>与上述方法相比，对抗性判别域适应（ADDA） 通过取消权重来考虑独立的源和目标映射，目标模型的参数由预训练的源模型初始化。这种方法更加灵活，因为可以学习更多特定领域的特征提取。</p><p><img data-src="https://s2.loli.net/2024/06/30/7wux3qMtXFE8AlS.png" alt="image-20240630224001535"></p><h4 id="Reconstruction-based-approaches"><a href="#Reconstruction-based-approaches" class="headerlink" title="Reconstruction-based approaches"></a>Reconstruction-based approaches</h4><p>在 DA 中，源样本或目标样本的数据重构是一项辅助任务，它同时侧重于在两个域之间创建共享表征，并保持每个域的各自特点。</p><p><img data-src="https://s2.loli.net/2024/06/30/6xZTH9OQfjRpunr.png" alt="image-20240630224158266"></p><p>这篇文章分了一个同构和异构的DA方法,个人感觉其实没有太大的必要,下面直接介绍.</p><p><img data-src="https://s2.loli.net/2024/06/30/JREocqfp8jiwLeP.png" alt="image-20240630230147062"></p><p><strong>一些方法比较</strong></p><p><img data-src="https://s2.loli.net/2024/06/30/XtzFxWNyM5AC4ql.png" alt="image-20240630230339375"></p><h2 id="一些具体工作"><a href="#一些具体工作" class="headerlink" title="一些具体工作"></a>一些具体工作</h2><h3 id="Unsupervised-Domain-Adaptation-by-Backpropagation"><a href="#Unsupervised-Domain-Adaptation-by-Backpropagation" class="headerlink" title="Unsupervised Domain Adaptation by Backpropagation"></a>Unsupervised Domain Adaptation by Backpropagation</h3><p><a href="https://arxiv.org/pdf/1409.7495与[1505.07818">https://arxiv.org/pdf/1409.7495与[1505.07818</a> (arxiv.org)](<a href="https://arxiv.org/pdf/1505.07818">https://arxiv.org/pdf/1505.07818</a>)</p><p>较早的域自适应工作,时间上跟GAN类似,本身也跟GAN很像.</p><p><img data-src="https://s2.loli.net/2024/06/23/ym2ExsfAFX9cpP7.png" alt="image-20240623165143441"></p><h3 id="Simultaneous-Deep-Transfer-Across-Domains-and-Tasks"><a href="#Simultaneous-Deep-Transfer-Across-Domains-and-Tasks" class="headerlink" title="Simultaneous Deep Transfer Across Domains and Tasks"></a>Simultaneous Deep Transfer Across Domains and Tasks</h3><p><a href="https://arxiv.org/pdf/1510.02192">https://arxiv.org/pdf/1510.02192</a></p><p>同样也是远古时期论文</p><h3 id="Minimum-Class-Confusion-for-Versatile-Domain-Adaptation"><a href="#Minimum-Class-Confusion-for-Versatile-Domain-Adaptation" class="headerlink" title="Minimum Class Confusion for Versatile Domain Adaptation"></a>Minimum Class Confusion for Versatile Domain Adaptation</h3><p><img data-src="https://s2.loli.net/2024/06/27/w4semziX5HcTZo9.png" alt="image-20240627153353279"></p><h3 id="Maximum-Classifier-Discrepancy-for-Unsupervised-Domain-Adaptation"><a href="#Maximum-Classifier-Discrepancy-for-Unsupervised-Domain-Adaptation" class="headerlink" title="Maximum Classifier Discrepancy for Unsupervised Domain Adaptation"></a>Maximum Classifier Discrepancy for Unsupervised Domain Adaptation</h3><p><img data-src="https://s2.loli.net/2024/06/27/ikL3uemU5nxNT7f.png" alt="image-20240627155801158"></p><h3 id="Deep-Domain-Confusion-Maximizing-for-Domain-Invariance"><a href="#Deep-Domain-Confusion-Maximizing-for-Domain-Invariance" class="headerlink" title="Deep Domain Confusion: Maximizing for Domain Invariance"></a>Deep Domain Confusion: Maximizing for Domain Invariance</h3><p><img data-src="https://s2.loli.net/2024/06/30/Uh35uECtq9zAWVm.png" alt="image-20240630160801199"></p><h3 id="Taking-A-Closer-Look-at-Domain-Shift-Category-level-Adversaries-for-Semantics-Consistent-Domain-Adaptation"><a href="#Taking-A-Closer-Look-at-Domain-Shift-Category-level-Adversaries-for-Semantics-Consistent-Domain-Adaptation" class="headerlink" title="Taking A Closer Look at Domain Shift: Category-level Adversaries for Semantics Consistent Domain Adaptation"></a>Taking A Closer Look at Domain Shift: Category-level Adversaries for Semantics Consistent Domain Adaptation</h3><p><img data-src="https://s2.loli.net/2024/06/30/5pCyk8FE2alwqhL.png" alt="image-20240630231443263"></p><p>提出catergory-level的对齐.</p><p>da的关键在于减少领域偏移，即强制两个领域的数据分布相似。常见的策略之一是通过对抗学习来对齐特征空间中的边际分布。然而，这种全局对齐策略并不考虑类别级的联合分布,这种全局移动的一个可能后果是，一些原本在源域和目标域之间对齐良好的类别可能会被错误地映射，从而导致目标域的分割结果变差。</p><p>为了解决这个问题，我们引入了一个类别级对抗网络，目的是在全局对齐趋势中执行局部语义一致性。我们的想法是仔细观察类别级联合分布，并通过自适应对抗损失来对齐每个类别。具体来说，我们降低了类别级对齐特征的对抗损失权重，同时增加了那些对齐不佳特征的对抗力。</p><script type="math/tex; mode=display">\mathcal{L}_{seg}(G)=\sum_{i=1}^{H\times W}\sum_{c=1}^{C}-y_{ic}\log p_{ic}</script><script type="math/tex; mode=display">\mathcal{L}_{weight}(G)=\frac{\vec{w_1}\cdot\vec{w_2}}{\|\vec{w_1}\|\|\vec{w_2}\|}</script><script type="math/tex; mode=display">\begin{aligned}&\mathcal{L}_{adv}(G,D)=-E[\log(D(G(X_{S})))]-\\&E[(\lambda_{local}\mathcal{M}(p^{(1)},p^{(2)})+\epsilon)\log(1-D(G(X_{T})))] ,\end{aligned}</script><script type="math/tex; mode=display">\begin{gathered}\mathcal{L}_{CLAN}(G,D)= \mathcal{L}_{seg}(G)+\lambda_{weight}\mathcal{L}_{weight}(G)+ \\\lambda_{adv}\mathcal{L}_{adv}(G,D) , \end{gathered}</script><script type="math/tex; mode=display">G^*,D^*=\arg\min_G\max_D\mathcal{L}_{CLAN}(G,D).</script><h3 id="Cross-domain-adaptive-clustering-for-semisupervised-domain-adaptation"><a href="#Cross-domain-adaptive-clustering-for-semisupervised-domain-adaptation" class="headerlink" title="Cross-domain adaptive clustering for semisupervised domain adaptation"></a>Cross-domain adaptive clustering for semisupervised domain adaptation</h3><p><img data-src="https://s2.loli.net/2024/07/02/xOTivnD4tj2PrUG.png" alt="image-20240702113906287"></p><h3 id="Moment-Matching-for-Multi-Source-Domain-Adaptation"><a href="#Moment-Matching-for-Multi-Source-Domain-Adaptation" class="headerlink" title="Moment Matching for Multi-Source Domain Adaptation"></a>Moment Matching for Multi-Source Domain Adaptation</h3><p><img data-src="https://s2.loli.net/2024/06/27/tDwx9ZesFkz57yo.png" alt="image-20240627164102546"></p><h3 id="A-DIRT-T-APPROACH-TO-UNSUPERVISED-DOMAIN-ADAPTATION"><a href="#A-DIRT-T-APPROACH-TO-UNSUPERVISED-DOMAIN-ADAPTATION" class="headerlink" title="A DIRT-T APPROACH TO UNSUPERVISED DOMAIN ADAPTATION"></a>A DIRT-T APPROACH TO UNSUPERVISED DOMAIN ADAPTATION</h3><p><img data-src="https://s2.loli.net/2024/06/27/lgRXwOIv43etCjW.png" alt="image-20240627175801303"></p><h3 id="Reusing-the-Task-specific-Classifier-as-a-Discriminator-Discriminator-free-Adversarial-Domain-Adaptation"><a href="#Reusing-the-Task-specific-Classifier-as-a-Discriminator-Discriminator-free-Adversarial-Domain-Adaptation" class="headerlink" title="Reusing the Task-specific Classifier as a Discriminator: Discriminator-free Adversarial Domain Adaptation"></a>Reusing the Task-specific Classifier as a Discriminator: Discriminator-free Adversarial Domain Adaptation</h3><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>对抗学习在无监督领域适应（UDA）方面取得了卓越的成绩。现有的对抗性 UDA 方法通常采<strong>用额外的判别器与特征提取器进行最小-最大博弈</strong>.</p><p>现有的对抗性 UDA 方法通<strong>常采用额外的判别器与特征提取器进行最小-最大博弈.然而,这些方法大多不能有效利用预测的判别信息</strong>，从而导致生成器的模式崩溃。</p><p>在这项工作中,我们从不同的角度来解决这个问题,设计了一种简单而有效的对抗范式，即<strong>无判别器对抗学习网络</strong>（DALN）,其中<strong>类别分类器被重新用作判别器</strong>，通过统一的目标实现明确的领域对齐和类别区分,使 DALN 能够利用预测的判别信息进行充分的特征对齐。</p><p>基本上，我们引入了一种Nuclear-norm Wasserstein discrepancy，NWD，它对进行判别具有明确的指导意义。这种 NWD 可以与分类器相结合，作为满足 K-Lipschitz 约束的判别器，而无需额外的权重剪切或梯度惩罚策略。</p><h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>深度神经网络（DNN）在许多计算机视觉任务中取得了重大进展。然而，这些方法的成功在很大程度上取决于大量的注释数据，而获取这些数据极其耗时且昂贵。</p><p>此外，由于训练数据与真实世界测试数据之间存在差异，尽管进行了大量标注工作，但在标注数据上训练的 DNN 模型在测试集上的性能可能会急剧下降。为了解决这个问题，人们深入探讨了无监督领域适应（UDA）]，其目的是在领域转移的情况下，将知识从有标注的源领域转移到无标注的目标领域。</p><p>受 Ben-David 等人理论分析的启发，现有的 UDA 方法通常都在<strong>探索学习领域不变特征表征的思路</strong>。一般来说，这些方法可分为两个分支，即矩匹配方法和对抗学习方法。矩匹配方法通过匹配源域和目标域特征的明确分布差异，明确减少域偏移。</p><p>对抗性学习方法通过进行对抗性最小-最大双人博弈，隐含地减轻了领域转移的影响，这促使生成器提取不可区分的特征，以欺骗鉴别器</p><p>有一种方法利用两个特定任务分类器 C 和 C′的差异（可将其视为判别器）来隐式地实现对抗学习并提高特征的可转移性。这种范式使 UDA 方法<strong>能够减少类级域差异</strong>。但是，遵循这种范式的方法容易受到模糊预测的影响，从而阻碍适应性优化。</p><p>另一种方法直接构建了一个额外的域判别器 D，通过<strong>充分混淆跨域特征表示来提高特征的可转移性</strong>。然而，遵循这一范式的方法<strong>通常侧重于领域级特征混淆</strong>，这可能<strong>会损害类别级信息</strong>，从而导致模式崩溃问题</p><p><img data-src="https://s2.loli.net/2024/07/05/t2JurbfKWowqQEs.png" alt="image-20240705114005812"></p><h3 id="Domain-Adaptation-in-Object-Detection"><a href="#Domain-Adaptation-in-Object-Detection" class="headerlink" title="Domain Adaptation in Object Detection"></a>Domain Adaptation in Object Detection</h3><h4 id="Domain-Adaptive-Faster-R-CNN-for-Object-Detection-in-the-Wild"><a href="#Domain-Adaptive-Faster-R-CNN-for-Object-Detection-in-the-Wild" class="headerlink" title="Domain Adaptive Faster R-CNN for Object Detection in the Wild"></a>Domain Adaptive Faster R-CNN for Object Detection in the Wild</h4><p><img data-src="https://s2.loli.net/2024/06/30/dm3lApv8HMux15G.png" alt="image-20240630231624714"></p><p>较早的用于目标检测的domain adaptation方法,使用GRL和不同level的分类器.</p><h4 id="CDTRANS-CROSS-DOMAIN-TRANSFORMER-FOR-UNSUPERVISED-DOMAIN-ADAPTATION"><a href="#CDTRANS-CROSS-DOMAIN-TRANSFORMER-FOR-UNSUPERVISED-DOMAIN-ADAPTATION" class="headerlink" title="CDTRANS: CROSS-DOMAIN TRANSFORMER FOR UNSUPERVISED DOMAIN ADAPTATION"></a>CDTRANS: CROSS-DOMAIN TRANSFORMER FOR UNSUPERVISED DOMAIN ADAPTATION</h4><p>无监督领域适应（UDA）旨在将从标注源领域学习到的知识转移到不同的无标注目标领域。大多数现有的无监督领域适应方法都侧重于学习领域不变的特征表征，无论是从<strong>领域层面还是从类别层面</strong>，都使用基于卷积神经网络（CNN）的框架。<strong>基于类别层的 UDA 面临的一个基本问题是，目标域中的样本会产生伪标签，而伪标签通常噪声过大，无法进行准确的域对齐，这不可避免地会影响 UDA 的性能</strong>。</p><p>随着 Transformer 在各种任务中的成功应用，我们发现 Transformer 中的交叉关注对噪声输入对具有鲁棒性，可以更好地进行特征对齐，因此本文采用 Transformer 来完成具有挑战性的 UDA 任务。</p><p>具体来说,为了生成准确的输入对,设计了<strong>一种双向中心感知标签算法,为目标样本生成伪标签</strong>。除了伪标签,我们还提出了一个<strong>权重共享的三重分支transformer框架</strong>,分别用于源/目标特征学习和源/目标域对齐的自我关注和交叉关注.这种设计明确地强化了该框架,使其能够同时学习具有区分性的特定领域表征和领域不变表征。所提出的方法被称为 CDTrans（跨域transformer）它是用纯transformer解决方案解决 UDA 任务的首次尝试之一.</p><h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p>UDA方法主要有两个层次：领域级和类别级。域级 UDA 通过将源域和目标域拉入不同尺度级别的相同分布中，来缓解源域和目标域之间的分布分歧。常用的分歧度量包括最大均值差异（MMD）和相关对齐（CORAL）。</p><p>最近，一些研究侧重于通过特征提取器和两个特定领域分类器之间的对抗方式进行细粒度类别级标签分布对齐。与领域尺度的粗粒度对齐不同，<strong>这种方法通过将目标样本推向源样本在每个类别中的分布，来对齐源和目标领域数据之间的每个类别分布。显然，细粒度配准能在同一标签空间内实现更精确的分布配准。</strong>尽管对抗方法通过在类别级别上融合源样本和目标样本的细粒度配准操作实现了新的改进，但它仍然无法解决噪声样本在错误类别中的问题。我们的方法采用了<strong>类别级 UDA</strong> 的 Transformers 来解决噪声问题。</p><p>伪标签法首次被引入半监督学习,并在领域适应任务中得到普及.它<strong>利用预测概率学习标记未标记数据,并与标记数据一起执行微调</strong>.在将伪标签用于领域适应任务方面，采用<strong>伪标签进行条件分布对齐</strong>；<strong>将伪标签作为领域适应的正则化</strong>；Zou 等通过交替求解伪标签设计了一种自训练框架；Caron 等提出了一种深度自监督方法，通过 k-means 聚类生成伪标签来逐步训练模型；Liang 等开发了一种自监督伪标签方法来减轻噪声伪标签的影响。在Liang 等人的基础上，本文提出了一种双向中心感知标注算法，以进一步过滤噪声伪标签对</p><p><img data-src="C:\Users\proanimer\AppData\Roaming\Typora\typora-user-images\image-20240702114426708.png" alt="image-20240702114426708"></p><h4 id="Uncertainty-Aware-Unsupervised-Domain-Adaptation-in-Object-Detection"><a href="#Uncertainty-Aware-Unsupervised-Domain-Adaptation-in-Object-Detection" class="headerlink" title="Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection"></a>Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection</h4><p><img data-src="https://s2.loli.net/2024/07/05/DNVsxMT7WhRHvX5.png" alt="image-20240705113637158"></p><h4 id="ConfMix-Unsupervised-Domain-Adaptation-for-Object-Detection-via-Confidence-based-Mixing"><a href="#ConfMix-Unsupervised-Domain-Adaptation-for-Object-Detection-via-Confidence-based-Mixing" class="headerlink" title="ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing"></a>ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing</h4><p><img data-src="https://s2.loli.net/2024/07/05/wEb6aNTnig8HWIt.png" alt="image-20240705114702994"></p><p>用于对象检测的无监督域自适应 （UDA） 旨在调整在源域上训练的模型，以检测来自注释不可用的新目标域的实例。与传统方法不同，我们提出了ConfMix，这是第一种<strong>引入基于区域级检测置信度的样本混合策略的方法，用于自适应目标检测器学习</strong>。我们将对应于最可靠伪检测的目标样本的局部区域与源图像混合，并应用额外的一致性损失项以逐渐适应目标数据分布。为了稳健地定义一个区域的置信度分数，我们利用了每次伪检测的置信度分数，该置信度同时考虑了检测器依赖的置信度和边界框的不确定性</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://arxiv.org/pdf/2208.07422">2208.07422 (arxiv.org)</a></li><li><a href="https://www.youtube.com/watch?v=gvfLq4sPW4k&amp;ab_channel=Hung-yiLee">[TA 補充課] More about Domain Adaptation (1/2) (由助教趙崇皓同學講授) (youtube.com)</a></li></ol><p><strong>论文与代码库</strong></p><ul><li><p><a href="https://github.com/thuml/Transfer-Learning-Library">thuml/Transfer-Learning-Library: Transfer Learning Library for Domain Adaptation, Task Adaptation, and Domain Generalization (github.com)</a></p></li><li><p><a href="https://github.com/adapt-python/adapt">adapt-python/adapt: Awesome Domain Adaptation Python Toolbox (github.com)</a></p></li><li><p><a href="https://github.com/jindongwang/transferlearning">jindongwang/transferlearning: Transfer learning / domain adaptation / domain generalization / multi-task learning etc. Papers, codes, datasets, applications, tutorials.-迁移学习 (github.com)</a></p></li><li><p><a href="https://github.com/zhaoxin94/awesome-domain-adaptation">zhaoxin94/awesome-domain-adaptation: A collection of AWESOME things about domian adaptation (github.com)</a></p></li><li><p><a href="https://github.com/barebell/DA">barebell/DA: Unsupervised Domain Adaptation Papers and Code (github.com)</a></p></li><li><p><a href="https://github.com/agrija9/Deep-Unsupervised-Domain-Adaptation">agrija9/Deep-Unsupervised-Domain-Adaptation: Pytorch implementation of four neural network based domain adaptation techniques: DeepCORAL, DDC, CDAN and CDAN+E. Evaluated on benchmark dataset Office31. (github.com)</a></p></li><li><p><a href="https://github.com/jvanvugt/pytorch-domain-adaptation?tab=readme-ov-file">jvanvugt/pytorch-domain-adaptation: A collection of implementations of adversarial domain adaptation algorithms (github.com)</a></p></li></ul><p>目标检测的域适应</p><ul><li><a href="https://github.com/kinredon/DA_Detection_Material">kinredon/DA_Detection_Material: A Collection of Domain Adaptation for Object Detection Material (github.com)</a></li><li><a href="https://github.com/wangs311/awesome-domain-adaptation-object-detection?tab=readme-ov-file">wangs311/awesome-domain-adaptation-object-detection: A collection of papers about domain adaptation object detection. Welcome to PR the works (papers, repositories) that are missed by the repo. (github.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/371721493">【领域自适应目标检测】论文及代码整理 - 知乎 (zhihu.com)</a></li></ul><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;这个方向的技术目前没有那么火了,但是能应用的场景非常之多.&lt;br&gt;</summary>
    
    
    
    
    <category term="domain adaptation" scheme="https://www.sekyoro.top/tags/domain-adaptation/"/>
    
  </entry>
  
  <entry>
    <title>协同感知学习(二)</title>
    <link href="https://www.sekyoro.top/2024/05/17/%E5%8D%8F%E5%90%8C%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95-%E4%BA%8C/"/>
    <id>https://www.sekyoro.top/2024/05/17/%E5%8D%8F%E5%90%8C%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95-%E4%BA%8C/</id>
    <published>2024-05-17T14:42:49.000Z</published>
    <updated>2024-07-09T03:22:19.488Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>随着大模型时代的到来,原先通过修改模型结构提升性能写论文的方式已经有点out of date了,同时写文章的倾向已经从改架构成SOTA慢慢转变为回归任务背景以及讲好一个完整故事并给出自己的findings和insight了.也因此,在协作感知方面,论文方向也逐渐在转变,这里看看最近的文章整理一下思路.</p><span id="more"></span><h2 id="Domain-gap"><a href="#Domain-gap" class="headerlink" title="Domain gap"></a>Domain gap</h2><h3 id="Bridging-the-Domain-Gap-for-Multi-Agent-Perception-ICRA"><a href="#Bridging-the-Domain-Gap-for-Multi-Agent-Perception-ICRA" class="headerlink" title="Bridging the Domain Gap for Multi-Agent Perception ICRA"></a>Bridging the Domain Gap for Multi-Agent Perception ICRA</h3><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>现有的多智能体感知算法通常选择在智能体之间共享从原始感知数据中提取的深度神经特征，以实现精度和通信带宽限制之间的权衡.然而,<strong>这些方法假设所有智能体具有相同的神经网络，这在现实世界中可能是不实用的</strong>。</p><p>当模型不同时,传递的特征可能存在较大的<strong>领域差距</strong>(domain gap)，导致多智能体感知性能急剧下降.</p><p>在本文中，我们提出了第一个轻量级框架来为多智能体感知弥合这种领域鸿沟,它可以作为大多数现有系统的插件模块,同时保持机密性.</p><p>我们的框架包括一个可学习的特征成形模来对齐多个维度的特征,以及一个用于领域自适应的稀疏跨域转换器.在公开的多智能体感知数据集V2XSet上的大量实验表明,对于基于点云的三维目标检测,我们的方法可以有效地弥合不同领域特征之间的差距,并显著优于其他基线方法至少8%。</p><h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>最近的研究表明，通过利用车联网( Vehicle-to- Everything，V2X )通信技术共享视觉信息，多智能体感知系统可以通过透视遮挡和感知更远的范围来显著提高单智能体系统的性能.</p><p>现有方法通常不共享原始感知数据或检测输出,而是共享由传感器数据计算得到的中间神经特征,因为它们可以在精度和带宽需求之间实现最佳权衡.</p><p>此外,传递的中间特征对GPS噪声和通信延迟的鲁棒性更强.</p><p>这忽略了一个关键的事实<strong>:为所有智能体部署相同的模型是不现实的,特别是对于连接的自动驾驶</strong>.</p><p>不同公司的网联自动驾驶汽车( CAV )和基础设施产品的检测模型通常是不同的。即使对于同一公司,由于车载软件版本的不同,<strong>也可能存在不同的检测模型.当共享特征来自不同的骨干时,存在一个明显的域间隙,这很容易削弱协作的好处。</strong></p><p>在本文中,我们深入研究了多智能体感知中,特别是自动驾驶中这一尚未解决的实际问题.我们首先仔细<strong>研究了不同特征图的领域差距</strong>,然后在分析的基础上提出了我们的框架.</p><p><img data-src="https://s2.loli.net/2024/05/17/R4nUZOVyzfJCTcw.png" alt="image-20240517150815672"></p><h4 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h4><p>由于<strong>数据标注的时间消耗</strong>和<strong>不同域之间的域差距</strong>,域适应被用来解决这些问题,通过适应在有标签的源域上训练的模型来解决无标签的目标域.</p><p>最近的领域自适应工作主要针对不同的计算机视觉任务</p><p>在领域自适应中,为了最小化不同领域之间的领域偏移,特征分布可以在共同的层次上对齐：领域层次和类别层次。</p><p>领域级对齐通常涉及最小化源和目标特征分布之间的某种距离度量，如最大均值差异.</p><h4 id="Learnable-Feature-Resizer"><a href="#Learnable-Feature-Resizer" class="headerlink" title="Learnable Feature Resizer"></a>Learnable Feature Resizer</h4><p>在ego代理上计算特征图作为source domain,接受其他代理的特征作为target domain.</p><p>特征缩放器Φ的目标是以可学习的方式将源域特征的维度与目标域进行对齐</p><script type="math/tex; mode=display">F_T^{'}=\Phi(F_T),\mathrm{~s.t.~}F_T^{'}\in\mathbb{R}^{N\times H_S\times W_S\times C_S}</script><p>我们将Φ与多智能体检测模型联合训练，使其能够智能地学习调整特征尺寸的最优方法，这与双线性插值等简单的尺寸调整方法有根本的不同。</p><p>可学习特征成形模的体系结构设计所示,它包括四个主要组件:通道对齐器，FAX成形模，跳跃连接和res - block。</p><p><strong>Channel Aligner</strong>:使用一个简单的1 × 1卷积层对齐通道维度,其输入通道数为$C_{in}$ = 2$C_S$,输出CS通道。当$C^T &gt; C^{in}$时,随机丢弃$C^{in} - C^{T}$通道,应用1 × 1卷积层得到新的特征.我们在$F^T$上重复这个过程n次,得到$n×H^T×W^T×C^S$维度的特征，并沿第一个维度进行平均。</p><p>通过这种方式,我们改善了由于信道衰落造成的信息丢失.当$C<em>T$ &lt; $C</em>{in}$时，我们从FT中随机选择通道进行填充,以满足1 × 1卷积所需的输入通道数。</p><p><strong>FAX Resizer</strong></p><p>由于LiDAR特征通常由于空体素而具有稀疏性,应用大核卷积获取全局信息可能会将无意义的信息扩散到重要区域.因此,我们在双线性缩放之前应用了融合的轴向( FAX )注意力块,以获得更好的特征表示.</p><p><strong>跳跃连接</strong>:在跳跃连接中,使用了双线性特征调整方法,以使学习更容易。</p><p><strong>残差块</strong>( Res-Block ):在重新调整特征图大小后执行标准残差块r次,以进一步细化特征图.</p><h4 id="Sparse-Cross-Domain-Transformer"><a href="#Sparse-Cross-Domain-Transformer" class="headerlink" title="Sparse Cross-Domain Transformer"></a>Sparse Cross-Domain Transformer</h4><p>在检索到缩放后的特征$F^′_{T}$后,需要将其模式从domain classifier中转换为不可区分的模式,以获得领域不变特征.为了达到这个目的,我们需要有效地从局部和全局两个方面来推理$F^{′}_T$和$F_S$之间的相关性.因此,我们提出了稀疏跨域transformer,在避免昂贵计算的同时,享受了transformer架构带来的动态和全局关注的好处.</p><script type="math/tex; mode=display">Q=W_{Q}(F_{T}^{'}),\quad K=W_{K}(F_{S}),\quad V=W_{V}(F_{S}),\\\hat{F_{T}^{'}}=Q+LN(FAX(Q,K,V)),\\F_{T}^{''}=\hat{F_{T}^{'}}+LN(FFN(\hat{F_{T}^{'}})),</script><p>其中LN是层标准化,Q是查询,K是键,V是值.然后,我们将$F^{′′}_T$和$F_S$配对在一起，并将它们送入域分类器和多智能体融合模块.</p><h4 id="Domain-Classifier"><a href="#Domain-Classifier" class="headerlink" title="Domain Classifier"></a>Domain Classifier</h4><p>设X为可能来自源域或目标域的特征图,h:X→{ 0,1 }为域分类器,试图预测源域样本$X_S$为0,目标域样本$X_T$为1</p><script type="math/tex; mode=display">\max_G\min_{h\in H}\left(\mathbf{E}_S(h(X))+\mathbf{E}_T(h(X))\right.</script><h4 id="Multi-Agent-Fusion"><a href="#Multi-Agent-Fusion" class="headerlink" title="Multi-Agent Fusion"></a>Multi-Agent Fusion</h4><p>选择了一个最先进的模型V2X - ViT作为我们的多智能体融合算法。V2X - ViT依次采用异构多智能体自注意力块和多尺度窗口注意力块,对不同智能体的特征进行智能融合。</p><script type="math/tex; mode=display">\min_{G,M}(\mathbf{E}_D(V)),\quad V=M(F_S,F_T^{''})</script><h3 id="MACP-Efficient-Model-Adaptation-for-Cooperative-Perception-WACV"><a href="#MACP-Efficient-Model-Adaptation-for-Cooperative-Perception-WACV" class="headerlink" title="MACP: Efficient Model Adaptation for Cooperative Perception WACV"></a>MACP: Efficient Model Adaptation for Cooperative Perception WACV</h3><h4 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h4><p>车对车（V2V）通信通过信息共享实现了 “看穿遮挡物”，极大地增强了联网和自动驾驶车辆（CAV）的感知能力，从而显著提高了性能。然而，当现有的单个代理模型显示出卓越的泛化能力时，从头开始开发和训练复杂的多代理感知模型可能既昂贵又没有必要。在本文中，我们提出了一个名为 MACP 的新框架，它<strong>能使预先训练好的单个代理模型具备合作能力</strong>。为了实现这一目标，我们<strong>确定了从单一代理转向合作设置所面临的关键挑战，并通过冻结大部分参数和添加一些轻量级模块来调整模型</strong>。我们在实验中证明，所提出的框架可以有效地利用合作观察，并在模拟和真实世界合作感知基准中优于其他最先进的方法，同时所需的可调参数大大减少，通信成本也降低了。</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>我们的目标是求解一个最佳模型 $f^{∗}$，该模型能够检测和划定周围物体的边界框，并分配适当的标签.</p><p>为了简化符号，我们用一个 d′维向量 $y_j∈R^{d′}$ 来表示每个边界框及其类别标签。</p><p>在不失一般性的前提下，物体检测模型 f 是一个从点云空间到边界框及其标签的联合空间 f : X → Y 的映射，经过训练的模型理想地描述了以观测点云集 x 为条件观测边界框集 y 的概率，其值为</p><script type="math/tex; mode=display">p(\mathbf{y}|\mathbf{x};f)=\frac{p(\mathbf{x},\mathbf{y})}{p(\mathbf{x})}</script><p>如果我们用 pS (x) 表示在单个代理感知中观察到点云集的边际概率，用 pC(x) 表示在合作感知中观察到精确点云集的概率，由于 V2V 通信共享了额外的点云，这两个概率可能不同，即 pS (x) ̸= pC(x) 。</p><p>预训练模型给出的点云和边界框的联合分布偏离合作环境下的地面实况联合分布</p><script type="math/tex; mode=display">\hat{p}_{\mathcal{C}}(\mathbf{x},\mathbf{y};f)=\frac{p_{\mathcal{S}}(\mathbf{x},\mathbf{y})}{p_{\mathcal{S}}(\mathbf{x})}\cdot p_{\mathcal{C}}(\mathbf{x})\neq p_{\mathcal{C}}(\mathbf{x},\mathbf{y}) \\g^*=\underset{g\in\mathcal{G}}{\text{argmin}\mathcal{L}}\left(p_{\mathcal{C}}(\mathbf{x},\mathbf{y}),\hat{p}_{\mathcal{C}}(\mathbf{x},\mathbf{y};f\cdot g)\right) \\p(\mathbf{y}|\mathbf{x};f\cdot g)=g\left\lfloor\frac{p_{\mathcal{S}}(\mathbf{x},\mathbf{y})}{p_{\mathcal{S}}(\mathbf{x})}\right\rfloor</script><p><img data-src="https://s2.loli.net/2024/05/08/GZMfEleua21jYVv.png" alt="image-20240508151535055"></p><h4 id="Convolution-Adapter"><a href="#Convolution-Adapter" class="headerlink" title="Convolution Adapter"></a>Convolution Adapter</h4><p>ConAda 模块是特征编码器的关键组件。特征编码器网络是卷积块的级联，其中卷积层的输出经过 ConAda 模块，并通过残差连接加回自身。我们只在训练过程中训练 ConAda 参数，并在卷积层和 ConAda 模块之后的其他层中冻结预训练参数。</p><p>同时，ConAda 还充当车辆之间的通信通道。在通信过程中，ConAda 模块中的下卷积层和激活层帮助压缩和加密编码特征，以便进行广播，而上卷积层则用于解压缩接收信号，以便进行特征融合。</p><h4 id="SSF-Operator-for-Fused-Feature"><a href="#SSF-Operator-for-Fused-Feature" class="headerlink" title="SSF Operator for Fused Feature"></a>SSF Operator for Fused Feature</h4><p>我们在连续的神经网络层中执行 SSF 算子，以考虑域偏移.</p><p>假设卷积层的输出特征图由 $X^{output}_{i,j}$ ∈ $R^{H′×W ′×C′}$ 给出，我们使用缩放因子 $\gamma$∈ $R^{C′}$和移动因子 β ∈ $R^{C′}$更新特征图</p><script type="math/tex; mode=display">X_{i,j}^{\mathrm{output}}=\gamma\odot X_{i,j}^{\mathrm{output}}+\beta</script><p>最后,基于 ConAda 的通信信道可以灵活压缩信号传输,从而缓解通信瓶颈.</p><p><img data-src="https://s2.loli.net/2024/05/08/AjeXstVr2Ih6E5g.png" alt="image-20240508165439383"></p><p>这篇文章主要基于微调的方法和思想,使用的是Adapter,此外还有LoRA等.关于大模型压缩技术还有剪枝、蒸馏以及量化等等,感觉都可以试试.</p><h3 id="DI-V2X-Learning-Domain-Invariant-Representation-for-Vehicle-Infrastructure-Collaborative-3D-Object-Detection-AAAI"><a href="#DI-V2X-Learning-Domain-Invariant-Representation-for-Vehicle-Infrastructure-Collaborative-3D-Object-Detection-AAAI" class="headerlink" title="DI-V2X: Learning Domain-Invariant Representation for Vehicle-Infrastructure Collaborative 3D Object Detection AAAI"></a>DI-V2X: Learning Domain-Invariant Representation for Vehicle-Infrastructure Collaborative 3D Object Detection AAAI</h3><p><strong>Task</strong> Collaborative 3D Object Detection</p><p><strong>method</strong> learn domain-invariant representation</p><p><strong>inner thoughts</strong>  distillation</p><h4 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h4><p>车对物（V2X）协同感知最近获得了极大关注，因为它能够通过整合来自不同代理（如车辆和基础设施）的信息来增强场景理解能力。<strong>然而，目前的研究通常对来自每个代理的信息一视同仁，忽略了每个代理使用不同激光雷达传感器所造成的固有领域差距，从而导致性能不尽如人意</strong>。</p><blockquote><p>也就是不同的LiDAR传感器本身的不同会导致一种domain gap,会使性能下降.这种说法看起来make sense,但加上一些示意图补充可能更好.这篇文章就加了一张.</p></blockquote><p>提出了 DI-V2X,旨在通过一个<strong>新的蒸馏框架来学习领域不变表征</strong>,以减轻 V2X 3D 物体检测中的领域差异。</p><p>DI-V2X 包括三个基本组件：域混合实例增强（DMA）模块、渐进式域不变性蒸馏（PDD）模块和域自适应融合（DAF）模块.</p><p>具体来说,DMA 在训练过程中为教师模型和学生模型建立了一个领域混合三维实例库，从而形成对齐的数据表示.接下来,PDD 鼓励来自不同领域的学生模型逐步学习与教师领域无关的特征表示,并利用代理之间的重叠区域作为指导,促进提炼过程.</p><p>此外,DAF 通过校准感知领域自适应注意力,缩小了学生之间的领域差距.在具有挑战性的 DAIR-V2X 和 V2XSet 基准数据集上进行的大量实验表明,DI-V2X 性能卓越,超过了之前所有的 V2X 模型.</p><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>它充分利用从不同代理（即车辆和路边基础设施）收集到的传感器数据，精确感知复杂的驾驶场景.例如,在车辆视线可能受阻的情况下,由于基础设施的视角不同,它们提供的信息可以作为重要的冗余.</p><p>与以往的单车自动驾驶系统相比,这种合作从根本上扩大了感知范围,减少了盲点,提高了整体感知能力.</p><p>为了有效融合来自不同代理的信息,领先的 V2X 方法倾向于采用基于特征的中间协作,即中间融合）。这种方法在特征层保留了每个代理的基本信息，然后对其进行压缩以提高效率。因此，中间融合确保了性能与带宽的权衡，优于早期融合或后期融合方法，前者需要在代理之间传输原始点云数据，而后者则容易受到每个模型产生的不完整结果的影响。</p><p>然而，当前的中间融合模型主要集中在增强来自不同代理的特征之间的交互。</p><p>如图 1(a)所示，<strong>车辆和基础设施可能拥有不同类型的激光雷达传感器，因此直接融合不同来源的点云数据或中间特征难免会影响最终性能</strong>。因此，在这种情况下，如何从多源数据中明确学习域不变表示仍有待探索。</p><p><img data-src="https://s2.loli.net/2024/05/13/D38nvIVKNeUi6xB.png" alt="image-20240513150627484"></p><p>为此，DI-V2X 引入了一种新的师生提炼模型.<strong>在训练过程中，我们强制要求学生模型（即车辆和基础设施）学习与早期融合的教师模型一致的领域不变表示法</strong>,即把来自多个视角的点云整合为一个整体视图来训练教师。<strong>在推理过程中，只保留学生模型</strong>。具体来说，DI-V2X 由三个必要组件组成：领域混合实例增强（DMA）模块、渐进式领域不变性提炼（PDD）模块和领域自适应融合（DAF）模块</p><blockquote><p>其实基础思想就是蒸馏,搞一个结构相似但参数量更小的模型替代原本较大的模型. 关键是让小模型学会大模型的”知识”</p></blockquote><p>DMA 的目的是在训练过程中建立一个mixed ground-truth instance bank，以对齐教师和学生的点云输入，其中的实例来自车侧、路侧或融合侧。</p><p>之后，PDD 的目标是在不同阶段，即在领域适应性融合之前和之后，逐步将信息从教师传递给学生.例如,在融合之前,引导学生在<strong>非重叠区域分别学习领域不变的表征</strong>。而在融合之后，我们将重点放在重叠区域内的提炼上，因为信息已经得到了很好的汇总.</p><p>在 DAF 模块中，来自不同领域的特征会根据其空间重要性进行自适应融合。此外，DAF 还通过整合校准偏移来增强模型对姿态误差的适应能力，从而确保 V2X 检测性能的稳健性。</p><p><img data-src="https://s2.loli.net/2024/05/13/kZdD3lKJYPfWLue.png" alt="image-20240513214314409"></p><p>在DMA中,对于教师模型,使用车端数据,路端数据以及早期融合后的数据(就是转换到统一坐标系后的点云结果)利用PointPillars的decoder进行增强,使用增强后的$P_e$,再使用VoxelNet处理成BEV的二维特征图$B_t$.</p><p>学生模型结构跟教师模型类似,处理$P_v$和$P_i$提取得到对应特征图.然后使用DAF进行融合得到$B_f$</p><p>在训练的时候,在DAF融合之前和之后会有一个PDD模型将学生模型得到的特征和老师模型得到的特征利用overlapping area进行对齐.</p><p>DMA本是类似一个数据增强模块,首先将 $P<em>i$ 投影到自我车辆的坐标系上，这样 $P^T_i$ =$T(i→v)$$P^T_i$,其中 $T(i→v)$ ∈ $R^{4×4} $是基础设施到车辆系统的变换矩阵.然后,我们利用地面实况边界框 $B</em>{gt}$ = {$b<em>k$} 从 $P_v$ 和 $P_i$ 获取实例.来自不同domain、对应于同一地面实况对象的实例将被合并，得到一个早期融合实例 pk = Concat($p^v_k$, $p^i_k$) ∈ $R^{N</em>{k}×4}$，其中 $p^v_k$∈ Pv 和 $p^i_k$∈ Pi 是来自两个领域、以 $b_k$为索引的实例点。由于代理之间的相对位置会随着自我车辆的运动而发生动态变化，因此有些实例可能仅来自单个域，而另一些实例则可能直接来自早期融合的重叠区域。为了确定每个实例的域来源，我们通过计算来自每个域的点比例，将这些实例分为三类：</p><script type="math/tex; mode=display">\begin{aligned}&D_{i} =\{\mathbf{p}_k|N_k^v/(N_k^v+N_k^i)<\tau_l\}  \\&D_{f} =\{\mathbf{p}_k|\tau_l<N_k^v/(N_k^v+N_k^i)<\tau_h\}  \\&D_{v} =\{\mathbf{p}_k|N_k^v/(N_k^v+N_k^i)>\tau_h\} \end{aligned}</script><p>$N^{v}<em>{k}$ 和 $N^{i}</em>{k}$ 分别代表车辆侧和基础设施侧的点数，τl、τh 表示阈值.然后，得到一个实例库$D<em>{mixed}$ = $D_i$ ∪ $D_f$ ∪ $D_v$，其中包含来自所有领域（即包括融合领域）的混合实例。在训练过程中，我们按照一定的概率从$D</em>{mixed}$中随机抽取实例，并将这些实例添加给教师和学生.</p><p>通过涉及不同领域的实例<strong>增强了训练数据的多样性</strong>.此外,从每个学生的角度来看,来自其他领域的信息也会通过实例级混合被纳入其中（Zhang 等人，2018 年）.这种方法从根本上调整了教师模型和学生模型之间的数据分布,从而在随后的知识提炼过程中产生了更具普适性的特征。</p><p>为了获得跟域无关的特征,采用了两阶段蒸馏策略，即在领域自适应融合（DAF）模块之前和之后进行蒸馏。第一个蒸馏阶段是将学生的分布与教师模型相一致，作为 DAF 的输入，这对准确的信息融合至关重要。</p><p>然而，根据经验发现，直接对学生和教师之间的整个特征图进行蒸馏会产生次优性能.为此选择在第一阶段对非重叠区域进行蒸馏.在第二阶段,由于学生特征已通过 DAF 得到很好的融合,我们可以集中精力对重叠区域进行蒸馏.这种两阶段的提炼过程可使学生模型与来自不同区域的教师模型的特征表示相匹配,从而缩小学生之间的差距.</p><p>在融合之前的蒸馏,首先需要计算重叠掩码,以确定重叠区域.</p><p>将基础设施一侧的感知区域转换到车辆一侧，得到一个新的矩形 $A<em>i$ = ($x_i,y_i,2R_x, 2R_y, θ_i$)。然后我们可以计算 $A_v$ 和 $A_i$ 之间的重叠区域，即 $P</em>{overlap}$ = Intersection($A<em>v$，$A_i$)。然后对得到的 $P</em>{overlap}$（即多边形）进行下采样,以匹配特征地图 $B_v$ ∈ $R^{H×W ×C}$ 的大小.</p><script type="math/tex; mode=display">\left.\mathbf{M}(i,j)=\left\{\begin{array}{cc}1&,&\mathrm{if~}(i,j)\in\mathbf{P}_{overlap}\\0&,&\mathrm{otherwise}\end{array}\right.\right.</script><p>M(i, j) ∈ 0, 1 表示（i, j）坐标处的二进制值。通过只对非重叠区域 进行提炼,我们允许每个学生集中学习与各自领域一致的表征。这就避免了强制要求不完整的学生特征向教师的完整特征学习的严格约束</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{da}& =\mathcal{L}_1(\mathbf{B}_t,\mathbf{B}_v\odot\tilde{\mathbf{M}}_v)+\mathcal{L}_1(\mathbf{B}_t,\mathbf{B}_i\odot\tilde{\mathbf{M}}_i)  \\&=\frac1{HW}\sum_m^H\sum_m^W|\mathbf{B}_t(m,n)-\mathbf{B}_v(m,n)|\times\tilde{\mathbf{M}}_v(m,n) \\&+\frac1{HW}\sum_m^H\sum_n^W|\mathbf{B}_t(m,n)-\mathbf{B}_i(m,n)|\times\tilde{\mathbf{M}}_i(m,n)\end{aligned}</script><p>在融合后的蒸馏,使用 DAF 模块有效地合并了来自不同领域的学生特征.因此,我们得到了一个能力很强的融合表征,用 Bf 表示,它可以与教师的特征表征 $B_t$ 配对.</p><p>直观地说,Bt 是通过混合点云数据的早期协作获得的,其本质上涉及最小的信息损失.通过强制中间融合特征 $B_f$ 逐步与$B_t$ 保持一致,可以有效地确保在整个学习过程中始终整合通过早期融合阶段获得的基本知识,从而形成与领域无关的特征表征.</p><p>此外，我们还可以超越特征级对齐，扩展到预测级对齐.由于我们的最终目标是从两个 $B_f$ 解码出最终的三维边界框，确保预测层面的对齐将进一步提高结果的一致性和准确性.</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{f}& =\mathcal{L}_1(\mathbf{B}_t,\mathbf{B}_f\odot\mathbf{M}_v)  \\&=\frac1{HW}\sum_m^H\sum_m^W|\mathbf{B}_t(m,n)-\mathbf{B}_f(m,n)|\times\tilde{\mathbf{M}}_v(m,n)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{p}& =\mathcal{L}_{class}+\mathcal{L}_{regression}  \\&=\frac1K\sum_k^K(|\mathbf{c}_k-\mathbf{c}_k^s|+|\mathbf{r}_k-\mathbf{r}_k^s|)\end{aligned}</script><script type="math/tex; mode=display">\mathcal{L}=\mathcal{L}_{detect}+\lambda_{kd}(\mathcal{L}_{da}+\mathcal{L}_f+\mathcal{L}_p)</script><p>DAF 模块的目标是聚合车辆和基础设施的特征,创建一个包含各领域有价值信息的增强表示.然而,这一融合过程面临着两大挑战:双方姿势的潜在错位和设计合适的特征交互策略.</p><p><img data-src="https://s2.loli.net/2024/05/14/s9KUC8vfEXOgTNb.png" alt="image-20240514152437112"></p><p>由于<strong>传感器噪声</strong>、<strong>动态运动</strong>和不同时间戳的不一致性等原因，现实世界中车辆和基础设施的相对姿态很容易受到影响，这将影响 V2X 感知的准确性.为了解决这个问题,利用校准偏移来动态纠正潜在的姿势误差.</p><p>首先用卷积层预测校准偏移,使$B_i$与$B_v$更好地对齐,记为</p><script type="math/tex; mode=display">\Delta_{(i\to v)}=\text{Conv}(\text{Concat}(\mathbf{B}_v,\mathbf{B}_i))\in\mathbb{R}^{H\times W\times2}</script><script type="math/tex; mode=display">\mathbf{B}_i^{^{\prime}}(p_k)=\mathbf{B}_i(p_k+\mathbf{\Delta}_{(i\to v)}(p_k)),0\leq k<HW</script><script type="math/tex; mode=display">\mathbf{A}_d=\mathrm{Softmax}(\mathrm{Conv}(\mathbf{B}_{cat}))\in\mathbb{R}^{H\times W\times C\times2}\\\mathbf{A}_s=\mathrm{Conv}(\mathbf{B}_{cat})+\max(\mathbf{B}_{cat})\\\mathbf{B}_f=\mathrm{Conv}(\mathbf{A}_d\odot\mathbf{A}_s\cdot\mathbf{B}_{cat})\in\mathbb{R}^{H\times W\times C}</script><p>空间自适应注意力可以通过聚合多粒度特征,提供稳健而灵活的注意力图</p><p>最后结果展示包括在两个数据集上与No fusion,early和late fusion以及一些列经典中期融合模型对比.</p><p>然后证明domain generalization实验证明模型学到了域不变的特征.此外还有消融实验,证明提出的每个组件的作用.</p><p><img data-src="https://s2.loli.net/2024/05/14/v4PD6HNOp1ercGx.png" alt="image-20240514172721623"></p><p><img data-src="https://s2.loli.net/2024/05/14/MA5Ia4qDBscdp1L.png" alt="image-20240514172919650"></p><h3 id="Model-Agnostic-Multi-Agent-Perception-Framework-ICRA"><a href="#Model-Agnostic-Multi-Agent-Perception-Framework-ICRA" class="headerlink" title="Model-Agnostic Multi-Agent Perception Framework  ICRA"></a>Model-Agnostic Multi-Agent Perception Framework  ICRA</h3><h3 id="Abs"><a href="#Abs" class="headerlink" title="Abs"></a>Abs</h3><p>现有的多智能体感知系统假设每个智能体使用相同的模型，具有相同的参数和结构，这在现实世界中往往是不切实际的.当感知<strong>模型存在明显差异时,多智能体系统带来的显著性能提升会显著降低</strong>.</p><p>在这项工作中,我们提出了一个model-agnostic的多Agent框架,<strong>以减少模型差异带来的负面影响</strong>，并保持机密性(隐私?).具体来说,我们通过集成一个新颖的不确定性校准器来考虑智能体之间的感知异质性,<strong>该校准器可以消除智能体预测置信度评分之间的偏差</strong>.每个代理在一个标准的公共数据库上独立地执行这种校准,因此知识产权可以得到保护。</p><p>为了进一步细化检测精度,我们还提出了一种新的算法,称为”促进-抑制聚合” ( Promotion-Suppression Aggregation，PSA ),该算法<strong>不仅考虑了proposals的置信度评分,还考虑了其邻居的空间一致性</strong>.</p><p>我们的实验强调了跨不同代理进行模型校准的必要性,结果表明我们提出的方法在开放的OPV2V数据集上的3D目标检测性能优于最先进的基线方法.</p><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>深度学习的最新进展提高了现代感知系统在许多任务上的性能，如目标检测、语义分割和视觉导航。尽管取得了令人瞩目的进展，但由于单视角的限制，单智能体感知系统仍然存在许多局限性。例如，自动驾驶车辆( Autonomous Vehicles，AVs )通常会遭受遮挡，由于缺乏对遮挡区域的感官观察，这种情况很难处理。为了解决这一问题，<strong>最近的研究探索了无线通信技术，使附近的智能体能够共享感知信息并协同感知周围环境</strong>。</p><p>尽管现有方法获得了显著的3D目标检测性能提升，但它们假设所有协作智能体共享相同的模型，且具有相同的参数，这在实际中往往不成立，特别是在自动驾驶中。在AV之间分配模型参数可能会引起隐私和保密问题，特别是对于来自不同汽车公司的车辆。对同步良好的检测器的依赖是不可靠的，因为AV可能具有不同的更新频率</p><p>如果不妥善处理不一致性挑战，共享的感知信息可能存在较大的领域鸿沟，多智能体感知带来的优势将迅速减弱。</p><p>由于不同主体使用的模型不同，不同主体提供的置信度得分可能存在系统性偏差，即不同主体具有不同的置信度估计偏差。</p><p>一些代理置信度更高另一些较低,忽略这种偏见并通过非极大值抑制( NMS )直接融合来自相邻代理的边界框建议，可能会由于存在过度自信但低质量的建议而导致较差的检测精度。</p><p><img data-src="https://s2.loli.net/2024/05/29/CBp764zMDr8Ooil.png" alt="image-20240529212209574"></p><p>一些代理的信心分数系统性地大于其他代理人,例如,蓝色分数相对于橙色分数,然而,他们可能过度自信并提供误导性建议.根据置信度得分对建议进行融合,而不进行适当的校准可能会删除正确的建议.置信度得分稍低(橙色)但与邻近框具有较高空间一致性的提议可以优于置信度得分较高的单个提议.</p><p>在我们的框架中,我们集成了一个灵活而简单的不确定性校准器,称为双边界校准( Doubly Bounded Scaling，DBS ),以减轻失调。</p><p>此外,在bbox aggregation阶段，我们还提出了一个新的模块- -促进-抑制聚合( Promotion-Suppression Aggregation，PSA ),以替代经典的NMS,并利用box proposals在Agent之间的空间相关性和一致性,进一步细化最终结果.</p><p>我们在一个开源的大规模多智能体感知数据集OPV2V [ 12 ]上评估了我们的方法。实验表明，当涉及到智能体之间的模型差异时，我们的框架显著提高了基于多智能体LiDAR的三维目标检测性能，在平均精度( Average Precision，AP )方面比现有方法至少提高了6 %。</p><h4 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h4><p>在本文中，我们考虑了异构多智能体系统中的协作感知，其中智能体通信以共享来自不同感知模型的感知信息，而不泄露模型信息，即模型不可知协作。</p><p>我们专注于自动驾驶中的3D LiDAR检测任务，但该方法也可以定制并用于其他协同感知应用中。我们的目标是开发一个健壮的框架来处理代理之间的异质性，同时保持机密性。</p><p>因此，我们提出了一个模型不可知的集体感知框架，可以分为两个阶段。<strong>在离线阶段，我们训练了一个模型特定的校准器。在在线阶段，对实时的道路传感信息进行校准和汇总。</strong></p><p><img data-src="https://s2.loli.net/2024/05/29/mRenpvsdrHfqyih.png" alt="image-20240529215358768"></p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>在合作感知情境下，来自不同的代理人具有异质性模式。由于机密性的考虑，与模型和参数相关的信息不应该被透露给其他代理。</p><p>由于机密性的考虑，与模型和参数相关的信息不应该被透露给其他代理。在这项工作中，我们<strong>提出了一个模型无关的协作框架,解决了纯晚期融合策略的两个关键挑战.</strong>首先，我们提出了一个Doubly Bounded Scaling不确定性校准器来对齐不同智能体的置信度得分分布。其次，新的提升抑制聚合算法通过充分利用共享信息(bounding box spatial congruence and confidence score propagation.)，进一步提高了检测精度。</p><p>在大规模协作感知数据集上的实验表明了跨异构代理进行模型校准的必要性。结果表明，当不同的智能体使用不同的感知模型时，结合所提出的两种技术可以提高协作3D目标检测的</p><h2 id="Sim2Real"><a href="#Sim2Real" class="headerlink" title="Sim2Real"></a>Sim2Real</h2><h3 id="S2R-ViT-for-Multi-Agent-Cooperative-Perception-Bridging-the-Gap-from-Simulation-to-Reality-ICRA"><a href="#S2R-ViT-for-Multi-Agent-Cooperative-Perception-Bridging-the-Gap-from-Simulation-to-Reality-ICRA" class="headerlink" title="S2R-ViT for Multi-Agent Cooperative Perception: Bridging the Gap from Simulation to Reality ICRA"></a>S2R-ViT for Multi-Agent Cooperative Perception: Bridging the Gap from Simulation to Reality ICRA</h3><h4 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h4><p>由于缺乏足够的真实多智能体数据且标注耗时，现有的多智能体协同感知算法通常选取模拟的传感器数据进行训练和验证。<strong>然而，当这些经过仿真训练的模型被部署到真实世界时，由于仿真数据和真实数据之间存在显著的领域差距，感知性能会下降</strong>。</p><p>在本文中，我们提出了第一个使用新型视觉转换器的多智能体协作感知的仿真到现实迁移学习框架，命名为S2R - ViT，它同时考虑了模拟数据和真实数据之间的部署差距和特征差距。</p><p>我们研究了这两种类型的域间隙的影响，并提出了一种新的不确定感知视觉转换器来有效地缓解部署间隙，并提出了一种基于代理的特征自适应模块，通过代理间和代理间的鉴别器来减小特征间隙。</p><p>在公开的多智能体协同感知数据集OPV2V和V2V4Real上的大量实验表明，本文提出的S2R - ViT方法能够有效地弥补仿真与现实之间的差距，在基于点云的三维目标检测中显著优于其他方法。</p><h4 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h4><p>多智能体协作感知的最新进展显示出克服单智能体感知受感知范围和遮挡挑战的局限性的潜力.多智能体协作感知系统通过利用智能体之间的通信技术共享信息，相比于单智能体感知，能够显著提升感知性能</p><p>由于在真实世界中收集具有通信的多智能体数据的困难，<strong>在多样化和复杂的真实世界环境中收集足够多的真实数据是昂贵且不容易的。此外，多智能体协同感知系统的地面真值数据标注和统一坐标投影尤为耗时。</strong>因此，现有的许多多智能体协同感知研究工作通常选取模拟数据进行模型训练和验证</p><p>然而，<strong>当我们将用模拟数据训练的模型应用于真实世界时，感知性能通常会下降。这种现象是由于模拟数据和真实数据之间存在显著的域差距</strong>。</p><p>在本文中，我们的研究重点是<strong>利用有标记的模拟数据和无标记的真实世界数据作为迁移学习，以减少多智能体协作感知的领域差距</strong>。</p><p><img data-src="https://s2.loli.net/2024/05/17/DbfYtlhCnFSpTE7.png" alt="image-20240517203347621"></p><p>我们观察到，多智能体协作感知从模拟到现实的领域差距包括以下两个角度</p><p><strong>部署差距</strong>( Deployment Gap ):与理想的仿真环境不同,<strong>在现实世界的智能体通信过程中，由于不可避免的GPS误差和通信延迟(时间延迟),多个智能体可能存在定位(位置和航向)错误</strong></p><p><strong>特征差距</strong>( Feature Gap ):<strong>现实世界的点云特征分布可能与仿真数据有显著差异,例如更复杂的驾驶场景、不同的激光雷达通道数、混合交通流、各种点云变化等。</strong></p><p>在本文中，我们提出了第一个使用新型视觉转换器( ViT )的多智能体协作感知的仿真到现实( S2R )迁移学习框架，命名为S2R - ViT，同时考虑了部署间隙和特征间隙。我们选择车辆到车辆( Vehicle-to-Vehicle，V2V )协同感知任务作为基于点云的三维目标检测的算法开发。具体来说，我们的框架将来自模拟的有标记点云数据和来自真实世界的无标记数据作为输入，从而大量地利用模拟数据。在机器学习研究中，这种设置被广泛称为从源域(模拟)到目标域(现实)的无监督域适应。</p><p>S2R - ViT包括两个关键部分：( 1 ) <strong>S2R-UViT：一种新型的S2R不确定感知视觉转换器，可以有效地缓解develomment gap带来的不确定性</strong>。具体来说，S2R - UViT包括一个<strong>局部和全局的多头自注意力( LG-MSA )模块</strong>，以<strong>增强所有智能体空间位置上的特征交互，以容忍不确定性的缺陷</strong>；<strong>还包括一个不确定性感知模块( UAM )，通过考虑不同不确定性水平的共享其他智能体特征来增强自我智能体的特征</strong>.(2)S2R-AFA：基于<strong>S2R Agent的特征自适应以缩小特征差距</strong>。<strong>S2RAFA利用智能体间和自我代理的判别器提取领域不变特征</strong>,以弥合feature gap。</p><blockquote><p>Uncertainty-aware vision Transformer,可有效缓解development gap带来的不确定性.</p><p>通过一个S2R agent-based feature adaptation利用代理间和自我代理判别器提取domain-invariant features. 注意这里domain-invariant features已经被之前的2024的DI-V2X文章提到了,但这里更偏重虚拟到显示,而DI-V2X偏重代理的不同.</p></blockquote><h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><p>Multi-Agent Perception.多智能体感知系统通过智能体之间的通信技术,能够克服遮挡和短距离感知的挑战,实现大范围感知,引起了众多研究者的关注.与交换原始传感数据或检测输出相比,当代方法通常共享由神经网络提取的中间特征.该策略在精度和带宽需求之间提供了一个最佳的平衡.</p><p>Challenges in Multi-Agent Perception:多Agent感知系统也引入了一些新的挑战，如定位误差、通信延迟、对抗攻击等。这些挑战可能会减少合作的好处.</p><p>Domain Adaptation for Perception:领域自适应是指将源领域训练的机器学习模型自适应到目标领域。许多领域自适应工作主要集中在RGB相机数据，而在LiDAR数据中提出了更多的领域自适应工作来解决这一问题.</p><p><img data-src="https://s2.loli.net/2024/05/20/TyuX2Zsjb19mcvL.png" alt="image-20240520100453017"></p><p>与交换原始传感数据或检测输出相比,当代方法通常共享由神经网络提取的中间特征.</p><p>这种策略在精度和带宽需求之间提供了一个最佳的平衡.</p><h4 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h4><p><img data-src="https://s2.loli.net/2024/05/28/KQvBeL8JiAk1tRE.png" alt="image-20240528161118892"></p><p>S2R-ViT。从其他周围CAV聚合的中间特征被输入到我们的主要组件S2R - ViT中，该组件由S2R - UViT和S2R - AFA模块组成。在接收到最终的融合特征后，我们利用预测头进行3D物体分类和定位</p><p>从仿真到现实的部署差距给自我和邻居智能体带来了不同的不确定性，例如GPS误差导致的空间偏差，通信延迟导致的坐标投影中的空间错位</p><p>在本文中提出从两个角度来回答这个问题：不确定性可以通过增强( 1 )所有智能体空间位置上的特征交互来更全面地缓解；( 2 )通过考虑不同不确定性水平的共享其他智能体特征来缓解自我-智能体特征。</p><p>这两个视角促使我们分别开发了新颖的局部-全局多头自注意力( LG-MSA )模块和不确定性感知模块( UAM )。</p><p>局部和全局多磁头自注意力机制( Local-and-Global多头Self Attention，LGMSA )：为了更全面地增强所有智能体空间位置上的特征交互，我们提出了LG - MSA来促进所有智能体空间位置上的局部和全局特征交互。在提出的LGMSA中，基于局部特征的注意力用于关注空间特征的局部细节，而基于全局特征的注意力用于关注空间特征的广泛范围。就是一个融合模块,使用不同窗口大小的类似swin-transformer模型.</p><p>以h = 8为头数，n = 2为窗口类型数，将标准多头自注意力模块( MSA ) [ 24 ]的多头h均匀划分为2组不同窗口大小，即局部分支为4 × 4，全局分支为8 × 8。在局部分支中，将分割后的特征F^l^~e,o~∈R^h/n×H×W×kC/h^以4 × 4的小窗口尺寸输入MSAL，以增强空间特征的局部细节。在全局分支中，另一个分裂特征F^g^~e,o~∈R^h/n×H×W×kC/h^以8 × 8的大窗口尺寸输入MSAG以捕获全局空间特征信息</p><script type="math/tex; mode=display">F_{e,o}^p=\mathrm{SA}(\mathrm{Concat}(\mathrm{MSA}_L(F_{e,o}^l),\mathrm{MSA}_G(F_{e,o}^g)))</script><p><strong>Uncertainty-Aware Module (UAM).</strong></p><p>不确定性图,说白了得到一个跟特征图大小一样的map对除了ego代理的特征进行选择,这种设计在其他很多方法中都涉及.</p><p>以中位数为阈值，将具有高不确定度等级(即,低置信度)的预测不确定度等级图M中的特征值重置为1.</p><p>UPN是由简化而来的基于编码器-解码器的神经网络,可以在我们整个架构的端到端训练过程中学习.</p><p>受进化机制中自然选择的启发,以中位数为阈值,将具有高不确定性水平(即,低置信度)的预测不确定性水平图M中的特征值重置为1.它产生了一个新的不确定性等级图M~t~ .</p><p>基于共享的他者-施动者特征来增强自我-施动者特征,不应忽视其不同的不确定性水平.</p><script type="math/tex; mode=display">F_{e,o}^h=\mathrm{Concat}(\Delta[\mathrm{UPN}(F_o^p)]\otimes F_e^p,F_o^p)</script><p>Δ [ · ]表示阈值过程,⊛表示矩阵点积。</p><script type="math/tex; mode=display">F_{e,o}^h=\mathrm{S2RAttn}(\mathrm{LN}(F_{e,o}))+F_{e,o},\\\hat{F_{e,o}^h}=\mathrm{MLP}(\mathrm{LN}(F_{e,o}^h))+F_{e,o}^h,</script><p><strong>S2R-AFA: simultaion-to-Reality Agent-based Feature Adaptation.</strong></p><p>为了缩小仿真特征Fs与真实特征Fr之间的特征差距,在融合前和融合后分别设计了两个领域判别器/分类器,使用BCE损失用于二分类.</p><script type="math/tex; mode=display">\min_{G_m}\max_{D_i,D_e}\mathcal{L}_{AFA}=\mathbb{E}_{s,r}[D_i(F_s,F_r)]+\mathbb{E}_{s,r}[D_e(F_s^e,F_r^e)]</script><p>E~s,r~分别表示仿真和现实中的领域分类误差，G~m~是我们的整体模型(主干网、S2R - UViT和检测头)，可以认为是生成对抗网络的生成器.</p><p>由于S2R - AFA,我们的生成模型G~m~将具有提取模拟和现实的域不变特征的能力. 损失包含目标检测损失和Agent-based Feature Adaptation损失.</p><script type="math/tex; mode=display">\mathcal{L}_{total}=w_1\mathcal{L}_{det}+w_2\mathcal{L}_{AFA}</script><h3 id="DUSA-Decoupled-Unsupervised-Sim2Real-Adaptation-for-Vehicle-to-Everything-Collaborative-Perception-MM"><a href="#DUSA-Decoupled-Unsupervised-Sim2Real-Adaptation-for-Vehicle-to-Everything-Collaborative-Perception-MM" class="headerlink" title="DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception MM"></a>DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception MM</h3><h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>车联网( Vehicle-to-Ething，V2X )协同感知对于自动驾驶的推进至关重要。然而，实现高精度的V2X感知<strong>需要大量有标注的真实世界数据，而这些数据往往是昂贵和难以获得的</strong>。</p><p>由于<strong>模拟数据可以以极低的成本大规模生产，因此受到了广泛的关注。然而，模拟数据和真实世界数据之间显著的域差距，包括传感器类型、反射模式和道路环境的差异，往往导致在模拟数据上训练的模型在真实世界数据上评估时性能较差</strong>。</p><p>此外，现实世界中的协作智能体之间仍然存在域间鸿沟，例如<strong>不同类型的传感器可能安装在具有不同外在特征的自动驾驶车辆和路边基础设施上</strong>，进一步增加了sim2现实泛化的难度。</p><p>为了充分利用模拟数据，提出了一种新的用于V2X协作检测的无监督Sim2真实域自适应方法，称为解耦无监督Sim2real域自适应( Decoupled Unsupervised Sim2Real Adaptation，DUSA )。</p><p>我们的新方法将V2X协作sim2真实域自适应问题解耦为<strong>sim2real域自适应和智能体间自适应</strong>两个子问题。对于sim2real自适应，我们设计了一个位置自适应的Sim2Real Adapter ( LSA )模块，从特征图的关键位置自适应地聚合特征，并在聚合的全局特征上通过sim / real判别器对模拟数据和真实数据之间的特征进行对齐。对于智能体间自适应，我们进一步设计了一个置信度感知的智能体间适配器( Confidence-aware Inter-agent Adapter，CIA )模块，在智能体间置信图的指导下，对来自异构智能体的细粒度特征进行对齐。</p><p>实验证明了本文提出的DUSA方法在从模拟的V2XSet数据集到真实的DAIR -V2X-C数据集的无监督sim2real自适应上的有效性。</p><h4 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h4><p><strong>Collaborative 3D Object Detection</strong></p><p>利用协作感知来支持单车的自动驾驶已经成为一个越来越受关注的研究课题。方法<a href="https://ieeexplore.ieee.org/document/9228884">Cooperative Perception for 3D Object Detection in Driving Scenarios Using Infrastructure Sensors </a>首先介绍了车辆和基础设施之间的协同感知系统中的早期和晚期融合方案。</p><p>WIBAM模型提出了一种使用弱监督来微调交通观测相机模型的技术</p><p>Cooper利用来自多个车辆的原始点云，开发了SPOD网络。F-Cooper 在Cooper的基础上实现了特征级融合，在保证精度的同时减少了通信数据量。</p><p>V2VNet 引入了中间融合方法，该方法使用一种感知空间关系的图神经网络来合并来自多个车辆的数据。DiscoNet 使用知识蒸馏来训练一个椎间盘造影术，这有助于在多智能体感知中实现性能和带宽使用之间的最佳平衡。V2X-ViT 提出了一种视觉transformer框架来实现车辆和基础设施之间的特征融合。SyncNet解决了时域同步问题。where2comm 提出使用空间置信图来减少所需的通信带宽量。这是通过限制不必要数据的传输来实现的。CoBEVT 利用融合的轴向注意力来协同生成多个智能体和相机之间的鸟瞰图( BEV )预测。AdaFusion 提出了3种自适应模型用于鸟瞰图( BEV )中的特征融合，以提高感知精度。<strong>MPDA识别了在不同代理之间出现的域间隙问题</strong>，并通过使用完整的特征图来标准化模式来解决。</p><p><strong>Unsupervised Domain Adaptation</strong></p><p>无监督领域自适应( UDA )旨在利用有标签的源数据和无标签的目标数据，生成一个能够有效泛化到目标领域的鲁棒模型。许多工作<strong>利用对抗学习</strong>，通过<strong>最小化两个域之间的H -散度</strong>或<strong>Jensen - Shannon散度</strong>来对齐不同域之间的特征分布。另一类方法针对<strong>未标记的目标域开发多种伪标签，实现自训练</strong></p><p>在三维目标检测的领域自适应方面，PointDAN 是第一个使用对抗学习来匹配具有非自动驾驶场景的领域之间点云分布的方法。</p><p>SN利用来自目标域的对象统计信息对源域中的对象大小进行归一化处理，以减少大小层次上的域间隙。</p><p>SRDAN提出了尺度感知和范围感知的域对齐策略，利用三维数据的几何特征来指导两个域之间的分布对齐。MLC-Net 采用师生范式，利用多层一致性来促进跨域迁移。ST3D 提出了一种基于随机对象缩放策略的伪标签生成和训练过程的综合流水线。此外，ST3D + +进一步提出了3D UDA背景下去噪伪标注的优化策略。</p><p>在这项工作中，我们解决了<strong>面向V2X协作3D检测的无监督sim2real域适应问题</strong>。在这个问题中，我们有一组带有标签的模拟样本作为源域，一组未标记的真实世界样本作为目标域。每个样本包含多个协同智能体，每个智能体包含一个LiDAR点云及其在世界坐标下的位姿。协作代理可以在传感器类型和位置等方面具有异构性。<strong>我们期望该模型能够充分地利用已标注的模拟样本来提高其在未标注的真实世界样本上的性能</strong>。</p><p><img data-src="https://s2.loli.net/2024/06/18/xmAuqhW7XdG3iwN.png" alt="image-20240618210513642"></p><p>在自适应之前，一个统一的位置编码被连接到每个代理的特征上。我们将具有位置编码的特征记为” F ( Xi ; θ) “。统一位置编码是一个2D坐标，表示与自我主体的相对距离。这样，与自我代理距离相近的位置将被分配到相同的坐标。</p><p>LSA模块和CIA模块在训练过程中对齐来自不同域和代理的特征。<strong>LSA模块引入了自我Agent的特征，并区分Agent是来自仿真还是真实世界</strong>。<strong>CIA模块接收每个真实世界Agent的特征和置信图，并判别Agent的类型</strong>。两个模块鼓励特征提取器通过对抗训练产生sim / real - invariant和agent - invariant特征，其中两个模块和特征提取器的训练目标是相反的。</p><p>与简单区分所有协作Agent是模拟的还是真实的相比，DUSA将区分问题解耦为两个更具体、更少纠缠的子任务，即sim / real区分和Agent类型区分。解耦后的任务可以让判别器发现更详细的域间隙，并通过对抗训练增加特征提取器的域不变性。</p><h4 id="Location-adaptive-Sim2Real-Adapter"><a href="#Location-adaptive-Sim2Real-Adapter" class="headerlink" title="Location-adaptive Sim2Real Adapter"></a>Location-adaptive Sim2Real Adapter</h4><p>位置自适应的Sim2Real Adapter ( LSA )模块旨在弥合模拟数据和真实世界数据之间的域鸿沟。为了将智能体之间的域间隙从sim / real域间隙中完全排除，LSA模块只对具有相对相似传感器的智能体进行特征区分。从这两个领域中选择自我主体的特征” F (ego Pego ) ; θ) “来进行区分，因为他们通常在顶部安装有机械式激光雷达，无论他们来自模拟还是真实数据.</p><p><img data-src="https://s2.loli.net/2024/06/18/G5PyrlN9R7qs8An.png" alt="image-20240618211624223"></p><p>单个主体的显著位置分布有其内在规律。例如，靠近智能体的网格通常比远离智能体的网格拥有更多的领域线索，因为它们通常在附近的车辆上拥有更多的LiDAR点。此外，车辆前方的网格通常比车辆后方的网格更加显著。因此，我们设计了一个位置自适应的特征选择器模块，根据分布自适应地选择重要的特征。具体来说，我们<strong>使用一个可学习的特征选择图M~loc~来捕获分布的内部模式，并相应地从自我代理的特征图中选择具有重要意义的特征</strong></p><script type="math/tex; mode=display">\tilde{F}^{weighted}(P_{ego};\theta)=\tilde{F}(P_{ego};\theta)\odot M_{loc}</script><p>然后使用全局平均池化操作来获得一个全局特征</p><script type="math/tex; mode=display">S(\tilde{F}(P_{ego};\theta))=\frac{1}{HW}\sum_{u,v}\tilde{F}^{weighted}(P_{ego};\theta)^{(u,v)}</script><p>我们对聚合后的全局特征S ( “ F “ ( P~ego~ ; θ) )进行sim / real判别。sim / real鉴别器包含若干个全连接层,具有ReLU激活和Dropout.我们将其记为D^sim^( · ; wsim)，其中w^sim^是sim / real判别器的参数.</p><script type="math/tex; mode=display">\max_{\theta}\min_{w^{sim}}\mathcal{L}_{sim}=\frac{1}{N}\sum_{i=1}^{N}\mathcal{L}_{BCE}(D^{sim}(S(\tilde{F}(P_{ego};\theta));w^{sim}),d_{i})</script><blockquote><p>为了联合优化方程中的最大最小化优化问题，在LSA模块的输入之前插入一个梯度反转层( GRL ).</p><p>通过这样做，可以在单步内完成优化</p></blockquote><h4 id="Confidence-aware-Inter-agent-Adapter"><a href="#Confidence-aware-Inter-agent-Adapter" class="headerlink" title="Confidence-aware Inter-agent Adapter"></a>Confidence-aware Inter-agent Adapter</h4><p><img data-src="https://s2.loli.net/2024/06/18/tl34MIGVQLrNZOJ.png" alt="image-20240618212733684"></p><p>置信度感知的智能体适配器( CIA )模块旨在最小化现实世界中<strong>异构智能体之间的领域差距</strong>。它专注于识别真实世界智能体的细粒度特征图” F ( Xt i ; θ) “，排除了仿真和真实世界之间的领域差距。</p><p>我们对来自目标域(真实世界)的智能体细粒度特征图” F ( Xt i ; θ) “进行智能体间判别。智能体间判别器包括若干个具有ReLU激活的1 × 1卷积层。我们将其记为D^agent^ ( · ; w^agent^)，其中w agent是agent间判别器的参数.</p><p>在智能体细粒度特征图中，存在一些几乎没有网格的网格，这些网格中的点非常少。因此，这些网格包含很少的关于传感器的线索，并且不适合进行智能体之间的区分。在这些网格上监督智能体之间的鉴别器可能会在梯度中包含噪声，并增加优化过程的不稳定性。为了解决这个问题，我们<strong>提出利用智能体间的置信图来reweight智能体间的区分度损失</strong>。</p><script type="math/tex; mode=display">M_{conf}^{(u,v)}=\min_jP^{conf}(F(X_i^t;\theta)_j;\beta)^{(u,v)}</script><p>然后使用重称map M~conf~重新平衡每个网格的损失。</p><p>L~CE~为交叉熵损失，j表示agent个数。在CIA模块的输入之前还插入了一个梯度反转层( GRL ) </p><script type="math/tex; mode=display">\begin{aligned}\max_{\theta}\min_{w^{agent}}\mathcal{L}_{agent}=& \frac1{N_t\cdot n_a}\sum_{i=1}^{N_t}\sum_{j=1}^{n_a}\sum_{u,v}M_{conf}^{(u,v)}.  \\&\mathcal{L}_{CE}(D^{agent}(\tilde{F}(X_{i}^{t};\theta)_{j};w^{agent})^{(u,v)},j)\end{aligned}</script><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;随着大模型时代的到来,原先通过修改模型结构提升性能写论文的方式已经有点out of date了,同时写文章的倾向已经从改架构成SOTA慢慢转变为回归任务背景以及讲好一个完整故事并给出自己的findings和insight了.也因此,在协作感知方面,论文方向也逐渐在转变,这里看看最近的文章整理一下思路.&lt;/p&gt;</summary>
    
    
    
    
    <category term="collaborative perception" scheme="https://www.sekyoro.top/tags/collaborative-perception/"/>
    
  </entry>
  
  <entry>
    <title>computer graphics:计算机图形学学习</title>
    <link href="https://www.sekyoro.top/2024/05/07/computer-graphics-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/05/07/computer-graphics-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-05-07T10:46:32.000Z</published>
    <updated>2024-06-25T02:49:39.344Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>简简单单学个概念.<br><span id="more"></span></p><p>早期的OpenGL使用立即渲染模式（Immediate mode，也就是固定渲染管线），这个模式下绘制图形很方便。OpenGL的大多数功能都被库隐藏起来，开发者很少有控制OpenGL如何进行计算的自由。而开发者迫切希望能有更多的灵活性。随着时间推移，规范越来越灵活，开发者对绘图细节有了更多的掌控。立即渲染模式确实容易使用和理解，但是效率太低。<strong>因此从OpenGL3.2开始，规范文档开始废弃立即渲染模式，并鼓励开发者在OpenGL的核心模式(Core-profile)下进行开发</strong>，这个分支的规范完全移除了旧的特性。</p><p>当使用OpenGL的核心模式时，OpenGL迫使我们使用现代的函数。当我们试图使用一个已废弃的函数时，OpenGL会抛出一个错误并终止绘图。现代函数的优势是更高的灵活性和效率，然而也更难于学习。立即渲染模式从OpenGL<strong>实际</strong>运作中抽象掉了很多细节，因此它在易于学习的同时，也很难让人去把握OpenGL具体是如何运作的。现代函数要求使用者真正理解OpenGL和图形编程，它有一些难度，然而提供了更多的灵活性，更高的效率，更重要的是可以更深入的理解图形编程</p><p>使用GLAD和GLFW作为版本和窗口管理库.</p><ul><li><p>glfwWindowShouldClose函数在我们每次循环的开始前检查一次GLFW是否被要求退出，如果是的话，该函数返回<code>true</code>，渲染循环将停止运行，之后我们就可以关闭应用程序。</p></li><li><p>glfwPollEvents函数检查有没有触发什么事件（比如键盘输入、鼠标移动等）、更新窗口状态，并调用对应的回调函数（可以通过回调方法手动设置）。</p></li><li><p>glfwSwapBuffers函数会交换颜色缓冲（它是一个储存着GLFW窗口每一个像素颜色值的大缓冲），它在这一迭代中被用来绘制，并且将会作为输出显示在屏幕上。</p></li></ul><p>在OpenGL中，任何事物都在3D空间中，而屏幕和窗口却是2D像素数组，这导致OpenGL的大部分工作都是关于把3D坐标转变为适应你屏幕的2D像素。3D坐标转为2D坐标的处理过程是由OpenGL的图形渲染管线（Graphics Pipeline，大多译为管线，<strong>实际上指的是一堆原始图形数据途经一个输送管道，期间经过各种变化处理最终出现在屏幕的过程）管理的</strong>。图形渲染管线可以被划分为两个主要部分：<strong>第一部分把你的3D坐标转换为2D坐标</strong>，<strong>第二部分是把2D坐标转变为实际的有颜色的像素</strong>。</p><p><strong>图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出</strong>。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个阶段的输出作为输入。所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且很容易并行执行。正是由于它们具有并行执行的特性，当今大多数显卡都有成千上万的小处理核心，<strong>它们在GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据。这些小程序叫做着色器(Shader)</strong>。</p><p>有些着色器可以由开发者配置，因为允许用自己写的着色器来代替默认的，所以能够更细致地控制图形渲染管线中的特定部分了。因为它们运行在GPU上，所以节省了宝贵的CPU时间。<strong>OpenGL着色器是用OpenGL着色器语言(OpenGL Shading Language, GLSL)写成的</strong></p><p><img data-src="https://learnopengl-cn.github.io/img/01/04/pipeline.png" alt="img" style="zoom: 67%;" /></p><p><strong>图形渲染管线包含很多部分，每个部分都将在转换顶点数据到最终像素这一过程中处理各自特定的阶段</strong></p><p>图形渲染管线的第一个部分是<strong>顶点着色器</strong>(Vertex Shader)，它把一个单独的顶点作为输入。顶点着色器主要的目的是把3D坐标转为另一种3D坐标，同时顶点着色器允许我们对顶点属性进行一些基本处理</p><p>顶点着色器阶段的输出可以选择性地传递给<strong>几何着色器</strong>(Geometry Shader)。几何着色器将一组顶点作为输入，<strong>这些顶点形成图元，并且能够通过发出新的顶点来形成新的(或其他)图元来生成其他形状</strong>。在这个例子中，它从给定的形状中生成第二个三角形。</p><blockquote><p>为了让OpenGL知道我们的坐标和颜色值构成的到底是什么，OpenGL需要你去指定这些数据所表示的渲染类型。我们是希望把这些数据渲染成一系列的点？一系列的三角形？还是仅仅是一个长长的线？<strong>做出的这些提示叫做图元(Primitive)，任何一个绘制指令的调用都将把图元传递给OpenGL。这是其中的几个：GL_POINTS、GL_TRIANGLES、GL_LINE_STRIP</strong>。</p></blockquote><p><strong>图元装配</strong>(Primitive Assembly)阶段将顶点着色器（或几何着色器）输出的所有顶点作为输入（如果是GL_POINTS，那么就是一个顶点），并将所有的点装配成指定图元的形状</p><p>图元装配阶段的输出会被传入光栅化阶段(Rasterization Stage)，这里它会把图元映射为最终屏幕上相应的像素，生成供片段着色器(Fragment Shader)使用的片段(Fragment)。在片段着色器运行之前会执行裁切(Clipping)。裁切会丢弃超出你的视图以外的所有像素，用来提升执行效率。</p><p>片段着色器的主要目的是计算一个像素的最终颜色，这也是所有OpenGL高级效果产生的地方。通常，片段着色器包含3D场景的数据（比如光照、阴影、光的颜色等等），这些数据可以被用来计算最终像素的颜色</p><p>在所有对应颜色值确定以后，最终的对象将会被传到最后一个阶段，我们叫做Alpha测试和混合(Blending)阶段。这个阶段检测片段的对应的深度（和模板(Stencil)）值（后面会讲），用它们来判断这个像素是其它物体的前面还是后面，决定是否应该丢弃。这个阶段也会检查alpha值（alpha值定义了一个物体的透明度）并对物体进行混合(Blend)。所以，即使在片段着色器中计算出来了一个像素输出的颜色，在渲染多个三角形的时候最后的像素颜色也可能完全不同</p><p><strong>然而，对于大多数场合，我们只需要配置顶点和片段着色器就行了。几何着色器是可选的，通常使用它默认的着色器就行了。</strong></p><p>在现代OpenGL中，我们<strong>必须</strong>定义至少一个顶点着色器和一个片段着色器（因为GPU中没有默认的顶点/片段着色器）。出于这个原因，刚开始学习现代OpenGL的时候可能会非常困难，因为在你能够渲染自己的第一个三角形之前已经需要了解一大堆知识了。在本节结束你最终渲染出你的三角形的时候，你也会了解到非常多的图形编程知识。</p><p>OpenGL是一个3D图形库，所以在OpenGL中我们指定的所有坐标都是3D坐标（x、y和z）。OpenGL不是简单地把<strong>所有的</strong>3D坐标变换为屏幕上的2D像素；<strong>OpenGL仅当3D坐标在3个轴（x、y和z）上-1.0到1.0的范围内时才处理它</strong>。所有在这个范围内的坐标叫做标准化设备坐标(Normalized Device Coordinates)，此范围内的坐标最终显示在屏幕上（在这个范围以外的坐标则不会显示）。</p><p>通常深度可以理解为z坐标，它代表一个像素在空间中和你的距离，如果离你远就可能被别的像素遮挡，你就看不到它了，它会被丢弃，以节省资源。</p><p>通过使用由glViewport函数提供的数据，进行视口变换(Viewport Transform)，标准化设备坐标(Normalized Device Coordinates)会变换为屏幕空间坐标(Screen-space Coordinates)。所得的屏幕空间坐标又会被变换为片段输入到片段着色器中。 定义这样的顶点数据以后，我们会把它作为输入发送给图形渲染管线的第一个处理阶段：顶点着色器。它会在GPU上创建内存用于储存我们的顶点数据，还要配置OpenGL如何解释这些内存，并且指定其如何发送给显卡。顶点着色器接着会处理我们在内存中指定数量的顶点。</p><p>我们通过顶点缓冲对象(Vertex Buffer Objects, VBO)管理这个内存，它会在GPU内存（通常被称为显存）中储存大量顶点。使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次。从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据。当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> VBO;</span><br><span class="line"><span class="built_in">glGenBuffers</span>(<span class="number">1</span>, &amp;VBO);</span><br><span class="line"><span class="built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, VBO); </span><br><span class="line"><span class="built_in">glBufferData</span>(GL_ARRAY_BUFFER, <span class="built_in"><span class="keyword">sizeof</span></span>(vertices), vertices, GL_STATIC_DRAW);</span><br></pre></td></tr></table></figure><p>现在我们已经把顶点数据储存在显卡的内存中，用VBO这个顶点缓冲对象管理。下面我们会创建一个顶点着色器和片段着色器来真正处理这些数据。。</p><p>顶点着色器(Vertex Shader)是几个可编程着色器中的一个。如果我们打算做渲染的话，现代OpenGL需要我们至少设置一个<strong>顶点和一个片段着色器</strong>。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#version 330 core</span></span><br><span class="line"><span class="keyword">layout</span> (<span class="keyword">location</span> = <span class="number">0</span>) <span class="keyword">in</span> <span class="type">vec3</span> aPos;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> main()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">gl_Position</span> = <span class="type">vec4</span>(aPos.x, aPos.y, aPos.z, <span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>in</code>关键字，在顶点着色器中声明所有的输入顶点属性(Input Vertex Attribute)。现在我们只关心位置(Position)数据，所以我们只需要一个顶点属性。GLSL有一个向量数据类型，它包含1到4个<code>float</code>分量，包含的数量可以从它的后缀数字看出来</p><p>每个顶点都有一个3D坐标，我们就创建一个<code>vec3</code>输入变量aPos。我们同样也通过<code>layout (location = 0)</code>设定了输入变量的位置值(Location)你后面会看到为什么我们会需要这个位置值.</p><p>写好glsl后,首先创建一个着色器对象，注意还是用ID来引用的。所以我们储存这个顶点着色器为<code>unsigned int</code>，然后用glCreateShader创建这个着色器</p><h3 id="GAMES101"><a href="#GAMES101" class="headerlink" title="GAMES101"></a>GAMES101</h3><h4 id="转换"><a href="#转换" class="headerlink" title="转换"></a>转换</h4><p>使用homegeneous coordinates,因为<strong>Translation cannot be represented in matrix form</strong></p><p><img data-src="https://s2.loli.net/2024/05/12/36b2pEjwCWGf7N8.png" alt="image-20240512215001385"></p><p><img data-src="https://s2.loli.net/2024/05/12/rA39m7M5WTFwQRD.png" alt="image-20240512223828687"></p><p><img data-src="https://s2.loli.net/2024/05/12/OxDF2GB7sUk8iRt.png" alt="image-20240512225758095"></p><p><img data-src="https://s2.loli.net/2024/05/12/yNZU6TEMkJw8vS5.png" alt="image-20240512231120803"></p><p><img data-src="https://s2.loli.net/2024/05/12/LjWzDSbx2McfVpa.png" alt="image-20240512231103788"></p><h4 id="assignment"><a href="#assignment" class="headerlink" title="assignment"></a>assignment</h4><h5 id="HW0"><a href="#HW0" class="headerlink" title="HW0"></a>HW0</h5><p>学习Eigen库,二维和三维的空间变换,都可以拆成旋转,放缩和平移,但是平移无法使用与坐标维数相同的转换矩阵,可以通过homogeneous coordinates.</p><h5 id="HW1"><a href="#HW1" class="headerlink" title="HW1"></a>HW1</h5><p>观测转换,视图和投影转换. 投影转换又可以分为正交和透视投影.</p><p>view transformation就是相机的摆放,包括位置,朝向和向上的方向.</p><p><img data-src="https://s2.loli.net/2024/05/19/yApJSIKMls4CZzF.png" alt="image-20240519160531237"></p><p> 又叫做ModelView Transformation.</p><p>相当于将相机连着物体一起做变换,使得相机朝着-Z,位置在原点,向上方向在Y.</p><p><img data-src="https://s2.loli.net/2024/05/19/U5DBHQOvcAd2wqp.png" alt="image-20240519163320086"></p><p>一般做view transformation就是先平移后旋转.</p><p><img data-src="https://s2.loli.net/2024/05/19/9EodBgHcTr5J874.png" alt="image-20240519164238487"></p><p>然后做投影,也就是将3D变为2D,先做透视再做正交. 做透视因为符合视觉系统,做正交将物体归一化并放在中心.</p><p><img data-src="https://s2.loli.net/2024/05/19/niHmVGBdhUIR2qv.png" alt="image-20240519164611669"></p><p>做正交矩阵如下.</p><p><img data-src="https://s2.loli.net/2024/05/19/ucndILDTHwEMpmW.png" alt="image-20240519164927743"></p><p><img data-src="https://s2.loli.net/2024/05/19/t85cSLD7JZ6Vaep.png" alt="image-20240519164732598"></p><p>做投影如下,</p><p><img data-src="https://s2.loli.net/2024/05/19/Hl7XgyvkEi8Gen9.png" alt="image-20240519164510132"></p><p>重点是关于透视矩阵的推理,首先因为等比例的坐标缩放,</p><p><img data-src="https://s2.loli.net/2024/05/19/Rv2IMdrlYDpk9Tq.png" alt="image-20240519181537968"></p><script type="math/tex; mode=display">\begin{pmatrix}x\\y\\z\\1\end{pmatrix}\Rightarrow\begin{pmatrix}nx/z\\ny/z\\\text{unknown}\\1\end{pmatrix}\overset{\text{mult by z}}{\operatorname*{==}}\begin{pmatrix}nx\\ny\\\text{still unknown}\\z\end{pmatrix}</script><p>这样就知道透视投影矩阵的三行信息</p><script type="math/tex; mode=display">M_{persp\to ortho}^{(4\times4)}\begin{pmatrix}x\\y\\z\\1\end{pmatrix}=\begin{pmatrix}nx\\ny\\\text{unknown}\\z\end{pmatrix} \\M_{persp\to ortho}=\begin{pmatrix}n&0&0&0\\0&n&0&0\\?&?&?&?\\0&0&1&0\end{pmatrix}</script><p>此外,有两点:在near plane也就是投影到的平面上的坐标经过这个矩阵转换后依然不变,而far plane上的坐标经过透视投影后z坐标不变.</p><p>对于near plane(x,y,n,1),由于转换后坐标相同得到(nx,ny,n^2^,n).</p><script type="math/tex; mode=display">\begin{pmatrix}0&0&A&B\end{pmatrix}\begin{pmatrix}x\\y\\n\\1\end{pmatrix}=n^2</script><p>所以第三行的值必须是(0,0,A,B).即有An+B=n^2^.</p><p>假设far plane上的一个点坐标是(x,y,f,1),也有Af+B=f^2^.解得</p><script type="math/tex; mode=display">\begin{aligned}An+B&=n^2\\Af+B&=f^2\end{aligned}\quad\begin{array}{c}A=n+f\\B=-nf\end{array}</script><p>所以透视矩阵如下,其中n是near plane上的点的z坐标,f是随便一个点的z坐标.</p><script type="math/tex; mode=display">M_{persp\to ortho}=\begin{pmatrix}n&0&0&0\\0&n&0&0\\0&0&n+f&-nf\\0&0&1&0\end{pmatrix}</script><p>有了透视矩阵后,正交矩阵比较简单.在进行投影时先透视后正交就得到投影矩阵了. 如果有了near plane的四个点坐标就方便进行视口变换,或者通过fovY和aspect ratio,前者是一个角度,可以通过这个角度知道视点与near plane平面的距离,aspect ratio是平面宽度/高度.</p><p><img data-src="https://s2.loli.net/2024/05/19/N5qEdQ7yZGDzgKn.png" alt="image-20240519231541738"></p><p><img data-src="https://s2.loli.net/2024/05/19/V6DlLH2M4jmpgXZ.png" alt="image-20240519224805373"></p><script type="math/tex; mode=display">\tan\frac{fovY}2=\frac t{|n|}\\aspect=\frac rt</script><p><img data-src="https://s2.loli.net/2024/05/19/PLHMImvQDRfVTUW.png" alt="image-20240519224814121"></p><p>在图形学的MVP(model transformation,view transformation,project transformation)之后,得到了规范的2D投影.然后需要将规范的cube转到screen上(视口转换),screen就是一个pixel的数组,大小是分辨率.raster就是screen.</p><p>因为坐标已经归一到[-1,1],再转到[0,width]x[0,height],线性转换即可.z坐标不用管</p><p><img data-src="https://s2.loli.net/2024/05/19/vuFnfNzxKCAotEl.png" alt="image-20240519225110452"></p><p><img data-src="https://s2.loli.net/2024/05/19/rasPKwzLBvY7SUk.png" alt="image-20240519225120720"></p><p><img data-src="https://s2.loli.net/2024/05/24/f5SoqHvmld8UpDV.png" alt="image-20240524111542315"></p><p>提升题</p><p>绕任意过原点的轴的旋转变换矩阵。</p><p><img data-src="https://s2.loli.net/2024/05/24/LCIpUV8lKBtJRAD.png" alt="image-20240524171158093"></p><h5 id="HW2"><a href="#HW2" class="headerlink" title="HW2"></a>HW2</h5><p>上面的就画出了一个线框,但是为了画出完整三角形,线框里的值还需要光栅化.首先需要判定点是否在线框内,涉及到cross products和使用bounding box. 如果在内部,还需要判断内部点的深度.如果当前点更靠近相机,设置像素颜色并更新depth buffer.</p><p><img data-src="https://s2.loli.net/2024/05/24/zsNxrbOg79kwHAy.png" alt="image-20240524213309445"></p><p><img data-src="https://s2.loli.net/2024/05/24/8nHkRoxrWDL7QTK.png" alt="image-20240524213330256"></p><p>首先bounding box比较简单,直接获得x,y的最小值最大值即可 .</p><p>判定点是否在三角形内,在三角形内还需要使用重心插值得到z-buffering,这里越小表示越近,如果更小就设置颜色.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> x = <span class="built_in">floor</span>(lb_x); x &lt; <span class="built_in">ceil</span>(rt_x); x++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> y = <span class="built_in">floor</span>(lb_y); y &lt; <span class="built_in">ceil</span>(rt_y); y++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">insideTriangle</span>(x+<span class="number">0.5</span>, y+<span class="number">0.5</span>, t.v)) &#123;</span><br><span class="line">                <span class="keyword">auto</span>[alpha, beta, gamma] = <span class="built_in">computeBarycentric2D</span>(x, y, t.v);</span><br><span class="line">                <span class="keyword">float</span> w_reciprocal = <span class="number">1.0</span>/(alpha / v[<span class="number">0</span>].<span class="built_in">w</span>() + beta / v[<span class="number">1</span>].<span class="built_in">w</span>() + gamma / v[<span class="number">2</span>].<span class="built_in">w</span>());</span><br><span class="line">                <span class="keyword">float</span> z_interpolated = alpha * v[<span class="number">0</span>].<span class="built_in">z</span>() / v[<span class="number">0</span>].<span class="built_in">w</span>() + beta * v[<span class="number">1</span>].<span class="built_in">z</span>() / v[<span class="number">1</span>].<span class="built_in">w</span>() + gamma * v[<span class="number">2</span>].<span class="built_in">z</span>() / v[<span class="number">2</span>].<span class="built_in">w</span>();</span><br><span class="line">                z_interpolated *= w_reciprocal;</span><br><span class="line">                <span class="keyword">int</span> index = <span class="built_in">get_index</span>(x, y);</span><br><span class="line">                <span class="keyword">if</span> (z_interpolated &lt; depth_buf[index]) &#123;</span><br><span class="line">                    depth_buf[index] = z_interpolated;</span><br><span class="line">                    <span class="built_in">set_pixel</span>(<span class="built_in">Vector3f</span>(x, y, <span class="number">1.0f</span>), t.<span class="built_in">getColor</span>());</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/05/24/HT3ogl5RuJWtbLz.png" alt="image-20240524175457757"></p><p><img data-src="https://s2.loli.net/2024/05/24/xp6UaqQC7lscWmV.png" alt="image-20240524202223373" style="zoom:50%;" /></p><p>为了解决锯齿问题(antialiasing),可以先进行卷积,也可以进行supersamping,这里使用super-samping,对每个像素进行2x2采样.</p><p>方法是</p><ol><li>Take NxN samples in each pixel.</li><li>Average the NxN samples “inside” each pixel</li></ol><p>具体做的时候针对每个pixel,需要保存两个 sample list里面存着周围几个元素的颜色与depth. 然后算color的均值.</p><p>super-sampling时,会对一个像素结合多个强度(颜色),也就是均值.采样的值太大图像会变糊.</p><p><img data-src="https://s2.loli.net/2024/05/24/IXzWOyn49Y5JpVE.png" alt="image-20240524212850965"></p><h5 id="HW3"><a href="#HW3" class="headerlink" title="HW3"></a>HW3</h5><p>之前涉及到了MVP,视口转换以及Raster、=-Z-buffer. 现在到了shading</p><p>Shading:The process of applying a material to an object.The darkening or coloring of an illustration or  diagram with parallel lines or a block of color</p><p>这里Shading介绍了Blinn-Phong反射模型,包括漫反射,高光反射和环境光.</p><p><img data-src="https://s2.loli.net/2024/05/25/3ZsDz6MlRxehIfP.png" alt="image-20240525212040023"></p><p><img data-src="https://s2.loli.net/2024/05/24/elFT8BIydC3XLEw.png" alt="image-20240524220535971"></p><p><strong>漫反射</strong></p><p><img data-src="https://s2.loli.net/2024/05/24/PIprAbJe1HD9SvE.png" alt="image-20240524215603681">与看的方向无关,与距离和入射角度有关. kd对漫反射影响如下.</p><p><img data-src="https://s2.loli.net/2024/05/24/3fKa4mPENFXgz9o.png" alt="image-20240524221426912"></p><p><strong>高光反射</strong></p><p><img data-src="https://s2.loli.net/2024/05/24/LpxJqyRU2u7rd19.png" alt="image-20240524220408626"></p><p>与看的角度有关,角度跟入射角相等时最大.</p><p><img data-src="https://s2.loli.net/2024/05/24/oFExtZaYjLsqD7I.png" alt="image-20240524220506998"></p><p>半程向量就是以l和v向量为边的中线,而p叫做cosine power plots,越大相同角度下越小.</p><p>ks和p对高光反射影响如下</p><p><img data-src="https://s2.loli.net/2024/05/24/i47jFfRGB3t9Lx8.png" alt="image-20240524221457998"></p><p><strong>环境光</strong></p><p><img data-src="https://s2.loli.net/2024/05/24/XnR9HyYvdjcSpox.png" alt="image-20240524221924122"></p><p>不依赖于任何东西,相当于加点环境噪音</p><p>所以最后在Blinn-Phong反射模型中,着色如下</p><p><img data-src="https://s2.loli.net/2024/05/24/QhGcYsCd1ny8e3D.png" alt="image-20240524222152219"></p><p>此外shading还跟着色频率有关,分为三种类型,包括flat shading,gouraud shading,Phong shading</p><p><strong>flat shading</strong></p><ul><li>Triangle face is  flat — one normal  vector  </li><li>Not good for  smooth surfaces</li></ul><p>对于每个三角形做shading,每个三角形就一个normal vector</p><p><strong>gouraud shading</strong></p><ul><li>Interpolate colors  from vertices across  triangle </li><li>Each vertex has a  normal vector</li></ul><p>对于每个vertex做,每个vertex搞出来一个normal vector.</p><p><strong>Phong shading</strong></p><ul><li>Interpolate normal  vectors across each  triangle </li><li>Compute full shading  model at each pixel </li></ul><p>对于每个pixel做.</p><p><img data-src="https://s2.loli.net/2024/05/24/PpGrA8hL17vcmBF.png" alt="image-20240524230245562"></p><p><strong>重心插值</strong></p><p><img data-src="https://s2.loli.net/2024/05/24/SMDGjIbdVWiUFYa.png" alt="image-20240524230332105"></p><p><img data-src="https://s2.loli.net/2024/05/25/YLGaUhMpVnyrTSE.png" alt="image-20240525114414968"></p><p><img data-src="https://s2.loli.net/2024/05/25/39j5Q6aWqIZr87X.png" alt="image-20240525200857191"></p><p>重心坐标系是指平面上任意一点可以用三角形的三个顶点的坐标的线性组合表示,其中三个系数的和为1。</p><p><strong>Texture mapping</strong></p><p>apply textures = sampling</p><p><img data-src="https://s2.loli.net/2024/05/25/ZwzPhiv72LuEHJp.png" alt="image-20240525134129545"></p><p>应用texture的方法,对于每个screen的点,得到对应的texture coords(u,v)然后sample出一个颜色,设置这个颜色为点的颜色,常作为漫反射的系数kd</p><p><img data-src="https://s2.loli.net/2024/05/25/D5L4jirsAwNCfI7.png" alt="image-20240525114612818"></p><p>每个vertex rasterize之后坐标与贴图上某个坐标对应</p><p><img data-src="https://s2.loli.net/2024/05/25/R8Uj61yvnXmoIbc.png" alt="image-20240525112721794"></p><p><img data-src="https://s2.loli.net/2024/05/25/ysCe1ApBbnlkqZR.png" alt="image-20240525112703661"></p><p><strong>Texture magnification</strong></p><blockquote><p>当纹理图像的分辨率低于显示屏上需要的分辨率时，就会出现纹理放大的情况。例如，当你将一个小纹理贴图拉伸到一个较大的表面上时，就会遇到纹理放大。这个过程需要决定如何在纹理中插值以生成更多的像素</p></blockquote><p>如果texture分辨率太小的解决方法.</p><p>放大纹理时常用的插值方法有：</p><ol><li><strong>最近邻插值（Nearest Neighbor Interpolation）</strong>：这种方法简单高效，但通常会产生锯齿状的边缘，因为它只是选择最接近的纹理像素。</li><li><strong>双线性插值（Bilinear Interpolation）</strong>：这种方法通过对周围的四个纹理像素进行加权平均，可以生成较为平滑的结果。</li><li><strong>三线性插值（Trilinear Interpolation）</strong>：在双线性插值的基础上，加入了对不同MIP贴图层次的线性插值，以进一步提高质量。</li></ol><p><img data-src="https://s2.loli.net/2024/05/25/OWIxDR7yqBC5uen.png" alt="image-20240525115208103"></p><p><img data-src="https://s2.loli.net/2024/05/25/YhmLPEoxGZjJ7wn.png" alt="image-20240525124210774"></p><p><img data-src="https://s2.loli.net/2024/05/25/Tm2kfgzHxyO1b5S.png" alt="image-20240525131324085"></p><p>如果texture太大,需要将多个texel取均值分给一个pixel.</p><p><img data-src="https://s2.loli.net/2024/05/25/XkthROUmr3TzDaq.png" alt="image-20240525141722341"></p><p><strong>Texture minification</strong></p><blockquote><p>纹理缩小发生在纹理图像的分辨率高于显示屏上需要的分辨率时。例如，当你将一个大纹理贴图缩小到一个较小的表面上时，就会遇到纹理缩小。这个过程需要决定如何对纹理进行采样，以避免混叠效应（aliasing）</p></blockquote><p>缩小纹理时常用的方法有：</p><ol><li><strong>MIP贴图（Mipmapping）</strong>：这是最常用的方法，它预先生成一系列缩小分辨率的纹理图像（MIP层），在渲染时根据需要选择合适的层进行采样，以减少混叠效应。MIP贴图通常与三线性插值结合使用。</li><li><strong>各向异性过滤（Anisotropic Filtering）</strong>：在MIP贴图的基础上，这种方法进一步提高了纹理在不同角度下的清晰度，特别是在视角较大时效果明显。</li></ol><p><strong>Mipmap</strong></p><p>mipmap是一种多级纹理映射技术.它通过预先生成并存储一系列逐渐降低分辨率的纹理图像来实现.每个降低分辨率的纹理图像称为一个MIP层</p><p><img data-src="https://s2.loli.net/2024/05/25/vVYOIxGN6bmPuow.png" alt="image-20240525145752235"></p><p><img data-src="https://s2.loli.net/2024/05/25/UIFbenyzPNkY782.png" alt="image-20240525152604833"></p><p>将得到的D四舍五入</p><p>在mipmap上再进行插值,</p><p><img data-src="https://s2.loli.net/2024/05/25/M6kJeFrKCiPWYd9.png" alt="image-20240525152427773"></p><p>作业要求实现normal_fragment_shader,利用了(法向量+1)/2作为颜色.还有Blinn-Phong反射模型,以及纹理.</p><p><strong>normal_fragment_shader</strong>比较简单,直接穿法向量即可.</p><p><strong>Blinn-Phong反射模型</strong>按照公式写即可.</p><p>纹理模型主要需要使用对应uv位置的颜色,将原本使用的颜色替换用来算diffuse light.</p><p>实现纹理时可以考虑texture magnification的双线性插值,以及minification的mipmap.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Eigen::Vector3f <span class="title">getColorBilinear</span><span class="params">(<span class="keyword">float</span> u, <span class="keyword">float</span> v)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> u_img = u * width;</span><br><span class="line">  <span class="keyword">auto</span> v_img = (<span class="number">1</span> - v) * height;</span><br><span class="line">  <span class="keyword">float</span> v11 = <span class="built_in">ceil</span>(v_img);</span><br><span class="line">  <span class="keyword">float</span> v01 = <span class="built_in">floor</span>(v_img);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> u01 = <span class="built_in">floor</span>(u_img);</span><br><span class="line">  <span class="keyword">float</span> u11 = <span class="built_in">ceil</span>(u_img);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> rightBottomColor = image_data.at&lt;cv::Vec3b&gt;(v01, u11);</span><br><span class="line">  <span class="keyword">auto</span> leftBottomColor = image_data.at&lt;cv::Vec3b&gt;(v01, u01);</span><br><span class="line">  <span class="keyword">auto</span> rightTopColor = image_data.at&lt;cv::Vec3b&gt;(v11, u11);</span><br><span class="line">  <span class="keyword">auto</span> leftTopColor = image_data.at&lt;cv::Vec3b&gt;(v11, u01);</span><br><span class="line">  <span class="keyword">float</span> s = (u_img - u01) / (u11 - u01);</span><br><span class="line">  <span class="keyword">float</span> t = (v_img - v01) / (v11 - v01);</span><br><span class="line">  <span class="keyword">auto</span> topColor = leftTopColor + s * (rightTopColor - leftTopColor);</span><br><span class="line">  <span class="keyword">auto</span> bottomColor =</span><br><span class="line">      leftBottomColor + s * (rightBottomColor - leftBottomColor);</span><br><span class="line">  <span class="keyword">auto</span> final_color = bottomColor + t * (topColor - bottomColor);</span><br><span class="line">  <span class="keyword">return</span> Eigen::<span class="built_in">Vector3f</span>(final_color[<span class="number">0</span>], final_color[<span class="number">1</span>], final_color[<span class="number">2</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>进阶方法包括Bump mapping,有了凹凸效果,还有displacement mapping.</p><p><img data-src="https://s2.loli.net/2024/05/26/hAqye8oJLWr2RI3.png" alt="image-20240526161155111"></p><p>Bump mapping算法</p><h5 id="HW4"><a href="#HW4" class="headerlink" title="HW4"></a><img data-src="https://s2.loli.net/2024/05/26/GEkQeCXYNxbMqJ7.png" alt="image-20240526164218979">HW4</h5><p>Geometry 表示几何形状的几种方法,包括显示和隐式.</p><p><img data-src="https://s2.loli.net/2024/05/26/sYHdUhBcTq5tw17.png" alt="image-20240526193619807"></p><p>隐式描述优点:</p><ul><li>描述简洁（如函数） </li><li>便于某些查询（物体内部、与表面的距离） </li><li>适用于射线与曲面的交叉（稍后详述） </li><li>对于简单形状，可精确描述/无采样误差 </li><li>易于处理拓扑结构的变化（如流体</li></ul><p>缺点</p><ul><li>难以模拟复杂形状</li></ul><p>显示模型包括点云,多边形网格(polygon mesh),</p><p>点云</p><ul><li>最简单的表示方法：点列表（x,y,z） </li><li>可轻松表示任何几何图形 </li><li>适用于大型数据集（&gt;&gt;1 点/像素） </li><li>通常转换为多边形网格 </li><li>难以绘制采样不足的区域</li></ul><p>多边形网格</p><ul><li>存储顶点和多边形（通常为三角形或四边形） </li><li>更易于处理/模拟、自适应采样 </li><li>数据结构更复杂 </li><li>可能是图形中最常见的表示法</li></ul><p><strong>曲线</strong></p><p>Bézier Curves</p><p><img data-src="https://s2.loli.net/2024/05/26/rhK4ZOqMtGzNu2X.png" alt="image-20240526213851885" style="zoom:67%;" /></p><p>还有cubic贝塞尔曲线,其实就是order更高.</p><p>这些曲线都可以归结为多项式.de Casteljau算法</p><p><img data-src="https://s2.loli.net/2024/05/26/O8xQhoubFZafzD9.png" alt="image-20240526220606516" style="zoom:50%;" /></p><p><img data-src="https://s2.loli.net/2024/05/26/t6yMUePEfpdZ25w.png" alt="image-20240526221101195"></p><p><img data-src="https://s2.loli.net/2024/05/28/FdiBq6fVnyUm7wg.png" alt="image-20240528205956947"></p><p>贝塞尔曲线特点</p><p>内插端点<br>与端点相切<br>仿射变换特性 </p><ul><li>通过变换控制点来变换曲线<br>convex hull property </li><li>曲线位于控制点的凸边内</li></ul><p>利用Piecewise Bézier Curves,将连续的低阶贝塞尔曲线连在一起.</p><p>曲线除了贝塞尔曲线,还有splines和B-splines.</p><p><strong>Bézier Surfaces</strong></p><p><img data-src="https://s2.loli.net/2024/05/26/bISzRwqsTp3BhAj.png" alt="image-20240526225234591" style="zoom:50%;" /></p><p><img data-src="https://s2.loli.net/2024/05/26/93tqJlgfBMupFIC.png" alt="image-20240526230516215"></p><p><strong>Mesh</strong></p><p>对mesh的操作包括subdivision,simplification以及regularization.</p><p>subdivision就是将三角形split然后根据一些权重重新分配三角形位置.</p><p>此外还有catmull-clark subdivison.</p><p>simplification</p><p><img data-src="https://s2.loli.net/2024/05/26/HvDeG2loYQ6E4Kf.png" alt="image-20240526231621354"></p><p>shadow mapping</p><p>不在阴影中的点必须同时被灯光和摄像机看到</p><p>作业就是画贝塞尔曲线并反走样.通过[0,1]的t值确定曲线点。naive的方法就是使用多项式直接算,更好的方法是,根据四个点反复的插值得到曲线点. 反走样就是antialiasing,将曲线点的附近点的值赋值,可以根据距离.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cv::Point2f <span class="title">recursive_bezier</span><span class="params">(<span class="keyword">const</span> std::vector&lt;cv::Point2f&gt; &amp;control_points,</span></span></span><br><span class="line"><span class="params"><span class="function">                             <span class="keyword">float</span> t)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Implement de Casteljau&#x27;s algorithm</span></span><br><span class="line">  <span class="comment">// 首先，将相邻的点连接起来以形成线段</span></span><br><span class="line">  <span class="keyword">if</span> (control_points.<span class="built_in">size</span>() == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> control_points[<span class="number">0</span>];</span><br><span class="line">  &#125;</span><br><span class="line">  std::vector&lt;cv::Point2f&gt; points;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; control_points.<span class="built_in">size</span>() - <span class="number">1</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">auto</span> point = t * control_points[i] + (<span class="number">1</span> - t) * control_points[i + <span class="number">1</span>];</span><br><span class="line">    points.<span class="built_in">push_back</span>(point);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">recursive_bezier</span>(points, t);</span><br><span class="line">  <span class="comment">//  用 t : (1 − t) 的比例细分每个线段，并找到该分割点</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 得到的分割点作为新的控制点序列，新序列的长度会减少一。</span></span><br><span class="line">  <span class="comment">// 如果序列只包含一个点，则返回该点并终止。否则，使用新的控制点序列并</span></span><br><span class="line">  <span class="comment">// 转到步骤 1。</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bezier</span><span class="params">(<span class="keyword">const</span> std::vector&lt;cv::Point2f&gt; &amp;control_points, cv::Mat &amp;window)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Iterate through all t = 0 to t = 1 with small steps, and call de</span></span><br><span class="line">  <span class="comment">// Casteljau&#x27;s recursive Bezier algorithm.</span></span><br><span class="line">  <span class="keyword">float</span> max_dist = <span class="number">1.5f</span> * <span class="built_in">sqrt</span>(<span class="number">2</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">float</span> t = <span class="number">0</span>; t &lt;= <span class="number">1.0f</span>; t += <span class="number">0.001</span>) &#123;</span><br><span class="line">    <span class="keyword">auto</span> point = <span class="built_in">recursive_bezier</span>(control_points, t);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="built_in">round</span>(point.x) - <span class="number">1</span>; i &lt; <span class="built_in">round</span>(point.x) + <span class="number">2</span>; i++) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="built_in">round</span>(point.y) - <span class="number">1</span>; j &lt; <span class="built_in">round</span>(point.y) + <span class="number">2</span>; j++) &#123;</span><br><span class="line">        <span class="keyword">auto</span> samplePoint = cv::<span class="built_in">Point2f</span>(i, j);</span><br><span class="line">        <span class="keyword">float</span> d = cv::<span class="built_in">norm</span>(samplePoint - point);</span><br><span class="line">        <span class="keyword">float</span> color = <span class="number">255.0f</span> * (<span class="number">1</span> - d / max_dist);</span><br><span class="line">        window.at&lt;cv::Vec3b&gt;(samplePoint.y, samplePoint.x)[<span class="number">2</span>] =</span><br><span class="line">            std::<span class="built_in">max</span>(window.at&lt;cv::Vec3b&gt;(samplePoint.y, samplePoint.x)[<span class="number">2</span>],</span><br><span class="line">                     (uchar)color);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// window.at&lt;cv::Vec3b&gt;(point.y, point.x)[1] = 255;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="HW5"><a href="#HW5" class="headerlink" title="HW5"></a>HW5</h5><p>走过了Rasterization和Geometry,终于到了也令人激动的Ray tracing.</p><p>在计算机图形学渲染中,我们通常会模拟Light Rays的传播过程,以计算光照效果。主要方法包括:</p><ol><li>光线追踪(Ray Tracing): 从观察者视角发射光线,模拟其在场景中的传播过程。</li><li>光栅化(Rasterization): 直接计算每个像素的颜色,不追踪光线的具体传播过程。</li><li>辐射度函数(Radiance Function): 利用数学模型描述Light Rays在空间中的传播特性。</li></ol><p>光栅化的缺点:不能处理全局的效果,光反射会超过一次.</p><p>Ray tracing is accurate, but is very slow</p><p>Ray-Tracing的算法</p><p><strong>Light Rays</strong></p><p>Light Rays的主要特点如下:</p><ol><li>传播方向: Light Rays沿直线传播,遵循光线传播的直线性质。</li><li>强度衰减: Light Rays的强度随着传播距离的增加而衰减,遵循逆平方定律。</li><li>反射和折射: 当Light Rays遇到物体表面时,可能会发生反射或折射,遵循光学定律。</li></ol><p><img data-src="https://s2.loli.net/2024/05/28/DRq8BcZVJI9OeaM.png" alt="image-20240528211704213"></p><p><strong>Ray Casting</strong></p><p><img data-src="https://s2.loli.net/2024/05/28/SjqaQ59pxYfIH2E.png" alt="image-20240528212212368"></p><p><img data-src="https://s2.loli.net/2024/05/28/IZsbODHYcXngwt6.png" alt="image-20240528212339608"></p><p>Shadow Rays是光线追踪算法中一个非常重要的技术,它用于计算物体在三维场景中投射出的阴影.</p><p><img data-src="https://s2.loli.net/2024/05/28/EI7yp4GToHrVsXb.png" alt="image-20240528213753449"></p><p>在光线追踪渲染过程中,<strong>当一条光线与场景中的物体发生相交时,通常需要判断该点是否位于阴影中。为此,我们会发射一条从交点出发指向光源的shadow ray.</strong></p><p>如果这条shadow ray在到达光源之前与任何其他物体相交,那么该交点就位于阴影中.</p><p><strong>Ray-Surface Intersection</strong></p><p>Ray is defined by its origin and a direction vector</p><p><img data-src="https://s2.loli.net/2024/05/28/bZOxpmvrok3MQeV.png" alt="image-20240528213710912" style="zoom:67%;" /></p><p><img data-src="https://s2.loli.net/2024/05/28/jltgudeDTN9mQzs.png" alt="image-20240528213858434"></p><p><img data-src="https://s2.loli.net/2024/05/28/mR8edIxybTEYkBU.png" alt="image-20240528214148744"></p><p>与隐式表示的surface相交的ray计算.</p><p><img data-src="https://s2.loli.net/2024/05/28/qL38YXn9dE1WiUK.png" alt="image-20240528214431784"></p><p>与三角形mesh交叉</p><p><img data-src="https://s2.loli.net/2024/05/28/o51pJvBfFK9zDeZ.png" alt="image-20240528214803254"></p><p>简单的想法是让ray与每一个triangle交叉,ray-plane交叉,看点是否在三角形内部.</p><p>平面由法向量和面上的一个点定义.</p><p><img data-src="https://s2.loli.net/2024/05/28/EAhgOXmBbc2l5yW.png" alt="image-20240528215109831"></p><p><img data-src="https://s2.loli.net/2024/05/28/e1MHiZQhqJW4jow.png" alt="image-20240528215650898"></p><p><strong>Möller Trumbore Algorithm</strong></p><p><img data-src="https://s2.loli.net/2024/05/28/yGVeQkYPOg3j6zs.png" alt="image-20240528220838253"></p><p><strong>Bounding Volumes</strong></p><p>使用这东西来看有没有相交.</p><p><strong>box is the intersection of 3 pairs of slabs</strong></p><p><img data-src="https://s2.loli.net/2024/05/28/Rgu7eK4kMxSHI2L.png" alt="image-20240528222129198"></p><p>这样做的好处</p><p>简单的光线-场景交点求解</p><ul><li>穷尽地测试每个三角形与光线的交点</li><li>找到最近的交点(即最小的t值)</li></ul><p>问题:</p><ul><li>朴素算法 = #像素 ⨉ # 三角形 (⨉ #反射次数)</li><li>非常慢!</li></ul><p>快速避免交点的方法:<strong>用简单的体积包围复杂物体</strong></p><ul><li>物体完全包含在该体积中</li><li>如果光线没有击中该体积,就不会击中该物体</li><li>所以先测试包围体积,如果击中了,再测试物体本身</li></ul><p><img data-src="https://s2.loli.net/2024/05/28/L235usfSm9aliGZ.png" alt="image-20240528230330356"></p><p>Render的方法,其实就是坐标系的一个变换以及castRay算反射以及阴影等.</p><p>计算Render的过程:</p><ol><li>首先需要使用帧的尺寸来对像素位置进行归一化。</li><li>归一化后的像素坐标被称为NDC空间(Normalized Device Coordinates)。</li><li>在将像素坐标转换到NDC空间时,我们需要在原始坐标上加上0.5的偏移量。这是为了确保最终的相机光线穿过像素的中心。</li><li>NDC空间中的像素坐标范围是[0, 1]。这与光栅化领域中NDC空间的范围[-1, 1]不同。</li><li>由于成像平面是以世界坐标系的原点为中心的,因此我们需要进一步将[0, 1]范围的NDC坐标映射到[-1, 1]的范围内。这样做可以确保左侧像素有负的x坐标,右侧像素有正的x坐标,上面的像素有正的y坐标,下面的像素有负的y坐标。</li><li>当图像的长宽比不是1:1时,我们需要考虑图像的宽高比。</li><li>对于一个7x5像素的图像,宽高比是1.4。</li><li>在屏幕空间(NDC空间)中,像素坐标范围仍然是[-1, 1]。但由于横向有更多像素,所以像素会被拉伸变形。</li><li>为了让像素保持正方形,我们需要将x坐标乘以图像的宽高比1.4。这样可以将x坐标范围拉伸到[-1.4, 1.4]。</li><li>这个操作不会影响y坐标,它仍然在[-1, 1]范围内。</li></ol><p>rayTriangleIntersect判断是否相交以及是否在三角形内部,公式如下:</p><p><img data-src="https://s2.loli.net/2024/05/31/elBK7zRus5wXCE4.png" alt="image-20240531232626151"></p><h5 id="HW6"><a href="#HW6" class="headerlink" title="HW6"></a>HW6</h5><p>主要是为了加速ray-tracing的rayTriangle intersection. 进行分割.</p><p>包括uniform grid和spatial partitions,前者就是均匀分块,后者包括Oct-Tree,KD-Tree,BSP-Tree多种,还有Bounding Volume Hierarchy的方法.</p><p><img data-src="https://s2.loli.net/2024/06/01/PYjBZp936Kq2QVl.png" alt="image-20240601202540887"></p><p><img data-src="https://s2.loli.net/2024/06/01/8D2tV9AEnzIh3mH.png" alt="image-20240601174238696"></p><p><img data-src="https://s2.loli.net/2024/06/01/WCjEBS4LIXgKYhk.png" alt="image-20240601174248719"></p><p><img data-src="https://s2.loli.net/2024/06/01/nDaNxQ2GTb3iUfW.png" alt="image-20240601174312126"></p><p><img data-src="https://s2.loli.net/2024/06/01/ZCQs6uEma59rGJx.png" alt="image-20240601174320918"></p><p><img data-src="https://s2.loli.net/2024/06/01/cBWnDoLRqmEM1rs.png" alt="image-20240601174336245"></p><p>确定ray是否与AABB相交</p><p><img data-src="https://s2.loli.net/2024/06/01/F6riHxW9OvYPB52.png" alt="image-20240601224405331" style="zoom:50%;" /></p><p>再确定ray是否与三角形相交,与上一次作业类似.在判断,判断是否与box相交,不相交则没有交点,如果相交,看是否是叶子节点,如果是叶子节点,看是否与其中的object相交,如果不是在分别判断.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Intersection <span class="title">BVHAccel::getIntersection</span><span class="params">(BVHBuildNode* node,</span></span></span><br><span class="line"><span class="params"><span class="function">                                       <span class="keyword">const</span> Ray&amp; ray)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// TODO Traverse the BVH to find intersection</span></span><br><span class="line">  Intersection isect;</span><br><span class="line">  <span class="keyword">if</span> (!node || !node-&gt;bounds.<span class="built_in">IntersectP</span>(ray, ray.direction_inv, &#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125;)) &#123;</span><br><span class="line">    <span class="keyword">return</span> isect;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (node-&gt;left == <span class="literal">nullptr</span> &amp;&amp; node-&gt;right == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> node-&gt;object-&gt;<span class="built_in">getIntersection</span>(ray);</span><br><span class="line">  &#125;</span><br><span class="line">  Intersection left = <span class="built_in">getIntersection</span>(node-&gt;left, ray);</span><br><span class="line">  Intersection right = <span class="built_in">getIntersection</span>(node-&gt;right, ray);</span><br><span class="line">  <span class="keyword">if</span> (left.distance &lt; right.distance) &#123;</span><br><span class="line">    <span class="keyword">return</span> left;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> right;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> isect;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>BVH的构造如下</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">BVHAccel::<span class="built_in">BVHAccel</span>(std::vector&lt;Object*&gt; p, <span class="keyword">int</span> maxPrimsInNode,</span><br><span class="line">                   SplitMethod splitMethod)</span><br><span class="line">    : <span class="built_in">maxPrimsInNode</span>(std::<span class="built_in">min</span>(<span class="number">255</span>, maxPrimsInNode)),</span><br><span class="line">      <span class="built_in">splitMethod</span>(splitMethod),</span><br><span class="line">      <span class="built_in">primitives</span>(std::<span class="built_in">move</span>(p)) &#123;</span><br><span class="line">  <span class="keyword">time_t</span> start, stop;</span><br><span class="line">  <span class="built_in">time</span>(&amp;start);</span><br><span class="line">  <span class="keyword">if</span> (primitives.<span class="built_in">empty</span>()) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  root = <span class="built_in">recursiveBuild</span>(primitives);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">time</span>(&amp;stop);</span><br><span class="line">  <span class="keyword">double</span> diff = <span class="built_in">difftime</span>(stop, start);</span><br><span class="line">  <span class="keyword">int</span> hrs = (<span class="keyword">int</span>)diff / <span class="number">3600</span>;</span><br><span class="line">  <span class="keyword">int</span> mins = ((<span class="keyword">int</span>)diff / <span class="number">60</span>) - (hrs * <span class="number">60</span>);</span><br><span class="line">  <span class="keyword">int</span> secs = (<span class="keyword">int</span>)diff - (hrs * <span class="number">3600</span>) - (mins * <span class="number">60</span>);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(</span><br><span class="line">      <span class="string">&quot;\rBVH Generation complete: \nTime Taken: %i hrs, %i mins, %i secs\n\n&quot;</span>,</span><br><span class="line">      hrs, mins, secs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">BVHBuildNode* <span class="title">BVHAccel::recursiveBuild</span><span class="params">(std::vector&lt;Object*&gt; objects)</span> </span>&#123;</span><br><span class="line">  BVHBuildNode* node = <span class="keyword">new</span> <span class="built_in">BVHBuildNode</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Compute bounds of all primitives in BVH node</span></span><br><span class="line">  Bounds3 bounds;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; objects.<span class="built_in">size</span>(); ++i)</span><br><span class="line">    bounds = <span class="built_in">Union</span>(bounds, objects[i]-&gt;<span class="built_in">getBounds</span>());</span><br><span class="line">  <span class="keyword">if</span> (objects.<span class="built_in">size</span>() == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="comment">// Create leaf _BVHBuildNode_</span></span><br><span class="line">    node-&gt;bounds = objects[<span class="number">0</span>]-&gt;<span class="built_in">getBounds</span>();</span><br><span class="line">    node-&gt;object = objects[<span class="number">0</span>];</span><br><span class="line">    node-&gt;left = <span class="literal">nullptr</span>;</span><br><span class="line">    node-&gt;right = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (objects.<span class="built_in">size</span>() == <span class="number">2</span>) &#123;</span><br><span class="line">    node-&gt;left = <span class="built_in">recursiveBuild</span>(std::vector&#123;objects[<span class="number">0</span>]&#125;);</span><br><span class="line">    node-&gt;right = <span class="built_in">recursiveBuild</span>(std::vector&#123;objects[<span class="number">1</span>]&#125;);</span><br><span class="line"></span><br><span class="line">    node-&gt;bounds = <span class="built_in">Union</span>(node-&gt;left-&gt;bounds, node-&gt;right-&gt;bounds);</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Bounds3 centroidBounds;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; objects.<span class="built_in">size</span>(); ++i)</span><br><span class="line">      centroidBounds =</span><br><span class="line">          <span class="built_in">Union</span>(centroidBounds, objects[i]-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>());</span><br><span class="line">    <span class="keyword">int</span> dim = centroidBounds.<span class="built_in">maxExtent</span>();</span><br><span class="line">    <span class="built_in"><span class="keyword">switch</span></span> (dim) &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">        std::<span class="built_in">sort</span>(objects.<span class="built_in">begin</span>(), objects.<span class="built_in">end</span>(), [](<span class="keyword">auto</span> f1, <span class="keyword">auto</span> f2) &#123;</span><br><span class="line">          <span class="keyword">return</span> f1-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>().x &lt; f2-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>().x;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">        std::<span class="built_in">sort</span>(objects.<span class="built_in">begin</span>(), objects.<span class="built_in">end</span>(), [](<span class="keyword">auto</span> f1, <span class="keyword">auto</span> f2) &#123;</span><br><span class="line">          <span class="keyword">return</span> f1-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>().y &lt; f2-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>().y;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">        std::<span class="built_in">sort</span>(objects.<span class="built_in">begin</span>(), objects.<span class="built_in">end</span>(), [](<span class="keyword">auto</span> f1, <span class="keyword">auto</span> f2) &#123;</span><br><span class="line">          <span class="keyword">return</span> f1-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>().z &lt; f2-&gt;<span class="built_in">getBounds</span>().<span class="built_in">Centroid</span>().z;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> beginning = objects.<span class="built_in">begin</span>();</span><br><span class="line">    <span class="keyword">auto</span> middling = objects.<span class="built_in">begin</span>() + (objects.<span class="built_in">size</span>() / <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">auto</span> ending = objects.<span class="built_in">end</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> leftshapes = std::vector&lt;Object*&gt;(beginning, middling);</span><br><span class="line">    <span class="keyword">auto</span> rightshapes = std::vector&lt;Object*&gt;(middling, ending);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">assert</span>(objects.<span class="built_in">size</span>() == (leftshapes.<span class="built_in">size</span>() + rightshapes.<span class="built_in">size</span>()));</span><br><span class="line"></span><br><span class="line">    node-&gt;left = <span class="built_in">recursiveBuild</span>(leftshapes);</span><br><span class="line">    node-&gt;right = <span class="built_in">recursiveBuild</span>(rightshapes);</span><br><span class="line"></span><br><span class="line">    node-&gt;bounds = <span class="built_in">Union</span>(node-&gt;left-&gt;bounds, node-&gt;right-&gt;bounds);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上面是BVH,再看SAH.</p><p><img data-src="https://s2.loli.net/2024/06/01/kQfWdLwKM8JEAO6.png" alt="image-20240601230318319"></p><p><img data-src="https://s2.loli.net/2024/06/01/SdR4eM9Lzmqx83u.png" alt="image-20240601225049873"></p><p><img data-src="https://s2.loli.net/2024/06/01/dEh2QYDNBZq4Gmw.png" alt="image-20240601230545159"></p><p><img data-src="https://s2.loli.net/2024/06/01/Lt8SdEIrph3s7wC.png" alt="image-20240601230754416"></p><h5 id="HW7"><a href="#HW7" class="headerlink" title="HW7"></a>HW7</h5><p><strong>radiometry</strong></p><p>Radiant flux, intensity, irradiance, radiance</p><p><strong>辐射能</strong>(Radiant energy)是电磁 辐射能。它以焦耳为单位</p><p>Q [J = Joule]</p><p> <strong>辐射通量</strong>（功率）是单位时间内发射、反射、传输或接收的能量、<br>单位时间内反射、传输或接收的能量</p><script type="math/tex; mode=display">\Phi\equiv\frac{\mathrm{d}Q}{\mathrm{d}t}\text{ [W=Watt] [lm=lumen]}</script><p><img data-src="https://s2.loli.net/2024/06/02/UHw3QStEyLeJvcg.png" alt="image-20240602161533270"></p><p>有三个衡量指标,包括intensiry,irradiance和radiance.</p><p><img data-src="https://s2.loli.net/2024/06/02/b2unaV1cI5EjAGO.png" alt="image-20240602161706417"></p><p>实心角：球面上被摄面积与半径平方的比值：球面面积与半径平方之比 ,球有4Π steradians</p><p><img data-src="https://s2.loli.net/2024/06/02/m6cLVeHiUGlbMfZ.png" alt="image-20240602163911047" style="zoom:67%;" /></p><p><img data-src="https://s2.loli.net/2024/06/02/xD2i9V1WznUTF4q.png" alt="image-20240602164606816"></p><p><img data-src="https://s2.loli.net/2024/06/02/OMtKHV5yo8TWziU.png" alt="image-20240602164655440"></p><p><img data-src="https://s2.loli.net/2024/06/02/NJcHQwevWK9ZO1z.png" alt="image-20240602165849277"></p><p>辐照度(irradiance)是入射到表面点的单位面积功率</p><p><img data-src="https://s2.loli.net/2024/06/02/2lu7SGBX5qcUTbr.png" alt="image-20240602170041748"></p><p>表面的辐照度与光照方向和表面法线之间夹角的余弦成正比。</p><p><img data-src="https://s2.loli.net/2024/06/02/hjSAJr1gxt7Bmep.png" alt="image-20240602170804889"></p><p><img data-src="https://s2.loli.net/2024/06/02/DofShqERXKj6wPJ.png" alt="image-20240602171113537" style="zoom:67%;" /></p><p> 辐射度(Radiance)是描述光在环境中分布的基本场量 </p><ul><li>辐照度是与光线相关的量 </li><li>渲染就是计算辐射度</li></ul><p><img data-src="https://s2.loli.net/2024/06/02/nSJchK5OdA4fpNt.png" alt="image-20240602172100181"></p><p><img data-src="https://s2.loli.net/2024/06/02/xv3qSwf4XlWAGQs.png" alt="image-20240602172146849"></p><p>Incident radiance:入射辐射度是到达表面的单位固角辐照度</p><p>Exiting Radiance:离开表面辐射度是离开表面的单位投影面积强度。</p><p><strong>Bidirectional Reflectance  Distribution Function</strong></p><p>双向反射分布函数（BRDF）表示从每个入射方向反射到每个出射方向的光量</p><p><img data-src="https://s2.loli.net/2024/06/02/gsSYMKUADz4Xp3b.png" alt="image-20240602173440574"></p><p><img data-src="https://s2.loli.net/2024/06/02/L1fjxdF4gEzKbpM.png" alt="image-20240602174423412"></p><p><img data-src="https://s2.loli.net/2024/06/02/snL4oXfVMKzmqxR.png" alt="image-20240602205209811"></p><p><img data-src="https://s2.loli.net/2024/06/02/BRbCeu6IHMSpiFL.png" alt="image-20240602174856955"></p><p><img data-src="https://pic3.zhimg.com/v2-c9128ac3f985a48f1c42ea7f12803f8e_b.jpg" alt="img"></p><p><img data-src="https://s2.loli.net/2024/06/02/FEoybKz31a5Mpc6.png" alt="image-20240602211917267"></p><p>将L~i~转为经过反射后的光L~r~再经过简化.</p><ul><li>此时我们令相机接受到的直接光照为：e(u)</li><li>最终接收到的光为:l(u)</li><li>其他表面弹过来的光为:l(v)</li><li>BRDF那些式子为：K（u，v）</li></ul><p><img data-src="https://pic3.zhimg.com/v2-1df15bb2a394315d869b916c594e1fb2_b.jpg" alt="img"></p><p><img data-src="https://s2.loli.net/2024/06/02/IAHsizpe86rmSCo.png" alt="image-20240602212016496"></p><p><strong>Monte Carlo Integration</strong></p><p><img data-src="https://s2.loli.net/2024/06/02/xKZpAtQFj8yimU4.png" alt="image-20240602214239624"></p><p><strong>Path Tracing</strong></p><p>光线追踪 </p><ul><li>始终执行镜面反射/折射 </li><li>在漫反射表面停止反弹 </li></ul><p>使用Monte Carlo Integration解决反射公式.</p><p><img data-src="https://s2.loli.net/2024/06/02/EhnZtXl7cMkPb2a.png" alt="image-20240602215544122"></p><p><img data-src="https://s2.loli.net/2024/06/02/NufB9EKD4wZOPU6.png" alt="image-20240602220952675"></p><p><img data-src="https://s2.loli.net/2024/06/02/Fowx9kp7sRbHdMY.png" alt="image-20240602222734803" style="zoom:67%;" /></p><p>存在的两个问题: </p><p><strong>Explosion of #rays as #bounces go up</strong></p><p>由于反射,在反射时需要通过蒙特卡洛方法计算多个值,这样多次反射计算量增加.</p><p>所以只取一个方向作为入射,但在每个pixel上采样多个值取平均.</p><p><img data-src="https://s2.loli.net/2024/06/02/li1ahLZm26DvMru.png" alt="image-20240602230032888"></p><p><strong>The recursive algorithm will never stop</strong></p><p>光会无数次反弹. 解决方法:俄罗斯轮盘赌 Russian Roulette (RR)</p><p><img data-src="https://s2.loli.net/2024/06/02/NugfonpHmWKzX1V.png" alt="image-20240602230335879"></p><p><img data-src="https://s2.loli.net/2024/06/02/CwaPL4fyJtV8uc7.png" alt="image-20240602230436474" style="zoom:50%;" /></p><p>此外N=1的采样还存在问题:即低采样率的问题，由于我们将平均放到了像素块处用接收到的光线来替代平均着色点的光线，但如果对于一个场景就没有或存在很少的间接光照，主要是直接光照的时候，那这个平均也无法消除误差噪声。</p><blockquote><p>如果光源面积很小，则均匀采样就需要很大的N才能保证采样到光源方向。也就是这里问题来自两个第一个是均匀抽样方法浪费了很多光源不存在的角度</p></blockquote><p>对光采样</p><p><img data-src="https://s2.loli.net/2024/06/02/t2TL8lFwkCp4XfK.png" alt="image-20240602232512769"></p><p><img data-src="https://s2.loli.net/2024/06/02/4vfesAZGRpgjChi.png" alt="z"></p><p><img data-src="https://s2.loli.net/2024/06/02/y8Wdgb4t2TJY9qZ.png" alt="image-20240602232751423"></p><p><img data-src="https://iewug.github.io/book/img/15renderingEquation.png" alt="img"></p><p>渲染公式通过BRDF得到</p><p>演进过程:渲染公式-&gt;使用蒙特卡洛方式积分解-&gt;引入全局光照,碰到物体会反射-&gt;由于反射太多,直接每次只会反射一根光线-&gt;由于只反射一根光线,采样不够,在一个pixel上采样更多次-&gt;此外这个算法会无穷的进行下去(因为最后只在打到灯光后停止),每次反射通过俄罗斯转盘减少能量-&gt;此外还是不够有效,考虑sample the light,sample light本身是dA,需要从dw转到dA-&gt;现在选择一个区域作为light source直接照射,另外区域都是间接的</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 总体流程如下：</span></span><br><span class="line"><span class="comment">// 从像素打出射线，检查射线是否命中，命中则继续下一步，反之结束</span></span><br><span class="line"><span class="comment">// 对光源表面进行采样，得到一个采样的交点 Intersection 和光源的 pdf</span></span><br><span class="line"><span class="comment">// 检查光源采样点和像素射线交点，两点之间是否有其他物体遮挡，没有遮挡则可计算直接光</span></span><br><span class="line"><span class="comment">// 计算俄罗斯轮盘赌概率，如果成功进行下一步</span></span><br><span class="line"><span class="comment">// 按照像素射线交点材质的性质，给定像素射线入射方向与交点法向量，用某种分布采样一个出射方向，这里是漫反射</span></span><br><span class="line"><span class="comment">// 有了出射方向和交点，得到新的射线，计算是否有命中</span></span><br><span class="line"><span class="comment">// 如果命中了非光源，计算新射线命中交点给原来像素射线交点带来的间接光</span></span><br><span class="line"><span class="comment">// 最后将直接光和间接光结合，得到最初命中的位置的颜色</span></span><br><span class="line"><span class="comment">// Implementation of Path Tracing</span></span><br><span class="line"><span class="function">Vector3f <span class="title">Scene::castRay</span><span class="params">(<span class="keyword">const</span> Ray &amp;ray, <span class="keyword">int</span> depth)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// TO DO Implement Path Tracing Algorithm here</span></span><br><span class="line">  Vector3f l_indir&#123;<span class="number">0.f</span>&#125;;</span><br><span class="line">  Vector3f l_dir&#123;<span class="number">0.f</span>&#125;;</span><br><span class="line">  Intersection ray_inter = <span class="built_in">intersect</span>(ray);</span><br><span class="line">  <span class="keyword">if</span> (!ray_inter.happened) &#123;</span><br><span class="line">    <span class="comment">// 没有与任何物体相碰</span></span><br><span class="line">    <span class="keyword">return</span> l_dir + l_indir;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">float</span> pdf_light;</span><br><span class="line">  Intersection light_inter;</span><br><span class="line">  <span class="built_in">sampleLight</span>(light_inter, pdf_light);</span><br><span class="line"></span><br><span class="line">  Vector3f N = ray_inter.normal;</span><br><span class="line">  Vector3f x = light_inter.coords;</span><br><span class="line">  Vector3f wo = ray.direction;</span><br><span class="line">  Vector3f p = ray_inter.coords;</span><br><span class="line">  Vector3f ws = (x - p).<span class="built_in">normalized</span>();</span><br><span class="line">  <span class="comment">// shoot a ray from p to x</span></span><br><span class="line">  Ray ray_light_to_p = <span class="built_in">Ray</span>(p + EPSILON * N, ws);</span><br><span class="line">  <span class="keyword">auto</span> rpx_inter = <span class="built_in">intersect</span>(ray_light_to_p);</span><br><span class="line">  Vector3f NN = rpx_inter.normal;</span><br><span class="line">  Material *m = ray_inter.m;</span><br><span class="line">  <span class="comment">// if the ray is not blocked in the middle</span></span><br><span class="line">  <span class="keyword">if</span> (rpx_inter.happened &amp;&amp; rpx_inter.m-&gt;<span class="built_in">hasEmission</span>()) &#123;</span><br><span class="line">    l_dir = rpx_inter.m-&gt;<span class="built_in">getEmission</span>() * m-&gt;<span class="built_in">eval</span>(wo, ws, N) *</span><br><span class="line">            <span class="built_in">dotProduct</span>(ws, N) * <span class="built_in">dotProduct</span>(-ws, NN) / (rpx_inter.distance) /</span><br><span class="line">            pdf_light;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">get_random_float</span>() &lt; RussianRoulette) &#123;</span><br><span class="line">    Vector3f wi = (m-&gt;<span class="built_in">sample</span>(wo, N)).<span class="built_in">normalized</span>();</span><br><span class="line">    <span class="function">Ray <span class="title">rpwi</span><span class="params">(p, wi)</span></span>;</span><br><span class="line">    <span class="keyword">auto</span> rpwi_inter = <span class="built_in">intersect</span>(rpwi);</span><br><span class="line">    <span class="keyword">if</span> (rpwi_inter.happened &amp;&amp; !rpwi_inter.m-&gt;<span class="built_in">hasEmission</span>()) &#123;</span><br><span class="line">      l_indir = <span class="built_in">castRay</span>(rpwi, depth + <span class="number">1</span>) * m-&gt;<span class="built_in">eval</span>(wo, wi, N) *</span><br><span class="line">                <span class="built_in">dotProduct</span>(wi, N) / m-&gt;<span class="built_in">pdf</span>(wo, wi, N) / RussianRoulette;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> m-&gt;<span class="built_in">getEmission</span>() + l_dir + l_indir; <span class="comment">//物体表面的emission和直接从光发射的和反射的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>from <a href="https://iewug.github.io/book/GAMES101.html#19-cameras-lenses-and-light-fields">GAMES101笔记 (iewug.github.io)</a></p><p><img data-src="https://iewug.github.io/book/img/18.png" alt="img"></p><h5 id="相机与透镜"><a href="#相机与透镜" class="headerlink" title="相机与透镜"></a>相机与透镜</h5><p><img data-src="https://s2.loli.net/2024/06/24/6UpBiyaDNRWGFws.png" alt="Controlled by lens aperture and focal length "></p><p>Shutter Exposes Sensor For Precise Duration</p><p>Sensor Accumulates Irradiance During Exposure</p><p><img data-src="https://s2.loli.net/2024/06/24/bSJjU1PMziDhyg2.png" alt="image-20240624205234472"></p><p><img data-src="https://s2.loli.net/2024/06/24/CBP6qkOpLA21a5z.png" alt="image-20240624205208978"></p><p><img data-src="https://s2.loli.net/2024/06/24/ieFozQaEGCmhxd9.png" alt="image-20240624205321605" style="zoom:67%;" /></p><p><img data-src="https://iewug.github.io/book/img/19coc.png" alt="img"></p><p><img data-src="https://iewug.github.io/book/img/19dof.png" alt="img"></p><p>一些概念:focal length,FOV,exposure,ISO(感光度),F-step(焦距除以口径的直径),CoC大小(当物体远离Focal Plane，原本的一个点落在sensor plane上就会变成一个圆),景深,指的是在相机拍摄过程中,成像清晰的范围或深度。</p><h5 id="光场、颜色与感知"><a href="#光场、颜色与感知" class="headerlink" title="光场、颜色与感知"></a>光场、颜色与感知</h5><p><strong>光场</strong>（<strong>light field</strong>或称为<strong>lumigraph</strong>），即是空间中任意点发出的任意方向的光的集合</p><p><img data-src="https://s2.loli.net/2024/06/24/yrHGxeBONiDd2Pz.png" alt=""></p><p><img data-src="https://s2.loli.net/2024/06/24/Hx2PZirjtD4Lw5d.png" alt=""></p><h5 id="HW8"><a href="#HW8" class="headerlink" title="HW8"></a>HW8</h5><p><strong>Mass Spring System</strong> 质量-弹簧系统</p><p><img data-src="https://s2.loli.net/2024/06/24/nf1QyZV5pgU9BHi.png" alt="image-20240624220439532"></p><p><img data-src="https://s2.loli.net/2024/06/24/4pGTPO6Ws1wUvdf.png" alt="image-20240624220852340"></p><p><img data-src="https://s2.loli.net/2024/06/24/ErmvTYSaBPXUnMu.png" alt="image-20240624221049069"></p><p><strong>粒子系统</strong></p><p>将动态系统建模为大量粒子的集合<br>大量粒子的集合,每个粒子的运动由一组<br>物理（或非物理）力<br>图形和游戏中的流行技术 </p><ul><li>易于理解和实施 </li><li>可扩展：粒子数量越少速度越快，粒子数量越多<br>以提高复杂性<br>挑战 </li><li>可能需要很多粒子（如流体） </li><li>可能需要加速结构（如<br>找到最近的粒子进行交互） </li></ul><p>吸引力和斥力 </p><ul><li>重力、电磁力、… </li><li>弹簧、推进力 …<br>阻尼力 </li><li>摩擦力、空气阻力、粘滞力 …<br>碰撞 </li><li>墙壁、容器、固定物体、 … </li><li><p>动态物体、角色身体部位</p></li><li><p><strong>正向运动学</strong>（forward kinematics）：已知初始的关键点位置和相对旋转，计算最终的关键点位置。唯一解</p></li><li><strong>反向运动学</strong>（inverse kinematics）：根据初始的关键点位置和最终关键点位置，计算相对旋转的数学过程。无解或无穷多解（ill-posed problem）。</li></ul><p><strong>Rigging(绑定)</strong></p><p>装配是对角色进行更高级别的控制，可以更快、更直观地修改角色的姿势、变形和表情等。<br>更快、更直观地修改姿势、变形和表情等。</p><ul><li>就像木偶上的线 </li><li>捕捉所有有意义的角色的变化 </li><li>因角色而异</li><li>角色制作成本高 </li><li>手工制作 </li><li>需要艺术和技术培训</li></ul><p>代替骨架，直接在曲面之间插值<br>例如，建立面部表情集合模型<br>表情模型：<br>最简单的方案：对顶点位置进行线性组合<br>使用样条曲线控制随时间变化的权重选择</p><p><strong>Motion Capture(动捕)</strong></p><p>创建动画序列的数据驱动方法 </p><ul><li>记录真实世界中的表演（例如，人在执行一项活动） </li><li>从收集到的数据中提取姿势与时间的函数关系</li></ul><p><strong>Single Particle Simulation</strong></p><p><img data-src="https://s2.loli.net/2024/06/24/25FQh4KbNSsTrey.png" alt="image-20240624222909275">首先，假设粒子的运动由速度矢量场决定，速度矢量场是位置和时间的函数：v(x, t)计算粒子随时间变化的位置 需要求解一个一阶常微分方程： “一阶 “指的是导数。”普通 “意味着没有 “偏” 导数,即x只是t的函数.</p><p>在给定粒子初始位置 x0 的条件下，我们可以通过正向数值积分来求解 ODE</p><p>欧拉法（又称前向欧拉法、显式欧拉法） </p><ul><li>简单迭代法 </li><li>常用 </li><li>非常不准确 </li><li>经常不稳定</li></ul><p><img data-src="https://s2.loli.net/2024/06/24/prX2HEvQnexuTPm.png" alt="image-20240624223202577" style="zoom:67%;" /></p><p><strong>消除不稳定因素</strong></p><p>中点法/修正欧拉法 </p><ul><li>起点和终点的平均速度<br>自适应步长 </li><li>递归比较一步和两个半步，直到<br>误差可接受<br>隐式方法 </li><li>使用下一时间步的速度（困难）<br>基于位置/Verlet 积分 </li><li>在时间步后约束粒子的位置和速度步</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">Rope::<span class="built_in">Rope</span>(Vector2D start, Vector2D end, <span class="keyword">int</span> num_nodes, <span class="keyword">float</span> node_mass,</span><br><span class="line">           <span class="keyword">float</span> k, vector&lt;<span class="keyword">int</span>&gt; pinned_nodes) &#123;</span><br><span class="line">  <span class="comment">// TODO (Part 1): Create a rope starting at `start`, ending at `end`, and</span></span><br><span class="line">  <span class="comment">// containing `num_nodes` nodes.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_nodes; i++) &#123;</span><br><span class="line">    Vector2D pos =</span><br><span class="line">        start + (end - start) * ((<span class="keyword">double</span>)i / ((<span class="keyword">double</span>)num_nodes - <span class="number">1.0</span>));</span><br><span class="line">    masses.<span class="built_in">push_back</span>(<span class="keyword">new</span> <span class="built_in">Mass</span>(pos, node_mass, <span class="literal">false</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_nodes - <span class="number">1</span>; i++) &#123;</span><br><span class="line">    springs.<span class="built_in">push_back</span>(<span class="keyword">new</span> <span class="built_in">Spring</span>(masses[i], masses[i + <span class="number">1</span>], k));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;i : pinned_nodes) &#123;</span><br><span class="line">    masses[i]-&gt;pinned = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//        for (auto &amp;i : pinned_nodes) &#123;</span></span><br><span class="line">  <span class="comment">//            masses[i]-&gt;pinned = true;</span></span><br><span class="line">  <span class="comment">//        &#125;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Rope::simulateEuler</span><span class="params">(<span class="keyword">float</span> <span class="keyword">delta_t</span>, Vector2D gravity)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;s : springs) &#123;</span><br><span class="line">    <span class="comment">// （solving constraints)</span></span><br><span class="line">    <span class="keyword">auto</span> mod_ab = (s-&gt;m1-&gt;position - s-&gt;m2-&gt;position).<span class="built_in">norm</span>();</span><br><span class="line">    s-&gt;m1-&gt;forces += -s-&gt;k * (s-&gt;m1-&gt;position - s-&gt;m2-&gt;position) / mod_ab *</span><br><span class="line">                     (mod_ab - s-&gt;rest_length);</span><br><span class="line">    s-&gt;m2-&gt;forces += -s-&gt;k * (s-&gt;m2-&gt;position - s-&gt;m1-&gt;position) / mod_ab *</span><br><span class="line">                     (mod_ab - s-&gt;rest_length);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;m : masses) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!m-&gt;pinned) &#123;</span><br><span class="line">      <span class="keyword">auto</span> a = m-&gt;forces / m-&gt;mass + gravity;</span><br><span class="line">      m-&gt;position += m-&gt;velocity * <span class="keyword">delta_t</span>;  <span class="comment">//  explicit</span></span><br><span class="line">      m-&gt;velocity += a * <span class="keyword">delta_t</span>;</span><br><span class="line">      m-&gt;position += m-&gt;velocity * <span class="keyword">delta_t</span>;  <span class="comment">//  implicit</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reset all forces on each mass</span></span><br><span class="line">    m-&gt;forces = <span class="built_in">Vector2D</span>(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Rope::simulateVerlet</span><span class="params">(<span class="keyword">float</span> <span class="keyword">delta_t</span>, Vector2D gravity)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;s : springs) &#123;</span><br><span class="line">    <span class="comment">// TODO (Part 3): Simulate one timestep of the rope using explicit Verlet</span></span><br><span class="line">    <span class="comment">// （solving constraints)</span></span><br><span class="line">    <span class="keyword">auto</span> mod_ab = (s-&gt;m1-&gt;position - s-&gt;m2-&gt;position).<span class="built_in">norm</span>();</span><br><span class="line">    s-&gt;m1-&gt;forces += -s-&gt;k * (s-&gt;m1-&gt;position - s-&gt;m2-&gt;position) / mod_ab *</span><br><span class="line">                     (mod_ab - s-&gt;rest_length);</span><br><span class="line">    s-&gt;m2-&gt;forces += -s-&gt;k * (s-&gt;m2-&gt;position - s-&gt;m1-&gt;position) / mod_ab *</span><br><span class="line">                     (mod_ab - s-&gt;rest_length);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;m : masses) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!m-&gt;pinned) &#123;</span><br><span class="line">      Vector2D temp_position = m-&gt;position;</span><br><span class="line">      <span class="comment">// TODO (Part 3.1): Set the new position of the rope mass</span></span><br><span class="line">      <span class="keyword">auto</span> a = m-&gt;forces / m-&gt;mass + gravity;</span><br><span class="line">      <span class="comment">// TODO (Part 4): Add global Verlet damping</span></span><br><span class="line">      m-&gt;position = temp_position + (temp_position - m-&gt;last_position) +</span><br><span class="line">                    a * <span class="keyword">delta_t</span> * <span class="keyword">delta_t</span>;</span><br><span class="line">      m-&gt;last_position = temp_position;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reset all forces on each mass</span></span><br><span class="line">    m-&gt;forces = <span class="built_in">Vector2D</span>(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Rope::simulateVerlet</span><span class="params">(<span class="keyword">float</span> <span class="keyword">delta_t</span>, Vector2D gravity)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;s : springs) &#123;</span><br><span class="line">    <span class="comment">// TODO (Part 3): Simulate one timestep of the rope using explicit Verlet</span></span><br><span class="line">    <span class="comment">// （solving constraints)</span></span><br><span class="line">    <span class="keyword">auto</span> mod_ab = (s-&gt;m1-&gt;position - s-&gt;m2-&gt;position).<span class="built_in">norm</span>();</span><br><span class="line">    s-&gt;m1-&gt;forces += -s-&gt;k * (s-&gt;m1-&gt;position - s-&gt;m2-&gt;position) / mod_ab *</span><br><span class="line">                     (mod_ab - s-&gt;rest_length);</span><br><span class="line">    s-&gt;m2-&gt;forces += -s-&gt;k * (s-&gt;m2-&gt;position - s-&gt;m1-&gt;position) / mod_ab *</span><br><span class="line">                     (mod_ab - s-&gt;rest_length);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> damping_factor = <span class="number">0.00005</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;m : masses) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!m-&gt;pinned) &#123;</span><br><span class="line">      Vector2D temp_position = m-&gt;position;</span><br><span class="line">      <span class="comment">// TODO (Part 3.1): Set the new position of the rope mass</span></span><br><span class="line">      <span class="keyword">auto</span> a = m-&gt;forces / m-&gt;mass + gravity;</span><br><span class="line">      <span class="comment">// TODO (Part 4): Add global Verlet damping</span></span><br><span class="line">      m-&gt;position = temp_position +</span><br><span class="line">                    (<span class="number">1</span> - damping_factor) * (temp_position - m-&gt;last_position) +</span><br><span class="line">                    a * <span class="keyword">delta_t</span> * <span class="keyword">delta_t</span>;</span><br><span class="line">      m-&gt;last_position = temp_position;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reset all forces on each mass</span></span><br><span class="line">    m-&gt;forces = <span class="built_in">Vector2D</span>(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><h4 id="缓冲对象"><a href="#缓冲对象" class="headerlink" title="缓冲对象"></a>缓冲对象</h4><p>比如顶点缓冲对象,顶点数组对象.</p><p>定义顶点数据以后，我们会把它作为输入发送给图形渲染管线的第一个处理阶段：<strong>顶点着色器</strong>。它<strong>会在GPU上创建内存用于储存我们的顶点数据，还要配置OpenGL如何解释这些内存，并且指定其如何发送给显卡</strong>。顶点着色器接着会处理我们在内存中指定数量的顶点。</p><p>通过顶点缓冲对象(Vertex Buffer Objects, VBO)管理这个内存，它会在GPU内存（通常被称为显存）中储存大量顶点。使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次。从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据。当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程。</p><h4 id="缓冲对象类型"><a href="#缓冲对象类型" class="headerlink" title="缓冲对象类型"></a>缓冲对象类型</h4><p>比如顶点缓冲对象类型,创建好的缓冲可以绑定到某种对象类型上.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> VBO;</span><br><span class="line"><span class="built_in">glGenBuffers</span>(<span class="number">1</span>, &amp;VBO);</span><br><span class="line"><span class="built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, VBO); </span><br></pre></td></tr></table></figure><p>从这一刻起，我们使用的任何（在GL_ARRAY_BUFFER目标上的）缓冲调用都会用来配置当前绑定的缓冲(VBO)。然后我们可以调用glBufferData函数，它会把之前定义的顶点数据复制到缓冲的显存中</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">glBufferData</span>(GL_ARRAY_BUFFER, <span class="built_in"><span class="keyword">sizeof</span></span>(vertices), vertices, GL_STATIC_DRAW);</span><br></pre></td></tr></table></figure><h4 id="shader与GLSL"><a href="#shader与GLSL" class="headerlink" title="shader与GLSL"></a>shader与GLSL</h4><p><strong>图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出</strong>。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个阶段的输出作为输入。所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且很容易并行执行。正是由于它们具有并行执行的特性，当今大多数显卡都有成千上万的小处理核心，<strong>它们在GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据。这些小程序叫做着色器(Shader)</strong>。</p><p>包括顶点着色器等等</p><h4 id="VAO"><a href="#VAO" class="headerlink" title="VAO"></a>VAO</h4><p>顶点数组对象(又称 VAO)可以像顶点缓冲区对象一样绑定,此后的顶点属性调用都将存储在 VAO 中.</p><h3 id="书籍和网站推荐"><a href="#书籍和网站推荐" class="headerlink" title="书籍和网站推荐"></a>书籍和网站推荐</h3><p><strong>解题参考</strong></p><p><a href="https://www.cnblogs.com/lawliet12/p/17719365.html">Games101现代计算机图形学入门 - 作业1~8 集合含提高项总结 - lawliet9 - 博客园 (cnblogs.com)</a></p><p><strong>书籍</strong></p><ol><li>Fundamentals of Computer Graphics<a href="https://github.com/FCG-Translators/FundamentalsOfComputerGraphics-CN">FCG-Translators/FundamentalsOfComputerGraphics-CN: 计算机图形学基础（中文译本） (github.com)</a></li><li><a href="https://book.douban.com/subject/35221845/">OpenGL超级宝典（第7版） (豆瓣) (douban.com)</a></li></ol><p><strong>网站</strong></p><ol><li><a href="https://learnopengl.com/">Learn OpenGL, extensive tutorial resource for learning Modern OpenGL</a></li><li><a href="https://www.scratchapixel.com/">Scratchapixel 4.0, Learn Computer Graphics Programming</a></li><li><a href="https://ogldev.org/">OpenGL Step by Step - OpenGL Development (ogldev.org)</a></li><li><a href="https://cs184.eecs.berkeley.edu/">https://cs184.eecs.berkeley.edu/</a></li><li><a href="http://15462.courses.cs.cmu.edu/fall2022/">15-462/662 Fall 2022 (cmu.edu)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;简简单单学个概念.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
