<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sekyoro的博客小屋</title>
  
  
  <link href="https://www.sekyoro.top/atom.xml" rel="self"/>
  
  <link href="https://www.sekyoro.top/"/>
  <updated>2024-02-21T13:12:30.000Z</updated>
  <id>https://www.sekyoro.top/</id>
  
  <author>
    <name>Sekyoro</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深度学习有用的库以及介绍</title>
    <link href="https://www.sekyoro.top/2024/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%89%E7%94%A8%E7%9A%84%E5%BA%93%E4%BB%A5%E5%8F%8A%E4%BB%8B%E7%BB%8D/"/>
    <id>https://www.sekyoro.top/2024/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%89%E7%94%A8%E7%9A%84%E5%BA%93%E4%BB%A5%E5%8F%8A%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-02-19T07:49:03.000Z</published>
    <updated>2024-02-21T13:12:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在看其他源代码时以及自己写代码时可能用到的有用的库以及一些常用写法.<br><span id="more"></span></p><h2 id="python自带的库"><a href="#python自带的库" class="headerlink" title="python自带的库"></a>python自带的库</h2><h3 id="itertools"><a href="#itertools" class="headerlink" title="itertools"></a>itertools</h3><p>用于迭代器的工具<a href="https://docs.python.org/zh-cn/3/library/itertools.html">itertools —- 为高效循环而创建迭代器的函数 — Python 3.12.2 文档</a></p><h3 id="functools"><a href="#functools" class="headerlink" title="functools"></a>functools</h3><p>用于处理函数的工具</p><h3 id="collections"><a href="#collections" class="headerlink" title="collections"></a>collections</h3><p>集合工具</p><h2 id="深度学习库"><a href="#深度学习库" class="headerlink" title="深度学习库"></a>深度学习库</h2><h3 id="timm"><a href="#timm" class="headerlink" title="timm"></a>timm</h3><h3 id="einops"><a href="#einops" class="headerlink" title="einops"></a>einops</h3><h3 id="from-torch-import-einsum"><a href="#from-torch-import-einsum" class="headerlink" title="from torch import einsum"></a>from torch import einsum</h3><h2 id="一些有用的资料"><a href="#一些有用的资料" class="headerlink" title="一些有用的资料"></a>一些有用的资料</h2><ol><li><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks">CS 230 - Deep Learning Tips and Tricks Cheatsheet (stanford.edu)</a></li><li><a href="https://github.com/Conchylicultor/Deep-Learning-Tricks">Conchylicultor/Deep-Learning-Tricks: Enumerate diverse machine learning training tricks. (github.com)</a></li><li><a href="https://github.com/ayyucedemirbas/Deep-Learning-Tips-and-Tricks">ayyucedemirbas/Deep-Learning-Tips-and-Tricks (github.com)</a></li><li>找一些模型代码<a href="https://github.com/huggingface/pytorch-image-models">huggingface/pytorch-image-models: PyTorch image models, scripts, pretrained weights — ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more (github.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在看其他源代码时以及自己写代码时可能用到的有用的库以及一些常用写法.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>transformer and attention(三)</title>
    <link href="https://www.sekyoro.top/2024/02/16/transformer-and-attention-%E4%B8%89/"/>
    <id>https://www.sekyoro.top/2024/02/16/transformer-and-attention-%E4%B8%89/</id>
    <published>2024-02-16T14:44:00.000Z</published>
    <updated>2024-02-21T15:14:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这里介绍一些细节信息.有关位置编码信息和用于图像的transformer.<br><span id="more"></span></p><h2 id="线性注意力"><a href="#线性注意力" class="headerlink" title="线性注意力"></a>线性注意力</h2><script type="math/tex; mode=display">Attention(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V})=softmax\left(\boldsymbol{Q}\boldsymbol{K}^\top\right)\boldsymbol{V}</script><p>其中$Q\in\mathbb{R}^{n\times d_k},\boldsymbol{K}\in\mathbb{R}^{m\times d_k},\boldsymbol{V}\in\mathbb{R}^{m\times d_v}$​,一般情况下n&gt;d甚至n&gt;&gt;d.所以如果对QK^T^进行softmax操作,复杂度为O(mn),所以去掉Softmax的Attention的复杂度可以降到最理想的线性级别Linear Attention.</p><script type="math/tex; mode=display">Attention(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V})_i=\frac{\sum_{j=1}^nsim(\boldsymbol{q}_i,\boldsymbol{k}_j)\boldsymbol{v}_j}{\sum_{j=1}^nsim(\boldsymbol{q}_i,\boldsymbol{k}_j)}</script><p>只要保证Attention相似的分布特性,要求sim(q~i~,k~j~)≥0恒成立.比如可以把核函数改为激活函数使得输出大于0.</p><p>还可以改成softmax.</p><p><img data-src="https://s2.loli.net/2024/02/17/wE3HgYJ7KnxZ5pe.png" alt="image-20240217224419083"></p><p>其中softmax1、softmax2分别指在第一个（n）、第二个维度（d）进行Softmax运算.</p><p><a href="https://spaces.ac.cn/archives/7546">线性Attention的探索：Attention必须有个Softmax吗？ - 科学空间|Scientific Spaces</a>提出将指数</p><p>e^qK^泰勒展开,$e^{\boldsymbol{q}_i^\top\boldsymbol{k}_j}\approx1+\boldsymbol{q}_i^\top\boldsymbol{k}_j$</p><p><img data-src="https://s2.loli.net/2024/02/17/fhBMIgcsqzZQt3k.png" alt="image-20240217224836831"></p><p>此外还有稀疏注意力,这里就不多介绍了.</p><h2 id="图像中的transformer与attention"><a href="#图像中的transformer与attention" class="headerlink" title="图像中的transformer与attention"></a>图像中的transformer与attention</h2><p>注意力机制以及transformer都是先在NLP领域发展,所以一般attention可能会处理一些1维数据,有CNN与transformer结合的Conformer<a href="https://arxiv.org/abs/2005.08100">[2005.08100] Conformer: Convolution-augmented Transformer for Speech Recognition (arxiv.org)</a>,conformer中的编码采用相对位置编码.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, einsum</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exists</span>(<span class="params">val</span>):</span></span><br><span class="line">    <span class="keyword">return</span> val <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">default</span>(<span class="params">val, d</span>):</span></span><br><span class="line">    <span class="keyword">return</span> val <span class="keyword">if</span> exists(val) <span class="keyword">else</span> d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Swish</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * x.sigmoid()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, mult=<span class="number">4</span>, dropout=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(dim, dim * mult),</span><br><span class="line">            Swish(),  <span class="comment"># or can be replace by nn.silu()</span></span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">            nn.Linear(dim * mult, dim),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, heads=<span class="number">8</span>, dim_head=<span class="number">64</span>, dropout=<span class="number">0.0</span>, max_pos_emb=<span class="number">512</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dim_head * heads</span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dim_head**-<span class="number">0.5</span></span><br><span class="line">        self.to_q = nn.Linear(dim, inner_dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_kv = nn.Linear(dim, inner_dim * <span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_out = nn.Linear(inner_dim, dim)</span><br><span class="line"></span><br><span class="line">        self.max_pos_emb = max_pos_emb</span><br><span class="line">        self.rel_pos_emb = nn.Embedding(<span class="number">2</span> * max_pos_emb + <span class="number">1</span>, dim_head)</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, context=<span class="literal">None</span>, mask=<span class="literal">None</span>, context_mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        n, device, h, max_pos_emb, has_context = (</span><br><span class="line">            x.shape[-<span class="number">2</span>],</span><br><span class="line">            x.device,</span><br><span class="line">            self.heads,</span><br><span class="line">            self.max_pos_emb,</span><br><span class="line">            exists(context),</span><br><span class="line">        )</span><br><span class="line">        context = default(context, x)</span><br><span class="line"></span><br><span class="line">        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(<span class="number">2</span>, dim=-<span class="number">1</span>))</span><br><span class="line">        q, k, v = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: rearrange(t, <span class="string">&quot;b n (h d) -&gt; b h n d&quot;</span>, h=h), (q, k, v))</span><br><span class="line"></span><br><span class="line">        dots = einsum(<span class="string">&quot;b h i d, b h j d -&gt; b h i j&quot;</span>, q, k) * self.scale</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shaw&#x27;s relative positional embedding</span></span><br><span class="line">        seq = torch.arange(n, device=device)</span><br><span class="line">        dist = rearrange(seq, <span class="string">&quot;i -&gt; i ()&quot;</span>) - rearrange(seq, <span class="string">&quot;j -&gt; () j&quot;</span>)</span><br><span class="line">        dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb</span><br><span class="line">        rel_pos_emb = self.rel_pos_emb(dist).to(q)</span><br><span class="line">        pos_attn = einsum(<span class="string">&quot;b h n d, n r d -&gt; b h n r&quot;</span>, q, rel_pos_emb) * self.scale</span><br><span class="line">        dots = dots + pos_attn</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> exists(mask) <span class="keyword">or</span> exists(context_mask):</span><br><span class="line">            mask = default(mask, <span class="keyword">lambda</span>: torch.ones(*x.shape[:<span class="number">2</span>], device=device))</span><br><span class="line">            context_mask = (</span><br><span class="line">                default(context_mask, mask)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> has_context</span><br><span class="line">                <span class="keyword">else</span> default(</span><br><span class="line">                    context_mask, <span class="keyword">lambda</span>: torch.ones(*context.shape[:<span class="number">2</span>], device=device)</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">            mask_value = -torch.finfo(dots.dtype).<span class="built_in">max</span></span><br><span class="line">            mask = rearrange(mask, <span class="string">&quot;b i -&gt; b () i ()&quot;</span>) * rearrange(</span><br><span class="line">                context_mask, <span class="string">&quot;b j -&gt; b () () j&quot;</span></span><br><span class="line">            )</span><br><span class="line">            dots.masked_fill_(~mask, mask_value)</span><br><span class="line"></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = einsum(<span class="string">&quot;b h i j, b h j d -&gt; b h i d&quot;</span>, attn, v)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        out = self.to_out(out)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_same_padding</span>(<span class="params">kernel_size</span>):</span></span><br><span class="line">    pad = kernel_size // <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> pad, pad - (kernel_size + <span class="number">1</span>) % <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DepthWiseConv1d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, chan_in, chan_out, kernel_size, padding</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.padding = padding</span><br><span class="line">        self.conv = nn.Conv1d(chan_in, chan_out, kernel_size, groups=chan_in)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.pad(x, self.padding)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GLU</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out, gate = x.chunk(<span class="number">2</span>, dim=self.dim)</span><br><span class="line">        <span class="keyword">return</span> out * gate.sigmoid()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConformerConvModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, dim, causal=<span class="literal">False</span>, expansion_factor=<span class="number">2</span>, kernel_size=<span class="number">31</span>, dropout=<span class="number">0.0</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dim * expansion_factor</span><br><span class="line">        padding = calc_same_padding(kernel_size) <span class="keyword">if</span> <span class="keyword">not</span> causal <span class="keyword">else</span> (kernel_size - <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            Rearrange(<span class="string">&quot;b n d -&gt; b d n&quot;</span>),</span><br><span class="line">            nn.Conv1d(dim, inner_dim * <span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">            GLU(dim=<span class="number">1</span>),</span><br><span class="line">            DepthWiseConv1d(</span><br><span class="line">                inner_dim, inner_dim, kernel_size=kernel_size, padding=padding</span><br><span class="line">            ),</span><br><span class="line">            nn.BatchNorm1d(inner_dim) <span class="keyword">if</span> <span class="keyword">not</span> causal <span class="keyword">else</span> nn.Identity(),</span><br><span class="line">            Swish(),</span><br><span class="line">            nn.Conv1d(inner_dim, dim, <span class="number">1</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b d n -&gt; b n d&quot;</span>),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scale</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, scale, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.scale = scale</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fn(x, **kwargs) * self.scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PreNorm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fn = fn</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> self.fn(x, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConformerBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        *,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_mult=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_expansion_factor=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_kernel_size=<span class="number">31</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_causal=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.ff1 = FeedForward(dim=dim, mult=ff_mult, dropout=ff_dropout)</span><br><span class="line">        self.attn = Attention(</span><br><span class="line">            dim=dim, dim_head=dim_head, heads=heads, dropout=attn_dropout</span><br><span class="line">        )</span><br><span class="line">        self.conv = ConformerConvModule(</span><br><span class="line">            dim=dim,</span><br><span class="line">            causal=conv_causal,</span><br><span class="line">            expansion_factor=conv_expansion_factor,</span><br><span class="line">            kernel_size=conv_kernel_size,</span><br><span class="line">            dropout=conv_dropout,</span><br><span class="line">        )</span><br><span class="line">        self.ff2 = FeedForward(dim=dim, mult=ff_mult, dropout=ff_dropout)</span><br><span class="line"></span><br><span class="line">        self.attn = PreNorm(dim, self.attn)</span><br><span class="line">        self.ff1 = Scale(<span class="number">0.5</span>, PreNorm(dim, self.ff1))</span><br><span class="line">        self.ff2 = Scale(<span class="number">0.5</span>, PreNorm(dim, self.ff2))</span><br><span class="line"></span><br><span class="line">        self.post_norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        x = self.ff1(x) + x</span><br><span class="line">        x = self.attn(x, mask=mask) + x</span><br><span class="line">        x = self.conv(x) + x</span><br><span class="line">        x = self.ff2(x) + x</span><br><span class="line">        x = self.post_norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        *,</span></span></span><br><span class="line"><span class="params"><span class="function">        depth,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_mult=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_expansion_factor=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_kernel_size=<span class="number">31</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_causal=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(</span><br><span class="line">                ConformerBlock(</span><br><span class="line">                    dim=dim,</span><br><span class="line">                    dim_head=dim_head,</span><br><span class="line">                    heads=heads,</span><br><span class="line">                    ff_mult=ff_mult,</span><br><span class="line">                    conv_expansion_factor=conv_expansion_factor,</span><br><span class="line">                    conv_kernel_size=conv_kernel_size,</span><br><span class="line">                    conv_causal=conv_causal,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = block(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上一节中其实已经充分使用了feature map也就是二维数据上的注意力机制,现在介绍一下在视觉领域表现出色的transformer及其变体.</p><h2 id="Vision-Transformer"><a href="#Vision-Transformer" class="headerlink" title="Vision Transformer"></a>Vision Transformer</h2><p><img data-src="https://s2.loli.net/2024/02/17/mdybruOEWxgSDVt.png" alt="image-20240217121859843"></p><p>将transformer拿到CV领域的出名作品,通过patch embedding得到序列,再加上位置编码就能像在nlp一样处理问题.</p><p><img data-src="https://pic1.zhimg.com/80/v2-1c6aa554d8fc53daa7bf79c755b1f86c_720w.webp" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="comment"># helpers</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pair</span>(<span class="params">t</span>):</span></span><br><span class="line">    <span class="keyword">return</span> t <span class="keyword">if</span> <span class="built_in">isinstance</span>(t, <span class="built_in">tuple</span>) <span class="keyword">else</span> (t, t)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">posemb_sincos_2d</span>(<span class="params">h, w, dim, temperature: <span class="built_in">int</span> = <span class="number">10000</span>, dtype=torch.float32</span>):</span></span><br><span class="line">    y, x = torch.meshgrid(torch.arange(h), torch.arange(w), indexing=<span class="string">&quot;ij&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> (dim % <span class="number">4</span>) == <span class="number">0</span>, <span class="string">&quot;feature dimension must be multiple of 4 for sincos emb&quot;</span></span><br><span class="line">    omega = torch.arange(dim // <span class="number">4</span>) / (dim // <span class="number">4</span> - <span class="number">1</span>)</span><br><span class="line">    omega = <span class="number">1.0</span> / (temperature**omega)</span><br><span class="line"></span><br><span class="line">    y = y.flatten()[:, <span class="literal">None</span>] * omega[<span class="literal">None</span>, :]</span><br><span class="line">    x = x.flatten()[:, <span class="literal">None</span>] * omega[<span class="literal">None</span>, :]</span><br><span class="line">    pe = torch.cat((x.sin(), x.cos(), y.sin(), y.cos()), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pe.<span class="built_in">type</span>(dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># classes</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, hidden_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            nn.Linear(dim, hidden_dim),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Linear(hidden_dim, dim),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, heads=<span class="number">8</span>, dim_head=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dim_head * heads</span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dim_head**-<span class="number">0.5</span></span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">        self.attend = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.to_qkv = nn.Linear(dim, inner_dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_out = nn.Linear(inner_dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line"></span><br><span class="line">        qkv = self.to_qkv(x).chunk(<span class="number">3</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        q, k, v = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: rearrange(t, <span class="string">&quot;b n (h d) -&gt; b h n d&quot;</span>, h=self.heads), qkv)</span><br><span class="line"></span><br><span class="line">        dots = torch.matmul(q, k.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) * self.scale</span><br><span class="line"></span><br><span class="line">        attn = self.attend(dots)</span><br><span class="line"></span><br><span class="line">        out = torch.matmul(attn, v)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> self.to_out(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, depth, heads, dim_head, mlp_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(</span><br><span class="line">                nn.ModuleList(</span><br><span class="line">                    [</span><br><span class="line">                        Attention(dim, heads=heads, dim_head=dim_head),</span><br><span class="line">                        FeedForward(dim, mlp_dim),</span><br><span class="line">                    ]</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> attn, ff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x) + x</span><br><span class="line">            x = ff(x) + x</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleViT</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        *,</span></span></span><br><span class="line"><span class="params"><span class="function">        image_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        patch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_classes,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        depth,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        channels=<span class="number">3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        image_height, image_width = pair(image_size)</span><br><span class="line">        patch_height, patch_width = pair(patch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            image_height % patch_height == <span class="number">0</span> <span class="keyword">and</span> image_width % patch_width == <span class="number">0</span></span><br><span class="line">        ), <span class="string">&quot;Image dimensions must be divisible by the patch size.&quot;</span></span><br><span class="line"></span><br><span class="line">        patch_dim = channels * patch_height * patch_width</span><br><span class="line"></span><br><span class="line">        self.to_patch_embedding = nn.Sequential(</span><br><span class="line">            Rearrange(</span><br><span class="line">                <span class="string">&quot;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&quot;</span>,</span><br><span class="line">                p1=patch_height,</span><br><span class="line">                p2=patch_width,</span><br><span class="line">            ),</span><br><span class="line">            nn.LayerNorm(patch_dim),</span><br><span class="line">            nn.Linear(patch_dim, dim),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pos_embedding = posemb_sincos_2d(</span><br><span class="line">            h=image_height // patch_height,</span><br><span class="line">            w=image_width // patch_width,</span><br><span class="line">            dim=dim,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)</span><br><span class="line"></span><br><span class="line">        self.pool = <span class="string">&quot;mean&quot;</span></span><br><span class="line">        self.to_latent = nn.Identity()</span><br><span class="line"></span><br><span class="line">        self.linear_head = nn.Linear(dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        device = img.device</span><br><span class="line"></span><br><span class="line">        x = self.to_patch_embedding(img)</span><br><span class="line">        x += self.pos_embedding.to(device, dtype=x.dtype)</span><br><span class="line"></span><br><span class="line">        x = self.transformer(x)</span><br><span class="line">        x = x.mean(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.to_latent(x)</span><br><span class="line">        <span class="keyword">return</span> self.linear_head(x)</span><br></pre></td></tr></table></figure><p>上面做了patch之后的位置编码使用三角函数绝对编码,attention和feednetwork与transformer没有什么差别.</p><h2 id="卷积注意力"><a href="#卷积注意力" class="headerlink" title="卷积注意力"></a>卷积注意力</h2><p>使用vision transformer中使用的绝对位置注意力,但是也可以使用相对位置注意力或者卷积注意力.</p><blockquote><p>卷积位置嵌入( CPE )方法考虑了输入序列的2D性质。采用补零的方式进行2D卷积采集位置信息。卷积位置嵌入( Convolutional Position嵌入，CPE )可用于合并ViT不同阶段的位置数据。CPE可以具体引入到自注意力模块，前馈网络，或者在两个编码器层之间的。</p></blockquote><p>卷积注意力通常方法是利用2D卷积或者depth-wise的卷积将已经做了patch的图像数据进行处理.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvolutionalPositionEmbedding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(d_model, d_model, kernel_size, padding=padding)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 将通道维度和序列长度维度交换</span></span><br><span class="line">        x = x.unsqueeze(<span class="number">2</span>)  <span class="comment"># 在通道维度和序列长度维度之间添加一个维度</span></span><br><span class="line">        x = self.conv(x)  <span class="comment"># 对输入进行卷积操作</span></span><br><span class="line">        x = x.squeeze(<span class="number">2</span>)  <span class="comment"># 移除添加的维度</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 将通道维度和序列长度维度交换回来</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="CVT"><a href="#CVT" class="headerlink" title="CVT"></a>CVT</h3><p><img data-src="https://github.com/rishikksh20/convolution-vision-transformers/raw/master/assets/model.PNG" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#   #!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#   #-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#  Copyleft (C) 2024 proanimer, Inc. All Rights Reserved</span></span><br><span class="line"><span class="comment">#   author:proanimer</span></span><br><span class="line"><span class="comment">#   createTime:2024/2/18 上午10:38</span></span><br><span class="line"><span class="comment">#   lastModifiedTime:2024/2/18 上午10:38</span></span><br><span class="line"><span class="comment">#   file:cvt.py</span></span><br><span class="line"><span class="comment">#   software: classicNets</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange, repeat</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> einsum</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SepConv2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">        out_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">        kernel_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        padding=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dilation=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SepConv2d, self).__init__()</span><br><span class="line">        self.depthwise = torch.nn.Conv2d(</span><br><span class="line">            in_channels,</span><br><span class="line">            in_channels,</span><br><span class="line">            kernel_size=kernel_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            padding=padding,</span><br><span class="line">            dilation=dilation,</span><br><span class="line">            groups=in_channels,</span><br><span class="line">        )</span><br><span class="line">        self.bn = torch.nn.BatchNorm2d(in_channels)</span><br><span class="line">        self.pointwise = torch.nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.depthwise(x)</span><br><span class="line">        x = self.bn(x)</span><br><span class="line">        x = self.pointwise(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fn(x, **kwargs) + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PreNorm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fn(self.norm(x), **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, hidden_dim, dropout=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(dim, hidden_dim),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">            nn.Linear(hidden_dim, dim),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        img_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        kernel_size=<span class="number">3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        q_stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        k_stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        v_stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        last_stage=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.last_stage = last_stage</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        inner_dim = dim_head * heads</span><br><span class="line">        project_out = <span class="keyword">not</span> (heads == <span class="number">1</span> <span class="keyword">and</span> dim_head == dim)</span><br><span class="line"></span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dim_head**-<span class="number">0.5</span></span><br><span class="line">        pad = (kernel_size - q_stride) // <span class="number">2</span></span><br><span class="line">        self.to_q = SepConv2d(dim, inner_dim, kernel_size, q_stride, pad)</span><br><span class="line">        self.to_k = SepConv2d(dim, inner_dim, kernel_size, k_stride, pad)</span><br><span class="line">        self.to_v = SepConv2d(dim, inner_dim, kernel_size, v_stride, pad)</span><br><span class="line"></span><br><span class="line">        self.to_out = (</span><br><span class="line">            nn.Sequential(nn.Linear(inner_dim, dim), nn.Dropout(dropout))</span><br><span class="line">            <span class="keyword">if</span> project_out</span><br><span class="line">            <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        b, n, _, h = *x.shape, self.heads</span><br><span class="line">        <span class="keyword">if</span> self.last_stage:</span><br><span class="line">            cls_token = x[:, <span class="number">0</span>]</span><br><span class="line">            x = x[:, <span class="number">1</span>:]</span><br><span class="line">            cls_token = rearrange(cls_token.unsqueeze(<span class="number">1</span>), <span class="string">&quot;b n (h d) -&gt; b h n d&quot;</span>, h=h)</span><br><span class="line">        x = rearrange(x, <span class="string">&quot;b (l w) n -&gt; b n l w&quot;</span>, l=self.img_size, w=self.img_size)</span><br><span class="line">        q = self.to_q(x)</span><br><span class="line">        q = rearrange(q, <span class="string">&quot;b (h d) l w -&gt; b h (l w) d&quot;</span>, h=h)</span><br><span class="line"></span><br><span class="line">        v = self.to_v(x)</span><br><span class="line">        v = rearrange(v, <span class="string">&quot;b (h d) l w -&gt; b h (l w) d&quot;</span>, h=h)</span><br><span class="line"></span><br><span class="line">        k = self.to_k(x)</span><br><span class="line">        k = rearrange(k, <span class="string">&quot;b (h d) l w -&gt; b h (l w) d&quot;</span>, h=h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.last_stage:</span><br><span class="line">            q = torch.cat((cls_token, q), dim=<span class="number">2</span>)</span><br><span class="line">            v = torch.cat((cls_token, v), dim=<span class="number">2</span>)</span><br><span class="line">            k = torch.cat((cls_token, k), dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        dots = einsum(<span class="string">&quot;b h i d, b h j d -&gt; b h i j&quot;</span>, q, k) * self.scale</span><br><span class="line"></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = einsum(<span class="string">&quot;b h i j, b h j d -&gt; b h i d&quot;</span>, attn, v)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        out = self.to_out(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        img_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        depth,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head,</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        last_stage=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(</span><br><span class="line">                nn.ModuleList(</span><br><span class="line">                    [</span><br><span class="line">                        PreNorm(</span><br><span class="line">                            dim,</span><br><span class="line">                            ConvAttention(</span><br><span class="line">                                dim,</span><br><span class="line">                                img_size,</span><br><span class="line">                                heads=heads,</span><br><span class="line">                                dim_head=dim_head,</span><br><span class="line">                                dropout=dropout,</span><br><span class="line">                                last_stage=last_stage,</span><br><span class="line">                            ),</span><br><span class="line">                        ),</span><br><span class="line">                        PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout)),</span><br><span class="line">                    ]</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> attn, ff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x) + x</span><br><span class="line">            x = ff(x) + x</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cvt</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        image_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_classes,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        kernels=[<span class="number">7</span>, <span class="number">3</span>, <span class="number">3</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        strides=[<span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        depth=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">10</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        pool=<span class="string">&quot;cls&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        emb_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        scale_dim=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>(cvt, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> pool <span class="keyword">in</span> &#123;</span><br><span class="line">            <span class="string">&quot;cls&quot;</span>,</span><br><span class="line">            <span class="string">&quot;mean&quot;</span>,</span><br><span class="line">        &#125;, <span class="string">&quot;pool type must be either cls (cls token) or mean (mean pooling)&quot;</span></span><br><span class="line">        self.pool = pool</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.stage1_conv_embed = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, dim, kernels[<span class="number">0</span>], strides[<span class="number">0</span>], <span class="number">2</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b c h w -&gt; b (h w) c&quot;</span>, h=image_size // <span class="number">4</span>, w=image_size // <span class="number">4</span>),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line">        self.stage_1_transformer = nn.Sequential(</span><br><span class="line">            Transformer(</span><br><span class="line">                dim,</span><br><span class="line">                img_size=image_size // <span class="number">4</span>,</span><br><span class="line">                depth=depth[<span class="number">0</span>],</span><br><span class="line">                heads=heads[<span class="number">0</span>],</span><br><span class="line">                dim_head=dim // heads[<span class="number">0</span>],</span><br><span class="line">                mlp_dim=dim * scale_dim,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                last_stage=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">            Rearrange(<span class="string">&quot;b (h w) c -&gt; b c h w&quot;</span>, h=image_size // <span class="number">4</span>, w=image_size // <span class="number">4</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#     stage 2</span></span><br><span class="line">        in_channels = dim</span><br><span class="line">        scale = heads[<span class="number">1</span>] // heads[<span class="number">0</span>]</span><br><span class="line">        dim = scale * dim</span><br><span class="line">        self.stage2_conv_embed = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, dim, kernels[<span class="number">1</span>], strides[<span class="number">1</span>], <span class="number">1</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b c h w -&gt; b (h w) c&quot;</span>, h=image_size // <span class="number">8</span>, w=image_size // <span class="number">8</span>),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line">        self.stage_2_transformer = nn.Sequential(</span><br><span class="line">            Transformer(</span><br><span class="line">                dim,</span><br><span class="line">                img_size=image_size // <span class="number">8</span>,</span><br><span class="line">                depth=depth[<span class="number">1</span>],</span><br><span class="line">                heads=heads[<span class="number">1</span>],</span><br><span class="line">                dim_head=dim // heads[<span class="number">1</span>],</span><br><span class="line">                mlp_dim=dim * scale_dim,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                last_stage=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">            Rearrange(<span class="string">&quot;b (h w) c -&gt; b c h w&quot;</span>, h=image_size // <span class="number">8</span>, w=image_size // <span class="number">8</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#     stage 3</span></span><br><span class="line">        in_channels = dim</span><br><span class="line">        scale = heads[<span class="number">2</span>] // heads[<span class="number">1</span>]</span><br><span class="line">        dim = scale * dim</span><br><span class="line">        self.stage3_conv_embed = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, dim, kernels[<span class="number">2</span>], strides[<span class="number">2</span>], <span class="number">1</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b c h w -&gt; b (h w) c&quot;</span>, h=image_size // <span class="number">16</span>, w=image_size // <span class="number">16</span>),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line">        self.stage_3_transformer = nn.Sequential(</span><br><span class="line">            Transformer(</span><br><span class="line">                dim=dim,</span><br><span class="line">                img_size=image_size // <span class="number">16</span>,</span><br><span class="line">                depth=depth[<span class="number">2</span>],</span><br><span class="line">                heads=heads[<span class="number">2</span>],</span><br><span class="line">                dim_head=self.dim,</span><br><span class="line">                mlp_dim=dim * scale_dim,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                last_stage=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">        self.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))</span><br><span class="line">        self.drop_large = nn.Dropout(emb_dropout)</span><br><span class="line"></span><br><span class="line">        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,img</span>):</span></span><br><span class="line">        xs = self.stage1_conv_embed(img)</span><br><span class="line">        xs = self.stage1_transformer(xs)</span><br><span class="line"></span><br><span class="line">        xs = self.stage2_conv_embed(xs)</span><br><span class="line">        xs = self.stage2_transformer(xs)</span><br><span class="line"></span><br><span class="line">        xs = self.stage3_conv_embed(xs)</span><br><span class="line">        b, n, _ = xs.shape</span><br><span class="line">        cls_tokens = repeat(self.cls_token, <span class="string">&#x27;() n d -&gt; b n d&#x27;</span>, b=b)</span><br><span class="line">        xs = torch.cat((cls_tokens, xs), dim=<span class="number">1</span>)</span><br><span class="line">        xs = self.stage3_transformer(xs)</span><br><span class="line">        xs = xs.mean(dim=<span class="number">1</span>) <span class="keyword">if</span> self.pool == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> xs[:, <span class="number">0</span>]</span><br><span class="line">        xs = self.mlp_head(xs)</span><br><span class="line">        <span class="keyword">return</span> xs</span><br></pre></td></tr></table></figure><h3 id="PVT"><a href="#PVT" class="headerlink" title="PVT"></a>PVT</h3><p><img data-src="https://s2.loli.net/2024/02/18/w8EUDyAJ4sIv51n.png" alt="image-20240218105527163"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#   #!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#   #-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#  Copyleft (C) 2024 proanimer, Inc. All Rights Reserved</span></span><br><span class="line"><span class="comment">#   author:proanimer</span></span><br><span class="line"><span class="comment">#   createTime:2024/2/18 下午2:22</span></span><br><span class="line"><span class="comment">#   lastModifiedTime:2024/2/18 下午2:22</span></span><br><span class="line"><span class="comment">#   file:pvt.py</span></span><br><span class="line"><span class="comment">#   software: classicNets</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> timm.models.layers <span class="keyword">import</span> DropPath, to_2tuple, trunc_normal_</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mlp</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_features,</span></span></span><br><span class="line"><span class="params"><span class="function">        hidden_features=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        out_features=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        act_layer=nn.GELU,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qkv_bias=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qk_scale=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        proj_drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        sr_ratio=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            dim % num_heads == <span class="number">0</span></span><br><span class="line">        ), <span class="string">f&quot;dim <span class="subst">&#123;dim&#125;</span> should be divided by num_heads <span class="subst">&#123;num_heads&#125;</span>.&quot;</span></span><br><span class="line"></span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        self.scale = qk_scale <span class="keyword">or</span> head_dim**-<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.q = nn.Linear(dim, dim, bias=qkv_bias)</span><br><span class="line">        self.kv = nn.Linear(dim, dim * <span class="number">2</span>, bias=qkv_bias)</span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop)</span><br><span class="line"></span><br><span class="line">        self.sr_ratio = sr_ratio</span><br><span class="line">        <span class="keyword">if</span> sr_ratio &gt; <span class="number">1</span>:</span><br><span class="line">            self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)</span><br><span class="line">            self.norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, H, W</span>):</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        q = (</span><br><span class="line">            self.q(x)</span><br><span class="line">            .reshape(B, N, self.num_heads, C // self.num_heads)</span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.sr_ratio &gt; <span class="number">1</span>:</span><br><span class="line">            x_ = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(B, C, H, W)</span><br><span class="line">            x_ = self.sr(x_).reshape(B, C, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">            x_ = self.norm(x_)</span><br><span class="line">            kv = (</span><br><span class="line">                self.kv(x_)</span><br><span class="line">                .reshape(B, -<span class="number">1</span>, <span class="number">2</span>, self.num_heads, C // self.num_heads)</span><br><span class="line">                .permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            kv = (</span><br><span class="line">                self.kv(x)</span><br><span class="line">                .reshape(B, -<span class="number">1</span>, <span class="number">2</span>, self.num_heads, C // self.num_heads)</span><br><span class="line">                .permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">            )</span><br><span class="line">        k, v = kv[<span class="number">0</span>], kv[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale  <span class="comment"># q (B,H,N,C)  K(B,H,C,N)</span></span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = self.attn_drop(attn)</span><br><span class="line"></span><br><span class="line">        x = (</span><br><span class="line">            (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)</span><br><span class="line">        )  <span class="comment"># (B,H,N,N) @ (B,H,N,C) -&gt; (B,H,N,C)</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        x = self.proj_drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_ratio=<span class="number">4.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qkv_bias=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qk_scale=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop_path=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        act_layer=nn.GELU,</span></span></span><br><span class="line"><span class="params"><span class="function">        norm_layer=nn.LayerNorm,</span></span></span><br><span class="line"><span class="params"><span class="function">        sr_ratio=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm1 = norm_layer(dim)</span><br><span class="line">        self.attn = Attention(</span><br><span class="line">            dim,</span><br><span class="line">            num_heads=num_heads,</span><br><span class="line">            qkv_bias=qkv_bias,</span><br><span class="line">            qk_scale=qk_scale,</span><br><span class="line">            attn_drop=attn_drop,</span><br><span class="line">            proj_drop=drop,</span><br><span class="line">            sr_ratio=sr_ratio,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> drop path for stochastic depth, we shall see if this is better than dropout here</span></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.norm2 = norm_layer(dim)</span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        self.mlp = Mlp(</span><br><span class="line">            in_features=dim,</span><br><span class="line">            hidden_features=mlp_hidden_dim,</span><br><span class="line">            act_layer=act_layer,</span><br><span class="line">            drop=drop,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, H, W</span>):</span></span><br><span class="line">        x = x + self.drop_path(self.attn(self.norm1(x), H, W))</span><br><span class="line">        x = x + self.drop_path(self.mlp(self.norm2(x)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PatchEmbed</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Image to Patch Embedding&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        patch_size = to_2tuple(patch_size)</span><br><span class="line"></span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            img_size[<span class="number">0</span>] % patch_size[<span class="number">0</span>] == <span class="number">0</span> <span class="keyword">and</span> img_size[<span class="number">1</span>] % patch_size[<span class="number">1</span>] == <span class="number">0</span></span><br><span class="line">        ), <span class="string">f&quot;img_size <span class="subst">&#123;img_size&#125;</span> should be divided by patch_size <span class="subst">&#123;patch_size&#125;</span>.&quot;</span></span><br><span class="line">        self.H, self.W = img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>]</span><br><span class="line">        self.num_patches = self.H * self.W</span><br><span class="line">        self.proj = nn.Conv2d(</span><br><span class="line">            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size</span><br><span class="line">        )</span><br><span class="line">        self.norm = nn.LayerNorm(embed_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line"></span><br><span class="line">        x = (</span><br><span class="line">            self.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        )  <span class="comment"># B,C,H,W-&gt;B,embed_dim,seq*seq-&gt;B,seq*seq,embed_dim</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        H, W = H // self.patch_size[<span class="number">0</span>], W // self.patch_size[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, (H, W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyramidVisionTransformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        img_size=<span class="number">224</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        patch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_chans=<span class="number">3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_classes=<span class="number">1000</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        embed_dims=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        num_heads=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_ratios=[<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        qkv_bias=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qk_scale=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_drop_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop_path_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        norm_layer=nn.LayerNorm,</span></span></span><br><span class="line"><span class="params"><span class="function">        depths=[<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        sr_ratios=[<span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        F4=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_stages=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.depths = depths</span><br><span class="line">        self.F4 = F4</span><br><span class="line">        self.num_stages = num_stages</span><br><span class="line"></span><br><span class="line">        dpr = [</span><br><span class="line">            x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))</span><br><span class="line">        ]  <span class="comment"># stochastic depth decay rule</span></span><br><span class="line">        cur = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_stages):</span><br><span class="line">            patch_embed = PatchEmbed(</span><br><span class="line">                img_size=img_size <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> img_size // (<span class="number">2</span> ** (i + <span class="number">1</span>)),</span><br><span class="line">                patch_size=patch_size <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="number">2</span>,</span><br><span class="line">                in_chans=in_chans <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> embed_dims[i - <span class="number">1</span>],</span><br><span class="line">                embed_dim=embed_dims[i],</span><br><span class="line">            )  <span class="comment"># [B,seq=num_patches,dim=patch_size**2*embed_dim]</span></span><br><span class="line">            num_patches = (</span><br><span class="line">                patch_embed.num_patches</span><br><span class="line">                <span class="keyword">if</span> i != num_stages - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span> patch_embed.num_patches + <span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches, embed_dims[i]))</span><br><span class="line">            pos_drop = nn.Dropout(p=drop_rate)</span><br><span class="line"></span><br><span class="line">            block = nn.ModuleList(</span><br><span class="line">                [</span><br><span class="line">                    Block(</span><br><span class="line">                        dim=embed_dims[i],</span><br><span class="line">                        num_heads=num_heads[i],</span><br><span class="line">                        mlp_ratio=mlp_ratios[i],</span><br><span class="line">                        qkv_bias=qkv_bias,</span><br><span class="line">                        qk_scale=qk_scale,</span><br><span class="line">                        drop=drop_rate,</span><br><span class="line">                        attn_drop=attn_drop_rate,</span><br><span class="line">                        drop_path=dpr[cur + j],</span><br><span class="line">                        norm_layer=norm_layer,</span><br><span class="line">                        sr_ratio=sr_ratios[i],</span><br><span class="line">                    )</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(depths[i])</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line">            cur += depths[i]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;patch_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, patch_embed)</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;pos_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, pos_embed)</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;pos_drop<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, pos_drop)</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;block<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, block)</span><br><span class="line"></span><br><span class="line">            trunc_normal_(pos_embed, std=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># init weights</span></span><br><span class="line">        self.apply(self._init_weights)</span><br><span class="line">        <span class="comment"># self.init_weights(pretrained)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_weights</span>(<span class="params">self, m</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">            trunc_normal_(m.weight, std=<span class="number">0.02</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_pos_embed</span>(<span class="params">self, pos_embed, patch_embed, H, W</span>):</span></span><br><span class="line">        <span class="keyword">if</span> H * W == self.patch_embed1.num_patches:</span><br><span class="line">            <span class="keyword">return</span> pos_embed</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (</span><br><span class="line">                F.interpolate(</span><br><span class="line">                    pos_embed.reshape(<span class="number">1</span>, patch_embed.H, patch_embed.W, -<span class="number">1</span>).permute(</span><br><span class="line">                        <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">                    ),</span><br><span class="line">                    size=(H, W),</span><br><span class="line">                    mode=<span class="string">&quot;bilinear&quot;</span>,</span><br><span class="line">                )</span><br><span class="line">                .reshape(<span class="number">1</span>, -<span class="number">1</span>, H * W)</span><br><span class="line">                .permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        outs = []</span><br><span class="line">        B = x.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_stages):</span><br><span class="line">            patch_embed = <span class="built_in">getattr</span>(self, <span class="string">f&quot;patch_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            pos_embed = <span class="built_in">getattr</span>(self, <span class="string">f&quot;pos_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            pos_drop = <span class="built_in">getattr</span>(self, <span class="string">f&quot;pos_drop<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            block = <span class="built_in">getattr</span>(self, <span class="string">f&quot;block<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            x, (H, W) = patch_embed(x)</span><br><span class="line">            <span class="keyword">if</span> i == self.num_stages - <span class="number">1</span>:</span><br><span class="line">                pos_embed = self._get_pos_embed(pos_embed[:, <span class="number">1</span>:], patch_embed, H, W)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pos_embed = self._get_pos_embed(pos_embed, patch_embed, H, W)</span><br><span class="line"></span><br><span class="line">            x = pos_drop(x + pos_embed)</span><br><span class="line">            <span class="keyword">for</span> blk <span class="keyword">in</span> block:</span><br><span class="line">                x = blk(x, H, W)</span><br><span class="line">            x = x.reshape(B, H, W, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>).contiguous()</span><br><span class="line">            outs.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.forward_features(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.F4:</span><br><span class="line">            x = x[<span class="number">3</span>:<span class="number">4</span>]</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="PVT-v2"><a href="#PVT-v2" class="headerlink" title="PVT v2"></a>PVT v2</h3><p><a href="https://arxiv.org/pdf/2106.13797.pdf">2106.13797.pdf (arxiv.org)</a>对之前的pvt进行了改进,包括空间大小降低放的方法,patch embdedding改为了有重叠区域的patch embedding.FeedNetwork中加了depth-wise卷积.</p><p><img data-src="https://s2.loli.net/2024/02/21/buMGx8v6TfNOQht.png" alt="image-20240221212026465"></p><p><img data-src="https://s2.loli.net/2024/02/21/OhtbAGq8NgvKnEX.png" alt="image-20240221212055900"></p><h3 id="CPVT中的PEG"><a href="#CPVT中的PEG" class="headerlink" title="CPVT中的PEG"></a>CPVT中的PEG</h3><p><img data-src="https://s2.loli.net/2024/02/19/LHY9bVrE8w2DlZs.png" alt="image-20240219150034479"></p><p>conditional position encoding</p><p><img data-src="https://s2.loli.net/2024/02/18/cfmP5yO41sN6h8o.png" alt="image-20240218103528794"></p><p>出自论文<a href="https://arxiv.org/pdf/2102.10882.pdf">2102.10882.pdf (arxiv.org)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PEG</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim=<span class="number">256</span>, k=<span class="number">3</span></span>):</span></span><br><span class="line">        self.proj = nn.Conv2d(dim, dim, k, <span class="number">1</span>, k//<span class="number">2</span>, groups=dim)</span><br><span class="line">        <span class="comment"># Only for demo use, more complicated functions are effective too.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, H, W</span>):</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        cls_token, feat_token = x[:, <span class="number">0</span>], x[:, <span class="number">1</span>:] <span class="comment"># cls token不参与PEG</span></span><br><span class="line">        cnn_feat = feat_token.transpose(<span class="number">1</span>, <span class="number">2</span>).view(B, C, H, W)</span><br><span class="line">        x = self.proj(cnn_feat) + cnn_feat <span class="comment"># 产生PE加上自身</span></span><br><span class="line">        x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = torch.cat((cls_token.unsqueeze(<span class="number">1</span>), x), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VisionTransformer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">layers=<span class="number">12</span>, dim=<span class="number">192</span>, nhead=<span class="number">3</span>, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span></span>):</span></span><br><span class="line">        self.pos_block = PEG(dim)</span><br><span class="line">        self.blocks = nn.ModuleList([TransformerEncoderLayer(dim</span><br><span class="line">, nhead, dim*<span class="number">4</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(layers)])</span><br><span class="line">        self.patch_embed = PatchEmbed(img_size, patch_size, dim</span><br><span class="line">*<span class="number">4</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        x, patch_size = self.patch_embed(x)</span><br><span class="line">        _H, _W = H // patch_size, W // patch_size</span><br><span class="line">        x = torch.cat((self.cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i, blk <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.blocks):</span><br><span class="line">            x = blk(x)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>: <span class="comment"># 第一个encoder之后施加PEG</span></span><br><span class="line">                x = self.pos_block(x, _H, _W)</span><br><span class="line">        <span class="keyword">return</span> x[:, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><h3 id="LocalVit"><a href="#LocalVit" class="headerlink" title="LocalVit"></a>LocalVit</h3><p><img data-src="https://s2.loli.net/2024/02/18/ncu63LwS7bKhl8j.png" alt="image-20240218105718876"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, depth, heads, dim_head, patch_height, patch_width, scale = <span class="number">4</span>, depth_kernel = <span class="number">3</span>, dropout = <span class="number">0.</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(nn.ModuleList([</span><br><span class="line">                Residual(PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout))),</span><br><span class="line">                Residual(PreNorm(dim, ConvFF(dim, scale, depth_kernel, patch_height, patch_width)))</span><br><span class="line">            ]))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> attn, convff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x)</span><br><span class="line">            cls_tokens = x[:, <span class="number">0</span>]</span><br><span class="line">            x = convff(x[:, <span class="number">1</span>:])</span><br><span class="line">            x = torch.cat((cls_tokens.unsqueeze(<span class="number">1</span>), x), dim=<span class="number">1</span>) </span><br><span class="line">        <span class="keyword">return</span> xclass ConvFF(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim = <span class="number">192</span>, scale = <span class="number">4</span>, depth_kernel = <span class="number">3</span>, patch_height = <span class="number">14</span>, patch_width = <span class="number">14</span>, dropout=<span class="number">0.</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        scale_dim = dim*scale</span><br><span class="line">        self.up_proj = nn.Sequential(</span><br><span class="line">                                    Rearrange(<span class="string">&#x27;b (h w) c -&gt; b c h w&#x27;</span>, h=patch_height, w=patch_width),</span><br><span class="line">                                    nn.Conv2d(dim, scale_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                                    nn.Hardswish()</span><br><span class="line">                                    )</span><br><span class="line">        </span><br><span class="line">        self.depth_conv = nn.Sequential(</span><br><span class="line">                        nn.Conv2d(scale_dim, scale_dim, kernel_size=depth_kernel, padding=<span class="number">1</span>, groups=scale_dim, bias=<span class="literal">True</span>),</span><br><span class="line">                        nn.Conv2d(scale_dim, scale_dim, kernel_size=<span class="number">1</span>, bias=<span class="literal">True</span>),</span><br><span class="line">                        nn.Hardswish()</span><br><span class="line">                        )</span><br><span class="line">        </span><br><span class="line">        self.down_proj = nn.Sequential(</span><br><span class="line">                                    nn.Conv2d(scale_dim, dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                                    nn.Dropout(dropout),</span><br><span class="line">                                    Rearrange(<span class="string">&#x27;b c h w -&gt;b (h w) c&#x27;</span>)</span><br><span class="line">                                    )</span><br></pre></td></tr></table></figure><p>在feed-forward中使用2d的卷积.</p><h2 id="transformer中的绝对和相对位置编码"><a href="#transformer中的绝对和相对位置编码" class="headerlink" title="transformer中的绝对和相对位置编码"></a>transformer中的绝对和相对位置编码</h2><p>位置编码可以分为使用<code>nn.Embedding</code>或者<code>nn.Parameter</code>的可学习参数,也可以直接使用固定的值,比如三角函数编码.此外可以分为相对位置和绝对位置编码</p><h3 id="绝对位置编码"><a href="#绝对位置编码" class="headerlink" title="绝对位置编码"></a>绝对位置编码</h3><p>transformer中使用了位置编码信息,被认为是绝对位置编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;Implement the PE function.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, dropout, max_len=<span class="number">5000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)],</span><br><span class="line">                         requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure><blockquote><p>我们可能希望使用相对位置编码而不是绝对位置编码，原因有很多。首先，使用绝对位置信息必然意味着模型可以处理的token数量有限制。假设一个语言模型最多只能编码1024个位置。这必然意味着任何长于1024个token的序列都不能被模型处理;相对位置编码可以推广到看不见长度的序列，因为理论上它编码的唯一信息是两个标记之间的相对成对距离。</p></blockquote><h3 id="相对位置编码的历史"><a href="#相对位置编码的历史" class="headerlink" title="相对位置编码的历史"></a>相对位置编码的历史</h3><blockquote><p>相对位置嵌入( Relative Position Embedding，RPE )技术主要用于将与相对位置相关的信息纳入到注意力模块中。该技术基于这样的思想：块之间的空间关系比它们的绝对位置承载更多的权重。为了计算RPE值，使用了基于可学习参数的查找表。查找过程由图像patch间的相对距离决定。虽然RPE技术可以扩展到不同长度的序列，但它可能会增加训练和测试时间。</p></blockquote><p>在<code>attention is all you need</code>中的attention中,自我注意力可以表述为如下,并使用三角函数索引进行位置编码.</p><script type="math/tex; mode=display">z_i=\sum_{j=1}^n\alpha_{ij}(x_jW^V) \\\alpha_{ij}=\frac{\exp e_{ij}}{\sum_{k=1}^n\exp e_{ik}} \\e_{ij}=\frac{(x_iW^Q)(x_jW^K)^T}{\sqrt{d_z}}</script><h3 id="1D数据"><a href="#1D数据" class="headerlink" title="1D数据"></a>1D数据</h3><h4 id="Shaw"><a href="#Shaw" class="headerlink" title="Shaw"></a>Shaw</h4><p>相对位置编码在swin-transformer以及Self-Attention with Relative Position Representations中都有体现.较早的论文<a href="https://arxiv.org/pdf/1803.02155.pdf">1803.02155.pdf (arxiv.org)</a></p><script type="math/tex; mode=display">z_i=\sum_{j=1}^n\alpha_{ij}(x_jW^V+a_{ij}^V) \\e_{ij}=\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\sqrt{d_z}} \\\begin{aligned}a_{ij}^{K}& =w_{\mathrm{clip}(j-i,k)}^{K}  \\a_{ij}^{V}& =w_{\mathrm{clip}(j-i,k)}^{V}  \\\operatorname{clip}(x,k)& =\max(-k,\min(k,x)) \end{aligned}</script><p>其中的w^k^和w^v^是需要训练的参数.</p><script type="math/tex; mode=display">w^{K}=(w_{-k}^{K},\ldots,w_{k}^{K}) \\w^{V}=(\dot{w_{-k}^{V}},\ldots,w_{k}^{V})</script><p>以下是<a href="https://arxiv.org/pdf/1803.02155.pdf">1803.02155.pdf (arxiv.org)</a>中的相对位置注意力</p><p><img data-src="https://s2.loli.net/2024/02/16/4esqYAdLkgNuybn.png" alt="image-20240216225108501" style="zoom: 67%;" /></p><p><img data-src="https://pic4.zhimg.com/80/v2-f6d057978590bd14fd876856500b69df_720w.webp" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaw&#x27;s relative positional embedding</span></span><br><span class="line">seq = torch.arange(n, device=device)</span><br><span class="line">dist = rearrange(seq, <span class="string">&quot;i -&gt; i ()&quot;</span>) - rearrange(seq, <span class="string">&quot;j -&gt; () j&quot;</span>)</span><br><span class="line">dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb</span><br><span class="line">rel_pos_emb = self.rel_pos_emb(dist).to(q)</span><br><span class="line">pos_attn = einsum(<span class="string">&quot;b h n d, n r d -&gt; b h n r&quot;</span>, q, rel_pos_emb) * self.scale</span><br><span class="line">dots = dots + pos_attn</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> exists(mask) <span class="keyword">or</span> exists(context_mask):</span><br><span class="line">    mask = default(mask, <span class="keyword">lambda</span>: torch.ones(*x.shape[:<span class="number">2</span>], device=device))</span><br><span class="line">    context_mask = (</span><br><span class="line">        default(context_mask, mask)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> has_context</span><br><span class="line">        <span class="keyword">else</span> default(</span><br><span class="line">            context_mask, <span class="keyword">lambda</span>: torch.ones(*context.shape[:<span class="number">2</span>], device=device)</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    mask_value = -torch.finfo(dots.dtype).<span class="built_in">max</span></span><br><span class="line">    mask = rearrange(mask, <span class="string">&quot;b i -&gt; b () i ()&quot;</span>) * rearrange(</span><br><span class="line">        context_mask, <span class="string">&quot;b j -&gt; b () () j&quot;</span></span><br><span class="line">    )</span><br><span class="line">    dots.masked_fill_(~mask, mask_value)</span><br><span class="line"></span><br><span class="line">attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">out = einsum(<span class="string">&quot;b h i j, b h j d -&gt; b h i d&quot;</span>, attn, v)</span><br><span class="line">out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">out = self.to_out(out)</span><br></pre></td></tr></table></figure><h4 id="transformer-xl"><a href="#transformer-xl" class="headerlink" title="transformer-xl"></a>transformer-xl</h4><p>众所周知,q=xW~Q~,k=xW~K~,加入相对位置编码后,展开一般注意力公式有</p><p><img data-src="https://pic4.zhimg.com/80/v2-5ee0eed4bc859e400591d7c83047bffb_720w.webp" alt="img"></p><p><img data-src="https://pic1.zhimg.com/80/v2-733f110568f1c83519ada84af1e32014_720w.webp" alt="img"></p><p>Transformer-XL的做法很简单，直接将 $p<em>j$ 替换为相对位置向量 $R</em>{i-j}$, 至于两个 $p_i$ , 则干脆替换为两个可训练的问量 $u,v$</p><p>之后的改进也是基于此,并且不再改动计算V了.</p><p>在transformer-xl(或者也是XLNET中使用的编码)中</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q+\mathbf{u})(\mathbf{x}_j\mathbf{W}^K)^T+(\mathbf{x}_i\mathbf{W}^Q+\mathbf{v})(\mathbf{s}_{i-j}\mathbf{W}^R)^T}{\sqrt{d_z}},</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEmbedding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, demb</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEmbedding, self).__init__()</span><br><span class="line">        self.demb = demb</span><br><span class="line">        inv_freq = <span class="number">1</span> / (<span class="number">10000</span> ** (torch.arange(<span class="number">0.0</span>, demb, <span class="number">2.0</span>) / demb))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, pos_seq</span>):</span></span><br><span class="line">        sinusoid_inp = torch.outer(pos_seq, self.inv_freq) <span class="comment"># 向量之间相乘</span></span><br><span class="line">        pos_emb = torch.cat([sinusoid_inp.sin(), sinusoid_inp.cos()], dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> pos_emb[:,<span class="literal">None</span>,:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">w_head_q = w_head_q.view(qlen, bsz, self.n_head, self.d_head)           <span class="comment"># qlen x bsz x n_head x d_head</span></span><br><span class="line">w_head_k = w_head_k.view(klen, bsz, self.n_head, self.d_head)           <span class="comment"># qlen x bsz x n_head x d_head</span></span><br><span class="line">w_head_v = w_head_v.view(klen, bsz, self.n_head, self.d_head)           <span class="comment"># qlen x bsz x n_head x d_head</span></span><br><span class="line"></span><br><span class="line">r_head_k = r_head_k.view(rlen, self.n_head, self.d_head)                <span class="comment"># qlen x n_head x d_head</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### compute attention score</span></span><br><span class="line">rw_head_q = w_head_q + r_w_bias   <span class="comment">#加上biase                                       # qlen x bsz x n_head x d_head</span></span><br><span class="line">AC = torch.einsum(<span class="string">&#x27;ibnd,jbnd-&gt;ijbn&#x27;</span>, (rw_head_q, w_head_k))             <span class="comment"># qlen x klen x bsz x n_head</span></span><br><span class="line"></span><br><span class="line">rr_head_q = w_head_q + r_r_bias  <span class="comment">#加上biase  </span></span><br><span class="line">BD = torch.einsum(<span class="string">&#x27;ibnd,jnd-&gt;ijbn&#x27;</span>, (rr_head_q, r_head_k))              <span class="comment"># qlen x klen x bsz x n_head</span></span><br><span class="line">BD = self._rel_shift(BD)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [qlen x klen x bsz x n_head]</span></span><br><span class="line">attn_score = AC + BD</span><br><span class="line">attn_score.mul_(self.scale)</span><br></pre></td></tr></table></figure><p>其中u,v是两个可学习参数,W^R^是一个矩阵将s~i-j~投影到一个与位置相关的key向量.</p><h4 id="Music-transformer"><a href="#Music-transformer" class="headerlink" title="Music transformer"></a>Music transformer</h4><p>后来Huang对shaw的相对位置编码进行改进</p><p><img data-src="https://s2.loli.net/2024/02/16/PX9Ev1HjwKDB5xt.png" alt="image-20240216225143335" style="zoom: 67%;" /></p><h4 id="Huang"><a href="#Huang" class="headerlink" title="Huang"></a>Huang</h4><p>此外还有<a href="https://arxiv.org/pdf/2009.13658.pdf">2009.13658.pdf (arxiv.org)</a>提出的</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q+\mathbf{p}_{ij})(\mathbf{x}_j\mathbf{W}^K+\mathbf{p}_{ij})^T-\mathbf{p}_{ij}\mathbf{p}_{ij}^T}{\sqrt{d_z}},</script><h4 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h4><p><img data-src="https://pic1.zhimg.com/80/v2-16c2aa40bbf7a888a62d9dc1373d6c94_720w.webp" alt="img" style="zoom:50%;" /></p><h4 id="DeBERTa"><a href="#DeBERTa" class="headerlink" title="DeBERTa"></a>DeBERTa</h4><p><img data-src="https://pic3.zhimg.com/80/v2-b5436edfcde32b292cdf24c7f39d9c0e_720w.webp" alt="img"></p><p>总结下来就是在计算attention权重时或者在计算最后的注意力时加上一个与相对位置信息相关的值.这个值的计算通常类似如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaw&#x27;s relative positional embedding</span></span><br><span class="line">seq = torch.arange(n, device=device)</span><br><span class="line">dist = rearrange(seq, <span class="string">&quot;i -&gt; i ()&quot;</span>) - rearrange(seq, <span class="string">&quot;j -&gt; () j&quot;</span>)</span><br><span class="line">dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb</span><br><span class="line">rel_pos_emb = self.rel_pos_emb(dist).to(q)</span><br></pre></td></tr></table></figure><p>以上大多用于1D数据比如音频和文字.</p><h3 id="2D数据"><a href="#2D数据" class="headerlink" title="2D数据"></a>2D数据</h3><h4 id="Stand-Alone-Self-Attention-in-Vision-Models"><a href="#Stand-Alone-Self-Attention-in-Vision-Models" class="headerlink" title="Stand-Alone Self-Attention in Vision Models"></a>Stand-Alone Self-Attention in Vision Models</h4><p><img data-src="https://user-images.githubusercontent.com/19909320/137499552-3bdf3189-7f57-4f95-a85e-8d5dd2ef6fd0.png" alt="SASA" style="zoom:50%;" /></p><p>公式如下</p><script type="math/tex; mode=display">y_{ij}=\sum_{a,b\in\mathcal{N}_{k}(i,j)}\text{softmax}_{ab}\left(q_{ij}^{\top}k_{ab}+q_{ij}^{\top}r_{a-i,b-j}\right)v_{ab}</script><p>对相对距离进行维度分解，每个元素ab∈N~k(i,j)~得到两个距离：行偏移量a-i和列偏移量b-j .</p><p>行偏移和列偏移分别与一个嵌入r~a-i~和r~b-j~相关联，每个嵌入维度为1/2d~out~,行偏移嵌入和列偏移嵌入被串联起来形成r~a-i,b-j~。</p><p>或者表示如下</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q)(\mathbf{x}_j\mathbf{W}^K+concat(\mathbf{p}_{\delta\bar{x}}^K,\mathbf{p}_{\delta\bar{y}}^K))^T}{\sqrt{d_z}},</script><p>其中p是可训练参数,长度是1/2d~z~</p><p><img data-src="https://s2.loli.net/2024/02/17/2S9UbyF7DYfujVw.png" alt="image-20240217180330619"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">use_cuda = torch.cuda.is_available()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SASA_Layer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, kernel_size=<span class="number">7</span>, num_heads=<span class="number">8</span>, image_size=<span class="number">224</span>, inference=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SASA_Layer, self).__init__()</span><br><span class="line">        self.kernel_size = <span class="built_in">min</span>(kernel_size, image_size) <span class="comment"># receptive field shouldn&#x27;t be larger than input H/W         </span></span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.dk = self.dv = in_channels</span><br><span class="line">        self.dkh = self.dk // self.num_heads</span><br><span class="line">        self.dvh = self.dv // self.num_heads</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> self.dk % self.num_heads == <span class="number">0</span>, <span class="string">&quot;dk should be divided by num_heads. (example: dk: 32, num_heads: 8)&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> self.dk % self.num_heads == <span class="number">0</span>, <span class="string">&quot;dv should be divided by num_heads. (example: dv: 32, num_heads: 8)&quot;</span>  </span><br><span class="line">        </span><br><span class="line">        self.k_conv = nn.Conv2d(self.dk, self.dk, kernel_size=<span class="number">1</span>).to(device)</span><br><span class="line">        self.q_conv = nn.Conv2d(self.dk, self.dk, kernel_size=<span class="number">1</span>).to(device)</span><br><span class="line">        self.v_conv = nn.Conv2d(self.dv, self.dv, kernel_size=<span class="number">1</span>).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Positional encodings</span></span><br><span class="line">        self.rel_encoding_h = nn.Parameter(torch.randn(self.dk // <span class="number">2</span>, self.kernel_size, <span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        self.rel_encoding_w = nn.Parameter(torch.randn(self.dk // <span class="number">2</span>, <span class="number">1</span>, self.kernel_size), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># later access attention weights</span></span><br><span class="line">        self.inference = inference</span><br><span class="line">        <span class="keyword">if</span> self.inference:</span><br><span class="line">            self.register_parameter(<span class="string">&#x27;weights&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        batch_size, _, height, width = x.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute k, q, v</span></span><br><span class="line">        padded_x = F.pad(x, [(self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>, (self.kernel_size-<span class="number">1</span>)-((self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>), (self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>, (self.kernel_size-<span class="number">1</span>)-((self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>)])</span><br><span class="line">        k = self.k_conv(padded_x)</span><br><span class="line">        q = self.q_conv(x)</span><br><span class="line">        v = self.v_conv(padded_x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Unfold patches into [BS, num_heads*depth, horizontal_patches, vertical_patches, kernel_size, kernel_size]</span></span><br><span class="line">        k = k.unfold(<span class="number">2</span>, self.kernel_size, <span class="number">1</span>).unfold(<span class="number">3</span>, self.kernel_size, <span class="number">1</span>)</span><br><span class="line">        v = v.unfold(<span class="number">2</span>, self.kernel_size, <span class="number">1</span>).unfold(<span class="number">3</span>, self.kernel_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Reshape into [BS, num_heads, horizontal_patches, vertical_patches, depth_per_head, kernel_size*kernel_size]</span></span><br><span class="line">        k = k.reshape(batch_size, self.num_heads, height, width, self.dkh, -<span class="number">1</span>)</span><br><span class="line">        v = v.reshape(batch_size, self.num_heads, height, width, self.dvh, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Reshape into [BS, num_heads, height, width, depth_per_head, 1]</span></span><br><span class="line">        q = q.reshape(batch_size, self.num_heads, height, width, self.dkh, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        qk = torch.matmul(q.transpose(<span class="number">4</span>, <span class="number">5</span>), k)    </span><br><span class="line">        qk = qk.reshape(batch_size, self.num_heads, height, width, self.kernel_size, self.kernel_size)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Add positional encoding</span></span><br><span class="line">        qr_h = torch.einsum(<span class="string">&#x27;bhxydz,cij-&gt;bhxyij&#x27;</span>, q, self.rel_encoding_h)</span><br><span class="line">        qr_w = torch.einsum(<span class="string">&#x27;bhxydz,cij-&gt;bhxyij&#x27;</span>, q, self.rel_encoding_w)</span><br><span class="line">        qk += qr_h</span><br><span class="line">        qk += qr_w</span><br><span class="line">        </span><br><span class="line">        qk = qk.reshape(batch_size, self.num_heads, height, width, <span class="number">1</span>, self.kernel_size*self.kernel_size)</span><br><span class="line">        weights = F.softmax(qk, dim=-<span class="number">1</span>)    </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.inference:</span><br><span class="line">            self.weights = nn.Parameter(weights)</span><br><span class="line">        </span><br><span class="line">        attn_out = torch.matmul(weights, v.transpose(<span class="number">4</span>, <span class="number">5</span>)) </span><br><span class="line">        attn_out = attn_out.reshape(batch_size, -<span class="number">1</span>, height, width)</span><br><span class="line">        <span class="keyword">return</span> attn_out</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>上面的代码可能有些问题,应该是将i,j的距离差嵌入到一个<code>embedding</code>中更合适</p><h4 id="Rethinking-and-Improving-Relative-Position-Encoding-for-Vision-Transformer"><a href="#Rethinking-and-Improving-Relative-Position-Encoding-for-Vision-Transformer" class="headerlink" title="Rethinking and Improving Relative Position Encoding for Vision Transformer"></a>Rethinking and Improving Relative Position Encoding for Vision Transformer</h4><p>这是篇好文章,关于注意力中相对位置用于2d图像数据的方法.也是在上面SASA的一种改进.</p><p><img data-src="https://s2.loli.net/2024/02/17/CHqOLZKXNxhIdzj.png" alt="image-20240217181329312"></p><p>以往的相对位置编码方法都依赖于输入嵌入。这就带来了一个问题，即编码能否独立于输入?</p><p>论文引入相对位置编码的偏向模式和语境模式来研究该问题。前者独立于输入嵌入，而后者考虑了与查询、键或值的交互。也就上图的两种模式.</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q)(\mathbf{x}_j\mathbf{W}^K)^T\color{blue}{+}b_{ij}}{\sqrt{d_z}} \\b_{ij}=\bold{r}_{ij} \space for \space  bias \space mode\\b_{ij}=(x_{i}W^Q)r_{ij}\space for\space  context  \space mode\\</script><p>计算attention weight加上一个偏置,在bias模式下,这个偏置是一个可学习的参数,表示相对位置的权重.</p><p>在context模式下,有多种可行的方式.其中r是一个可训练的向量,也表示相对位置,但它会与Q或K交互.</p><script type="math/tex; mode=display">b_{ij}=(\mathbf{x}_i\mathbf{W}^Q)(\mathbf{r}_{ij}^K)^T+(\mathbf{x}_j\mathbf{W}^K)(\mathbf{r}_{ij}^Q)^T</script><p>此外context模式也可以应用于value嵌入</p><script type="math/tex; mode=display">\mathbf{z}_i=\sum_{j=1}^n\alpha_{ij}(\mathbf{x}_j\mathbf{W}^V\color{red}{+}\mathbf{r}_{ij}^V),</script><p>为了计算二维图像平面上的相对位置并定义相对权重r~ij~,提出了两种无向映射方法Euclidean和Quantization，以及两种有向映射方法Cross和Product。</p><script type="math/tex; mode=display">\mathbf{r}_{ij}=\mathbf{p}_{I(i,j)},</script><script type="math/tex; mode=display">I(i,j)=g(\sqrt{(\tilde{x}_i-\tilde{x}_j)^2+(\tilde{y}_i-\tilde{y}_j)^2}),</script><p>在上述欧几里得方法中，距离较近的两个具有不同相对距离的邻居可能被映射到同一个索引中，例如二维相对位置( 1、0 )和( 1 , 1)都被映射到索引1中。假设近邻应该是分离的。因此对欧氏距离进行量化，即将不同的实数映射成不同的整数。</p><script type="math/tex; mode=display">I(i,j)=g(quant(\sqrt{(\tilde{x}_i-\tilde{x}_j)^2+(\tilde{y}_i-\tilde{y}_j)^2}).</script><p>运算quant ( · )将一组实数{ 0，1，1.41，2，2.24，.. }映射为一组整数{ 0，1，2，3，4，.. } .这种方法也是无向的.</p><p>像素的位置方向对图像也很重要，因此提出了有向映射方法。这种方法被称为Cross方法，它分别在水平和垂直方向上计算编码，然后进行汇总。方法如下</p><script type="math/tex; mode=display">\begin{gathered}\mathbf{r}_{ij}=\mathbf{p}_{I^{\tilde{x}}(i,j)}^{\tilde{x}}+\mathbf{p}_{I^{\tilde{y}}(i,j)}^{\tilde{y}}, \\I^{\tilde{x}}(i,j)=g(\tilde{x_{i}}-\tilde{x_{j}}), \\I^{\tilde{y}}(i,j)=g(\tilde{y}_i-\tilde{y}_j), \end{gathered}</script><p>如果某个方向上的距离是相同的，那么Cross方法将不同的相对位置编码到同一个嵌入中，此外带来了额外的计算开销。为了提高效率并包含更多的方向性信息，设计了Product方法，公式如下：</p><p><img data-src="https://s2.loli.net/2024/02/17/2rIStXgva96PhTZ.png" alt="image-20240217223648427"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h3 id="Swin-transformer"><a href="#Swin-transformer" class="headerlink" title="Swin transformer"></a>Swin transformer</h3><p><a href="https://arxiv.org/abs/2103.14030">[2103.14030] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (arxiv.org)</a></p><p><a href="https://arxiv.org/abs/2111.09883">[2111.09883] Swin Transformer V2: Scaling Up Capacity and Resolution (arxiv.org)</a></p><p><img data-src="https://s2.loli.net/2024/02/18/NMFCXv8EKabh6cp.png" alt="image-20240218140849412"></p><script type="math/tex; mode=display">\begin{aligned}\Omega(\mathbf{MSA})&=4hwC^2+2(hw)^2C,\\\Omega(\mathbf{W-MSA})&=4hwC^2+2M^2hwC,\end{aligned}</script><p><img data-src="https://s2.loli.net/2024/02/18/WBD3do8KnrHqlLU.png" alt="image-20240218141119075"></p><blockquote><p>将Transformer从语言转换到视觉的挑战来自于两个领域之间的差异，例如视觉实体的尺度变化较大，图像中的像素相对于文本中的文字分辨率较高。</p><p>为了解决这些差异，提出了一个分层Transformer，其表示由Shifted窗口计算。移位窗口方案通过将自注意力计算限制在不重叠的局部窗口，同时允许跨窗口连接，从而带来更高的效率。这种分层架构具有在各种尺度下建模的灵活性，并且具有与图像大小相关的线性计算复杂度。</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/21/If19Km8TFPneM6x.png" alt="image-20240221231106703"></p><h3 id="Swin-transformerV2"><a href="#Swin-transformerV2" class="headerlink" title="Swin-transformerV2"></a>Swin-transformerV2</h3><p><a href="https://arxiv.org/abs/2111.09883">[2111.09883] Swin Transformer V2: Scaling Up Capacity and Resolution (arxiv.org)</a></p><p><img data-src="https://s2.loli.net/2024/02/21/6izranSXgP7CobN.png" alt="image-20240221231423057"></p><h3 id="Twins"><a href="#Twins" class="headerlink" title="Twins"></a>Twins</h3><p><a href="https://arxiv.org/abs/2104.13840">[2104.13840] Twins: Revisiting the Design of Spatial Attention in Vision Transformers (arxiv.org)</a></p><p><img data-src="https://github.com/lucidrains/vit-pytorch/raw/main/images/twins_svt.png" alt="img" style="zoom:67%;" /></p><p><img data-src="https://s2.loli.net/2024/02/18/1Zf5pWymzPTaHoB.png" alt="image-20240218141741213"></p><blockquote><p>在这项工作中，重新审视了空间注意力的设计，并证明了一个精心设计但简单的空间注意力机制与最先进的方案相比具有良好的性能。因此，我们提出了两种视觉转换器结构，即Twins - PCPVT和TwinsSVT。我们提出的架构高效且易于实现，只涉及在现代深度学习框架中高度优化的矩阵乘法。更重要的是，所提出的架构在包括图像级cla在内的广泛的视觉任务上取得了优异的性能</p></blockquote><p>此外随着时间发展,目前已经有了空间注意力,通道注意力等等可以用于2D数据的注意力模型.但是基本思想是类似的.</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/364828960">Relative position embedding - 知乎 (zhihu.com)</a></li><li><a href="https://arxiv.org/abs/1803.02155">[1803.02155] Self-Attention with Relative Position Representations (arxiv.org)</a></li><li><a href="https://placebokkk.github.io/asr/2021/01/14/asr-rpe.html">Relative Positional Embedding | Chao Yang (placebokkk.github.io)</a></li><li><a href="https://aclanthology.org/2020.findings-emnlp.298.pdf">Improve Transformer Models with Better Relative Position Embeddings (aclanthology.org)</a></li><li><a href="https://zhuanlan.zhihu.com/p/352898810">让研究人员绞尽脑汁的Transformer位置编码 - 知乎 (zhihu.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/669523714">《A survey of the Vision Transformers and its CNN-Transformer based Variants》第一期 - 知乎 (zhihu.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;这里介绍一些细节信息.有关位置编码信息和用于图像的transformer.&lt;br&gt;</summary>
    
    
    
    
    <category term="transformers" scheme="https://www.sekyoro.top/tags/transformers/"/>
    
    <category term="attention" scheme="https://www.sekyoro.top/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>TypeScript on the way:学习TypeScript</title>
    <link href="https://www.sekyoro.top/2024/02/11/TypeScript-on-the-way-%E5%AD%A6%E4%B9%A0TypeScript/"/>
    <id>https://www.sekyoro.top/2024/02/11/TypeScript-on-the-way-%E5%AD%A6%E4%B9%A0TypeScript/</id>
    <published>2024-02-11T08:01:13.000Z</published>
    <updated>2024-02-13T12:02:04.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>早该学学了.<br><span id="more"></span></p><p>之前写过Python的类型系统,如果对于写C++,Java,C#等这类语言来说,typing根本不成问题,所以理解TypeScript也不是问题.</p><h2 id="特殊的类型"><a href="#特殊的类型" class="headerlink" title="特殊的类型"></a>特殊的类型</h2><h3 id="any-unknown与never"><a href="#any-unknown与never" class="headerlink" title="any,unknown与never"></a>any,unknown与never</h3><p>any,unknown是”顶层类型”,never是”底层类型”.never类型是所有类型共有的,any类型基本没有限制,unknown类型不能直接调用并且运算是有限的,只能进行比较运算.推荐使用unknown代替any然后使用as转换类型.</p><h2 id="类型系统"><a href="#类型系统" class="headerlink" title="类型系统"></a>类型系统</h2><h3 id="String与string-Number与number"><a href="#String与string-Number与number" class="headerlink" title="String与string,Number与number"></a>String与string,Number与number</h3><p>String与string是不同的,前者是可以包含后者的.但是在ts中,很多方法只能使用后者.</p><p>所以推荐只使用后者.</p><p><img data-src="https://s2.loli.net/2024/02/11/4DiknPFr569Ulgp.png" alt="image-20240211171858237"></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> obj: <span class="built_in">Object</span>;</span><br><span class="line"><span class="keyword">let</span> obj2:&#123;&#125;;</span><br><span class="line">obj = &#123; <span class="attr">name</span>: <span class="string">&quot;John&quot;</span> &#125;;</span><br><span class="line">obj = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure><p>此外Object类型包括除了undefined和null的基本类型.所以这并不符合直觉,推荐使用<code>object</code></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> obj3:<span class="built_in">object</span>;</span><br><span class="line">obj3 = &#123;<span class="attr">name</span>:<span class="string">&quot;John&quot;</span>&#125;;</span><br><span class="line">obj3 = <span class="number">13</span>; <span class="comment">//报错 不能将number分配给类型object</span></span><br></pre></td></tr></table></figure><p>object类型包含对象,数组,函数.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> ccx = &#123; <span class="attr">foo</span>: <span class="number">1</span> &#125;;</span><br><span class="line">ccx.foo = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">let</span> t = &#123; <span class="attr">foo</span>: <span class="number">1</span> &#125;;</span><br><span class="line">t.foo = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">let</span> hh:<span class="built_in">object</span> = &#123;<span class="attr">foo</span>:<span class="number">1</span>&#125;</span><br><span class="line"><span class="comment">// hh.foo 报错 类型不对</span></span><br></pre></td></tr></table></figure><p>此外undefined和null也可以赋值为number,object等等.</p><p>TypeScript中单个值也是类型成为值类型</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> t: <span class="string">&quot;dfasdf&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> xy = <span class="string">&quot;https&quot;</span>;</span><br><span class="line"><span class="built_in">console</span>.log(xy);</span><br></pre></td></tr></table></figure><p>将多个类型组合起来就是联合类型,如果严格检查也就是设置<code>strictNullChecks</code>,使得其他类型变量不能被赋值为undefined或null.这个时候就可以用联合类型</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> setting: <span class="literal">true</span> | <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> gender: <span class="string">&quot;male&quot;</span> | <span class="string">&quot;female&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> rainbowColor: <span class="string">&quot;赤&quot;</span> | <span class="string">&quot;橙&quot;</span> | <span class="string">&quot;黄&quot;</span> | <span class="string">&quot;绿&quot;</span> | <span class="string">&quot;青&quot;</span> | <span class="string">&quot;蓝&quot;</span> | <span class="string">&quot;紫&quot;</span>;</span><br><span class="line"><span class="keyword">let</span> name: <span class="built_in">string</span> | <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">name = <span class="string">&quot;John&quot;</span>;</span><br><span class="line">name = <span class="literal">null</span>;</span><br></pre></td></tr></table></figure><p>对象的合成可以给对象添加新的属性,属于交叉类型.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> obj5: &#123; <span class="attr">foo</span>: <span class="built_in">string</span> &#125; &amp; &#123; <span class="attr">bar</span>: <span class="built_in">number</span> &#125;;</span><br></pre></td></tr></table></figure><h3 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Age = <span class="built_in">number</span>;</span><br><span class="line"><span class="keyword">let</span> age:Age =  <span class="number">55</span>;</span><br></pre></td></tr></table></figure><p>跟Python的typing和Go语言类似.</p><h2 id="数组-元组"><a href="#数组-元组" class="headerlink" title="数组 元组"></a>数组 元组</h2><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> arr: <span class="built_in">number</span>[] = [];</span><br><span class="line"><span class="keyword">let</span> arr2: (<span class="built_in">number</span>|<span class="built_in">string</span>)[] = [];</span><br><span class="line"><span class="keyword">let</span> arr3: <span class="built_in">Array</span>&lt;<span class="built_in">number</span>&gt; = [];</span><br></pre></td></tr></table></figure><p>const数组中的元素是可以改变的,所以在ts中增加了<code>readonly</code>,readonly数组是原本数组的子类型.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> arr5: <span class="built_in">number</span>[] = [<span class="number">0</span>, <span class="number">1</span>];</span><br><span class="line">arr5[<span class="number">0</span>] = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">let</span> arr6: <span class="keyword">readonly</span> <span class="built_in">number</span>[] = arr5;</span><br></pre></td></tr></table></figure><p>声明readonly数组</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> aa: <span class="keyword">readonly</span> <span class="built_in">number</span>[] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="keyword">let</span> a1: ReadonlyArray&lt;<span class="built_in">number</span>&gt; = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="keyword">let</span> a2: Readonly&lt;<span class="built_in">number</span>[]&gt; = [];</span><br><span class="line"><span class="keyword">let</span> a3 = [] <span class="keyword">as</span> <span class="keyword">const</span>;</span><br></pre></td></tr></table></figure><blockquote><p>TypeScript 推断类型时，遇到<code>const</code>命令声明的变量，如果代码里面没有注明类型，就会推断该变量是值类型。</p><p><code>const</code>命令声明的变量，如果赋值为对象，并不会推断为值类型,这是因为 JavaScript 里面，<code>const</code>变量赋值为对象时，属性值是可以改变的(数组等同理)</p></blockquote><h3 id="元组tuple"><a href="#元组tuple" class="headerlink" title="元组tuple"></a>元组tuple</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> s: [<span class="built_in">string</span>, <span class="built_in">string</span>, <span class="built_in">boolean</span>] = [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="literal">true</span>];</span><br></pre></td></tr></table></figure><p>使用元组时必须声明类型不然会默认数组.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> ot: [<span class="built_in">number</span>, <span class="built_in">string</span>?] | <span class="literal">undefined</span> = [<span class="number">1</span>];</span><br></pre></td></tr></table></figure><p>使用扩展运算符可以不下成员数量的元组.</p><p>元组也有只读元组</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> readonlyTuple: <span class="keyword">readonly</span> [<span class="built_in">number</span>] = [<span class="number">1</span>];</span><br><span class="line"><span class="keyword">let</span> point = [<span class="number">3</span>, <span class="number">4</span>] <span class="keyword">as</span> <span class="keyword">const</span>;</span><br></pre></td></tr></table></figure><h3 id="symbol类型"><a href="#symbol类型" class="headerlink" title="symbol类型"></a>symbol类型</h3><p>symbol主要用于类的属性.</p><p>ts增加了unique symbol作为symbol的子类型.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">const</span> x: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错</span></span><br><span class="line"><span class="keyword">let</span> y: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="keyword">const</span> x: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="keyword">const</span> x = <span class="built_in">Symbol</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> a: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="keyword">const</span> b: <span class="keyword">typeof</span> a = a; <span class="comment">// 正确</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>感觉平常可能用不上…</p><h3 id="函数-对象-interface"><a href="#函数-对象-interface" class="headerlink" title="函数 对象 interface"></a>函数 对象 interface</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">hello</span>(<span class="params">txt: <span class="built_in">string</span></span>): <span class="title">void</span> </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;hello &quot;</span> + txt);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法一</span></span><br><span class="line"><span class="keyword">const</span> hello = <span class="function"><span class="keyword">function</span> (<span class="params">txt: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;hello &quot;</span> + txt);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法二</span></span><br><span class="line"><span class="keyword">const</span> hello: <span class="function">(<span class="params">txt: <span class="built_in">string</span></span>) =&gt;</span> <span class="built_in">void</span> = <span class="function"><span class="keyword">function</span> (<span class="params">txt</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;hello &quot;</span> + txt);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>函数声明与函数变量声明.前者需要声明参数类型,否则默认为any.后者可以在选择在赋值时写出类型或者在声明变量时添加类型.此外还有这种写法</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> add: &#123;</span><br><span class="line">  (x: <span class="built_in">number</span>, <span class="attr">y</span>: <span class="built_in">number</span>): <span class="built_in">number</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">add = <span class="function"><span class="keyword">function</span> (<span class="params">x, y</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="箭头函数"><a href="#箭头函数" class="headerlink" title="箭头函数"></a>箭头函数</h4><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> repeat = (str: <span class="built_in">string</span>, <span class="attr">times</span>: <span class="built_in">number</span>): <span class="function"><span class="params">string</span> =&gt;</span> str.repeat(times);</span><br></pre></td></tr></table></figure><p>另外使用?表示可选参数</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x?: <span class="built_in">number</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f(); <span class="comment">// OK</span></span><br><span class="line">f(<span class="number">10</span>); <span class="comment">// OK</span></span><br></pre></td></tr></table></figure><p>默认值也类似.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">createPoint</span>(<span class="params">x: <span class="built_in">number</span> = <span class="number">0</span>, y: <span class="built_in">number</span> = <span class="number">0</span></span>): [<span class="title">number</span>, <span class="title">number</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> [x, y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">createPoint(); <span class="comment">// [0, 0]</span></span><br></pre></td></tr></table></figure><p>rest参数也可以用于将多个值包裹为数组或元组</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">joinNum</span>(<span class="params">...nums: [...<span class="built_in">number</span>[]]</span>): <span class="title">string</span> </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(nums);</span><br><span class="line">  <span class="keyword">return</span> nums.join(<span class="string">&quot; &quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">joinNum(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">joinNumAndString</span>(<span class="params">...args: [<span class="built_in">string</span>, <span class="built_in">number</span>]</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(args);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">joinNumAndString(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>参数也可以使用readonly进行修饰.</p><p>此外函数返回有void和never类型.前者表示没有返回值(或undefined)后者表示不会退出,常用于丢错误或循环.</p><h4 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a>函数重载</h4><p>不同于其他语言重载,</p><blockquote><p>有一些编程语言允许不同的函数参数，对应不同的函数实现。但是，JavaScript 函数只能有一个实现，必须在这个实现当中，处理不同的参数。因此，函数体内部就需要判断参数的类型及个数，并根据判断结果执行不同的操作。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">str: <span class="built_in">string</span></span>): <span class="title">string</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">arr: <span class="built_in">any</span>[]</span>): <span class="title">any</span>[]</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">stringOrArray: <span class="built_in">string</span> | <span class="built_in">any</span>[]</span>): <span class="title">string</span> | <span class="title">any</span>[] </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">typeof</span> stringOrArray === <span class="string">&quot;string&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> stringOrArray.split(<span class="string">&quot;&quot;</span>).reverse().join(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> stringOrArray.slice().reverse();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重载声明的排序很重要，因为 TypeScript 是按照顺序进行检查的，一旦发现符合某个类型声明，就不再往下检查了，所以类型最宽的声明应该放在最后面，防止覆盖其他类型声明</p><p><strong>构造函数</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> AnimalConstructor = <span class="keyword">new</span> () =&gt; Animal;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">create</span>(<span class="params">c: AnimalConstructor</span>): <span class="title">Animal</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> c();</span><br><span class="line">&#125;</span><br><span class="line">create(Animal);</span><br></pre></td></tr></table></figure><p>构造函数的类型写法，就是在参数列表前面加上<code>new</code>命令</p><p>此外也有对象形式写法</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> F = &#123;</span><br><span class="line">  <span class="keyword">new</span> (s: <span class="built_in">string</span>): <span class="built_in">object</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对对象,既可以使用<code>type</code>别名也可以使用<code>interface</code></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> ReadOnlyPerson &#123;</span><br><span class="line">  <span class="keyword">readonly</span> name: <span class="built_in">string</span>;</span><br><span class="line">  <span class="keyword">readonly</span> age: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> w:ReadOnlyPerson = &#123;</span><br><span class="line">  <span class="attr">name</span>:<span class="string">&quot;John&quot;</span>,</span><br><span class="line">  <span class="attr">age</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>空对象是 TypeScript 的一种特殊值，也是一种特殊类型。</p><blockquote><p>TypeScript 不允许动态添加属性，所以对象不能分步生成，必须生成时一次性声明所有属性。</p></blockquote><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;&#125;;</span><br><span class="line">obj.prop = <span class="number">123</span>; <span class="comment">// 报错</span></span><br></pre></td></tr></table></figure><p>因为<code>Object</code>可以接受各种类型的值，而空对象是<code>Object</code>类型的简写，所以它不会有严格字面量检查，赋值时总是允许多余的属性，只是不能读取这些属性。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Empty &#123;&#125;</span><br><span class="line"><span class="keyword">const</span> b: Empty = &#123; <span class="attr">myProp</span>: <span class="number">1</span>, <span class="attr">anotherProp</span>: <span class="number">2</span> &#125;; <span class="comment">// 正确</span></span><br><span class="line">b.myProp; <span class="comment">// 报错</span></span><br><span class="line"><span class="keyword">let</span> d: &#123;&#125;;</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="comment">// let d:Object;</span></span><br><span class="line"></span><br><span class="line">d = &#123;&#125;;</span><br><span class="line">d = &#123; <span class="attr">x</span>: <span class="number">1</span> &#125;;</span><br><span class="line">d = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">d = <span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>interface 是对象的模板，可以看作是一种类型约定，中文译为“接口”。使用了某个模板的对象，就拥有了指定的类型结构。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Person &#123;</span><br><span class="line">  <span class="attr">firstName</span>: <span class="built_in">string</span>;</span><br><span class="line">  lastName: <span class="built_in">string</span>;</span><br><span class="line">  age: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>interface 可以表示对象的各种语法，它的成员有 5 种形式。</p><ul><li>对象属性</li><li>对象的属性索引</li><li>对象方法</li><li>函数</li><li>构造函数</li></ul></blockquote><p>interface 与 type 的区别有下面几点。</p><p>（1）<code>type</code>能够表示非对象类型，而<code>interface</code>只能表示对象类型（包括数组、函数等）。</p><p>（2）<code>interface</code>可以继承其他类型，<code>type</code>不支持继承。</p><p>可以在interface中写方法以及利用interface写函数,构造函数.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写法一</span></span><br><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="built_in">boolean</span>): <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法二</span></span><br><span class="line"><span class="keyword">interface</span> B &#123;</span><br><span class="line">  <span class="attr">f</span>: <span class="function">(<span class="params">x: <span class="built_in">boolean</span></span>) =&gt;</span> <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法三</span></span><br><span class="line"><span class="keyword">interface</span> C &#123;</span><br><span class="line">  <span class="attr">f</span>: &#123; (x: <span class="built_in">boolean</span>): <span class="built_in">string</span> &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Add &#123;</span><br><span class="line">  (x: <span class="built_in">number</span>, <span class="attr">y</span>: <span class="built_in">number</span>): <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> myAdd: Add = <span class="function">(<span class="params">x, y</span>) =&gt;</span> x + y;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> ErrorConstructor &#123;</span><br><span class="line">  <span class="keyword">new</span> (message?: <span class="built_in">string</span>): <span class="built_in">Error</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>interface可以实现继承,而type不行.而且可以多继承.多重继承时,如果多个父接口存在同名属性,那么这些同名属性不能有类型冲突,否则会报错</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Shape &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Circle <span class="keyword">extends</span> Shape &#123;</span><br><span class="line">  <span class="attr">radius</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Style &#123;</span><br><span class="line">  <span class="attr">color</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Shape &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Circle <span class="keyword">extends</span> Style, Shape &#123;</span><br><span class="line">  <span class="attr">radius</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Country = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="built_in">string</span>;</span><br><span class="line">  capital: <span class="built_in">string</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> CountryWithPop <span class="keyword">extends</span> Country &#123;</span><br><span class="line">  <span class="attr">population</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，如果<code>type</code>命令定义的类型不是对象，interface 就无法继承</p><p>多个同名接口会进行合并.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Box &#123;</span><br><span class="line">  <span class="attr">height</span>: <span class="built_in">number</span>;</span><br><span class="line">  width: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Box &#123;</span><br><span class="line">  <span class="attr">length</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>举例来说，Web 网页开发经常会对<code>windows</code>对象和<code>document</code>对象添加自定义属性，但是 TypeScript 会报错，因为原始定义没有这些属性。解决方法就是把自定义属性写成 interface，合并进原始定义。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="string">&quot;foo&quot;</span>): <span class="built_in">boolean</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="built_in">any</span>): <span class="built_in">void</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="string">&quot;foo&quot;</span>): <span class="built_in">boolean</span>;</span><br><span class="line">  f(x: <span class="built_in">any</span>): <span class="built_in">void</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果两个 interface 组成的联合类型存在同名属性，那么该属性的类型也是联合类型</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Circle &#123;</span><br><span class="line">  <span class="attr">area</span>: bigint;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Rectangle &#123;</span><br><span class="line">  <span class="attr">area</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">const</span> s: Circle | Rectangle;</span><br><span class="line"></span><br><span class="line">s.area; <span class="comment">// bigint | number</span></span><br></pre></td></tr></table></figure><h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3><p>对于顶层声明的属性，可以在声明时同时给出类型,如果不给声明默认any.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">  <span class="attr">x</span>: <span class="built_in">number</span>;</span><br><span class="line">  y: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>TypeScript 有一个配置项<code>strictPropertyInitialization</code>，只要打开，就会检查属性是否设置了初值，如果没有就报错。</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/12/4chodubBD5QySIM.png" alt="image-20240212174733858"></p><p>如果打开了这个设置，但是某些情况下，不是在声明时赋值或在构造方法里面赋值，为了防止这个设置报错，可以使用非空断言。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">  x!: <span class="built_in">number</span>;</span><br><span class="line">  y!: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>泛型类</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&lt;<span class="title">Type</span>&gt; </span>&#123;</span><br><span class="line">  <span class="attr">contents</span>: Type;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="title">constructor</span>(<span class="params">value: Type</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.contents = value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> b: Box&lt;<span class="built_in">string</span>&gt; = <span class="keyword">new</span> Box(<span class="string">&quot;hello!&quot;</span>);</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="attr">key</span>: K;</span><br><span class="line">  value: V;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>抽象类</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="attr">foo</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="keyword">extends</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="attr">bar</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>抽象类的内部可以有已经实现好的属性和方法，也可以有还未实现的属性和方法。后者就叫做“抽象成员”（abstract member），即属性名和方法名有<code>abstract</code>关键字，表示该方法需要子类实现。如果子类没有实现抽象成员，就会报错。</p><h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getFirst</span>&lt;<span class="title">Type</span>&gt;(<span class="params">arr: Type[]</span>): <span class="title">Type</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arr[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不过为了方便，函数调用时，往往省略不写类型参数的值，让 TypeScript 自己推断,有些复杂的使用场景，TypeScript 可能推断不出类型参数的值，这时就必须显式给出.</p><blockquote><p>类型参数的名字，可以随便取，但是必须为合法的标识符。习惯上，类型参数的第一个字符往往采用大写字母。一般会使用<code>T</code>（type 的第一个字母）作为类型参数的名字。如果有多个类型参数，则使用 T 后面的 U、V 等字母命名，各个参数之间使用逗号（“,”）分隔。</p></blockquote><p>泛型主要用在四个场合：函数、接口、类和别名。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">id</span>&lt;<span class="title">T</span>&gt;(<span class="params">arg: T</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arg;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">id</span>&lt;<span class="title">T</span>&gt;(<span class="params">arg: T</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arg;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> myid: &lt;T&gt;<span class="function">(<span class="params">arg: T</span>) =&gt;</span> T = id;</span><br><span class="line"><span class="keyword">interface</span> Box&lt;Type&gt; &#123;</span><br><span class="line">  <span class="attr">contents</span>: Type;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> box: Box&lt;<span class="built_in">string</span>&gt;;</span><br></pre></td></tr></table></figure><p><strong>类型别名</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Nullable&lt;T&gt; = T | <span class="literal">undefined</span> | <span class="literal">null</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Container&lt;T&gt; = &#123; <span class="attr">value</span>: T &#125;;</span><br><span class="line"><span class="keyword">type</span> Tree&lt;T&gt; = &#123;</span><br><span class="line">  <span class="attr">value</span>: T;</span><br><span class="line">  left: Tree&lt;T&gt; | <span class="literal">null</span>;</span><br><span class="line">  right: Tree&lt;T&gt; | <span class="literal">null</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>类型参数默认值</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getFirst_</span>&lt;<span class="title">T</span> = <span class="title">string</span>&gt;(<span class="params">arr: T[]</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arr[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类型参数的约束条件</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">comp</span>&lt;<span class="title">Type</span> <span class="title">extends</span> </span>&#123; length: <span class="built_in">number</span> &#125;&gt;(a: Type, <span class="attr">b</span>: Type) &#123;</span><br><span class="line">  <span class="keyword">if</span> (a.length &gt; b.length) &#123;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Fn&lt;A <span class="keyword">extends</span> <span class="built_in">string</span>, B <span class="keyword">extends</span> <span class="built_in">string</span> = <span class="string">&quot;world&quot;</span>&gt; = [A, B];</span><br><span class="line"><span class="keyword">type</span> Result = Fn&lt;<span class="string">&quot;hello&quot;</span>&gt;</span><br></pre></td></tr></table></figure><p>类型参数的约束条件如下</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;TypeParameter <span class="keyword">extends</span> ConstraintType&gt;</span><br></pre></td></tr></table></figure><p>泛型使用注意:</p><ol><li><strong>尽量少用泛型</strong></li><li><strong>类型参数越少越好</strong></li><li><strong>类型参数需要出现两次</strong></li><li><strong>泛型可以嵌套</strong></li></ol><h3 id="Enum类型"><a href="#Enum类型" class="headerlink" title="Enum类型"></a>Enum类型</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">enum</span> Color &#123;</span><br><span class="line">  Red, <span class="comment">// 0</span></span><br><span class="line">  Green, <span class="comment">// 1</span></span><br><span class="line">  Blue, <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">enum</span> Direction &#123;</span><br><span class="line">  Up = <span class="string">&quot;UP&quot;</span>,</span><br><span class="line">  Down = <span class="string">&quot;DOWN&quot;</span>,</span><br><span class="line">  Left = <span class="string">&quot;LEFT&quot;</span>,</span><br><span class="line">  Right = <span class="string">&quot;RIGHT&quot;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Enum 结构本身也是一种类型。比如，上例的变量<code>c</code>等于<code>1</code>，它的类型可以是 Color，也可以是<code>number</code></p><p>多个同名的 Enum 结构会自动合并。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="built_in">enum</span> MediaTypes &#123;</span><br><span class="line">  <span class="built_in">JSON</span> = <span class="string">&quot;application/json&quot;</span>,</span><br><span class="line">  XML = <span class="string">&quot;application/xml&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> url = <span class="string">&quot;localhost&quot;</span>;</span><br><span class="line"></span><br><span class="line">fetch(url, &#123;</span><br><span class="line">  <span class="attr">headers</span>: &#123;</span><br><span class="line">    <span class="attr">Accept</span>: MediaTypes.JSON,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;).then(<span class="function">(<span class="params">response</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="类型断言"><a href="#类型断言" class="headerlink" title="类型断言"></a>类型断言</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法一</span></span><br><span class="line"><span class="keyword">let</span> bar: T = &lt;T&gt;foo;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 语法二</span></span><br><span class="line"><span class="keyword">let</span> bar: T = foo <span class="keyword">as</span> T;</span><br></pre></td></tr></table></figure><p>类型断言要求实际的类型与断言的类型兼容，实际类型可以断言为一个更加宽泛的类型（父类型），也可以断言为一个更加精确的类型（子类型），但不能断言为一个完全无关的类型</p><p>此外还有as const断言,<code>s const</code>断言只能用于字面量,<code>as const</code>也不能用于表达式</p><p>或者先断言为unknown.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expr <span class="keyword">as</span> unknown <span class="keyword">as</span> T;</span><br></pre></td></tr></table></figure><p>对于那些可能为空的变量（即可能等于<code>undefined</code>或<code>null</code>），TypeScript 提供了非空断言，保证这些变量不会为空，写法是在变量名后面加上感叹号<code>!</code></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> root = <span class="built_in">document</span>.getElementById(<span class="string">&quot;root&quot;</span>)!;</span><br></pre></td></tr></table></figure><p>断言函数</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">isString</span>(<span class="params">value: unknown</span>): <span class="title">asserts</span> <span class="title">value</span> <span class="title">is</span> <span class="title">string</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">typeof</span> value !== <span class="string">&quot;string&quot;</span>) <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">&quot;Not a string&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="模块和namespace"><a href="#模块和namespace" class="headerlink" title="模块和namespace"></a>模块和namespace</h3><p>TypeScript 模块除了支持所有 ES 模块的语法，特别之处在于允许输出和输入类型。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">type</span> Bool = <span class="literal">true</span> | <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><p>模块加载方式有classic和Node,也就是Command js和ES6.</p><p>namespace 用来建立一个容器，内部的所有变量和函数，都必须在这个容器里面使用。</p><blockquote><p>它出现在 ES 模块诞生之前，作为 TypeScript 自己的模块格式而发明的。但是，自从有了 ES 模块，官方已经不推荐使用 namespace 了。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> Utils &#123;</span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">isString</span>(<span class="params">value: <span class="built_in">any</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">typeof</span> value === <span class="string">&quot;string&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 正确</span></span><br><span class="line">  isString(<span class="string">&quot;yes&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Utils.isString(<span class="string">&quot;no&quot;</span>); <span class="comment">// 报错</span></span><br></pre></td></tr></table></figure><p>如果要在命名空间以外使用内部成员，就必须为该成员加上<code>export</code>前缀，表示对外输出该成员</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> Utility &#123;</span><br><span class="line">  <span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">log</span>(<span class="params">msg: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(msg);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">error</span>(<span class="params">msg: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.error(msg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Utility.log(<span class="string">&quot;Call me&quot;</span>);</span><br><span class="line">Utility.error(<span class="string">&quot;maybe!&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>装饰器（Decorator）是一种语法结构，用来在定义时修改类（class）的行为。</p><p>在语法上，装饰器有如下几个特征。</p><p>（1）第一个字符（或者说前缀）是<code>@</code>，后面是一个表达式。</p><p>（2）<code>@</code>后面的表达式，必须是一个函数（或者执行后可以得到一个函数）。</p><p>（3）这个函数接受所修饰对象的一些相关值作为参数。</p><p>（4）这个函数要么不返回值，要么返回一个新对象取代所修饰的目标对象。</p><p>装饰器函数和装饰器方法</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Decorator = <span class="function">(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">  value: DecoratedValue,</span></span></span><br><span class="line"><span class="params"><span class="function">  context: &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    kind: <span class="built_in">string</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    name: <span class="built_in">string</span> | symbol;</span></span></span><br><span class="line"><span class="params"><span class="function">    addInitializer?(initializer: () =&gt; <span class="built_in">void</span>): <span class="built_in">void</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">static</span>?: <span class="built_in">boolean</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">private</span>?: <span class="built_in">boolean</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    access: &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">      get?(): unknown;</span></span></span><br><span class="line"><span class="params"><span class="function">      set?(value: unknown): <span class="built_in">void</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;;</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) =&gt;</span> <span class="built_in">void</span> | ReplacementValue;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ClassDecorator = <span class="function">(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">  value: <span class="built_in">Function</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  context: &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    kind: <span class="string">&quot;class&quot;</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    name: <span class="built_in">string</span> | <span class="literal">undefined</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    addInitializer(initializer: () =&gt; <span class="built_in">void</span>): <span class="built_in">void</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) =&gt;</span> <span class="built_in">Function</span> | <span class="built_in">void</span>;</span><br></pre></td></tr></table></figure><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">countInstances</span>(<span class="params">value: <span class="built_in">any</span>, context: <span class="built_in">any</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> instanceCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> wrapper = <span class="function"><span class="keyword">function</span> (<span class="params">...args: <span class="built_in">any</span>[]</span>) </span>&#123;</span><br><span class="line">    instanceCount++;</span><br><span class="line">    <span class="keyword">const</span> instance = <span class="keyword">new</span> value(...args);</span><br><span class="line">    instance.count = instanceCount;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125; <span class="keyword">as</span> unknown <span class="keyword">as</span> <span class="keyword">typeof</span> MyClass;</span><br><span class="line"></span><br><span class="line">  wrapper.prototype = value.prototype; <span class="comment">// A</span></span><br><span class="line">  <span class="keyword">return</span> wrapper;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@countInstances</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> inst1 = <span class="keyword">new</span> MyClass();</span><br><span class="line">inst1 <span class="keyword">instanceof</span> MyClass; <span class="comment">// true</span></span><br><span class="line">inst1.count; <span class="comment">// 1</span></span><br></pre></td></tr></table></figure><h3 id="declare关键字"><a href="#declare关键字" class="headerlink" title="declare关键字"></a>declare关键字</h3><p>declare 关键字用来告诉编译器，某个类型是存在的，可以在当前文件中使用。</p><p>它的主要作用，就是让当前文件可以使用其他文件声明的类型。举例来说，自己的脚本使用外部库定义的函数，编译器会因为不知道外部函数的类型定义而报错，这时就可以在自己的脚本里面使用<code>declare</code>关键字，告诉编译器外部函数的类型。这样的话，编译单个脚本就不会因为使用了外部类型而报错。</p><p>declare 关键字可以描述以下类型。</p><ul><li>变量（const、let、var 命令声明）</li><li>type 或者 interface 命令声明的类型</li><li>class</li><li>enum</li><li>函数（function）</li><li>模块（module）</li><li>命名空间（namespace）</li></ul><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">let</span> x: <span class="built_in">number</span>;</span><br><span class="line"><span class="keyword">declare</span> <span class="function"><span class="keyword">function</span> <span class="title">sayHello</span>(<span class="params">name: <span class="built_in">string</span></span>): <span class="title">void</span></span>;</span><br><span class="line"></span><br><span class="line">sayHello(<span class="string">&quot;张三&quot;</span>);</span><br><span class="line"><span class="keyword">declare</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">  <span class="title">constructor</span>(<span class="params">name: <span class="built_in">string</span></span>);</span><br><span class="line">  eat(): <span class="built_in">void</span>;</span><br><span class="line">  sleep(): <span class="built_in">void</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">namespace</span> AnimalLib &#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    <span class="title">constructor</span>(<span class="params">name: <span class="built_in">string</span></span>);</span><br><span class="line">    eat(): <span class="built_in">void</span>;</span><br><span class="line">    sleep(): <span class="built_in">void</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">type</span> Animals = <span class="string">&quot;Fish&quot;</span> | <span class="string">&quot;Dog&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line"><span class="keyword">declare</span> <span class="built_in">module</span> AnimalLib &#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    <span class="title">constructor</span>(<span class="params">name: <span class="built_in">string</span></span>);</span><br><span class="line">    eat(): <span class="built_in">void</span>;</span><br><span class="line">    sleep(): <span class="built_in">void</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">type</span> Animals = <span class="string">&quot;Fish&quot;</span> | <span class="string">&quot;Dog&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="d-ts类型声明文件"><a href="#d-ts类型声明文件" class="headerlink" title="d.ts类型声明文件"></a>d.ts类型声明文件</h2><p>可以为每个模块脚本，定义一个<code>.d.ts</code>文件，把该脚本用到的类型定义都放在这个文件里面。但是，更方便的做法是为整个项目，定义一个大的<code>.d.ts</code>文件，在这个文件里面使用<code>declare module</code>定义每个模块脚本的类型</p><p>使用时，自己的脚本使用三斜杠命令，加载这个类型声明文件。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// &lt;reference path=&quot;node.d.ts&quot;/&gt;</span></span><br></pre></td></tr></table></figure><p>如果没有上面这一行命令，自己的脚本使用外部模块时，就需要在脚本里面使用 declare 命令单独给出外部模块的类型。</p><blockquote><p>单独使用的模块，一般会同时提供一个单独的类型声明文件（declaration file），把本模块的外部接口的所有类型都写在这个文件里面，便于模块使用者了解接口，也便于编译器检查使用者的用法是否正确。</p><p>类型声明文件里面只有类型代码，没有具体的代码实现。它的文件名一般为<code>[模块名].d.ts</code>的形式，其中的<code>d</code>表示 declaration（声明）</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// &lt;reference path=&quot;node.d.ts&quot;/&gt;</span></span><br><span class="line"><span class="keyword">import</span> &#123; test &#125; <span class="keyword">from</span> <span class="string">&quot;./test&quot;</span>;</span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">let</span> x: <span class="built_in">number</span>;</span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">console</span>.log(x);</span><br><span class="line"><span class="built_in">console</span>.log(test);</span><br><span class="line"><span class="keyword">let</span> p: Post = &#123; <span class="attr">id</span>: <span class="number">1</span>, <span class="attr">title</span>: <span class="string">&quot;title&quot;</span>, <span class="attr">content</span>: <span class="string">&quot;content&quot;</span> &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// node.d.ts</span></span><br><span class="line"><span class="keyword">interface</span> Post &#123;</span><br><span class="line">  <span class="attr">id</span>: <span class="built_in">number</span>;</span><br><span class="line">  title: <span class="built_in">string</span>;</span><br><span class="line">  content: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后推荐两个练习网站:</p><ul><li><a href="https://typehero.dev/">TypeHero</a></li><li><a href="https://github.com/type-challenges/type-challenges">type-challenges/type-challenges: Collection of TypeScript type challenges with online judge (github.com)</a></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://typescript.p6p.net">https://typescript.p6p.net</a></li><li><a href="https://www.typescriptlang.org/docs/handbook/intro.html">TypeScript: Handbook - The TypeScript Handbook (typescriptlang.org)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;早该学学了.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>回头再看前端框架</title>
    <link href="https://www.sekyoro.top/2024/02/03/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8B%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6/"/>
    <id>https://www.sekyoro.top/2024/02/03/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8B%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6/</id>
    <published>2024-02-03T06:34:45.000Z</published>
    <updated>2024-02-11T07:28:06.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>马上又要到农历新年了,趁现在回顾一下过去一年的前端发展.当然是站在我的角度,因为有许多新的技术,对于不同领域的人以及不同层面的开发者都有不同的意味.<br>对于我来说,快捷、轻松的开发体验是比较重要的,臃肿的大型框架并不是优秀的代名词,所以我会尽量使用或者倾向喜欢一些生态发展好,开发者使用体验好,社区也比较活跃的框架或者技术.此外,随着事件发展肯定会不断涌现一些新型技术甚至新的思想,对于学习者来说,这些东西还需要一些观望.<br><span id="more"></span></p><p>除开一些基本概念,我来写一些我平常会用的框架和技术.当然我这里并不是想做一个技术栈的介绍,更多的是在做一个web前端项目时可以考虑的提升开发效率的工具.</p><h2 id="Tailwind-css"><a href="#Tailwind-css" class="headerlink" title="Tailwind css"></a>Tailwind css</h2><p>虽然有争议,但这个css工具已经是极为方便的工具了,目前浏览器已经支持许多css新的特性,所以我觉得可以说,类似less和scss的工具是不需要的了.</p><p>Bootstrap或许过于臃肿,使用tailwind css本身并没有组件库,这里我推荐两个组件库，一个是<a href="https://daisyui.com/">daisyUI — Tailwind CSS Components ( version 4 update is here )</a>另一个是<a href="https://ui.shadcn.com/docs">Introduction - shadcn/ui</a></p><p>搭配现代的css特性,这样写css基本就够了.实在觉得不行可以再往Element-Plus也就是更抽象高级的组件库上靠.</p><h2 id="React"><a href="#React" class="headerlink" title="React"></a>React</h2><p>react的生态很好,状态管理工具以及搭配的一些动效库都很多.此外搭配Next.js,Remix.js等等成为一个较为完整的web前端解决方案.React是一个library,关键是使用了JSX,很多其他库也是受此影响,比如Solid,Preact,Millions等等.</p><h2 id="Vue"><a href="#Vue" class="headerlink" title="Vue"></a>Vue</h2><p>Vue在国内用的很多,当然国外也不少.相对来说我认为较大的差别是Vue的官方本身已经提供了整套的解决方案,Vue也有Nuxt解决SSR的问题,它有Pinia解决状态管理的问题,不像React状态管理通常会选用第三方的Zusland或者jotai等等(当然,如果需要管理的不多直接使用context也可以).目前vue2已经不在维护了,我也大力推荐直接上vue3.Vue使用单独的一个.vue文件表示一个或多个组件,svelte框架也类似.</p><p>可以这么说,如果要做一个中大型的前端项目,使用vue或者react的以及它们各自的生态工具是完全没有问题,也没有太大差异的.而且vue对于国内开发者还是比较友好的,各类文档的中文支持还是要比react好.</p><p>React和Vue都有SSR的框架,分别是Next和Nuxt,当然React还有Gatsby,Expo这些</p><h2 id="Svelte-or-Solid"><a href="#Svelte-or-Solid" class="headerlink" title="Svelte or Solid"></a>Svelte or Solid</h2><p>在virtual dom上不再赘述.而svelte和solid都是使用的真实的dom.</p><p>有的时候你并不需要也并不想要写一个较大的应用,并不想引入过多依赖,但是又想使用一些方便的库.</p><p>这时候react,vue就可以稍微退退,使用一些既新颖又成熟的方案,比如Svelte,Solid,Preact或者Million等等.前端框架的发展特别快,在使用过程中掌握一些基本概念会更好.</p><p>在浏览这些框架时,我也体会到一个深刻的事情,作为普通开发者在选择这些框架时,即使文档宣传有多么好多么快,如果背后的社区不坚持做下去不坚持宣传,背后的生态,背后没有一个较为统一的解决方案,还是无法做的长久.</p><p>我说这些话的意思是,在这么多前端框架出现的今天,如果想要有一个顺畅的开发体验,除了框架本身宣传的技术,还有背后的生态工具链也很重要,毕竟,当项目体积变大,事情就更复杂了.</p><p>Svelte官方提供了一个SvelteKit工具,也支持SSR等功能.</p><p>Solid也是类似.可以简单粗暴地说在语法上Svelte更像Vue,Solid更像React.而且后两者都提供了SSR的能力.</p><h2 id="对比一下Next-Nuxt以及SvelteKit和solid-js"><a href="#对比一下Next-Nuxt以及SvelteKit和solid-js" class="headerlink" title="对比一下Next,Nuxt以及SvelteKit和solid.js"></a>对比一下Next,Nuxt以及SvelteKit和solid.js</h2><p>平常我们写前端代码关注哪些点?</p><p>Next官网给了以下几点</p><p><img data-src="https://s2.loli.net/2024/02/03/gZW9YjzshmFBXnx.png" alt="image-20240203185447263" style="zoom:67%;" /></p><h3 id="构建工具"><a href="#构建工具" class="headerlink" title="构建工具"></a>构建工具</h3><p>对于Next,可以使用<code>create-next-app</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx create-next-app@latest</span><br></pre></td></tr></table></figure><p>使用Next或者Nuxt一般主要目的是使用SSR功能.当然除了SSR之外这些框架本身也提供了很多功能,一些开箱即用的库,一些默认的目录结构.不过不是为了强调SSR,SEO,貌似也没有必要使用Next(事实上你也可以使用这些框架但不过多使用它们的一些feature,好处是不用费时费力安装一些常用库)</p><p>如果不使用Next而是用React,可以考虑使用Vite等构建工具.</p><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><p>使用不同的构建工具或者框架会默认一些目录结构.</p><p>Next使用基于文件结构的路由,所录在目录结构上需要注意的.在Next的大更新也就是v13之后,路由默认使用App Router. App Router默认使用app目录进行路由,而Page Router 使用Page目录.</p><p>推荐只是用app router就够了.</p><p>在<code>app/layout.tsx</code>中创建html,在<code>app/page.tsx</code>中创建组件,然后创建public文件夹放图像和字体等静态文件.</p><p>具体Next项目结构参看<a href="https://nextjs.org/docs/getting-started/project-structure">Getting Started: Project Structure | Next.js (nextjs.org)</a>,可以看到还是有很多默认规则的.</p><h3 id="如何写一个组件"><a href="#如何写一个组件" class="headerlink" title="如何写一个组件"></a>如何写一个组件</h3><p>由于有了SSR功能,组件分为了服务端和客户端组件</p><h4 id="服务端组件"><a href="#服务端组件" class="headerlink" title="服务端组件"></a>服务端组件</h4><p>服务器组件相比于原本的CSR应用有很多好处.比如数据获取更快,更安全,有缓存,客户端需要的Bundle更小,更好的SEO.</p><p>渲染过程:在服务器上，Next.js使用React的API来编排渲染。渲染工作分为多个块：按各个route segments和suspense boundaries。</p><p>每个块(chunks)分两个步骤呈现：React将服务器组件呈现为一种特殊的数据格式，称为React服务器组件有效载荷（RSC Payload）。Next.js使用RSC Payload和Client Component JavaScript指令在服务器上呈现HTML。</p><p>然后，在客户端上：HTML用于立即显示对应路由的快速非交互式预览-这仅用于初始页面加载。React服务器组件有效负载用于协调客户端和服务器组件树，并更新DOM。JavaScript指令用于水合客户端组件并使应用程序具有交互性。</p><p><strong>渲染策略</strong></p><p>有静态渲染,动态渲染</p><p>默认是静态渲染,使用静态渲染，路由在构建时渲染，或在数据重新验证后在后台渲染。结果被缓存，并且可以被推送到内容交付网络（CDN）。此优化允许您在用户和服务器请求之间共享渲染工作的结果。当路由包含的数据不是针对用户个性化的，并且可能在构建时已知时（例如静态博客文章或产品页面），静态渲染非常有用。</p><p>使用动态渲染，<strong>可以在请求时为每个用户渲染路由</strong>。当路由具有针对用户个性化的数据或具有只能在请求时才知道的信息（如cookie或URL的搜索参数）时，动态呈现非常有用。</p><blockquote><p>作为开发人员，您不需要在静态和动态渲染之间进行选择，因为Next.js会根据所使用的功能和API自动为每条路由选择最佳渲染策略。相反，您可以选择何时缓存或重新验证特定数据，也可以选择流式处理UI的部分内容。</p></blockquote><p>此外还有streaming,流式处理使您能够从服务器逐步渲染UI。工作被分割成块，并在准备就绪时流式传输到客户端。这允许用户在整个内容完成呈现之前立即查看页面的部分内容。</p><h4 id="客户端组件"><a href="#客户端组件" class="headerlink" title="客户端组件"></a>客户端组件</h4><p>客户端组件<strong>可以使用state,effects以及事件监听.此外还可以使用浏览器的API</strong>.</p><p>“use client”用于声明服务器和客户端组件模块之间的边界。这意味着，通过在文件中定义“use clinet”，导入其中的所有其他模块，包括子组件，都被视为客户端捆绑包的一部分。</p><p>一旦定义了边界，导入其中的所有子组件和模块都将被视为客户端捆绑包的一部分。</p><h3 id="styling"><a href="#styling" class="headerlink" title="styling"></a>styling</h3><p>一般来说可以使用tailwind css,像这种主要关注的是组件化,也就是不同的组件之间的css不要互相污染.全局的css可以方便插入.除了tailwind css外还有css in js,css modules等方法,我建议使用其中两种搭配就行了,不然会让人confused(推荐css modules和tailwind css搭配).</p><h3 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h3><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fterminology-url-anatomy.png&amp;w=3840&amp;q=75&amp;dpl=dpl_8JSreCCcxctwsnJ6FNFujsNZdfsZ" alt="Terminology for URL Anatomy"></p><p>Next的app router支持共享布局,嵌套路由,加载状态,错误处理等等.文件用于定义路由.</p><p>每个目录表示一个路由段,使用<code>page.tsx</code>表示对于那个该路由的组件.</p><p>page默认是服务端组件,可以改为客户端组件</p><p>layouts在不同pages中是共享的,跳转时layouts保留state,不再重新渲染.这个组件应该接受一个<code>children</code>属性作为一个child layout或者一个child page.</p><p>顶层有一个Root Layout,这是必须的.在所有pages中共享.包含html和body.</p><p>每个路由段可以选择性定义自己的layout,路由中的layout默认被包含,每个父layout把子layout通过children包含在一起.layout和page可以在同一个目录下,layoput会包含这个page.</p><p>此外Next还有template,跟layouts类似,但是它并不会保持routes之间的state,这意思是当一个用户在共享一个template的不同路由之间跳转时,不会保持状态.会重新渲染元素.</p><p>在定义metadata信息时可以在page或者layout中导出metadata对象.</p><h3 id="链接与页面导航"><a href="#链接与页面导航" class="headerlink" title="链接与页面导航"></a>链接与页面导航</h3><p>Next有四种跳转路由的方式</p><ol><li>使用Link组件</li><li>使用useRouter hook(客户端组件)</li><li>使用redirect函数(服务端组件)</li><li>浏览器的History API</li></ol><h4 id="Link组件"><a href="#Link组件" class="headerlink" title="Link组件"></a>Link组件</h4><p>继承了\<a\>标签并且使得在客户端跳转提供了prefetching功能,优选方式</p><p>跳转路由时默认行为会到顶端,可以使用属性<code>scroll=&#123;false&#125;</code></p><h4 id="useRouter"><a href="#useRouter" class="headerlink" title="useRouter"></a>useRouter</h4><p>使用useRouter hook</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> &#123; useRouter &#125; <span class="keyword">from</span> <span class="string">&#x27;next/navigation&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="function"><span class="keyword">function</span> <span class="title">Page</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> router = useRouter()</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">onClick</span>=<span class="string">&#123;()</span> =&gt;</span> router.push(&#x27;/dashboard&#x27;)&#125;&gt;</span></span><br><span class="line"><span class="xml">      Dashboard</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于服务端组件,可以使用redirect.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; redirect &#125; <span class="keyword">from</span> <span class="string">&#x27;next/navigation&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">fetchTeam</span>(<span class="params">id: string</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> res = <span class="keyword">await</span> fetch(<span class="string">&#x27;https://...&#x27;</span>)</span><br><span class="line">  <span class="keyword">if</span> (!res.ok) <span class="keyword">return</span> <span class="literal">undefined</span></span><br><span class="line">  <span class="keyword">return</span> res.json()</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">Profile</span>(<span class="params">&#123; params &#125;: &#123; params: &#123; id: string &#125; &#125;</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> team = <span class="keyword">await</span> fetchTeam(params.id)</span><br><span class="line">  <span class="keyword">if</span> (!team) &#123;</span><br><span class="line">    redirect(<span class="string">&#x27;/login&#x27;</span>)</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Next.js路由默认缓存等机制.</p><p>使用<code>loading.js</code>加载一些内容,原本是React中的suspense.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Floading-ui.png&amp;w=3840&amp;q=75&amp;dpl=dpl_7E1cZLB9sZWvkjQY6Ei4tJ18mYN7" alt="Loading UI"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export default function Loading() &#123;</span><br><span class="line">  // You can add any UI inside Loading, including a Skeleton.</span><br><span class="line">  return &lt;LoadingSkeleton /&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用loading.js与suspense可以获得<strong>Streaming Server Rendering</strong> 和<strong>Selective Hydration</strong>的效果.</p><h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>使用error.js进行错误处理.如果要处理根目录下的错误,需要使用<code>global-error.tsx</code>文件,它可以处理包括根下layout.tsx和template.tsx中丢出的错误,此外也推荐再定义error.tsx处理根下page.tsx中的错误.</p><p>error.tsx文件会被嵌入到layout之中,所以不会处理layout.tsx中丢出的错误.</p><h4 id="重定向"><a href="#重定向" class="headerlink" title="重定向"></a>重定向</h4><p><img data-src="https://s2.loli.net/2024/02/06/Zav7h3fXBkOIR8g.png" alt="image-20240206130511356"></p><p>重定向跟路由类似,也分在服务端组件和客户端使用.</p><h4 id="redirect"><a href="#redirect" class="headerlink" title="redirect"></a>redirect</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x27;use server&#x27;</span><br><span class="line"> </span><br><span class="line">import &#123; redirect &#125; from &#x27;next/navigation&#x27;</span><br><span class="line">import &#123; revalidatePath &#125; from &#x27;next/cache&#x27;</span><br><span class="line"> </span><br><span class="line">export async function createPost(id: string) &#123;</span><br><span class="line">  try &#123;</span><br><span class="line">    // Call database</span><br><span class="line">  &#125; catch (error) &#123;</span><br><span class="line">    // Handle errors</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  revalidatePath(&#x27;/posts&#x27;) // Update cached posts</span><br><span class="line">  redirect(`/post/$&#123;id&#125;`) // Navigate to the new post page</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以在<code>next.config.js</code>中设置redirects使得在请求的页面渲染之前进行跳转.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  <span class="keyword">async</span> <span class="function"><span class="title">redirects</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">      <span class="comment">// Basic redirect</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">source</span>: <span class="string">&#x27;/about&#x27;</span>,</span><br><span class="line">        <span class="attr">destination</span>: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">        <span class="attr">permanent</span>: <span class="literal">true</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="comment">// Wildcard path matching</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">source</span>: <span class="string">&#x27;/blog/:slug&#x27;</span>,</span><br><span class="line">        <span class="attr">destination</span>: <span class="string">&#x27;/news/:slug&#x27;</span>,</span><br><span class="line">        <span class="attr">permanent</span>: <span class="literal">true</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外还有在Middleware中的跳转,方便在进行验证之后进行选择性跳转.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; NextResponse, NextRequest &#125; <span class="keyword">from</span> <span class="string">&#x27;next/server&#x27;</span></span><br><span class="line"><span class="keyword">import</span> &#123; authenticate &#125; <span class="keyword">from</span> <span class="string">&#x27;auth-provider&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">middleware</span>(<span class="params">request: NextRequest</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> isAuthenticated = authenticate(request)</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// If the user is authenticated, continue as normal</span></span><br><span class="line">  <span class="keyword">if</span> (isAuthenticated) &#123;</span><br><span class="line">    <span class="keyword">return</span> NextResponse.next()</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// Redirect to login page if not authenticated</span></span><br><span class="line">  <span class="keyword">return</span> NextResponse.redirect(<span class="keyword">new</span> URL(<span class="string">&#x27;/login&#x27;</span>, request.url))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> config = &#123;</span><br><span class="line">  <span class="attr">matcher</span>: <span class="string">&#x27;/dashboard/:path*&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="路由组"><a href="#路由组" class="headerlink" title="路由组"></a>路由组</h4><p>路由组可以将路由分成一组,同时使得在一个路由段建立多个嵌套的layout.</p><p>使用<code>()</code>包含一个目录名,这个目录不会被当作一个路由.在这个路由组中的路由可以共享一个layout.这个目录不会被处理成路由段,此外可以利用这个创建多个root layout.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Froute-group-multiple-root-layouts.png&amp;w=3840&amp;q=75&amp;dpl=dpl_Fr1VCq6W9RFeEuXYFe2L4sUmaW7a" alt="Route Groups with Multiple Root Layouts"></p><h4 id="项目结构和文件安排"><a href="#项目结构和文件安排" class="headerlink" title="项目结构和文件安排"></a>项目结构和文件安排</h4><p>在目录前加<code>_</code>使得其不可访问.</p><blockquote><p>：_folderName这表示文件夹是一个专用的实现细节，路由系统不应考虑它，从而选择不路由文件夹及其所有子文件夹。</p></blockquote><p>这样做可以使得UI与路由分开.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fproject-organization-private-folders.png&w=3840&q=75&dpl=dpl_FhZP1LTtukMJX1yNmAQ5DmdgAZ2Q" alt="An example folder structure using private folders" style="zoom:67%;" /></p><p>此外可以配置module aliases方便导入.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;compilerOptions&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;baseUrl&quot;</span>: <span class="string">&quot;.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;paths&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;@/components/*&quot;</span>: [<span class="string">&quot;components/*&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>项目组织策略</strong></p><p>可以将组件和lib库放在根目录,跟app目录同层.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fproject-organization-project-root.png&w=3840&q=75&dpl=dpl_FhZP1LTtukMJX1yNmAQ5DmdgAZ2Q" alt="An example folder structure with project files outside of app" style="zoom:50%;" /></p><p>还可以将这些目录放在app目录下,此外还可以放在路由目录下.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fproject-organization-app-root-split.png&amp;w=3840&amp;q=75&amp;dpl=dpl_FhZP1LTtukMJX1yNmAQ5DmdgAZ2Q" alt="An example folder structure with project files split by feature or route"></p><h4 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h4><p>给目录命名的时候使用<code>[]</code>,这样在layout,page,route或者generateMetadata函数中可以访问动态路由的参数.</p><p>此外使用<code>[...slug]</code>不仅可以捕获该路由下其下的子路由也能被捕获</p><p>使用<code>dynamicParams</code>控制<code>generateStaticParams</code>得到的结果之外的能否访问.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export const dynamicParams = false</span><br></pre></td></tr></table></figure><p>存在multiple-dynamic route以及catch-all segments</p><p><img data-src="https://s2.loli.net/2024/02/06/rcxIzpTYlAGDZPK.png" alt="image-20240206163014573"></p><p>此外还有Optional Catch-all Segments,<code>[[...]]</code>既可以匹配原本路由也可以匹配子路由</p><h4 id="并行路由"><a href="#并行路由" class="headerlink" title="并行路由"></a>并行路由</h4><p>并行路由允许您同时或有条件地呈现同一布局中的一个或多个页面。它们适用于应用程序的高度动态部分，如社交网站上的仪表板和提要。</p><p>使用<code>@</code>开头的目录,类似slot可以插入到layout中.</p><h4 id="插入路由"><a href="#插入路由" class="headerlink" title="插入路由"></a>插入路由</h4><p>截取路由允许您在当前布局中从应用程序的另一部分加载路由。当您希望在不让用户切换到不同上下文的情况下显示路线的内容时，这种路由范例可能很有用。</p><h4 id="路由处理器"><a href="#路由处理器" class="headerlink" title="路由处理器"></a>路由处理器</h4><p>这也是Next能作为全栈框架的原因,当然在这方面不如Nest.</p><p>路由处理器类似page.js而且不能跟其重合.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export const dynamic = &#x27;force-dynamic&#x27; // defaults to auto</span><br><span class="line">export async function GET(request: Request) &#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用GET方法并用Response返回能自动缓存.并且可以使用revalidate验证缓存数据.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">export async function GET() &#123;</span><br><span class="line">  const res = await fetch(&#x27;https://data.mongodb-api.com/...&#x27;, &#123;</span><br><span class="line">    next: &#123; revalidate: 60 &#125;, // Revalidate every 60 seconds</span><br><span class="line">  &#125;)</span><br><span class="line">  const data = await res.json()</span><br><span class="line"> </span><br><span class="line">  return Response.json(data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>page,layout和route handler有个<code>dynamic</code>属性,控制静态和动态的渲染和缓存.</p><p>默认为<code>auto</code>表示尽可能地缓存,<code>force-dynamic</code>表示强制动态渲染,使得每此渲染在每次请求的时候渲染.<code>error</code>如果每个组件使用了动态函数或者没有缓存的数据基会报错.</p><p><code>force-static</code>强制静态渲染并且缓存数据,cookies和headers等返回空值.</p><p>动态函数包括cookies和headers.</p><p>动态路由也可以处理请求的参数.</p><h4 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h4><blockquote><p>Middleware允许在请求完成之前运行代码。然后，根据传入的请求，您可以通<strong>过重写、重定向、修改请求或响应标头或直接响应</strong>来修改响应。</p></blockquote><p>在根目录使用<code>middleware.ts</code>进行对请求的拦截相应.</p><p><img data-src="https://s2.loli.net/2024/02/07/z9TjK2Om3EcICDY.png" alt="image-20240207234054276"></p><h3 id="Data-Fetching"><a href="#Data-Fetching" class="headerlink" title="Data Fetching"></a>Data Fetching</h3><p>由于引入了SSR等,数据获取也有了变化.分为在server上和在client上.</p><h4 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h4><p>在Next.js服务端中,fetch可以配置缓存和重验证.</p><p>在客户端中可以调用route handler获取数据,也可以使用React Query等第三方库.</p><h4 id="Server-Actions和Mutations"><a href="#Server-Actions和Mutations" class="headerlink" title="Server Actions和Mutations"></a>Server Actions和Mutations</h4><p>Server Actions是在服务上的异步函数,既可以在服务和客户端的组件来处理提交和和数据改变.</p><p>对于服务端组件,将”use server”放在一个异步函数的最顶部.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// Server Component</span><br><span class="line">export default function Page() &#123;</span><br><span class="line">  // Server Action</span><br><span class="line">  async function create() &#123;</span><br><span class="line">    &#x27;use server&#x27;</span><br><span class="line"> </span><br><span class="line">    // ...</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  return (</span><br><span class="line">    // ...</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于客户端组件,将”use server”放在客户端组件最顶部.</p><h3 id="Nuxt"><a href="#Nuxt" class="headerlink" title="Nuxt"></a>Nuxt</h3><p>Vue的SSR框架,Nuxt默认使用Vite构建工具.官方文档将它的和核心概念分为以下几个部分</p><p><img data-src="https://s2.loli.net/2024/02/06/iU72dluEKhtOkI9.png" alt="image-20240206000905397"></p><p>总体看来跟Next差别不大,具体的可以查看<a href="https://nuxt.com/docs/getting-started/introduction">Introduction · Get Started with Nuxt</a>.</p><h3 id="SvelteKit"><a href="#SvelteKit" class="headerlink" title="SvelteKit"></a>SvelteKit</h3><p>SvelteKit默认使用Vite构建,推荐使用SvelteKit创建一个svelte项目</p><blockquote><p>SvelteKit将处理调用Svelte编译器，将.Svelte文件转换为.js文件，这些文件创建DOM和.css文件。它还提供构建web应用程序所需的所有其他部分，如开发服务器、路由、部署以及SSR支持.</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/03/kOdja1mSY925byP.png" alt="image-20240203190856868"></p><p>值得注意的是,Svelte是的更新是基于赋值,使用数组的push等操作不会自动更新.</p><p>sveltekit类似Next也在路由,fetch数据,headers,cookies等有很多opinioned的配置.</p><h3 id="Solid"><a href="#Solid" class="headerlink" title="Solid"></a>Solid</h3><p>Solid也是使用Vite构建,使用<code>createSignal</code>来管理状态实现交互性.目前github上的star没有svelte多,因为发展成熟度还没有svelte高,但是solid目前更像一个方便的动态库,比较轻巧.</p><p>Solid的SSR支持有点特别.</p><blockquote><p>Solid有一个动态服务器端渲染解决方案，可以实现真正同构的开发体验。通过使用我们的Resource原语，可以轻松地进行异步数据请求，更重要的是，可以在客户端和浏览器之间自动序列化和同步。</p></blockquote><p>Solid的响应式基于Signal,Memo以及Effect.</p><p>目前Solid正在开发Solid Start,目的也是提供一个较为整体的Solid生态的解决方案.</p><p><img data-src="https://s2.loli.net/2024/02/08/CwB6zkX5yPvnf4q.png" alt="image-20240208002623304"></p><p>Solid和Svelte都有很好的tutorial而且在掌握vue或者react之后再去看它们的文档也并不困难.</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>对于这一类前端框架,以后可能还会不断涌现,但是其中的生态还是很重要的,如果想要快速没有太多心智负担的开发一个较为成熟生产应用,还是推荐使用React或者Vue等较为成熟的框架或者库.此外这些框架其中的要解决的问题是一致的,解决方法也是趋同的.</p><p>响应性,组件创建,生命周期等等,此外附带路由,状态管理,数据获取操作等等都有解决方法.</p><h2 id="Astro"><a href="#Astro" class="headerlink" title="Astro"></a>Astro</h2><p>我一看到这个框架的官网介绍就觉得这个框架适合写博客.当然它很灵活,功能很强大.</p><p>Astro本身并不与React和Vue冲突,所以一起用并没问题.<a href="https://docs.astro.build/zh-cn/guides/integrations-guide/">使用集成 | Docs (astro.build)</a></p><h2 id="Typescript"><a href="#Typescript" class="headerlink" title="Typescript"></a>Typescript</h2><p>现在流行用ts代替js了,所以还是学习一下.其实并不是很难.</p><h2 id="Bun-Deno"><a href="#Bun-Deno" class="headerlink" title="Bun?Deno?"></a>Bun?Deno?</h2><p>node之后的运行时.Deno现在没声了,可以考虑用用Bun.</p><blockquote><p>开发、测试、运行和捆绑JavaScript&amp;TypeScript项目——所有这些都使用Bun。Bun是一个一体化的JavaScript运行时和工具包，专为速度而设计，配有bundler、测试运行程序和Node.js兼容的包管理器。</p></blockquote><h2 id="htmlx"><a href="#htmlx" class="headerlink" title="htmlx??"></a>htmlx??</h2><p>最近比较火,但其实本身就是使用html的语法增加了一些原本用js才能实现的比如传文件、发送请求的功能.</p><p>但我总感觉定制化能力有点弱,可能本身也是为了快速开发一些web工具用的.</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>有很多技术我并没有提到,比如还有前端框架Angular以及WASM<a href="https://developer.mozilla.org/zh-CN/docs/WebAssembly">WebAssembly | MDN (mozilla.org)</a>,Qwik等等,因为我现实中并没有过多使用它们,还是让子弹飞一会吧.</p><p>一些前端框架的黑盒有点多,对于初学者还是要多多学习基础,学习框架时建议从简单入手,慢慢深入,毕竟很多框架的一些功能其实平常可能用不上.我推荐在掌握React,Next之后可以往Svelte或者Solid框架学习.因为Vue从一些概念上我觉得并没有与React太大的差异,主要是生态上差别,Vue的官方给的工具链已经比较齐全了,而React的生态可以说比较多样化,但也会导致在选择工具上的犹豫和困难.</p><p>Solid目前正在开发Solid Start框架,预计应该是类似于SvelteKit之于Svelte,期待后续发展.</p><p>而Astro这类框架用于个人博客等等还是很不错的.最后推荐几位Youtube上的前端博主,<a href="https://www.youtube.com/@WebDevSimplified">Web Dev Simplified - YouTube</a>,<a href="https://www.youtube.com/@TraversyMedia">Traversy Media - YouTube</a>,<a href="https://www.youtube.com/@Fireship">Fireship - YouTube</a>以及<a href="https://www.youtube.com/@freecodecamp">freeCodeCamp.org - YouTube</a>.当然不只是前端以及一些技术趋势.</p><h2 id="可以观看的一些视频和文章"><a href="#可以观看的一些视频和文章" class="headerlink" title="可以观看的一些视频和文章"></a>可以观看的一些视频和文章</h2><ol><li><a href="https://www.youtube.com/watch?v=Gc4Xh8u19NU">YouTube</a></li><li><a href="https://www.youtube.com/watch?v=9He4UBLyk8Y&amp;list=PLWKjhJtqVAbmMuZ3saqRIBimAKIMYkt0E&amp;ab_channel=freeCodeCamp.org">Front End Developer Roadmap 2024 - YouTube</a></li><li><a href="https://www.youtube.com/watch?v=8sXRyHI3bLw&amp;ab_channel=TraversyMedia">Web Development In 2024 - A Practical Guide (youtube.com)</a></li><li><a href="https://risingstars.js.org/2023/en">2023 JavaScript Rising Stars</a></li><li><a href="https://www.satellytes.com/blog/post/getting-started-gatsby-next-remix/">Getting Started: Gatsby vs. Next.js vs. Remix | Satellytes</a></li><li><a href="https://clonecoding.com/zh-cn/next-js-三种渲染方式-ssr-csr-ssg-优缺点分析/">[Next.js] 三种渲染方式 - SSR、CSR、SSG：优缺点分析 - CloneCoding</a></li><li><a href="https://juejin.cn/post/7145669817428049957">后起之秀svelte和solid是否值得花时间学习？ - 掘金 (juejin.cn)</a></li><li><a href="https://www.jdon.com/59675.html">比较前端框架ReactJs、SolidJS、Svelte和Lit底层逻辑 - Smashing - 极道 (jdon.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;马上又要到农历新年了,趁现在回顾一下过去一年的前端发展.当然是站在我的角度,因为有许多新的技术,对于不同领域的人以及不同层面的开发者都有不同的意味.&lt;br&gt;对于我来说,快捷、轻松的开发体验是比较重要的,臃肿的大型框架并不是优秀的代名词,所以我会尽量使用或者倾向喜欢一些生态发展好,开发者使用体验好,社区也比较活跃的框架或者技术.此外,随着事件发展肯定会不断涌现一些新型技术甚至新的思想,对于学习者来说,这些东西还需要一些观望.&lt;br&gt;</summary>
    
    
    
    
    <category term="front end" scheme="https://www.sekyoro.top/tags/front-end/"/>
    
  </entry>
  
  <entry>
    <title>协同融合代码学习</title>
    <link href="https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-01-31T11:15:43.000Z</published>
    <updated>2024-02-13T09:41:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>代码还是很重要的,虽然发现有些代码库不怎么样.<br><span id="more"></span></p><p>目前协同感知算法主要就是利用注意力机制和图神经网络,利用backbone(包括voxelNet,Point Pillar等网络)处理后的特征进行融合,具体的codebase我找到两个.一个是<a href="https://github.com/coperception/where2comm?tab=readme-ov-file">coperception/where2comm: [NeurIPS 2022] Where2comm (github.com)</a>另一个是<a href="https://github.com/DerrickXuNu/OpenCOOD">DerrickXuNu/OpenCOOD: [ICRA 2022] An opensource framework for cooperative detection. Official implementation for OPV2V. (github.com)</a>.可以说包含许多20年到现在的经典车辆协同感知的算法代码了,此外还有一些零散的算法代码,这里咱就细细把玩一下.</p><h2 id="Coperceptions"><a href="#Coperceptions" class="headerlink" title="Coperceptions"></a>Coperceptions</h2><p>包括where2comm,v2vnet,disconet,v2x-vit以及when2comm的代码.</p><p><img data-src="https://github.com/coperception/where2comm/raw/gh-pages/static/images/Intro.png" alt="Where2comm"></p><p>本身有mean,max,cat以及agent的融合方式.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>继承自FusionBase,而<code>FusionBase</code>又继承自<code>SegModelBase</code>,后者实现了一系列模型.在<code>FusionBase</code>中,首先对特征进行下采样,然后转换除了ego agent的特征,然后进行融合,最后再上采样.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> coperception.models.seg.SegModelBase <span class="keyword">import</span> SegModelBase</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FusionBase</span>(<span class="params">SegModelBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, n_channels, n_classes, num_agent=<span class="number">5</span>, kd_flag=<span class="literal">False</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line">        self.neighbor_feat_list = <span class="literal">None</span></span><br><span class="line">        self.tg_agent = <span class="literal">None</span></span><br><span class="line">        self.current_num_agent = <span class="literal">None</span></span><br><span class="line">        self.kd_flag = kd_flag</span><br><span class="line">        self.only_v2i = only_v2i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(</span><br><span class="line">            <span class="string">&quot;Please implement this method for specific fusion strategies&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, trans_matrices, num_agent_tensor</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)  <span class="comment"># b 512 32 32</span></span><br><span class="line">        size = (<span class="number">1</span>, <span class="number">512</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.compress_level &gt; <span class="number">0</span>:</span><br><span class="line">            x4 = F.relu(self.bn_compress(self.com_compresser(x4)))</span><br><span class="line">            x4 = F.relu(self.bn_decompress(self.com_decompresser(x4)))</span><br><span class="line"></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>) // self.num_agent</span><br><span class="line">        feat_list = <span class="built_in">super</span>().build_feat_list(x4, batch_size)</span><br><span class="line"></span><br><span class="line">        local_com_mat = torch.cat(<span class="built_in">tuple</span>(feat_list), <span class="number">1</span>)</span><br><span class="line">        local_com_mat_update = torch.cat(<span class="built_in">tuple</span>(feat_list), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            self.com_num_agent = num_agent_tensor[b, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            agent_feat_list = <span class="built_in">list</span>()</span><br><span class="line">            <span class="keyword">for</span> nb <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">                agent_feat_list.append(local_com_mat[b, nb])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">                self.tg_agent = local_com_mat[b, i]</span><br><span class="line"></span><br><span class="line">                self.neighbor_feat_list = <span class="built_in">list</span>()</span><br><span class="line">                self.neighbor_feat_list.append(self.tg_agent)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">                    <span class="keyword">if</span> j != i:</span><br><span class="line">                        <span class="keyword">if</span> self.only_v2i <span class="keyword">and</span> i != <span class="number">0</span> <span class="keyword">and</span> j != <span class="number">0</span>:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                        self.neighbor_feat_list.append(</span><br><span class="line">                            <span class="built_in">super</span>().feature_transformation(</span><br><span class="line">                                b,</span><br><span class="line">                                j,</span><br><span class="line">                                i,</span><br><span class="line">                                local_com_mat,</span><br><span class="line">                                size,</span><br><span class="line">                                trans_matrices,</span><br><span class="line">                            )</span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">                local_com_mat_update[b, i] = self.fusion()</span><br><span class="line"></span><br><span class="line">        feat_mat = <span class="built_in">super</span>().agents_to_batch(local_com_mat_update)</span><br><span class="line"></span><br><span class="line">        x5 = self.down4(feat_mat)</span><br><span class="line">        x6 = self.up1(x5, feat_mat)</span><br><span class="line">        x7 = self.up2(x6, x3)</span><br><span class="line">        x8 = self.up3(x7, x2)</span><br><span class="line">        x9 = self.up4(x8, x1)</span><br><span class="line">        logits = self.outc(x9)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.kd_flag:</span><br><span class="line">            <span class="keyword">return</span> logits, x9, x8, x7, x6, x5, feat_mat</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><p>使用了连续的下采样和上采样,先下采样,然后进行融合再进行上采样.这几种融合方式真是一层套一层,这么多参数效果不变强才怪…</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SegModelBase</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, n_channels, n_classes, bilinear=<span class="literal">True</span>, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line">        self.num_agent = num_agent</span><br><span class="line">        self.only_v2i = only_v2i</span><br><span class="line"></span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span> // factor)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">        self.compress_level = compress_level</span><br><span class="line">        <span class="keyword">if</span> compress_level &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">assert</span> compress_level &lt;= <span class="number">9</span></span><br><span class="line">            feat_map_channel_num = <span class="number">512</span></span><br><span class="line">            compress_channel_num = feat_map_channel_num // (<span class="number">2</span>**compress_level)</span><br><span class="line"></span><br><span class="line">            self.com_compresser = nn.Conv2d(</span><br><span class="line">                feat_map_channel_num, compress_channel_num, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            self.bn_compress = nn.BatchNorm2d(compress_channel_num)</span><br><span class="line"></span><br><span class="line">            self.com_decompresser = nn.Conv2d(</span><br><span class="line">                compress_channel_num, feat_map_channel_num, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            self.bn_decompress = nn.BatchNorm2d(feat_map_channel_num)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_feat_list</span>(<span class="params">self, feat_maps, batch_size</span>):</span></span><br><span class="line">        feat_maps = torch.flip(feat_maps, (<span class="number">2</span>,))</span><br><span class="line"></span><br><span class="line">        tmp_feat_map = &#123;&#125;</span><br><span class="line">        feat_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_agent):</span><br><span class="line">            tmp_feat_map[i] = torch.unsqueeze(</span><br><span class="line">                feat_maps[batch_size * i : batch_size * (i + <span class="number">1</span>)], <span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            feat_list.append(tmp_feat_map[i])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_list</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feature_transformation</span>(<span class="params">b, j, agent_idx, local_com_mat, size, trans_matrices</span>):</span></span><br><span class="line">        device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        nb_agent = torch.unsqueeze(local_com_mat[b, j], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        tfm_ji = trans_matrices[b, j, agent_idx]</span><br><span class="line">        M = (</span><br><span class="line">            torch.hstack((tfm_ji[:<span class="number">2</span>, :<span class="number">2</span>], -tfm_ji[:<span class="number">2</span>, <span class="number">3</span>:<span class="number">4</span>])).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>)</span><br><span class="line">        )  <span class="comment"># [1,2,3]</span></span><br><span class="line">        M = M.to(device)</span><br><span class="line"></span><br><span class="line">        mask = torch.tensor([[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span> / <span class="number">128</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span> / <span class="number">128</span>]]], device=M.device)</span><br><span class="line"></span><br><span class="line">        M *= mask</span><br><span class="line"></span><br><span class="line">        grid = F.affine_grid(M, size=torch.Size(size))</span><br><span class="line">        warp_feat = F.grid_sample(nb_agent, grid).squeeze()</span><br><span class="line">        <span class="keyword">return</span> warp_feat</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">agents_to_batch</span>(<span class="params">self, feats</span>):</span></span><br><span class="line">        feat_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_agent):</span><br><span class="line">            feat_list.append(feats[:, i, :, :, :])</span><br><span class="line">        feat_mat = torch.cat(feat_list, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        feat_mat = torch.flip(feat_mat, (<span class="number">2</span>,))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_mat</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, mid_channels=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mid_channels:</span><br><span class="line">            mid_channels = out_channels</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, mid_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(mid_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(mid_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> bilinear:</span><br><span class="line">            self.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&quot;bilinear&quot;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels, in_channels // <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.up = nn.ConvTranspose2d(</span><br><span class="line">                in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span></span><br><span class="line">            )</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        diff_y = x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]</span><br><span class="line">        diff_x = x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x1 = F.pad(</span><br><span class="line">            x1, [diff_x // <span class="number">2</span>, diff_x - diff_x // <span class="number">2</span>, diff_y // <span class="number">2</span>, diff_y - diff_y // <span class="number">2</span>]</span><br><span class="line">        )</span><br><span class="line">        x = torch.cat([x2, x1], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><p>mean,max和sum不用多说,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> coperception.models.seg.FusionBase <span class="keyword">import</span> FusionBase</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SumFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaxFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">max</span>(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>).values</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>catFusion将其他特征做个mean然后与自己的特征连接起来.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent, compress_level, only_v2i</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line">        self.modulation_layer_3 = ModulationLayer3()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        mean_feat = torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)  <span class="comment"># [c, h, w]</span></span><br><span class="line">        cat_feat = torch.cat([self.tg_agent, mean_feat], dim=<span class="number">0</span>)</span><br><span class="line">        cat_feat = cat_feat.unsqueeze(<span class="number">0</span>)  <span class="comment"># [1, 1, c, h, w]</span></span><br><span class="line">        <span class="keyword">return</span> self.modulation_layer_3(cat_feat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">FIXME:</span> Change size</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModulationLayer3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ModulationLayer3, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1_1 = nn.Conv2d(<span class="number">1024</span>, <span class="number">512</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.bn1_1 = nn.BatchNorm2d(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, x.size(-<span class="number">3</span>), x.size(-<span class="number">2</span>), x.size(-<span class="number">1</span>))</span><br><span class="line">        x_1 = F.relu(self.bn1_1(self.conv1_1(x)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x_1</span><br></pre></td></tr></table></figure><p>此外还有个<code>AgentWiseWeightedFusion</code>,每个ego_agent单独和每个其他特征cat在一起再通过,然后计算一个融合特征,再计算一个softmax作为特征的权重.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AgentWiseWeightedFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line">        self.agent_weighted_fusion = AgentWeightedFusion()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        agent_weight_list = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">            cat_feat = torch.cat([self.tg_agent, self.neighbor_feat_list[k]], dim=<span class="number">0</span>)</span><br><span class="line">            cat_feat = cat_feat.unsqueeze(<span class="number">0</span>)</span><br><span class="line">            agent_weight = self.agent_weighted_fusion(cat_feat)</span><br><span class="line">            agent_weight_list.append(agent_weight)</span><br><span class="line"></span><br><span class="line">        soft_agent_weight_list = torch.squeeze(</span><br><span class="line">            F.softmax(torch.tensor(agent_weight_list).unsqueeze(<span class="number">0</span>), dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        agent_wise_weight_feat = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">            agent_wise_weight_feat = (</span><br><span class="line">                agent_wise_weight_feat</span><br><span class="line">                + soft_agent_weight_list[k] * self.neighbor_feat_list[k]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> agent_wise_weight_feat</span><br></pre></td></tr></table></figure><p>discoNet特别之处就在于使用了所谓学生-教师模型进行知识蒸馏,在代码中添加了这个.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--kd_flag&quot;</span>,</span><br><span class="line">    default=<span class="number">0</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;Whether to enable distillation (only DiscNet is 1 )&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 还添加了权重参数,可见权重加得还挺大的.</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--kd_weight&quot;</span>, default=<span class="number">100000</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;KD loss weight&quot;</span>)</span><br></pre></td></tr></table></figure><p>然后类似<code>AgentWiseWeightedFusion</code>,将ego的特征与通信的单独每辆车的特征cat在一起传入一个网络中,计算得到所有值的幂和.然后再用各自的值乘以和(跟softmax差不多).算按出来权重再乘以对应的特征.最后的值是相加起来</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiscoNet</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, n_channels, n_classes, num_agent, kd_flag=<span class="literal">True</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels,</span><br><span class="line">            n_classes,</span><br><span class="line">            num_agent,</span><br><span class="line">            kd_flag=kd_flag,</span><br><span class="line">            compress_level=compress_level,</span><br><span class="line">            only_v2i=only_v2i,</span><br><span class="line">        )</span><br><span class="line">        self.pixel_weighted_fusion = PixelWeightedFusionSoftmax(<span class="number">512</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        tmp_agent_weight_list = <span class="built_in">list</span>()</span><br><span class="line">        sum_weight = <span class="number">0</span></span><br><span class="line">        nb_len = <span class="built_in">len</span>(self.neighbor_feat_list)</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nb_len):</span><br><span class="line">            cat_feat = torch.cat([self.tg_agent, self.neighbor_feat_list[k]], dim=<span class="number">0</span>)</span><br><span class="line">            cat_feat = cat_feat.unsqueeze(<span class="number">0</span>)</span><br><span class="line">            agent_weight = torch.squeeze(self.pixel_weighted_fusion(cat_feat))</span><br><span class="line">            tmp_agent_weight_list.append(torch.exp(agent_weight))</span><br><span class="line">            sum_weight = sum_weight + torch.exp(agent_weight)</span><br><span class="line"></span><br><span class="line">        agent_weight_list = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nb_len):</span><br><span class="line">            agent_weight = torch.div(tmp_agent_weight_list[k], sum_weight)</span><br><span class="line">            agent_weight.expand([<span class="number">256</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">            agent_weight_list.append(agent_weight)</span><br><span class="line"></span><br><span class="line">        agent_wise_weight_feat = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nb_len):</span><br><span class="line">            agent_wise_weight_feat = (</span><br><span class="line">                agent_wise_weight_feat</span><br><span class="line">                + agent_weight_list[k] * self.neighbor_feat_list[k]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> agent_wise_weight_feat</span><br></pre></td></tr></table></figure><h3 id="when2comm"><a href="#when2comm" class="headerlink" title="when2comm"></a>when2comm</h3><p>when2comm的代码就要复杂的多,它构建了很多块.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KmGenerator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, out_size=<span class="number">128</span>, input_feat_sz=<span class="number">32.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(KmGenerator, self).__init__()</span><br><span class="line">        feat_map_sz = input_feat_sz // <span class="number">4</span></span><br><span class="line">        self.n_feat = <span class="built_in">int</span>(<span class="number">256</span> * feat_map_sz * feat_map_sz)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(self.n_feat, <span class="number">256</span>),  <span class="comment">#</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">128</span>),  <span class="comment">#</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, out_size),</span><br><span class="line">        )  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features_map</span>):</span></span><br><span class="line">        outputs = self.fc(features_map.view(-<span class="number">1</span>, self.n_feat))</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PolicyNet4</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels=<span class="number">13</span>, input_feat_sz=<span class="number">32</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PolicyNet4, self).__init__()</span><br><span class="line">        feat_map_sz = input_feat_sz // <span class="number">4</span></span><br><span class="line">        self.n_feat = <span class="built_in">int</span>(<span class="number">256</span> * feat_map_sz * feat_map_sz)</span><br><span class="line">        self.lidar_encoder = LidarEncoder(height_feat_size=in_channels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Encoder</span></span><br><span class="line">        <span class="comment"># down 1</span></span><br><span class="line">        self.conv1 = Conv2DBatchNormRelu(<span class="number">512</span>, <span class="number">512</span>, k_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = Conv2DBatchNormRelu(<span class="number">512</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv3 = Conv2DBatchNormRelu(<span class="number">256</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># down 2</span></span><br><span class="line">        self.conv4 = Conv2DBatchNormRelu(<span class="number">256</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5 = Conv2DBatchNormRelu(<span class="number">256</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features_map</span>):</span></span><br><span class="line">        _, _, _, _, outputs1 = self.lidar_encoder(features_map)</span><br><span class="line">        outputs = self.conv1(outputs1)</span><br><span class="line">        outputs = self.conv2(outputs)</span><br><span class="line">        outputs = self.conv3(outputs)</span><br><span class="line">        outputs = self.conv4(outputs)</span><br><span class="line">        outputs = self.conv5(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line">   </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LidarEncoder</span>(<span class="params">Backbone</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The encoder class. Encodes input features in forward pass.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, height_feat_size=<span class="number">13</span>, compress_level=<span class="number">0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(height_feat_size, compress_level)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().encode(x)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LidarDecoder</span>(<span class="params">Backbone</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The decoder class. Decodes input features in forward pass.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, height_feat_size=<span class="number">13</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(height_feat_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, x_1, x_2, x_3, x_4, batch, kd_flag=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().decode(x, x_1, x_2, x_3, x_4, batch, kd_flag)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>首先使用encode进行降采样,选择某一层采样后的输出,利用采样后的输出计算q,k,v使用注意力机制融合.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">self.key_net = KmGenerator(</span><br><span class="line">    out_size=self.key_size, input_feat_sz=image_size / <span class="number">32</span></span><br><span class="line">)</span><br><span class="line">self.attention_net = MIMOGeneralDotProductAttention(</span><br><span class="line">    self.query_size, self.key_size, self.warp_flag</span><br><span class="line">)</span><br><span class="line"><span class="comment"># # Message generator</span></span><br><span class="line">self.query_key_net = PolicyNet4(in_channels=in_channels)</span><br><span class="line"><span class="keyword">if</span> self.has_query:</span><br><span class="line">    self.query_net = KmGenerator(</span><br><span class="line">        out_size=self.query_size, input_feat_sz=image_size / <span class="number">32</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>利用query_key_net生成特征,再利用key_net生成key,query_net生成query,使用attention_net利用注意力机制进行融合.val_mat就是采样后的输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">key_mat = torch.cat(<span class="built_in">tuple</span>(key_list), <span class="number">1</span>)</span><br><span class="line">query_mat = torch.cat(<span class="built_in">tuple</span>(query_list), <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>用的就是点积注意力,然后使用decoder回去.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment"># hand-shake</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MIMOGeneralDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scaled Dot-Product Attention&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, query_size, key_size, warp_flag, attn_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.sparsemax = Sparsemax(dim=<span class="number">1</span>)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.linear = nn.Linear(query_size, key_size)</span><br><span class="line">        self.warp_flag = warp_flag</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Msg size: &quot;</span>, query_size, <span class="string">&quot;  Key size: &quot;</span>, key_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, qu, k, v, sparse=<span class="literal">True</span></span>):</span></span><br><span class="line">      </span><br><span class="line">        query = self.linear(qu)  <span class="comment"># (batch,5,key_size)</span></span><br><span class="line">        attn_orig = torch.bmm(</span><br><span class="line">            k, query.transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        )  </span><br><span class="line">        attn_orig_softmax = self.softmax(attn_orig)  <span class="comment"># (batch,5,5)</span></span><br><span class="line"></span><br><span class="line">        attn_shape = attn_orig_softmax.shape</span><br><span class="line">        bats, key_num, query_num = attn_shape[<span class="number">0</span>], attn_shape[<span class="number">1</span>], attn_shape[<span class="number">2</span>]</span><br><span class="line">        attn_orig_softmax_exp = attn_orig_softmax.view(</span><br><span class="line">            bats, key_num, query_num, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.warp_flag == <span class="number">1</span>:</span><br><span class="line">            v_exp = v</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            v_exp = torch.unsqueeze(v, <span class="number">2</span>)</span><br><span class="line">            v_exp = v_exp.expand(-<span class="number">1</span>, -<span class="number">1</span>, query_num, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        output = attn_orig_softmax_exp * v_exp  <span class="comment"># (batch,5,channel,size,size)</span></span><br><span class="line">        output_sum = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output_sum, attn_orig_softmax</span><br></pre></td></tr></table></figure><p>训练的时候基本就拿这些特征给分类和回归的head做输出了.但是inference的时候设置了多种输出.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> inference == <span class="string">&#x27;softmax&#x27;</span>:</span><br><span class="line">              action = torch.argmax(prob_action, dim=<span class="number">2</span>)</span><br><span class="line">              num_connect = <span class="number">4</span></span><br><span class="line">              <span class="keyword">return</span> pred, prob_action, action, num_connect</span><br><span class="line">          <span class="keyword">elif</span> inference == <span class="string">&#x27;argmax_test&#x27;</span>:</span><br><span class="line">              action = torch.argmax(prob_action, dim=<span class="number">2</span>)</span><br><span class="line">              feat_argmax, num_connect = self.argmax_select(feat_map1, feat_map2, feat_map3, feat_map4, feat_map5,</span><br><span class="line">                                                            action, batch_size)</span><br><span class="line">              featmaps_argmax = feat_argmax.detach()</span><br><span class="line">              pred_argmax = self.decoder(featmaps_argmax)</span><br><span class="line">              <span class="keyword">return</span> pred_argmax, prob_action, action, num_connect</span><br><span class="line">          <span class="keyword">elif</span> inference == <span class="string">&#x27;activated&#x27;</span>:</span><br><span class="line">              feat_act, action, num_connect = self.activated_select(vals, prob_action)</span><br><span class="line">              featmaps_act = feat_act.detach()</span><br><span class="line">              pred_act = self.decoder(featmaps_act)</span><br><span class="line">              <span class="keyword">return</span> pred_act, prob_action, action, num_connect</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">              <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Incorrect inference mode&#x27;</span>)</span><br></pre></td></tr></table></figure><p>argmax_select和activated分别如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax_select</span>(<span class="params">self, val_mat, prob_action</span>):</span></span><br><span class="line">        <span class="comment"># v(batch, query_num, channel, size, size)</span></span><br><span class="line">        cls_num = prob_action.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#  进行one hot编码,</span></span><br><span class="line">        coef_argmax = F.one_hot(prob_action.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>],  num_classes=cls_num).<span class="built_in">type</span>(torch.cuda.FloatTensor)</span><br><span class="line">        coef_argmax = coef_argmax.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        attn_shape = coef_argmax.shape</span><br><span class="line">        bats, key_num, query_num = attn_shape[<span class="number">0</span>], attn_shape[<span class="number">1</span>], attn_shape[<span class="number">2</span>]</span><br><span class="line">        coef_argmax_exp = coef_argmax.view(bats, key_num, query_num, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        v_exp = torch.unsqueeze(val_mat, <span class="number">2</span>)</span><br><span class="line">        v_exp = v_exp.expand(-<span class="number">1</span>, -<span class="number">1</span>, query_num, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        output = coef_argmax_exp * v_exp  <span class="comment"># (batch,4,channel,size,size)</span></span><br><span class="line">        feat_argmax = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute connect</span></span><br><span class="line">        count_coef = copy.deepcopy(coef_argmax)</span><br><span class="line">        ind = np.diag_indices(self.agent_num)</span><br><span class="line">        count_coef[:, ind[<span class="number">0</span>], ind[<span class="number">1</span>]] = <span class="number">0</span></span><br><span class="line">        num_connect = torch.nonzero(count_coef).shape[<span class="number">0</span>] / (self.agent_num * count_coef.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_argmax, coef_argmax, num_connect</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activated_select</span>(<span class="params">self, val_mat, prob_action, thres=<span class="number">0.2</span></span>):</span></span><br><span class="line"></span><br><span class="line">        coef_act = torch.mul(prob_action, (prob_action &gt; thres).<span class="built_in">float</span>())</span><br><span class="line">        attn_shape = coef_act.shape</span><br><span class="line">        bats, key_num, query_num = attn_shape[<span class="number">0</span>], attn_shape[<span class="number">1</span>], attn_shape[<span class="number">2</span>]</span><br><span class="line">        coef_act_exp = coef_act.view(bats, key_num, query_num, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        v_exp = torch.unsqueeze(val_mat, <span class="number">2</span>)</span><br><span class="line">        v_exp = v_exp.expand(-<span class="number">1</span>, -<span class="number">1</span>, query_num, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        output = coef_act_exp * v_exp  <span class="comment"># (batch,4,channel,size,size)</span></span><br><span class="line">        feat_act = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute connect</span></span><br><span class="line">        count_coef = coef_act.clone()</span><br><span class="line">        ind = np.diag_indices(self.agent_num)</span><br><span class="line">        count_coef[:, ind[<span class="number">0</span>], ind[<span class="number">1</span>]] = <span class="number">0</span></span><br><span class="line">        num_connect = torch.nonzero(count_coef).shape[<span class="number">0</span>] / (self.agent_num * count_coef.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> feat_act, coef_act, num_connect\</span><br></pre></td></tr></table></figure><h3 id="V2VNet"><a href="#V2VNet" class="headerlink" title="V2VNet"></a>V2VNet</h3><p><img data-src="https://s2.loli.net/2024/02/13/LK8F15wDS6jdkPJ.png" alt="image-20240213170444226"></p><p>说实话,看了代码感觉也就那样…</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author: Hao Xiang &lt;haxiang@g.ucla.edu&gt;</span></span><br><span class="line"><span class="comment"># License: TDG-Attribution-NonCommercial-NoDistrib</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Implementation of V2VNet Fusion</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> opencood.models.sub_modules.torch_transformation_utils <span class="keyword">import</span> \</span><br><span class="line">    get_discretized_transformation_matrix, get_transformation_matrix, \</span><br><span class="line">    warp_affine, get_rotated_roi</span><br><span class="line"><span class="keyword">from</span> opencood.models.sub_modules.convgru <span class="keyword">import</span> ConvGRU</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">V2VNetFusion</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, args</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(V2VNetFusion, self).__init__()</span><br><span class="line">        </span><br><span class="line">        in_channels = args[<span class="string">&#x27;in_channels&#x27;</span>]</span><br><span class="line">        H, W = args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;H&#x27;</span>], args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;W&#x27;</span>]</span><br><span class="line">        kernel_size = args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;kernel_size&#x27;</span>]</span><br><span class="line">        num_gru_layers = args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;num_layers&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.discrete_ratio = args[<span class="string">&#x27;voxel_size&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">        self.downsample_rate = args[<span class="string">&#x27;downsample_rate&#x27;</span>]</span><br><span class="line">        self.num_iteration = args[<span class="string">&#x27;num_iteration&#x27;</span>]</span><br><span class="line">        self.gru_flag = args[<span class="string">&#x27;gru_flag&#x27;</span>]</span><br><span class="line">        self.agg_operator = args[<span class="string">&#x27;agg_operator&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.msg_cnn = nn.Conv2d(in_channels * <span class="number">2</span>, in_channels, kernel_size=<span class="number">3</span>,</span><br><span class="line">                                 stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv_gru = ConvGRU(input_size=(H, W),</span><br><span class="line">                                input_dim=in_channels * <span class="number">2</span>,</span><br><span class="line">                                hidden_dim=[in_channels],</span><br><span class="line">                                kernel_size=kernel_size,</span><br><span class="line">                                num_layers=num_gru_layers,</span><br><span class="line">                                batch_first=<span class="literal">True</span>,</span><br><span class="line">                                bias=<span class="literal">True</span>,</span><br><span class="line">                                return_all_layers=<span class="literal">False</span>)</span><br><span class="line">        self.mlp = nn.Linear(in_channels, in_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">regroup</span>(<span class="params">self, x, record_len</span>):</span></span><br><span class="line">        cum_sum_len = torch.cumsum(record_len, dim=<span class="number">0</span>)</span><br><span class="line">        split_x = torch.tensor_split(x, cum_sum_len[:-<span class="number">1</span>].cpu())</span><br><span class="line">        <span class="keyword">return</span> split_x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, record_len, pairwise_t_matrix</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fusion forwarding.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        x : torch.Tensor</span></span><br><span class="line"><span class="string">            input data, (B, C, H, W)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        record_len : list</span></span><br><span class="line"><span class="string">            shape: (B)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        pairwise_t_matrix : torch.Tensor</span></span><br><span class="line"><span class="string">            The transformation matrix from each cav to ego, </span></span><br><span class="line"><span class="string">            shape: (B, L, L, 4, 4) </span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        Fused feature.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        _, C, H, W = x.shape</span><br><span class="line">        B, L = pairwise_t_matrix.shape[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># split x:[(L1, C, H, W), (L2, C, H, W)]</span></span><br><span class="line">        split_x = self.regroup(x, record_len)</span><br><span class="line">        <span class="comment"># (B,L,L,2,3)</span></span><br><span class="line">        pairwise_t_matrix = get_discretized_transformation_matrix(</span><br><span class="line">            pairwise_t_matrix.reshape(-<span class="number">1</span>, L, <span class="number">4</span>, <span class="number">4</span>), self.discrete_ratio,</span><br><span class="line">            self.downsample_rate).reshape(B, L, L, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># (B*L,L,1,H,W)</span></span><br><span class="line">        roi_mask = get_rotated_roi((B * L, L, <span class="number">1</span>, H, W),</span><br><span class="line">                                   pairwise_t_matrix.reshape(B * L * L, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        roi_mask = roi_mask.reshape(B, L, L, <span class="number">1</span>, H, W)</span><br><span class="line">        batch_node_features = split_x</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># iteratively update the features for num_iteration times</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(self.num_iteration):</span><br><span class="line"></span><br><span class="line">            batch_updated_node_features = []</span><br><span class="line">            <span class="comment"># iterate each batch</span></span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(B):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># number of valid agent</span></span><br><span class="line">                N = record_len[b]</span><br><span class="line">                <span class="comment"># (N,N,4,4)</span></span><br><span class="line">                <span class="comment"># t_matrix[i, j]-&gt; from i to j</span></span><br><span class="line">                t_matrix = pairwise_t_matrix[b][:N, :N, :, :]</span><br><span class="line">                updated_node_features = []</span><br><span class="line">                <span class="comment"># update each node i</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">                    <span class="comment"># (N,1,H,W)</span></span><br><span class="line">                    mask = roi_mask[b, :N, i, ...]</span><br><span class="line"></span><br><span class="line">                    current_t_matrix = t_matrix[:, i, :, :]</span><br><span class="line">                    current_t_matrix = get_transformation_matrix(</span><br><span class="line">                        current_t_matrix, (H, W))</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                    neighbor_feature = warp_affine(batch_node_features[b],</span><br><span class="line">                                                   current_t_matrix,</span><br><span class="line">                                                   (H, W))</span><br><span class="line">                    <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                    ego_agent_feature = batch_node_features[b][i].unsqueeze(</span><br><span class="line">                        <span class="number">0</span>).repeat(N, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                    <span class="comment">#(N,2C,H,W)</span></span><br><span class="line">                    neighbor_feature = torch.cat(</span><br><span class="line">                        [neighbor_feature, ego_agent_feature], dim=<span class="number">1</span>)</span><br><span class="line">                    <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                    message = self.msg_cnn(neighbor_feature) * mask</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># (C,H,W)</span></span><br><span class="line">                    <span class="keyword">if</span> self.agg_operator==<span class="string">&quot;avg&quot;</span>:</span><br><span class="line">                        agg_feature = torch.mean(message, dim=<span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">elif</span> self.agg_operator==<span class="string">&quot;max&quot;</span>:</span><br><span class="line">                        agg_feature = torch.<span class="built_in">max</span>(message, dim=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">raise</span> ValueError(<span class="string">&quot;agg_operator has wrong value&quot;</span>)</span><br><span class="line">                    <span class="comment"># (2C, H, W)</span></span><br><span class="line">                    cat_feature = torch.cat(</span><br><span class="line">                        [batch_node_features[b][i, ...], agg_feature], dim=<span class="number">0</span>)</span><br><span class="line">                    <span class="comment"># (C,H,W)</span></span><br><span class="line">                    <span class="keyword">if</span> self.gru_flag:</span><br><span class="line">                        gru_out = \</span><br><span class="line">                            self.conv_gru(cat_feature.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>))[</span><br><span class="line">                                <span class="number">0</span>][</span><br><span class="line">                                <span class="number">0</span>].squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        gru_out = batch_node_features[b][i, ...] + agg_feature</span><br><span class="line">                    updated_node_features.append(gru_out.unsqueeze(<span class="number">0</span>))</span><br><span class="line">                <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                batch_updated_node_features.append(</span><br><span class="line">                    torch.cat(updated_node_features, dim=<span class="number">0</span>))</span><br><span class="line">            batch_node_features = batch_updated_node_features</span><br><span class="line">        <span class="comment"># (B,C,H,W)</span></span><br><span class="line">        out = torch.cat(</span><br><span class="line">            [itm[<span class="number">0</span>, ...].unsqueeze(<span class="number">0</span>) <span class="keyword">for</span> itm <span class="keyword">in</span> batch_node_features], dim=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># (B,C,H,W)</span></span><br><span class="line">        out = self.mlp(out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>有的实现没有RNN比如上面代码,也有的用了RNN和LSTM.后者代码代码简直就是屎…</p><h3 id="DiscoNet"><a href="#DiscoNet" class="headerlink" title="DiscoNet"></a>DiscoNet</h3><p>主要是利用了蒸馏,教师-学生模型这种理论.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.kd_flag == <span class="number">1</span>:</span><br><span class="line">        teacher = TeacherNet(config)</span><br><span class="line">        teacher = nn.DataParallel(teacher)</span><br><span class="line">        teacher = teacher.to(device)</span><br><span class="line">        faf_module = FaFModule(</span><br><span class="line">            model, teacher, config, optimizer, criterion, args.kd_flag</span><br><span class="line">        )</span><br><span class="line">        checkpoint_teacher = torch.load(args.resume_teacher)</span><br><span class="line">        start_epoch_teacher = checkpoint_teacher[<span class="string">&quot;epoch&quot;</span>]</span><br><span class="line">        faf_module.teacher.load_state_dict(checkpoint_teacher[<span class="string">&quot;model_state_dict&quot;</span>])</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">&quot;Load teacher model from &#123;&#125;, at epoch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                args.resume_teacher, start_epoch_teacher</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        faf_module.teacher.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><p>先使用tearcherNet拿数据进行训练,然后拿训练后的模型加载</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TeacherNet</span>(<span class="params">NonIntermediateModelBase</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The teacher net for knowledged distillation in DiscoNet.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, config</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(TeacherNet, self).__init__(config, compress_level=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, bevs, maps=<span class="literal">None</span>, vis=<span class="literal">None</span></span>):</span></span><br><span class="line">        bevs = bevs.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>)  <span class="comment"># (Batch, seq, z, h, w)</span></span><br><span class="line">        <span class="comment"># vis = vis.permute(0, 3, 1, 2)</span></span><br><span class="line">        <span class="keyword">return</span> self.stpn(bevs)</span><br></pre></td></tr></table></figure><p>使用教师模型得到的结果和原本模型得到的结果(一些中间融合层)计算损失,代码中用的KL交叉熵损失</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kd_loss</span>(<span class="params">self, batch_size, data, fused_layer, num_agent, x_5, x_6, x_7</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.kd_flag:</span><br><span class="line">        bev_seq_teacher = data[<span class="string">&quot;bev_seq_teacher&quot;</span>]</span><br><span class="line">        kd_weight = data[<span class="string">&quot;kd_weight&quot;</span>]</span><br><span class="line">        (</span><br><span class="line">            x_8_teacher,</span><br><span class="line">            x_7_teacher,</span><br><span class="line">            x_6_teacher,</span><br><span class="line">            x_5_teacher,</span><br><span class="line">            x_3_teacher,</span><br><span class="line">            x_2_teacher,</span><br><span class="line">        ) = self.teacher(bev_seq_teacher)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># for k, v in self.teacher.named_parameters():</span></span><br><span class="line">        <span class="comment"># if k != &#x27;xxx.weight&#x27; and k != &#x27;xxx.bias&#x27;:</span></span><br><span class="line">        <span class="comment"># print(v.requires_grad)  # should be False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># for k, v in self.model.named_parameters():</span></span><br><span class="line">        <span class="comment"># if k != &#x27;xxx.weight&#x27; and k != &#x27;xxx.bias&#x27;:</span></span><br><span class="line">        <span class="comment"># print(v.requires_grad)  # should be False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># -------- KD loss---------#</span></span><br><span class="line">        kl_loss_mean = nn.KLDivLoss(size_average=<span class="literal">True</span>, reduce=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># target_x8 = x_8_teacher.permute(0, 2, 3, 1).reshape(5 * batch_size * 256 * 256, -1)</span></span><br><span class="line">        <span class="comment"># student_x8 = x_8.permute(0, 2, 3, 1).reshape(5 * batch_size * 256 * 256, -1)</span></span><br><span class="line">        <span class="comment"># kd_loss_x8 = kl_loss_mean(F.log_softmax(student_x8, dim=1), F.softmax(target_x8, dim=1))</span></span><br><span class="line">        <span class="comment"># #</span></span><br><span class="line">        target_x7 = x_7_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">128</span> * <span class="number">128</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x7 = x_7.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">128</span> * <span class="number">128</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_x7 = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x7, dim=<span class="number">1</span>), F.softmax(target_x7, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        target_x6 = x_6_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">64</span> * <span class="number">64</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x6 = x_6.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">64</span> * <span class="number">64</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_x6 = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x6, dim=<span class="number">1</span>), F.softmax(target_x6, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># #</span></span><br><span class="line">        target_x5 = x_5_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x5 = x_5.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_x5 = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x5, dim=<span class="number">1</span>), F.softmax(target_x5, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        target_x3 = x_3_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x3 = fused_layer.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_fused_layer = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x3, dim=<span class="number">1</span>), F.softmax(target_x3, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        kd_loss = kd_weight * (</span><br><span class="line">            kd_loss_x7 + kd_loss_x6 + kd_loss_x5 + kd_loss_fused_layer</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># kd_loss = kd_weight * (kd_loss_x6 + kd_loss_x5 + kd_loss_fused_layer)</span></span><br><span class="line">        <span class="comment"># print(kd_loss)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        kd_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> kd_loss</span><br><span class="line"></span><br></pre></td></tr></table></figure><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;代码还是很重要的,虽然发现有些代码库不怎么样.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>transformer and attention(二):various attention modules</title>
    <link href="https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/"/>
    <id>https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/</id>
    <published>2024-01-23T12:18:17.000Z</published>
    <updated>2024-01-24T06:01:26.733Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码.<br><span id="more"></span></p><h2 id="Squeeze-and-Excitation-Networks-2018"><a href="#Squeeze-and-Excitation-Networks-2018" class="headerlink" title="Squeeze-and-Excitation Networks 2018"></a>Squeeze-and-Excitation Networks 2018</h2><p><img data-src="https://s2.loli.net/2024/01/10/Lq6VRkQuoUpYSmc.png" alt="image-20240110094833740"></p><blockquote><ol><li>SENet通过学习channel之间的相关性，筛选出了针对通道的注意力，稍微增加了一点计算量，但是效果提升较明显</li><li>Squeeze-and-Excitation(SE) block是一个子结构，可以有效地嵌到其他分类或检测模型中。</li><li>SENet的核心思想在于通过网络根据loss去学习feature map的特征权重来使模型达到更好的结果</li><li>SE模块本质上是一种attention机制</li></ol></blockquote><p><img data-src="https://s2.loli.net/2024/01/10/ZrhKeEALunoDxpF.png" alt="image-20240110095007870"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># implement SEAttention</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SEAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channel=<span class="number">512</span>, reduction=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SEAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(channel // reduction, channel),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                init.normal_(m.weight, std=<span class="number">0.001</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x * y.expand_as(x)</span><br></pre></td></tr></table></figure><h2 id="Bottlenet-attention-Module-BAM-2018"><a href="#Bottlenet-attention-Module-BAM-2018" class="headerlink" title="Bottlenet attention Module (BAM) 2018"></a>Bottlenet attention Module (BAM) 2018</h2><p><img data-src="https://s2.loli.net/2024/01/23/7XzeCTDLwFEuiSM.png" alt="image-20240123200825093"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Flatten</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>.view(<span class="built_in">input</span>.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,channel,reduction:<span class="built_in">int</span>=<span class="number">16</span>,num_layer:<span class="built_in">int</span>=<span class="number">3</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        gate_channels = [channel]</span><br><span class="line">        gate_channels += [channel // reduction] * num_layer</span><br><span class="line">        gate_channels += [channel]</span><br><span class="line"></span><br><span class="line">        self.ca = nn.Sequential()</span><br><span class="line">        self.ca.add_module(<span class="string">&#x27;flatten&#x27;</span>,Flatten())</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layer):</span><br><span class="line">            self.ca.add_module(<span class="string">&#x27;fc&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i),nn.Linear(gate_channels[i],gate_channels[i+<span class="number">1</span>]))</span><br><span class="line">            self.ca.add_module(<span class="string">&#x27;bn%d&#x27;</span> % i, nn.BatchNorm1d(gate_channels[i+<span class="number">1</span>]))</span><br><span class="line">            self.ca.add_module(<span class="string">&#x27;relu&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i),nn.ReLU())</span><br><span class="line"></span><br><span class="line">        self.ca.add_module(<span class="string">&#x27;last_fc&#x27;</span>,nn.Linear(gate_channels[-<span class="number">2</span>],gate_channels[-<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        res = self.avg_pool(x)</span><br><span class="line">        res = self.ca(res)</span><br><span class="line">        <span class="keyword">return</span> res.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>).expand_as(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,channel,reduction=<span class="number">16</span>,num_layers=<span class="number">3</span>,dia_val=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.sa = nn.Sequential()</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;conv_reduce1&#x27;</span>,nn.Conv2d(in_channels=channel,out_channels=channel//reduction,kernel_size=<span class="number">1</span>))</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;bn_reduce1&#x27;</span>,nn.BatchNorm2d(channel//reduction))</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;relu_reduce1&#x27;</span>,nn.ReLU())</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            self.sa.add_module(<span class="string">&#x27;conv_%d&#x27;</span> % i,nn.Conv2d(in_channels=channel//reduction,out_channels=channel//reduction,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>,dilation=dia_val))</span><br><span class="line">            self.sa.add_module(<span class="string">&#x27;bn_%d&#x27;</span> % i,nn.BatchNorm2d(channel//reduction))</span><br><span class="line">            self.sa.add_module(<span class="string">&#x27;relu_%d&#x27;</span> % i,nn.ReLU())</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;conv_last&#x27;</span>,nn.Conv2d(in_channels=channel//reduction,out_channels=channel,kernel_size=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        res = self.sa(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res.expand_as(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BAMBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,channel:<span class="built_in">int</span>=<span class="number">512</span>,reduction:<span class="built_in">int</span>=<span class="number">16</span>,dia_val:<span class="built_in">int</span>=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.ca = ChannelAttention(channel=channel,reduction=reduction)</span><br><span class="line">        self.sa = SpatialAttention(channel=channel,reduction=reduction,dia_val=dia_val)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">        self.init_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        sa_out = self.sa(x)</span><br><span class="line">        ca_out = self.ca(x)</span><br><span class="line">        weight = self.sigmoid(sa_out + ca_out)</span><br><span class="line">        out = (<span class="number">1</span> + weight) * x</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># initial weights for the model</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_in&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m,nn.BatchNorm2d):</span><br><span class="line">                init.constant_(m.weight,<span class="number">1</span>)</span><br><span class="line">                init.constant_(m.bias,<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m,nn.Linear):</span><br><span class="line">                init.normal_(m.weight,std=<span class="number">0.001</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias,<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/23/3PEUjp2y9aMLI8u.png" alt="image-20240123200842336"></p><h2 id="DANet-Dual-Attention-Network-2018"><a href="#DANet-Dual-Attention-Network-2018" class="headerlink" title="DANet: Dual Attention Network 2018"></a>DANet: Dual Attention Network 2018</h2><p><img data-src="https://s2.loli.net/2024/01/23/R9GMVDrs23ca7Qp.png" alt="image-20240123210612879"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionAttentionModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-<span class="number">1</span>)//<span class="number">2</span>)</span><br><span class="line">        self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        bs,c,h,w=x.shape</span><br><span class="line">        y=self.cnn(x)</span><br><span class="line">        y=y.view(bs,c,-<span class="number">1</span>).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#bs,h*w,c</span></span><br><span class="line">        y=self.pa(y,y,y) <span class="comment">#bs,h*w,c</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttentionModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-<span class="number">1</span>)//<span class="number">2</span>)</span><br><span class="line">        self.pa=SimplifiedScaledDotProductAttention(H*W,h=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        bs,c,h,w=x.shape</span><br><span class="line">        y=self.cnn(x)</span><br><span class="line">        y=y.view(bs,c,-<span class="number">1</span>) <span class="comment">#bs,c,h*w</span></span><br><span class="line">        y=self.pa(y,y,y) <span class="comment">#bs,c,h*w</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DAModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.position_attention_module=PositionAttentionModule(d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span>)</span><br><span class="line">        self.channel_attention_module=ChannelAttentionModule(d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span></span><br><span class="line">        bs,c,h,w=<span class="built_in">input</span>.shape</span><br><span class="line">        p_out=self.position_attention_module(<span class="built_in">input</span>)</span><br><span class="line">        c_out=self.channel_attention_module(<span class="built_in">input</span>)</span><br><span class="line">        p_out=p_out.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>).view(bs,c,h,w)</span><br><span class="line">        c_out=c_out.view(bs,c,h,w)</span><br><span class="line">        <span class="keyword">return</span> p_out+c_out</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="CBAM-Convolutional-Block-Attention-Module-2018"><a href="#CBAM-Convolutional-Block-Attention-Module-2018" class="headerlink" title="CBAM: Convolutional Block Attention Module 2018"></a>CBAM: Convolutional Block Attention Module 2018</h2><p><img data-src="https://s2.loli.net/2024/01/10/uPRhgXEveC9JbFS.png" alt="image-20240110104503985"></p><p>通道注意力</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_planes, ratio=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1   = nn.Conv2d(in_planes, in_planes // <span class="number">16</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2   = nn.Conv2d(in_planes // <span class="number">16</span>, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))</span><br><span class="line">        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))</span><br><span class="line">        out = avg_out + max_out</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(out)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/10/wxDGep963Qzs5tq.png" alt="image-20240110104513785"></p><p>空间注意力</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">&#x27;kernel size must be 3 or 7&#x27;</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        max_out, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/10/hyUFPErbDKB3TwI.png" alt="image-20240110104523806"></p><script type="math/tex; mode=display">\begin{aligned}\mathbf{F^{\prime}=M_c(F)\otimes F,}\\\mathbf{F^{\prime\prime}=M_s(F^{\prime})\otimes F^{\prime},}\end{aligned}</script><script type="math/tex; mode=display">\begin{gathered}\mathbf{M_{c}}(\mathbf{F}) =\sigma(MLP(AvgPool(\mathbf{F}))+MLP(MaxPool(\mathbf{F}))) \\=\sigma(\mathbf{W_1}(\mathbf{W_0}(\mathbf{F_{avg}^c}))+\mathbf{W_1}(\mathbf{W_0}(\mathbf{F_{max}^c}))), \end{gathered}</script><script type="math/tex; mode=display">\begin{aligned}\mathbf{M_{s}}(\mathbf{F})& =\sigma(f^{7\times7}([AvgPool(\mathbf{F});MaxPool(\mathbf{F})]))  \\&=\sigma(f^{7\times7}([\mathbf{F_{avg}^{s}};\mathbf{F_{max}^{s}}])),\end{aligned}</script><p><img data-src="https://s2.loli.net/2024/01/10/MQNWLjZP2yH8cwd.png" alt="image-20240110142553774"></p><h2 id="Non-Local-2018"><a href="#Non-Local-2018" class="headerlink" title="Non-Local 2018"></a>Non-Local 2018</h2><p><img data-src="https://s2.loli.net/2024/01/11/IW6cKRTQN178kp4.png" alt="image-20240111161108109"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NonLocalNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_dim=<span class="number">64</span>, output_dim=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NonLocalNet, self).__init__()</span><br><span class="line">        intermediate_dim = input_dim // <span class="number">2</span></span><br><span class="line">        self.to_q = nn.Conv2d(input_dim, intermediate_dim, <span class="number">1</span>)</span><br><span class="line">        self.to_k = nn.Conv2d(input_dim, intermediate_dim, <span class="number">1</span>)</span><br><span class="line">        self.to_v = nn.Conv2d(input_dim, intermediate_dim, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Conv2d(intermediate_dim, output_dim, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        q = self.to_q(x).squeeze()</span><br><span class="line">        k = self.to_k(x).squeeze()</span><br><span class="line">        v = self.to_v(x).squeeze()</span><br><span class="line"></span><br><span class="line">        u = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        u = torch.softmax(u, dim=<span class="number">1</span>)</span><br><span class="line">        out = torch.bmm(u, v)</span><br><span class="line">        out = out.unsqueeze(<span class="number">2</span>)</span><br><span class="line">        out = self.conv(out)</span><br><span class="line">        <span class="keyword">return</span> out + x</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/19/9eNWHCpuiFsYLtU.png" alt="image-20240119110302126"></p><h2 id="SKNet-2019"><a href="#SKNet-2019" class="headerlink" title="SKNet 2019"></a>SKNet 2019</h2><p><img data-src="https://s2.loli.net/2024/01/23/ypZfsSKPBq9iLV6.png" alt="image-20240123192700386"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SKConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    https://arxiv.org/pdf/1903.06586.pdf</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, feature_dim, WH, M, G, r, stride=<span class="number">1</span>, L=<span class="number">32</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Constructor</span></span><br><span class="line"><span class="string">         Args:</span></span><br><span class="line"><span class="string">             features: input channel dimensionality.</span></span><br><span class="line"><span class="string">             WH: input spatial dimensionality, used for GAP kernel size.</span></span><br><span class="line"><span class="string">             M: the number of branchs.</span></span><br><span class="line"><span class="string">             G: num of convolution groups.</span></span><br><span class="line"><span class="string">             r: the radio for compute d, the length of z.</span></span><br><span class="line"><span class="string">             stride: stride, default 1.</span></span><br><span class="line"><span class="string">             L: the minimum dim of the vector z in paper, default 32.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        d = <span class="built_in">max</span>(<span class="built_in">int</span>(feature_dim / r), L)</span><br><span class="line">        self.M = M</span><br><span class="line">        self.feature_dim = feature_dim</span><br><span class="line">        self.convs = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">            self.convs.append(nn.Sequential(</span><br><span class="line">                nn.Conv2d(feature_dim, feature_dim, kernel_size=<span class="number">3</span> + i * <span class="number">2</span>, stride=stride, padding=<span class="number">1</span> + i, groups=G),</span><br><span class="line">                nn.BatchNorm2d(feature_dim),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">            ))</span><br><span class="line">        self.gap = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(feature_dim, d)</span><br><span class="line">        self.fcs = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">            self.fcs.append(</span><br><span class="line">                nn.Linear(d, feature_dim)</span><br><span class="line">            )</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i, conv <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.convs):</span><br><span class="line">            feat = conv(x).unsqueeze_(dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                feas = feat</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                feas = torch.cat((feas, feat), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        fea_U = torch.<span class="built_in">sum</span>(feas, dim=<span class="number">1</span>)</span><br><span class="line">        fea_s = self.gap(fea_U).squeeze_()</span><br><span class="line">        fea_z = self.fc(fea_s)</span><br><span class="line">        <span class="keyword">for</span> i, fc <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.fcs):</span><br><span class="line">            vector = fc(fea_z).unsqueeze_(dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                attention_vectors = vector</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                attention_vectors = torch.cat((attention_vectors, vector), dim=<span class="number">1</span>)</span><br><span class="line">        attention_vectors = self.softmax(attention_vectors)</span><br><span class="line">        attention_vectors = attention_vectors.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        fea_v = (feas*attention_vectors).<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> fea_v</span><br></pre></td></tr></table></figure><h2 id="CC-Net和Axial-Attention"><a href="#CC-Net和Axial-Attention" class="headerlink" title="CC-Net和Axial Attention"></a>CC-Net和Axial Attention</h2><p>看论文时提到了CC-Net使用了交叉注意了.</p><p>参考<a href="https://www.codenong.com/cs106760382/">Axial Attention 和 Criss-Cross Attention及其代码实现 | 码农家园 (codenong.com)</a>这篇blog,写的不错.</p><h2 id="Axial-Attention"><a href="#Axial-Attention" class="headerlink" title="Axial Attention"></a>Axial Attention</h2><p>轴向注意力,Axial Attention 的感受野是目标像素的同一行(或者同一列) 的W(或H)个像素</p><p>比如row attention</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实现轴向注意力中的 row Attention</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Softmax</span><br><span class="line"></span><br><span class="line"><span class="comment"># device = torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RowAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, q_k_dim, device</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        in_dim : int</span></span><br><span class="line"><span class="string">            channel of input img tensor</span></span><br><span class="line"><span class="string">        q_k_dim: int</span></span><br><span class="line"><span class="string">            channel of Q, K vector</span></span><br><span class="line"><span class="string">        device : torch.device</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(RowAttention, self).__init__()</span><br><span class="line">        self.in_dim = in_dim</span><br><span class="line">        self.q_k_dim = q_k_dim</span><br><span class="line">        self.device = device</span><br><span class="line">        </span><br><span class="line">        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.in_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">2</span>)</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>)).to(self.device)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        x : Tensor</span></span><br><span class="line"><span class="string">            4-D , (batch, in_dims, height, width) -- (b,c1,h,w)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## c1 = in_dims; c2 = q_k_dim</span></span><br><span class="line">        b, _, h, w = x.size()</span><br><span class="line">        </span><br><span class="line">        Q = self.query_conv(x) <span class="comment">#size = (b,c2, h,w)</span></span><br><span class="line">        K = self.key_conv(x)   <span class="comment">#size = (b, c2, h, w)</span></span><br><span class="line">        V = self.value_conv(x) <span class="comment">#size = (b, c1,h,w)</span></span><br><span class="line">        </span><br><span class="line">        Q = Q.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(b*h, -<span class="number">1</span>,w).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#size = (b*h,w,c2)</span></span><br><span class="line">        K = K.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(b*h, -<span class="number">1</span>,w)  <span class="comment">#size = (b*h,c2,w)</span></span><br><span class="line">        V = V.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(b*h, -<span class="number">1</span>,w)  <span class="comment">#size = (b*h, c1,w)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*h,w,w) [:,i,j] 表示Q的所有h的第 Wi行位置上所有通道值与 K的所有h的第 Wj列位置上的所有通道值的乘积，</span></span><br><span class="line">        <span class="comment"># 即(1,c2) * (c2,1) = (1,1)</span></span><br><span class="line">        row_attn = torch.bmm(Q,K) </span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        <span class="comment">#此时的 row_atten的[:,i,0:w] 表示Q的所有h的第 Wi行位置上所有通道值与 K的所有行的 所有列(0:w)的逐个位置上的所有通道值的乘积</span></span><br><span class="line">        <span class="comment">#此操作即为 Q的某个（i,j）与 K的（i,0:w）逐个位置的值的乘积，得到行attn</span></span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#对row_attn进行softmax</span></span><br><span class="line">        row_attn = self.softmax(row_attn) <span class="comment">#对列进行softmax，即[k,i,0:w] ，某一行的所有列加起来等于1，</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*h,c1,w) 这里先需要对row_atten进行 行列置换，使得某一列的所有行加起来等于1</span></span><br><span class="line">        <span class="comment">#[:,i,j]即为V的所有行的某个通道上，所有列的值 与 row_attn的行的乘积，即求权重和</span></span><br><span class="line">        out = torch.bmm(V,row_attn.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)) </span><br><span class="line">        <span class="comment">#size = (b,c1,h,2)</span></span><br><span class="line">        out = out.view(b,h,-<span class="number">1</span>,w).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)  </span><br><span class="line">        out = self.gamma*out + x </span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment">#实现轴向注意力中的 cols Attention</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">20</span>).to(device)</span><br><span class="line">row_attn = RowAttention(in_dim = <span class="number">8</span>, q_k_dim = <span class="number">4</span>,device = device).to(device)</span><br><span class="line"><span class="built_in">print</span>(row_attn(x).size())</span><br></pre></td></tr></table></figure><p>列注意力同理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实现轴向注意力中的 column Attention</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Softmax</span><br><span class="line"></span><br><span class="line"><span class="comment"># device = torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, q_k_dim, device</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        in_dim : int</span></span><br><span class="line"><span class="string">            channel of input img tensor</span></span><br><span class="line"><span class="string">        q_k_dim: int</span></span><br><span class="line"><span class="string">            channel of Q, K vector</span></span><br><span class="line"><span class="string">        device : torch.device</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ColAttention, self).__init__()</span><br><span class="line">        self.in_dim = in_dim</span><br><span class="line">        self.q_k_dim = q_k_dim</span><br><span class="line">        self.device = device</span><br><span class="line">        </span><br><span class="line">        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.in_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">2</span>)</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>)).to(self.device)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        x : Tensor</span></span><br><span class="line"><span class="string">            4-D , (batch, in_dims, height, width) -- (b,c1,h,w)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## c1 = in_dims; c2 = q_k_dim</span></span><br><span class="line">        b, _, h, w = x.size()</span><br><span class="line">        </span><br><span class="line">        Q = self.query_conv(x) <span class="comment">#size = (b,c2, h,w)</span></span><br><span class="line">        K = self.key_conv(x)   <span class="comment">#size = (b, c2, h, w)</span></span><br><span class="line">        V = self.value_conv(x) <span class="comment">#size = (b, c1,h,w)</span></span><br><span class="line">        </span><br><span class="line">        Q = Q.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(b*w, -<span class="number">1</span>,h).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#size = (b*w,h,c2)</span></span><br><span class="line">        K = K.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(b*w, -<span class="number">1</span>,h)  <span class="comment">#size = (b*w,c2,h)</span></span><br><span class="line">        V = V.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(b*w, -<span class="number">1</span>,h)  <span class="comment">#size = (b*w,c1,h)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*w,h,h) [:,i,j] 表示Q的所有W的第 Hi行位置上所有通道值与 K的所有W的第 Hj列位置上的所有通道值的乘积，</span></span><br><span class="line">        <span class="comment"># 即(1,c2) * (c2,1) = (1,1)</span></span><br><span class="line">        col_attn = torch.bmm(Q,K) </span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        <span class="comment">#此时的 col_atten的[:,i,0:w] 表示Q的所有W的第 Hi行位置上所有通道值与 K的所有W的 所有列(0:h)的逐个位置上的所有通道值的乘积</span></span><br><span class="line">        <span class="comment">#此操作即为 Q的某个（i,j）与 K的（i,0:h）逐个位置的值的乘积，得到列attn</span></span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#对row_attn进行softmax</span></span><br><span class="line">        col_attn = self.softmax(col_attn) <span class="comment">#对列进行softmax，即[k,i,0:w] ，某一行的所有列加起来等于1，</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*w,c1,h) 这里先需要对col_atten进行 行列置换，使得某一列的所有行加起来等于1</span></span><br><span class="line">        <span class="comment">#[:,i,j]即为V的所有行的某个通道上，所有列的值 与 col_attn的行的乘积，即求权重和</span></span><br><span class="line">        out = torch.bmm(V,col_attn.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)) </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b,c1,h,w)</span></span><br><span class="line">        out = out.view(b,w,-<span class="number">1</span>,h).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        out = self.gamma*out + x </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"><span class="comment">#实现轴向注意力中的 cols Attention</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">20</span>).to(device)</span><br><span class="line">col_attn = ColAttention(<span class="number">8</span>, <span class="number">4</span>, device = device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(col_attn(x).size())</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Criss-Cross-Attention-Module-2019"><a href="#Criss-Cross-Attention-Module-2019" class="headerlink" title="Criss-Cross Attention Module 2019"></a>Criss-Cross Attention Module 2019</h2><p><img data-src="https://pic4.zhimg.com/80/v2-322dae3099e1ed29c2751c7c7efd88b7_720w.webp" alt="img"></p><p>CC-Attention 的感受野是与目标像素的同一行和同一列的(H + W - 1)个像素,目标元素的同一行和同一列.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrissCrossAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Criss-Cross Attention Module</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    reference: https://github.com/speedinghzl/CCNet</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CrissCrossAttention,self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.query_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">        self.key_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">        self.value_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">3</span>)</span><br><span class="line">        self.INF = INF</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, query, key, value</span>):</span></span><br><span class="line">        m_batchsize, _, height, width = query.size()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        proj_query = self.query_conv(query)</span><br><span class="line">        proj_query_H = proj_query.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        proj_query_W = proj_query.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        proj_key = self.key_conv(key)</span><br><span class="line">        proj_key_H = proj_key.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height)</span><br><span class="line">        proj_key_W = proj_key.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        proj_value = self.value_conv(value)</span><br><span class="line">        proj_value_H = proj_value.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height)</span><br><span class="line">        proj_value_W = proj_value.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width)</span><br><span class="line">        energy_H = (torch.bmm(proj_query_H, proj_key_H)+self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        energy_W = torch.bmm(proj_query_W, proj_key_W).view(m_batchsize,height,width,width)</span><br><span class="line">        concate = self.softmax(torch.cat([energy_H, energy_W], <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        att_H = concate[:,:,:,<span class="number">0</span>:height].permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*width,height,height)</span><br><span class="line">        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width)</span><br><span class="line">        out_H = torch.bmm(proj_value_H, att_H.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)).view(m_batchsize,width,-<span class="number">1</span>,height).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">        out_W = torch.bmm(proj_value_W, att_W.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)).view(m_batchsize,height,-<span class="number">1</span>,width).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">return</span> self.gamma*(out_H + out_W) + value</span><br></pre></td></tr></table></figure><p><img data-src="https://pic4.zhimg.com/80/v2-03942c1de5a5a77aafbdb1a1fe697fb3_720w.webp" alt="img"></p><h2 id="Coordinate-Attention-2021"><a href="#Coordinate-Attention-2021" class="headerlink" title="Coordinate Attention 2021"></a>Coordinate Attention 2021</h2><p><img data-src="https://s2.loli.net/2024/01/19/ZrmAMkChLcbFpfg.png" alt="image-20240119195945841"></p><p>在通道注意力的基础上兼顾其位置关系，将通道注意力与空间注意力联合起来</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">h_sigmoid</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplace=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(h_sigmoid, self).__init__()</span><br><span class="line">        self.relu = nn.ReLU6(inplace=inplace)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.relu(x + <span class="number">3</span>) / <span class="number">6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">h_swish</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplace=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(h_swish, self).__init__()</span><br><span class="line">        self.sigmoid = h_sigmoid(inplace=inplace)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * self.sigmoid(</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CA</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inp, reduction</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CA, self).__init__()</span><br><span class="line">        <span class="comment"># h:height(行)   w:width(列)</span></span><br><span class="line">        self.pool_h = nn.AdaptiveAvgPool2d((<span class="literal">None</span>, <span class="number">1</span>))  <span class="comment"># (b,c,h,w)--&gt;(b,c,h,1)</span></span><br><span class="line">        self.pool_w = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="literal">None</span>))  <span class="comment"># (b,c,h,w)--&gt;(b,c,1,w)</span></span><br><span class="line"></span><br><span class="line">         <span class="comment"># mip = max(8, inp // reduction)  论文作者所用</span></span><br><span class="line">        mip =  inp // reduction  </span><br><span class="line"> </span><br><span class="line">        self.conv1 = nn.Conv2d(inp, mip, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(mip)</span><br><span class="line">        self.act = h_swish()</span><br><span class="line"> </span><br><span class="line">        self.conv_h = nn.Conv2d(mip, inp, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.conv_w = nn.Conv2d(mip, inp, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        identity = x</span><br><span class="line"> </span><br><span class="line">        n, c, h, w = x.size()</span><br><span class="line">        x_h = self.pool_h(x)  <span class="comment"># (b,c,h,1)</span></span><br><span class="line">        x_w = self.pool_w(x).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)  <span class="comment"># (b,c,w,1)</span></span><br><span class="line"> </span><br><span class="line">        y = torch.cat([x_h, x_w], dim=<span class="number">2</span>)</span><br><span class="line">        y = self.conv1(y)</span><br><span class="line">        y = self.bn1(y)</span><br><span class="line">        y = self.act(y)</span><br><span class="line"> </span><br><span class="line">        x_h, x_w = torch.split(y, [h, w], dim=<span class="number">2</span>)</span><br><span class="line">        x_w = x_w.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">        a_h = self.conv_h(x_h).sigmoid()</span><br><span class="line">        a_w = self.conv_w(x_w).sigmoid()</span><br><span class="line"> </span><br><span class="line">        out = identity * a_w * a_h</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h2 id="Attentional-Feature-Fusion-2021"><a href="#Attentional-Feature-Fusion-2021" class="headerlink" title="Attentional Feature Fusion  2021"></a>Attentional Feature Fusion  2021</h2><p><a href="https://openaccess.thecvf.com/content/WACV2021/html/Dai_Attentional_Feature_Fusion_WACV_2021_paper.html">WACV 2021 Open Access Repository (thecvf.com)</a></p><p><a href="https://github.com/YimianDai/open-aff">YimianDai/open-aff: code and trained models for “Attentional Feature Fusion” (github.com)</a></p><p>这些注意力模块通常用在一些block(或叫unit)块中,然后一般把这些块放到多尺度的网络下</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://blog.csdn.net/weixin_43718675/article/details/106760382">Axial Attention 和 Criss-Cross Attention及其代码实现_cross attention代码-CSDN博客</a></li><li><a href="https://blog.csdn.net/qwedsaewq/article/details/89052643">sknet阅读笔记及pytorch实现代码_pytorch sknet-CSDN博客</a></li><li><a href="https://blog.csdn.net/weixin_43427721/article/details/124652525?ops_request_misc=%7B%22request%5Fid%22%3A%22170601489116800226596213%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&amp;request_id=170601489116800226596213&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-124652525-null-null.nonecase&amp;utm_term=注意力&amp;spm=1018.2226.3001.4450">【注意力机制集锦】Channel Attention通道注意力网络结构、源码解读系列一_通道注意力机制结构图-CSDN博客</a></li><li><a href="https://blog.csdn.net/weixin_43427721/article/details/124766242">【注意力机制集锦2】BAM&amp;SGE&amp;DAN原文、结构、源码详解_bam注意力机制-CSDN博客</a></li></ol><p>Thanks to <a href="https://github.com/lyp2333/External-Attention-pytorch/tree/master">lyp2333/External-Attention-pytorch (github.com)</a> and <a href="https://github.com/xmu-xiaoma666/External-Attention-pytorch">xmu-xiaoma666/External-Attention-pytorch: 🍀 Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.⭐⭐⭐ (github.com)</a></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码.&lt;br&gt;</summary>
    
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/categories/deep-learning/"/>
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>Golang学习:使用Gin</title>
    <link href="https://www.sekyoro.top/2024/01/17/Golang%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8Gin/"/>
    <id>https://www.sekyoro.top/2024/01/17/Golang%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8Gin/</id>
    <published>2024-01-17T10:17:45.000Z</published>
    <updated>2024-01-17T10:46:28.465Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Go语言simple并且easy,内置了很多有用的库,对并发支持比较好并且官方(指Google)还是比较重视的.<br><span id="more"></span><br>Go的官方资料就比较好学习<a href="https://go.dev/">The Go Programming Language</a>,有个tutorial还有个examples.写了个使用Colly用来爬取图片和Gin用来显示图片的代码.</p><p>目录结构比较简单</p><p><img data-src="https://s2.loli.net/2024/01/17/xMBdCzhvfZEgVAT.png" alt="image-20240117183718713"></p><p>使用Go的mod进行配置项目,比如<code>go mod init &lt;project name&gt;</code>初始化</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/gin-gonic/gin&quot;</span></span><br><span class="line"><span class="string">&quot;sekyoro.top/Goimg/routes&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">router := gin.Default()</span><br><span class="line">r := router.Group(<span class="string">&quot;/api&quot;</span>)</span><br><span class="line">router.Static(<span class="string">&quot;/img&quot;</span>, <span class="string">&quot;./imgs&quot;</span>)</span><br><span class="line">routes.DownloadPicRoutes(r)</span><br><span class="line">routes.ShowPicRoutes(r)</span><br><span class="line">routes.GetPicRoutes(r</span><br><span class="line">router.Run(<span class="string">&quot;:8080&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里设置了静态资源并使用分组路由构建路由到处理的方法.</p><p>在routes文件夹下就有对应的路由,比如在下载文件下,设置了两个路由.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> routes</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/gin-gonic/gin&quot;</span></span><br><span class="line"><span class="string">&quot;sekyoro.top/Goimg/handlers&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DownloadPicRoutes</span><span class="params">(router *gin.RouterGroup)</span></span> &#123;</span><br><span class="line">router.GET(<span class="string">&quot;/pix&quot;</span>, handlers.DownloadPixvisionPicHandler)</span><br><span class="line">router.GET(<span class="string">&quot;/booru/:type&quot;</span>, handlers.DownloadBooruPicHandler)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在downloader目录下写进行处理的方法.比如下面是<code>DownloadPixvisionPicHandler.go</code>去爬取图片并保存到本地</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> handlers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;log&quot;</span></span><br><span class="line"><span class="string">&quot;net/http&quot;</span></span><br><span class="line"><span class="string">&quot;os&quot;</span></span><br><span class="line"><span class="string">&quot;path/filepath&quot;</span></span><br><span class="line"><span class="string">&quot;time&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;github.com/gin-gonic/gin&quot;</span></span><br><span class="line"><span class="string">&quot;github.com/gocolly/colly/v2&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DownloadPixvisionPicHandler</span><span class="params">(ctx *gin.Context)</span></span> &#123;</span><br><span class="line">counter  := <span class="number">0</span></span><br><span class="line">allow_img_site := checkAllowSite()</span><br><span class="line"><span class="comment">// fmt.Println(allow_img_site)</span></span><br><span class="line">c := colly.NewCollector(colly.UserAgent(userAgent), colly.AllowedDomains(allow_img_site...),</span><br><span class="line">colly.Async())</span><br><span class="line">c.SetRequestTimeout(<span class="number">20</span> * time.Second)</span><br><span class="line"></span><br><span class="line">c.Limit(&amp;colly.LimitRule&#123;</span><br><span class="line">DomainGlob:  <span class="string">&quot;*pximg.*&quot;</span>,</span><br><span class="line">Parallelism: <span class="number">5</span>,</span><br><span class="line"><span class="comment">//Delay:      5 * time.Second,</span></span><br><span class="line">RandomDelay: <span class="number">500</span> * time.Duration(time.Millisecond),</span><br><span class="line">&#125;)</span><br><span class="line">c.Limit(&amp;colly.LimitRule&#123;</span><br><span class="line">DomainGlob:  <span class="string">&quot;*pixivision.*&quot;</span>,</span><br><span class="line">Parallelism: <span class="number">5</span>,</span><br><span class="line">Delay:       <span class="number">200</span> * time.Duration(time.Millisecond),</span><br><span class="line">RandomDelay: <span class="number">500</span> * time.Duration(time.Millisecond),</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">if</span> proxy != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> proxy[<span class="string">&quot;http&quot;</span>] != <span class="literal">nil</span> &#123;</span><br><span class="line">err := c.SetProxy(fmt.Sprintf(<span class="string">&quot;http://%s&quot;</span>, proxy[<span class="string">&quot;http&quot;</span>].(<span class="keyword">string</span>)))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Panic(err.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> proxy[<span class="string">&quot;socks5&quot;</span>] != <span class="literal">nil</span> &#123;</span><br><span class="line">err := c.SetProxy(fmt.Sprintf(<span class="string">&quot;socks5://%s&quot;</span>, proxy[<span class="string">&quot;socks5&quot;</span>].(<span class="keyword">string</span>)))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Panic(err.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">limit_page, ok := conf[<span class="string">&quot;limit_page&quot;</span>].(<span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">log.Panic(<span class="string">&quot;爬取图片目录数配置出错&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">log.Panic(<span class="string">&quot;下载路径配置出错&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Find and visit all links</span></span><br><span class="line">c.OnHTML(<span class="string">&quot;a[href]&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(e *colly.HTMLElement)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> e.DOM.Parent().HasClass(<span class="string">&quot;arc__title&quot;</span>) &#123;</span><br><span class="line">log.Default().Println(<span class="string">&quot;Link found:&quot;</span>, e.Attr(<span class="string">&quot;href&quot;</span>))</span><br><span class="line"><span class="keyword">if</span> counter &gt;= limit_page &#123;</span><br><span class="line">ctx.JSON(http.StatusOK, fmt.Sprintf(<span class="string">&quot;success! %d directory image&quot;</span>, limit_page))</span><br><span class="line">&#125;</span><br><span class="line">e.Request.Visit(e.Attr(<span class="string">&quot;href&quot;</span>))</span><br><span class="line">counter += <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">c.OnHTML(<span class="string">&quot;div[class=&#x27;_article-main&#x27;]&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(e *colly.HTMLElement)</span></span> &#123;</span><br><span class="line">title := e.ChildText(<span class="string">&quot;h1[class=&#x27;am__title&#x27;]&quot;</span>)</span><br><span class="line"><span class="comment">// log.Default().Println(&quot;title:&quot;, title)</span></span><br><span class="line"><span class="comment">// p := Pics&#123;title: title, pics: make(map[string]string)&#125;</span></span><br><span class="line">err := os.MkdirAll(filepath.Join(download_root_folder, title), os.ModePerm)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Default().Println(err.Error())</span><br><span class="line">&#125;</span><br><span class="line">e.ForEach(<span class="string">&quot;div.article-item:not(._feature-article-body__paragraph) div.am__work__main&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(i <span class="keyword">int</span>, h *colly.HTMLElement)</span></span> &#123;</span><br><span class="line">log.Default().Println(<span class="string">&quot;pic:&quot;</span>, h.ChildAttr(<span class="string">&quot;img&quot;</span>, <span class="string">&quot;src&quot;</span>))</span><br><span class="line">img_src := h.ChildAttr(<span class="string">&quot;img&quot;</span>, <span class="string">&quot;src&quot;</span>)</span><br><span class="line">h.Request.Visit(img_src)</span><br><span class="line">h.Request.Ctx.Put(<span class="string">&quot;title&quot;</span>, title)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">&#125;)</span><br><span class="line">c.OnResponse(<span class="function"><span class="keyword">func</span><span class="params">(r *colly.Response)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> img_url URL_path = url_path(r.Request.URL.Path)</span><br><span class="line"><span class="comment">// log.Default().Println(&quot;img_name:&quot;, img_name)</span></span><br><span class="line"><span class="keyword">if</span> img_url.isPic() &#123;</span><br><span class="line">img_path := filepath.Join(download_root_folder,r.Ctx.Get(<span class="string">&quot;title&quot;</span>), <span class="keyword">string</span>(img_url.(url_path)))</span><br><span class="line">r.Save(img_path)</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">c.OnRequest(<span class="function"><span class="keyword">func</span><span class="params">(r *colly.Request)</span></span> &#123;</span><br><span class="line">log.Default().Println(<span class="string">&quot;Visiting&quot;</span>, r.URL)</span><br><span class="line"><span class="keyword">if</span> r.URL.Host == <span class="string">&quot;i.pximg.net&quot;</span> &#123;</span><br><span class="line">r.Headers.Set(<span class="string">&quot;Referer&quot;</span>, <span class="string">&quot;https://www.pixivision.net/&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">c.OnError(<span class="function"><span class="keyword">func</span><span class="params">(r *colly.Response, err error)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">log.Default().Println(<span class="string">&quot;Request URL:&quot;</span>, r.Request.URL, <span class="string">&quot;failed with response:&quot;</span>, <span class="keyword">string</span>(r.Body), <span class="string">&quot;\nError:&quot;</span>, err.Error())</span><br><span class="line">&#125;)</span><br><span class="line">c.Visit(pixivision_site)</span><br><span class="line">c.Wait()</span><br><span class="line">ctx.JSON(http.StatusOK, fmt.Sprintf(<span class="string">&quot;success! %d directory image&quot;</span>, limit_page))</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在<code>configure.yaml</code>中进行配置相关信息.</p><p>最后部署可以考虑使用render<a href="https://render.com/">Cloud Application Hosting for Developers | Render</a>,来玩玩吧<a href="https://go-img.onrender.com/api/show">https://go-img.onrender.com/api/show</a></p><p>完整代码可以在我的github<a href="https://github.com/drowning-in-codes/myGo">drowning-in-codes/myGo (github.com)</a>上看,我也上传了docker<a href="https://hub.docker.com/r/proanimer/goimg">proanimer/goimg - Docker Image</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull proanimer/goimg</span><br></pre></td></tr></table></figure><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Go语言simple并且easy,内置了很多有用的库,对并发支持比较好并且官方(指Google)还是比较重视的.&lt;br&gt;</summary>
    
    
    
    
    <category term="Golang" scheme="https://www.sekyoro.top/tags/Golang/"/>
    
    <category term="Gin" scheme="https://www.sekyoro.top/tags/Gin/"/>
    
  </entry>
  
  <entry>
    <title>gRPC学习</title>
    <link href="https://www.sekyoro.top/2024/01/05/grpc%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/01/05/grpc%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-01-05T11:16:58.000Z</published>
    <updated>2024-01-06T08:03:32.668Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>RPC是远程调用,而google实现了grpc比较方便地实现了远程调用,gRPC是一个现代的开源远程过程调用(RPC)框架<br><span id="more"></span></p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><p>在gRPC中，客户端应用程序可以直接调用另一台计算机上的服务器应用程序上的方法，就好像它是本地对象一样。</p><blockquote><p>远程过程调用是一个分布式计算的客户端-服务器（Client/Server）的例子，它简单而又广受欢迎。<br>远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。<br>由于存在各式各样的变体和细节差异，对应地派生了各式远程过程调用协议，而且它们并不互相兼容。</p><p>为了允许不同的客户端均能访问服务器，<strong>许多标准化的 RPC 系统应运而生了。其中大部分采用接口描述语言（Interface Description Language，IDL），方便跨平台的远程过程调用</strong>。</p></blockquote><p>与许多RPC系统一样，gRPC基于定义服务的思想，指定可以通过其参数和返回类型远程调用的方法。在服务器端，服务器实现了这个接口，并运行gRPC服务器来处理客户端调用。在客户端，客户端有一个stub（在某些语言中称为客户端），它提供与服务器相同的方法。</p><p>它具有许多特性</p><ol><li><strong>强大的IDL特性</strong><br>RPC使用ProtoBuf来定义服务，ProtoBuf是由Google开发的一种数据序列化协议，性能出众，得到了广泛的应用。</li><li>支持多种语言<br>支持C++、Java、Go、Python、Ruby、C#、Node.js、Android Java、Objective-C、PHP等编程语言。</li><li>基于<strong>HTTP/2</strong>标准设计</li></ol><p><img data-src="https://grpc.io/img/landing-2.svg" alt="Concept Diagram"></p><p>默认情况下，gRPC使用<strong>Protocol Buffers</strong>，这是谷歌成熟的开源机制，<strong>用于序列化结构化数据(尽管它可以与JSON等其他数据格式一起使用)</strong></p><h3 id="与REST差异"><a href="#与REST差异" class="headerlink" title="与REST差异"></a>与REST差异</h3><p>RPC 的消息传输可以通过 TCP、UDP 或者 HTTP等，所以有时候我们称之为 RPC over TCP、 RPC over HTTP。</p><p>RPC 通过 HTTP 传输消息的时候和 RESTful的架构是类似的，但是也有不同。</p><blockquote><ul><li>gRPC使用HTTP/2，而REST使用HTTP1.1</li><li>gRPC使用协议缓冲区数据格式，而不是REST API中通常使用的标准JSON数据格式</li><li>使用gRPC,可以利用HTTP/2功能，如服务器端流式传输、客户端流式传输，甚至双向流式传输</li></ul></blockquote><p>首先 RPC 的客户端和服务器端师紧耦合的，客户端需要知道调用的过程的名字，过程的参数以及它们的类型、顺序等。<strong>一旦服务器更改了过程的实现，客户端的实现很容易出问题</strong>。RESTful基于 http的语义操作资源，参数的顺序一般没有关系，也很容易的<strong>通过代理转换链接和资源位置</strong>，从这一点上来说，RESTful 更灵活。</p><p>其次，它们操作的对象不一样。 RPC 操作的是方法和过程，它要操作的是方法对象。 RESTful 操作的是资源(resource)，而不是方法。</p><p>第三，RESTful执行的是对资源的操作，增加、查找、修改和删除等,主要是CURD，所以如果你要实现一个特定目的的操作，比如为名字姓张的学生的数学成绩都加上10这样的操作，<br>RESTful的API设计起来就不是那么直观或者有意义。在这种情况下, RPC的实现更有意义，它可以实现一个直接的方法方法供客户端调用</p><p><strong>RPC over TCP可以通过长连接减少连接的建立所产生的花费</strong>，在调用次数非常巨大的时候(这是目前互联网公司经常遇到的情况,大并发的情况下)，这个花费影响是非常巨大的。<br>当然 RESTful 也可以通过 keep-alive 实现长连接, 但是它最大的一个问题是它的<strong>request-response模型是阻塞的</strong> (http1.0和 http1.1, http 2.0没这个问题)，<br>发送一个请求后只有等到response返回才能发送第二个请求 (有些http server实现了pipeling的功能，但不是标配), RPC的实现没有这个限制。</p><h3 id="其他RPC框架"><a href="#其他RPC框架" class="headerlink" title="其他RPC框架"></a>其他RPC框架</h3><p>目前的 RPC 框架大致有两种不同的侧重方向,一种<strong>偏重于服务治理</strong>,另一种<strong>偏重于跨语言调用</strong>。</p><p>服务治理型的 RPC 框架有Alibabs <strong>Dubbo</strong>、Motan 等，这类的 RPC 框架的特点是功能丰富，<strong>提供高性能的远程调用以及服务发现和治理功能</strong>，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。</p><p>跨语言调用型的 RPC 框架有 Thrift、<strong>gRPC</strong>、Hessian、Finagle 等，<strong>这一类的 RPC 框架重点关注于服务的跨语言调用，能够支持大部分的语言进行语言无关的调用</strong>，非常适合于为不同语言提供通用远程服务的场景。但这类框架没有服务发现相关机制，实际使用时一般需要代理层进行请求转发和负载均衡策略控制。</p><p><a href="https://thrift.apache.org/">thrift</a>是Apache的一个跨语言的高性能的服务框架，也得到了广泛的应用。它的功能类似 gRPC, 支持跨语言，不支持服务治理。</p><p><a href="https://github.com/smallnest/rpcx">rpcx</a> 是一个分布式的Go语言的 RPC 框架，支持Zookepper、etcd、consul多种服务发现方式，多种服务路由方式， 是目前性能最好的 RPC 框架之一</p><h3 id="使用protobuf"><a href="#使用protobuf" class="headerlink" title="使用protobuf"></a>使用protobuf</h3><p>定义要在proto文件中序列化的数据的结构：这是一个扩展名为.proto的普通文本文件。协议缓冲区数据被构造为消息，其中每个消息都是一个包含一系列名值对（称为字段）的信息的小逻辑记录。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">  <span class="built_in">string</span> name = <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">int32</span> id = <span class="number">2</span>;</span><br><span class="line">  <span class="built_in">bool</span> has_ponycopter = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>指定了数据结构,就可以<strong>使用协议缓冲区编译器protoc从proto定义中生成首选语言的数据访问类</strong>.</p><p>它们为每个字段提供了简单的访问器,如name()和set_name()，以及将整个结构序列化到原始字节/从原始字节解析整个结构的方法。</p><p>因此，例如，如果选择的语言是C++，那么在上面的示例中运行编译器将生成一个名为Person的类。然后，您可以在应用程序中使用此类来填充、序列化和检索Person协议缓冲区消息。</p><p>gRPC使用protoc和一个特殊的gRPC插件从proto文件中生成代码：<strong>可以获得生成的gRPC客户端和服务器代码，以及用于填充、序列化和检索消息类型的常规协议缓冲区代码。</strong>(截至目前protobuf最新版本是v3)</p><h2 id="gRPC-in-Go"><a href="#gRPC-in-Go" class="headerlink" title="gRPC in Go"></a>gRPC in Go</h2><h3 id="下载protoc"><a href="#下载protoc" class="headerlink" title="下载protoc"></a>下载protoc</h3><blockquote><p>虽然不是强制性的，但gRPC应用程序通常利用proto buffer进行服务定义和数据序列化。</p></blockquote><p><a href="https://github.com/protocolbuffers/protobuf/releases">Releases · protocolbuffers/protobuf (github.com)</a></p><p>protoc用于编译.proto文件，其中包含服务和消息定义,Linux或Mac直接使用对应包管理器下载即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt install -y protobuf-compiler</span><br><span class="line">protoc --version  <span class="comment"># Ensure compiler version is 3+</span></span><br></pre></td></tr></table></figure><p>Windows在github上下载二进制包<a href="https://github.com/protocolbuffers/protobuf/releases">Releases · protocolbuffers/protobuf (github.com)</a></p><h3 id="protocol-compiler的Go插件"><a href="#protocol-compiler的Go插件" class="headerlink" title="protocol compiler的Go插件"></a>protocol compiler的Go插件</h3><h4 id="下载protoc-go-gen"><a href="#下载protoc-go-gen" class="headerlink" title="下载protoc-go-gen"></a>下载protoc-go-gen</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2</span><br><span class="line">go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28</span><br></pre></td></tr></table></figure><p>下载zip的文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b v1.60.1 --depth 1 https://github.com/grpc/grpc-go</span><br></pre></td></tr></table></figure><h4 id="proto文件"><a href="#proto文件" class="headerlink" title="proto文件"></a>proto文件</h4><p>下面定义了服务</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Interface exported by the server.</span></span><br><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">RouteGuide</span> </span>&#123;</span><br><span class="line">  <span class="comment">// A simple RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Obtains the feature at a given position.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// A feature with an empty name is returned if there&#x27;s no feature at the given</span></span><br><span class="line">  <span class="comment">// position.</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> GetFeature(Point) <span class="keyword">returns</span> (Feature) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A server-to-client streaming RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Obtains the Features available within the given Rectangle.  Results are</span></span><br><span class="line">  <span class="comment">// streamed rather than returned at once (e.g. in a response message with a</span></span><br><span class="line">  <span class="comment">// repeated field), as the rectangle may cover a large area and contain a</span></span><br><span class="line">  <span class="comment">// huge number of features.</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> ListFeatures(Rectangle) <span class="keyword">returns</span> (stream Feature) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A client-to-server streaming RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Accepts a stream of Points on a route being traversed, returning a</span></span><br><span class="line">  <span class="comment">// RouteSummary when traversal is completed.</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> RecordRoute(stream Point) <span class="keyword">returns</span> (RouteSummary) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A Bidirectional streaming RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Accepts a stream of RouteNotes sent while a route is being traversed,</span></span><br><span class="line">  <span class="comment">// while receiving other RouteNotes (e.g. from other users).</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> RouteChat(stream RouteNote) <span class="keyword">returns</span> (stream RouteNote) </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中涉及到一些参数message表示传递数据.</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Points are represented as latitude-longitude pairs in the E7 representation</span></span><br><span class="line"><span class="comment">// (degrees multiplied by 10**7 and rounded to the nearest integer).</span></span><br><span class="line"><span class="comment">// Latitudes should be in the range +/- 90 degrees and longitude should be in</span></span><br><span class="line"><span class="comment">// the range +/- 180 degrees (inclusive).</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">  <span class="built_in">int32</span> latitude = <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">int32</span> longitude = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A latitude-longitude rectangle, represented as two diagonally opposite</span></span><br><span class="line"><span class="comment">// points &quot;lo&quot; and &quot;hi&quot;.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Rectangle</span> </span>&#123;</span><br><span class="line">  <span class="comment">// One corner of the rectangle.</span></span><br><span class="line">  Point lo = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The other corner of the rectangle.</span></span><br><span class="line">  Point hi = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A feature names something at a given point.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If a feature could not be named, the name is empty.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Feature</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The name of the feature.</span></span><br><span class="line">  <span class="built_in">string</span> name = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The point where the feature is detected.</span></span><br><span class="line">  Point location = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A RouteNote is a message sent while at a given point.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">RouteNote</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The location from which the message is sent.</span></span><br><span class="line">  Point location = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The message to be sent.</span></span><br><span class="line">  <span class="built_in">string</span> <span class="class"><span class="keyword">message</span> = 2;</span></span><br><span class="line"><span class="class">&#125;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">// <span class="title">A</span> RouteSummary is received in response to a RecordRoute rpc.</span></span><br><span class="line"><span class="class">//</span></span><br><span class="line"><span class="class">// It contains the number of individual points received, the number of</span></span><br><span class="line"><span class="class">// detected features, and the total distance covered as the cumulative sum of</span></span><br><span class="line"><span class="class">// the distance between each point.</span></span><br><span class="line"><span class="class">message RouteSummary </span>&#123;</span><br><span class="line">  <span class="comment">// The number of points received.</span></span><br><span class="line">  <span class="built_in">int32</span> point_count = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The number of known features passed while traversing the route.</span></span><br><span class="line">  <span class="built_in">int32</span> feature_count = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The distance covered in metres.</span></span><br><span class="line">  <span class="built_in">int32</span> distance = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The duration of the traversal in seconds.</span></span><br><span class="line">  <span class="built_in">int32</span> elapsed_time = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的两个文件包括message实现和用于server,client的代码</p><p>在pb.go文件中对于每个message实现了其type,比如对于<code>Rectangle</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Rectangle <span class="keyword">struct</span> &#123;</span><br><span class="line">state         protoimpl.MessageState</span><br><span class="line">sizeCache     protoimpl.SizeCache</span><br><span class="line">unknownFields protoimpl.UnknownFields</span><br><span class="line"></span><br><span class="line"><span class="comment">// One corner of the rectangle.</span></span><br><span class="line">Lo *Point <span class="string">`protobuf:&quot;bytes,1,opt,name=lo,proto3&quot; json:&quot;lo,omitempty&quot;`</span></span><br><span class="line"><span class="comment">// The other corner of the rectangle.</span></span><br><span class="line">Hi *Point <span class="string">`protobuf:&quot;bytes,2,opt,name=hi,proto3&quot; json:&quot;hi,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">Reset</span><span class="params">()</span></span> &#123;</span><br><span class="line">*x = Rectangle&#123;&#125;</span><br><span class="line"><span class="keyword">if</span> protoimpl.UnsafeEnabled &#123;</span><br><span class="line">mi := &amp;file_routeguide_route_guide_proto_msgTypes[<span class="number">1</span>]</span><br><span class="line">ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))</span><br><span class="line">ms.StoreMessageInfo(mi)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">String</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> protoimpl.X.MessageStringOf(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Rectangle)</span> <span class="title">ProtoMessage</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">ProtoReflect</span><span class="params">()</span> <span class="title">protoreflect</span>.<span class="title">Message</span></span> &#123;</span><br><span class="line">mi := &amp;file_routeguide_route_guide_proto_msgTypes[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">if</span> protoimpl.UnsafeEnabled &amp;&amp; x != <span class="literal">nil</span> &#123;</span><br><span class="line">ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))</span><br><span class="line"><span class="keyword">if</span> ms.LoadMessageInfo() == <span class="literal">nil</span> &#123;</span><br><span class="line">ms.StoreMessageInfo(mi)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> ms</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> mi.MessageOf(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Deprecated: Use Rectangle.ProtoReflect.Descriptor instead.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Rectangle)</span> <span class="title">Descriptor</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> file_routeguide_route_guide_proto_rawDescGZIP(), []<span class="keyword">int</span>&#123;<span class="number">1</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">GetLo</span><span class="params">()</span> *<span class="title">Point</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> x != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> x.Lo</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">GetHi</span><span class="params">()</span> *<span class="title">Point</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> x != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> x.Hi</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于Client来说,定义接口.首先使用grpc库中的<code>grpc.ClientConnInterface</code>作为routeGuideClient的成员.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> routeGuideClient <span class="keyword">struct</span> &#123;</span><br><span class="line">cc grpc.ClientConnInterface</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>给结构体<code>routeGuideClient</code>实现多个方法,并定义接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> RouteGuideClient <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// A simple RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the feature at a given position.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A feature with an empty name is returned if there&#x27;s no feature at the given</span></span><br><span class="line"><span class="comment">// position.</span></span><br><span class="line">GetFeature(ctx context.Context, in *Point, opts ...grpc.CallOption) (*Feature, error)</span><br><span class="line"><span class="comment">// A server-to-client streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the Features available within the given Rectangle.  Results are</span></span><br><span class="line"><span class="comment">// streamed rather than returned at once (e.g. in a response message with a</span></span><br><span class="line"><span class="comment">// repeated field), as the rectangle may cover a large area and contain a</span></span><br><span class="line"><span class="comment">// huge number of features.</span></span><br><span class="line">ListFeatures(ctx context.Context, in *Rectangle, opts ...grpc.CallOption) (RouteGuide_ListFeaturesClient, error)</span><br><span class="line"><span class="comment">// A client-to-server streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of Points on a route being traversed, returning a</span></span><br><span class="line"><span class="comment">// RouteSummary when traversal is completed.</span></span><br><span class="line">RecordRoute(ctx context.Context, opts ...grpc.CallOption) (RouteGuide_RecordRouteClient, error)</span><br><span class="line"><span class="comment">// A Bidirectional streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of RouteNotes sent while a route is being traversed,</span></span><br><span class="line"><span class="comment">// while receiving other RouteNotes (e.g. from other users).</span></span><br><span class="line">RouteChat(ctx context.Context, opts ...grpc.CallOption) (RouteGuide_RouteChatClient, error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后通过<code>NewRouteGuideClient</code>返回结构体</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewRouteGuideClient</span><span class="params">(cc grpc.ClientConnInterface)</span> <span class="title">RouteGuideClient</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;routeGuideClient&#123;cc&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现结构体的方法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *routeGuideClient)</span> <span class="title">GetFeature</span><span class="params">(ctx context.Context, in *Point, opts ...grpc.CallOption)</span> <span class="params">(*Feature, error)</span></span> &#123;</span><br><span class="line">out := <span class="built_in">new</span>(Feature)</span><br><span class="line">err := c.cc.Invoke(ctx, RouteGuide_GetFeature_FullMethodName, in, out, opts...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> out, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *routeGuideClient)</span> <span class="title">ListFeatures</span><span class="params">(ctx context.Context, in *Rectangle, opts ...grpc.CallOption)</span> <span class="params">(RouteGuide_ListFeaturesClient, error)</span></span> &#123;</span><br><span class="line">stream, err := c.cc.NewStream(ctx, &amp;RouteGuide_ServiceDesc.Streams[<span class="number">0</span>], RouteGuide_ListFeatures_FullMethodName, opts...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">x := &amp;routeGuideListFeaturesClient&#123;stream&#125;</span><br><span class="line"><span class="keyword">if</span> err := x.ClientStream.SendMsg(in); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> err := x.ClientStream.CloseSend(); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> x, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果涉及stream还有新的结构,定义结构体,方法和接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> RouteGuide_ListFeaturesClient <span class="keyword">interface</span> &#123;</span><br><span class="line">Recv() (*Feature, error)</span><br><span class="line">grpc.ClientStream</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> routeGuideListFeaturesClient <span class="keyword">struct</span> &#123;</span><br><span class="line">grpc.ClientStream</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *routeGuideListFeaturesClient)</span> <span class="title">Recv</span><span class="params">()</span> <span class="params">(*Feature, error)</span></span> &#123;</span><br><span class="line">m := <span class="built_in">new</span>(Feature)</span><br><span class="line"><span class="keyword">if</span> err := x.ClientStream.RecvMsg(m); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> m, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于server类似,定义接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> RouteGuideServer <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// A simple RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the feature at a given position.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A feature with an empty name is returned if there&#x27;s no feature at the given</span></span><br><span class="line"><span class="comment">// position.</span></span><br><span class="line">GetFeature(context.Context, *Point) (*Feature, error)</span><br><span class="line"><span class="comment">// A server-to-client streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the Features available within the given Rectangle.  Results are</span></span><br><span class="line"><span class="comment">// streamed rather than returned at once (e.g. in a response message with a</span></span><br><span class="line"><span class="comment">// repeated field), as the rectangle may cover a large area and contain a</span></span><br><span class="line"><span class="comment">// huge number of features.</span></span><br><span class="line">ListFeatures(*Rectangle, RouteGuide_ListFeaturesServer) error</span><br><span class="line"><span class="comment">// A client-to-server streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of Points on a route being traversed, returning a</span></span><br><span class="line"><span class="comment">// RouteSummary when traversal is completed.</span></span><br><span class="line">RecordRoute(RouteGuide_RecordRouteServer) error</span><br><span class="line"><span class="comment">// A Bidirectional streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of RouteNotes sent while a route is being traversed,</span></span><br><span class="line"><span class="comment">// while receiving other RouteNotes (e.g. from other users).</span></span><br><span class="line">RouteChat(RouteGuide_RouteChatServer) error</span><br><span class="line">mustEmbedUnimplementedRouteGuideServer()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="实现server和client"><a href="#实现server和client" class="headerlink" title="实现server和client"></a>实现server和client</h4><p>当使用protoc生成文件之后,就可以写server和client了.</p><h5 id="server"><a href="#server" class="headerlink" title="server"></a>server</h5><p>定义结构体,注意定义时加上<code>pb.UnimplementedRouteGuideServer</code>这样避免有些方法没有实现.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> routeGuideServer <span class="keyword">struct</span> &#123;</span><br><span class="line">pb.UnimplementedRouteGuideServer</span><br><span class="line">savedFeatures []*pb.Feature <span class="comment">// read-only after initialized</span></span><br><span class="line"></span><br><span class="line">mu         sync.Mutex <span class="comment">// protects routeNotes</span></span><br><span class="line">routeNotes <span class="keyword">map</span>[<span class="keyword">string</span>][]*pb.RouteNote</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现接口满足的方法.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">GetFeature</span><span class="params">(ctx context.Context, point *pb.Point)</span> <span class="params">(*pb.Feature, error)</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">ListFeatures</span><span class="params">(rect *pb.Rectangle, stream pb.RouteGuide_ListFeaturesServer)</span></span> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">RecordRoute</span><span class="params">(stream pb.RouteGuide_RecordRouteServer)</span></span> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">RouteChat</span><span class="params">(stream pb.RouteGuide_RouteChatServer)</span></span></span><br></pre></td></tr></table></figure><p>然后使用tcp链接新建grpc服务</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">flag.Parse()</span><br><span class="line">lis, err := net.Listen(<span class="string">&quot;tcp&quot;</span>, fmt.Sprintf(<span class="string">&quot;localhost:%d&quot;</span>, *port))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to listen: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> opts []grpc.ServerOption</span><br><span class="line"><span class="keyword">if</span> *tls &#123;</span><br><span class="line"><span class="keyword">if</span> *certFile == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">*certFile = data.Path(<span class="string">&quot;x509/server_cert.pem&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> *keyFile == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">*keyFile = data.Path(<span class="string">&quot;x509/server_key.pem&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">creds, err := credentials.NewServerTLSFromFile(*certFile, *keyFile)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;Failed to generate credentials: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">opts = []grpc.ServerOption&#123;grpc.Creds(creds)&#125;</span><br><span class="line">&#125;</span><br><span class="line">grpcServer := grpc.NewServer(opts...)</span><br><span class="line">pb.RegisterRouteGuideServer(grpcServer, newServer())</span><br><span class="line">grpcServer.Serve(lis)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面使用<code>pb.RegisterRouteGuideServer</code>注册服务,参数分别是grpc服务和<code>newServer</code>返回的结构体</p><h5 id="client"><a href="#client" class="headerlink" title="client"></a>client</h5><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printFeature</span><span class="params">(client pb.RouteGuideClient, point *pb.Point)</span></span> &#123;</span><br><span class="line">log.Printf(<span class="string">&quot;Getting feature for point (%d, %d)&quot;</span>, point.Latitude, point.Longitude)</span><br><span class="line">ctx, cancel := context.WithTimeout(context.Background(), <span class="number">10</span>*time.Second)</span><br><span class="line"><span class="keyword">defer</span> cancel()</span><br><span class="line">feature, err := client.GetFeature(ctx, point)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;client.GetFeature failed: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">log.Println(feature)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用context创建ctx和cancel,利用<code>client := pb.NewRouteGuideClient(conn)</code>创建client调用方法.</p><p><code>NewRouteGuideClient</code>返回对应的client接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewRouteGuideClient</span><span class="params">(cc grpc.ClientConnInterface)</span> <span class="title">RouteGuideClient</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;routeGuideClient&#123;cc&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="gRPC面临的挑战"><a href="#gRPC面临的挑战" class="headerlink" title="gRPC面临的挑战"></a>gRPC面临的挑战</h2><p>虽然gRPC确实允许您使用这些较新的技术，但gRPC服务的原型设计更具挑战性，因为<strong>无法使用Postman HTTP客户端等工具来轻松地与您公开的gRPC服务交互</strong>。你确实有一些选择可以实现这一点，但这并不是一种在本地就可以获得的东西。</p><p>有一些选项可以使用诸如特使之类的工具来反转代理标准JSON请求，并将其转码为正确的数据格式，但这是一个额外的依赖项，对于简单的项目来说，设置它可能很困难。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://grpc.io/docs/">Documentation | gRPC</a></li><li><a href="https://tutorialedge.net/golang/go-grpc-beginners-tutorial/">Go gRPC Beginners Tutorial | TutorialEdge.net</a></li><li><a href="https://www.bookstack.cn/read/go-rpc-programming-guide/part1-gorpc.md">Go RPC开发简介 - 官方RPC库 - 《Go RPC开发指南 [中文文档]》 - 书栈网 · BookStack</a></li><li><a href="http://ruanyifeng.com/blog/2018/10/restful-api-best-practices.html">RESTful API 最佳实践 - 阮一峰的网络日志 (ruanyifeng.com)</a></li><li><a href="https://grpc.io/docs/languages/go/basics/">Basics tutorial | Go | gRPC</a></li><li><a href="https://grpc.io/docs/what-is-grpc/">What is gRPC? | gRPC</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;RPC是远程调用,而google实现了grpc比较方便地实现了远程调用,gRPC是一个现代的开源远程过程调用(RPC)框架&lt;br&gt;</summary>
    
    
    
    
    <category term="grpc" scheme="https://www.sekyoro.top/tags/grpc/"/>
    
  </entry>
  
  <entry>
    <title>gradio学习</title>
    <link href="https://www.sekyoro.top/2023/12/25/gradio%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/12/25/gradio%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-12-25T13:12:10.000Z</published>
    <updated>2023-12-26T04:22:16.789Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Gradio好啊,好啊,好啊.Hugging Face好啊,好啊.<br><span id="more"></span></p><blockquote><p>Gradio是一个开源Python包，允许您为机器学习模型、API或任何任意Python函数快速构建演示或web应用程序。然后，您可以使用Gradio的内置共享功能，在几秒钟内共享演示或web应用程序的链接。无需JavaScript、CSS或网络托管经验！</p></blockquote><h2 id="Hot-reload"><a href="#Hot-reload" class="headerlink" title="Hot reload"></a>Hot reload</h2><p><a href="https://www.gradio.app/guides/developing-faster-with-reload-mode">Developing Faster With Reload Mode (gradio.app)</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradio run.py</span><br></pre></td></tr></table></figure><p>在使用重载模式时,Gradio专门在代码中寻找一个名为demo的Gradio Blocks/Interface演示。如果您将您的demo命名为其他名称，则需要将演示的名称作为代码中的第二个参数传入。所以，如果你的run.py文件是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> my_demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;# Greetings from Gradio!&quot;</span>)</span><br><span class="line">    inp = gr.Textbox(placeholder=<span class="string">&quot;What is your name?&quot;</span>)</span><br><span class="line">    out = gr.Textbox()</span><br><span class="line"></span><br><span class="line">    inp.change(fn=<span class="keyword">lambda</span> x: <span class="string">f&quot;Welcome, <span class="subst">&#123;x&#125;</span>!&quot;</span>,</span><br><span class="line">               inputs=inp,</span><br><span class="line">               outputs=out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    my_demo.launch()<span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> my_demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;# Greetings from Gradio!&quot;</span>)</span><br><span class="line">    inp = gr.Textbox(placeholder=<span class="string">&quot;What is your name?&quot;</span>)</span><br><span class="line">    out = gr.Textbox()</span><br><span class="line"></span><br><span class="line">    inp.change(fn=<span class="keyword">lambda</span> x: <span class="string">f&quot;Welcome, <span class="subst">&#123;x&#125;</span>!&quot;</span>,</span><br><span class="line">               inputs=inp,</span><br><span class="line">               outputs=out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    my_demo.launch()</span><br></pre></td></tr></table></figure><p>使用下面命令启动reload模式</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradio run.py my_demo.</span><br></pre></td></tr></table></figure><p>我发现开发时使用reload最好把launch放在<strong>name</strong> == “<strong>main</strong>“下<a href="https://github.com/gradio-app/gradio/issues/4755">Unable to launch with reload mode with default port · Issue #4755 · gradio-app/gradio (github.com)</a></p><h3 id="launch参数"><a href="#launch参数" class="headerlink" title="launch参数"></a>launch参数</h3><p>在reload模式下没用,开发完毕后可以使用,用于改变端口、获得公网地址用于分享等.</p><h2 id="Interface-Class"><a href="#Interface-Class" class="headerlink" title="Interface Class"></a><strong><code>Interface</code> Class</strong></h2><p>Interface类旨在为机器学习模型创建演示，这些模型接受一个或多个输入，并返回一个或更多输出.</p><p>Interface类有三个核心参数：</p><ul><li>fn：包装用户界面（UI）的函数</li><li>inputs：用于输入的Gradio组件。组件的数量应与函数中的参数数量相匹配。</li><li>outputs：用于输出的Gradio组件。组件的数量应该与函数返回值的数量相匹配。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">demo = gr.Interface(</span><br><span class="line">    fn=greet,</span><br><span class="line">    inputs=[gr.components.Textbox(placeholder=<span class="string">&quot;input your words&quot;</span>), gr.Textbox(placeholder=<span class="string">&quot;&quot;</span>),gr.components.Slider()],</span><br><span class="line">    outputs=[<span class="string">&quot;text&quot;</span>,gr.Checkbox(label=<span class="string">&quot;选择&quot;</span>)],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>可以多个输入,多个输出,输出由fn计算得到,但是貌似这只能构建一个单组件.</p><h2 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h2><blockquote><p>Blocks是Gradio的低级API，它允许您创建比Interfaces更多的自定义web应用程序和演示（但仍然完全使用Python）。</p></blockquote><p>与Interface类相比，Blocks提供了更多的灵活性和控制：</p><p>（1）组件的布局（</p><p>2）触发功能执行的事件</p><p>（3）数据流（例如，输入可以触发输出，这可以触发下一级的输出）</p><p>Blocks还提供了将相关演示分组在一起的方法，例如使用选项卡。块的基本用法如下：创建一个块对象，然后将其用作上下文（使用“with”语句），然后在块上下文中定义布局、组件或事件。最后，调用launch（）方法来启动演示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello&quot;</span> + name + <span class="string">&quot;!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;## Hello World&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> gr.Row():</span><br><span class="line">        textbox = gr.Textbox(placeholder=<span class="string">&quot;input your words&quot;</span>)</span><br><span class="line">        slider = gr.components.Slider()</span><br><span class="line">    btn = gr.Button(<span class="string">&quot;Run&quot;</span>)</span><br><span class="line">    btn.click(fn=update,<span class="built_in">input</span>=textbox,output=slider)</span><br><span class="line">demo.launch()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increase</span>(<span class="params">num</span>):</span></span><br><span class="line">    <span class="keyword">return</span> num + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">    a = gr.Number(label=<span class="string">&quot;a&quot;</span>)</span><br><span class="line">    b = gr.Number(label=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    atob = gr.Button(<span class="string">&quot;a &gt; b&quot;</span>)</span><br><span class="line">    btoa = gr.Button(<span class="string">&quot;b &gt; a&quot;</span>)</span><br><span class="line">    atob.click(increase, a, b)</span><br><span class="line">    btoa.click(increase, b, a)</span><br><span class="line"></span><br><span class="line">demo.launch()</span><br></pre></td></tr></table></figure><h2 id="TabbedInterface"><a href="#TabbedInterface" class="headerlink" title="TabbedInterface"></a>TabbedInterface</h2><p>TabbedInterface是通过提供一个接口列表来创建的，每个接口都在一个单独的选项卡中呈现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello&quot;</span> + name + <span class="string">&quot;!&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks(theme=gr.themes.Glass()) <span class="keyword">as</span> test:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;## Hello World&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> gr.Row():</span><br><span class="line">        textbox = gr.Textbox(placeholder=<span class="string">&quot;input your words&quot;</span>,label=<span class="string">&quot;name&quot;</span>)</span><br><span class="line">        slider = gr.components.Slider(label=<span class="string">&quot;Greet&quot;</span>,interactive=<span class="literal">True</span>)</span><br><span class="line">    btn = gr.Button(<span class="string">&quot;Run&quot;</span>)</span><br><span class="line">    btn.click(fn=update, inputs=textbox, outputs=slider)</span><br><span class="line"></span><br><span class="line">stt_demo = gr.load(</span><br><span class="line">    <span class="string">&quot;huggingface/facebook/wav2vec2-base-960h&quot;</span>,</span><br><span class="line">    title=<span class="literal">None</span>,</span><br><span class="line">    inputs=<span class="string">&quot;mic&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Let me try to guess what you&#x27;re saying!&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">demo = gr.TabbedInterface([stt_demo,test],[<span class="string">&quot;STT&quot;</span>,<span class="string">&quot;Hello World&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo.launch()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ChatInterface"><a href="#ChatInterface" class="headerlink" title="ChatInterface"></a>ChatInterface</h2><blockquote><p>聊天机器人是大型语言模型的一个流行应用程序。使用gradio，您可以轻松地构建聊天机器人模型的演示并与用户共享，或者使用直观的聊天机器人UI自己尝试。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_response</span>(<span class="params">message, history</span>):</span></span><br><span class="line"> <span class="keyword">return</span> random.choice([<span class="string">&quot;Yes&quot;</span>, <span class="string">&quot;No&quot;</span>])</span><br><span class="line"></span><br><span class="line">gr.ChatInterface(random_response).launch()</span><br></pre></td></tr></table></figure><h3 id="streaming"><a href="#streaming" class="headerlink" title="streaming"></a>streaming</h3><p>如果应用程序预计流量会很大，请使用queue（）方法来控制处理速率。</p><p>可以搭配Openai或者Hugging Face上的大语言模型使用.同时搭配LangChain使用.</p><p>上面就是基本的四个大模块,此外还有许多组件,重点是<strong>一些组件如何组合</strong>,一般来说使用<code>gr.Blocks</code>进行构建.</p><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><ol><li><a href="https://www.gradio.app/guides">Gradio Guides</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Gradio好啊,好啊,好啊.Hugging Face好啊,好啊.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>dpsc:深度学习短课程学习</title>
    <link href="https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-12-24T12:55:08.000Z</published>
    <updated>2023-12-29T10:39:45.783Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Andrew Ng的Deep Learning短课程<a href="https://www.deeplearning.ai/short-courses/">Short Courses | Learn Generative AI from DeepLearning.AI</a>,此外还有Cousera上的课程.学的东西比较实用还比较新.</p><span id="more"></span><p>这些课程通常会使用一些公司的产品,比如<strong>Hugging Face</strong>的Gradio,diffusers,transformers,或者W&amp;B的wandb等等(这两个我平常都在用),此外还有谷歌、微软以及Langchain,这些工具都比较实用. 如果关注生成领域,那Diffusion Model肯定要看,如果关注LLM以及chatbot那<strong>Langchain</strong>最好利用起来,如果自己训练部署模型,那也可以使用<strong>wandb</strong>.</p><p>这里我主要关注三部分:<strong>生成式人工智能</strong>,<strong>LLM</strong>,<strong>模型部署和训练辅助工具</strong>.</p><h2 id="Reinforcement-Learning-from-Human-Feedback"><a href="#Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="Reinforcement Learning from Human Feedback"></a>Reinforcement Learning from Human Feedback</h2><p><img data-src="https://i.imgur.com/81KDzqo.png" alt="image-20231224221652027"></p><p><img data-src="https://i.imgur.com/TpXVnGU.png" alt="image-20231224231207302"></p><h2 id="Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases"><a href="#Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases" class="headerlink" title="Evaluating and Debugging Generative AI Models Using Weights and Biases"></a>Evaluating and Debugging Generative AI Models Using Weights and Biases</h2><p>作为模型训练者可能会用到的网站.文档<a href="https://docs.wandb.ai/ref/python/">Python Library | Weights &amp; Biases Documentation (wandb.ai)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wandb.init(</span><br><span class="line">    project=<span class="string">&quot;gpt5&quot;</span>,</span><br><span class="line">    config=config,</span><br><span class="line">)</span><br><span class="line">wandb.log(metrics)</span><br></pre></td></tr></table></figure><p>首先找到项目(如果没有就会另外创建),并且会根据config创建一个run.使用wandb.log输出最后结果.wandb会保存运行时系统环境信息,github repo甚至仓库文件信息.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">config</span>):</span></span><br><span class="line">    <span class="string">&quot;Train a model with a given config&quot;</span></span><br><span class="line">    </span><br><span class="line">    wandb.init(</span><br><span class="line">        project=<span class="string">&quot;gpt5&quot;</span>,</span><br><span class="line">        config=config,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the data</span></span><br><span class="line">    train_dl, valid_dl = get_dataloaders(DATA_DIR, </span><br><span class="line">                                         config.batch_size, </span><br><span class="line">                                         config.slice_size, </span><br><span class="line">                                         config.valid_pct)</span><br><span class="line">    n_steps_per_epoch = math.ceil(<span class="built_in">len</span>(train_dl.dataset) / config.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># A simple MLP model</span></span><br><span class="line">    model = get_model(config.dropout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Make the loss and optimizer</span></span><br><span class="line">    loss_func = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = Adam(model.parameters(), lr=config.lr)</span><br><span class="line"></span><br><span class="line">    example_ct = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(config.epochs), total=config.epochs):</span><br><span class="line">        model.train()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dl):</span><br><span class="line">            images, labels = images.to(DEVICE), labels.to(DEVICE)</span><br><span class="line"></span><br><span class="line">            outputs = model(images)</span><br><span class="line">            train_loss = loss_func(outputs, labels)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            train_loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            example_ct += <span class="built_in">len</span>(images)</span><br><span class="line">            metrics = &#123;</span><br><span class="line">                <span class="string">&quot;train/train_loss&quot;</span>: train_loss,</span><br><span class="line">                <span class="string">&quot;train/epoch&quot;</span>: epoch + <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;train/example_ct&quot;</span>: example_ct</span><br><span class="line">            &#125;</span><br><span class="line">            wandb.log(metrics)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># Compute validation metrics, log images on last epoch</span></span><br><span class="line">        val_loss, accuracy = validate_model(model, valid_dl, loss_func)</span><br><span class="line">        <span class="comment"># Compute train and validation metrics</span></span><br><span class="line">        val_metrics = &#123;</span><br><span class="line">            <span class="string">&quot;val/val_loss&quot;</span>: val_loss,</span><br><span class="line">            <span class="string">&quot;val/val_accuracy&quot;</span>: accuracy</span><br><span class="line">        &#125;</span><br><span class="line">        wandb.log(val_metrics)</span><br><span class="line">    </span><br><span class="line">    wandb.finish()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如何在同一个run更改,更新现有运行的配置.下面是我匿名使用wandb跑的一次run</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.<span class="built_in">Api</span>()</span><br><span class="line"></span><br><span class="line">run = api.<span class="built_in">run</span>(<span class="string">&quot;anony-mouse-988582345570149472/gpt5/&lt;run_id&gt;&quot;</span>)</span><br><span class="line">run.config[<span class="string">&quot;key&quot;</span>] = updated_value</span><br><span class="line">run.<span class="built_in">update</span>()</span><br></pre></td></tr></table></figure><p>将单个运行的指标导出到CSV文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.Api()</span><br><span class="line"></span><br><span class="line"><span class="comment"># run is specified by &lt;entity&gt;/&lt;project&gt;/&lt;run_id&gt;</span></span><br><span class="line">run = api.run(<span class="string">&quot;anony-mouse-946987442323310233/dlai_sprite_diffusion/&lt;run_id&gt;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save the metrics for the run to a csv file</span></span><br><span class="line">metrics_dataframe = run.history()</span><br><span class="line">metrics_dataframe.to_csv(<span class="string">&quot;metrics.csv&quot;</span>)</span><br></pre></td></tr></table></figure><p>读取运行指标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.Api()</span><br><span class="line"></span><br><span class="line">run = api.run(<span class="string">&quot;anony-mouse-946987442323310233/dlai_sprite_diffusion/&lt;run_id&gt;&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> run.state == <span class="string">&quot;finished&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i, row <span class="keyword">in</span> run.history().iterrows():</span><br><span class="line">      <span class="built_in">print</span>(row[<span class="string">&quot;_timestamp&quot;</span>], row[<span class="string">&quot;accuracy&quot;</span>])</span><br></pre></td></tr></table></figure><p>当您从历史中提取数据时，默认情况下会对其采样到500点。使用run.scan_history（）获取所有记录的数据点。下面是下载所有记录在历史中的丢失数据点的示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.Api()</span><br><span class="line"></span><br><span class="line">run = api.run(<span class="string">&quot;anony-mouse-946987442323310233/dlai_sprite_diffusion/&lt;run_id&gt;&quot;</span>)</span><br><span class="line">history = run.scan_history()</span><br><span class="line">losses = [row[<span class="string">&quot;loss&quot;</span>] <span class="keyword">for</span> row <span class="keyword">in</span> history]</span><br></pre></td></tr></table></figure><h3 id="wandb-Table"><a href="#wandb-Table" class="headerlink" title="wandb Table"></a>wandb Table</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">table = wandb.Table(columns=[<span class="string">&quot;input_noise&quot;</span>, <span class="string">&quot;ddpm&quot;</span>, <span class="string">&quot;ddim&quot;</span>, <span class="string">&quot;class&quot;</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> noise, ddpm_s, ddim_s, c <span class="keyword">in</span> <span class="built_in">zip</span>(noises, </span><br><span class="line">                                    ddpm_samples, </span><br><span class="line">                                    ddim_samples, </span><br><span class="line">                                    to_classes(ctx_vector)):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># add data row by row to the Table</span></span><br><span class="line">    table.add_data(wandb.Image(noise),</span><br><span class="line">                   wandb.Image(ddpm_s), </span><br><span class="line">                   wandb.Image(ddim_s),</span><br><span class="line">                   c)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> wandb.init(project=<span class="string">&quot;dlai_sprite_diffusion&quot;</span>, </span><br><span class="line">                job_type=<span class="string">&quot;samplers_battle&quot;</span>, </span><br><span class="line">                config=config):</span><br><span class="line">    </span><br><span class="line">    wandb.log(&#123;<span class="string">&quot;samplers_table&quot;</span>:table&#125;)</span><br></pre></td></tr></table></figure><p>先创建<code>wandb.Table</code>,再使用其添加数据,最后使用log推上去</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">table = wandb.Table(columns=[<span class="string">&quot;prompt&quot;</span>, <span class="string">&quot;generation&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> prompt <span class="keyword">in</span> prompts:</span><br><span class="line">    input_ids = tokenizer.encode(prefix + prompt, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">    output = model.generate(input_ids, do_sample=<span class="literal">True</span>, max_new_tokens=<span class="number">50</span>, top_p=<span class="number">0.3</span>)</span><br><span class="line">    output_text = tokenizer.decode(output[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    table.add_data(prefix + prompt, output_text)</span><br><span class="line">    </span><br><span class="line">wandb.log(&#123;<span class="string">&#x27;tiny_generations&#x27;</span>: table&#125;)</span><br></pre></td></tr></table></figure><h3 id="使用W-amp-B-sweep进行超参搜索调整"><a href="#使用W-amp-B-sweep进行超参搜索调整" class="headerlink" title="使用W&amp;B sweep进行超参搜索调整"></a>使用W&amp;B sweep进行超参搜索调整</h3><blockquote><p>在高维超参数空间中搜索以找到最具性能的模型可能会变得非常困难。超参数扫描提供了一种有组织、高效的方式来进行一系列模型的战斗，并选择最准确的模型。它们通过自动搜索超参数值的组合（例如学习率、批量大小、隐藏层的数量、优化器类型）来找到最优化的值。Sweep结合了一种尝试一堆超参数值的策略和评估代码</p></blockquote><ol><li>定义sweep：通过创建一个字典或YAML文件来实现这一点，该文件指定了要搜索的参数、搜索策略、优化指标等。</li></ol><p>首先选择搜索策略,包括网格,随机和贝叶斯.</p><blockquote><ul><li><strong><code>grid</code> Search</strong> – Iterate over every combination of hyperparameter values. Very effective, but can be computationally costly.</li><li><strong><code>random</code> Search</strong> – Select each new combination at random according to provided <code>distribution</code>s. Surprisingly effective!</li><li><strong><code>bayes</code>ian Search</strong> – Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sweep_config = &#123;</span><br><span class="line">    <span class="string">&#x27;method&#x27;</span>: <span class="string">&#x27;random&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">metric = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;loss&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;goal&#x27;</span>: <span class="string">&#x27;minimize&#x27;</span>   </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">sweep_config[<span class="string">&#x27;metric&#x27;</span>] = metric</span><br></pre></td></tr></table></figure><p>然后是训练网络的一些超参</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">parameters_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;values&#x27;</span>: [<span class="string">&#x27;adam&#x27;</span>, <span class="string">&#x27;sgd&#x27;</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&#x27;fc_layer_size&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;values&#x27;</span>: [<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&#x27;dropout&#x27;</span>: &#123;</span><br><span class="line">          <span class="string">&#x27;values&#x27;</span>: [<span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">sweep_config[<span class="string">&#x27;parameters&#x27;</span>] = parameters_dict</span><br></pre></td></tr></table></figure><p>通常情况下，有些超参数我们不想在这次扫描中发生变化，但我们仍然想在扫描_配置中设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parameters_dict.update(&#123;</span><br><span class="line">    <span class="string">&#x27;epochs&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;value&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><p><code>`rand</code>搜索策略可以指定一个正态分布进行选参数,默认是均匀分布.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">parameters_dict.update(&#123;</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: &#123;</span><br><span class="line">        <span class="comment"># a flat distribution between 0 and 0.1</span></span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;min&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&#x27;max&#x27;</span>: <span class="number">0.1</span></span><br><span class="line">      &#125;,</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: &#123;</span><br><span class="line">        <span class="comment"># integers between 32 and 256</span></span><br><span class="line">        <span class="comment"># with evenly-distributed logarithms </span></span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;q_log_uniform_values&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;q&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">&#x27;min&#x27;</span>: <span class="number">32</span>,</span><br><span class="line">        <span class="string">&#x27;max&#x27;</span>: <span class="number">256</span>,</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><p>所以参数包括<code>metho</code>,<code>metric</code>和<code>parameter</code>.此外还有一些这里就不介绍了</p><ol><li>初始化扫描：用一行代码初始化扫描并传入扫描配置字典：sweep_id=wandb.sweep（sweep_config）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sweep_id = wandb.sweep(sweep_config, project=<span class="string">&quot;pytorch-sweeps-demo&quot;</span>)</span><br></pre></td></tr></table></figure><p>创建一个sweep</p><ol><li>运行扫描代理：也可以用一行代码完成，我们调用wandb.agent（）并传递要运行的sweep_id，以及一个定义模型架构并对其进行训练的函数：wandb.agent（sweep_id，function=train）</li></ol><p>开始正常的训练.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">config=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># Initialize a new wandb run</span></span><br><span class="line">    <span class="keyword">with</span> wandb.init(config=config):</span><br><span class="line">        <span class="comment"># If called by wandb.agent, as below,</span></span><br><span class="line">        <span class="comment"># this config will be set by Sweep Controller</span></span><br><span class="line">        config = wandb.config</span><br><span class="line"></span><br><span class="line">        loader = build_dataset(config.batch_size)</span><br><span class="line">        network = build_network(config.fc_layer_size, config.dropout)</span><br><span class="line">        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.epochs):</span><br><span class="line">            avg_loss = train_epoch(network, loader, optimizer)</span><br><span class="line">            wandb.log(&#123;<span class="string">&quot;loss&quot;</span>: avg_loss, <span class="string">&quot;epoch&quot;</span>: epoch&#125;)           </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wandb.agent(sweep_id, train, count=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>使用Sweep Controller返回的随机生成的超参数值，启动一个运行训练5次的agents</p><p><img data-src="https://s2.loli.net/2023/12/29/2EruyQMvpSNoeRm.png" alt="image-20231229183908912" style="zoom:67%;" /></p><p>另外课程还讲了Tracer等,现在我用不上….主要还是上传loss和acc这些结果.</p><h2 id="How-Diffusion-Models-Work"><a href="#How-Diffusion-Models-Work" class="headerlink" title="How Diffusion Models Work"></a>How Diffusion Models Work</h2><p>Diffusion Models在前段时间非常火,也是现在prompt生成图像的主要模型.</p><p><img data-src="https://i.imgur.com/MkB11s7.png" alt="image-20231225195441214"></p><p><img data-src="https://i.imgur.com/lm5t6Jr.png" alt="image-20231225200851364"></p><p><img data-src="https://s2.loli.net/2023/12/28/LQaYoIzTJWd1yNs.png" alt="image-20231228224804703"></p><p><img data-src="https://s2.loli.net/2023/12/28/G7JTpmDg4zF1neq.png" alt="image-20231228232748110"></p><p>训练的预测噪声网络是Unet</p><p><img data-src="https://s2.loli.net/2023/12/29/8VAft1WN9L6lrmG.png" alt="image-20231229151559530"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ContextUnet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, n_feat=<span class="number">256</span>, n_cfeat=<span class="number">10</span>, height=<span class="number">28</span></span>):</span>  <span class="comment"># cfeat - context features</span></span><br><span class="line">        <span class="built_in">super</span>(ContextUnet, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># number of input channels, number of intermediate feature maps and number of classes</span></span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.n_feat = n_feat</span><br><span class="line">        self.n_cfeat = n_cfeat</span><br><span class="line">        self.h = height  <span class="comment">#assume h == w. must be divisible by 4, so 28,24,20,16...</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the initial convolutional layer</span></span><br><span class="line">        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the down-sampling path of the U-Net with two levels</span></span><br><span class="line">        self.down1 = UnetDown(n_feat, n_feat)        <span class="comment"># down1 #[10, 256, 8, 8]</span></span><br><span class="line">        self.down2 = UnetDown(n_feat, <span class="number">2</span> * n_feat)    <span class="comment"># down2 #[10, 256, 4,  4]</span></span><br><span class="line">        </span><br><span class="line">         <span class="comment"># original: self.to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())</span></span><br><span class="line">        self.to_vec = nn.Sequential(nn.AvgPool2d((<span class="number">4</span>)), nn.GELU())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Embed the timestep and context labels with a one-layer fully connected neural network</span></span><br><span class="line">        self.timeembed1 = EmbedFC(<span class="number">1</span>, <span class="number">2</span>*n_feat)</span><br><span class="line">        self.timeembed2 = EmbedFC(<span class="number">1</span>, <span class="number">1</span>*n_feat)</span><br><span class="line">        self.contextembed1 = EmbedFC(n_cfeat, <span class="number">2</span>*n_feat)</span><br><span class="line">        self.contextembed2 = EmbedFC(n_cfeat, <span class="number">1</span>*n_feat)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the up-sampling path of the U-Net with three levels</span></span><br><span class="line">        self.up0 = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">2</span> * n_feat, <span class="number">2</span> * n_feat, self.h//<span class="number">4</span>, self.h//<span class="number">4</span>), <span class="comment"># up-sample  </span></span><br><span class="line">            nn.GroupNorm(<span class="number">8</span>, <span class="number">2</span> * n_feat), <span class="comment"># normalize                       </span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">        )</span><br><span class="line">        self.up1 = UnetUp(<span class="number">4</span> * n_feat, n_feat)</span><br><span class="line">        self.up2 = UnetUp(<span class="number">2</span> * n_feat, n_feat)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the final convolutional layers to map to the same number of channels as the input image</span></span><br><span class="line">        self.out = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">2</span> * n_feat, n_feat, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># reduce number of feature maps   #in_channels, out_channels, kernel_size, stride=1, padding=0</span></span><br><span class="line">            nn.GroupNorm(<span class="number">8</span>, n_feat), <span class="comment"># normalize</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(n_feat, self.in_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># map to same number of channels as input</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, t, c=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x : (batch, n_feat, h, w) : input image</span></span><br><span class="line"><span class="string">        t : (batch, n_cfeat)      : time step</span></span><br><span class="line"><span class="string">        c : (batch, n_classes)    : context label</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># x is the input image, c is the context label, t is the timestep, context_mask says which samples to block the context on</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># pass the input image through the initial convolutional layer</span></span><br><span class="line">        x = self.init_conv(x)</span><br><span class="line">        <span class="comment"># pass the result through the down-sampling path</span></span><br><span class="line">        down1 = self.down1(x)       <span class="comment">#[10, 256, 8, 8]</span></span><br><span class="line">        down2 = self.down2(down1)   <span class="comment">#[10, 256, 4, 4]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># convert the feature maps to a vector and apply an activation</span></span><br><span class="line">        hiddenvec = self.to_vec(down2)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># mask out context if context_mask == 1</span></span><br><span class="line">        <span class="keyword">if</span> c <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            c = torch.zeros(x.shape[<span class="number">0</span>], self.n_cfeat).to(x)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># embed context and timestep</span></span><br><span class="line">        cemb1 = self.contextembed1(c).view(-<span class="number">1</span>, self.n_feat * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)     <span class="comment"># (batch, 2*n_feat, 1,1)</span></span><br><span class="line">        temb1 = self.timeembed1(t).view(-<span class="number">1</span>, self.n_feat * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        cemb2 = self.contextembed2(c).view(-<span class="number">1</span>, self.n_feat, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        temb2 = self.timeembed2(t).view(-<span class="number">1</span>, self.n_feat, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print(f&quot;uunet forward: cemb1 &#123;cemb1.shape&#125;. temb1 &#123;temb1.shape&#125;, cemb2 &#123;cemb2.shape&#125;. temb2 &#123;temb2.shape&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        up1 = self.up0(hiddenvec)</span><br><span class="line">        up2 = self.up1(cemb1*up1 + temb1, down2)  <span class="comment"># add and multiply embeddings</span></span><br><span class="line">        up3 = self.up2(cemb2*up2 + temb2, down1)</span><br><span class="line">        out = self.out(torch.cat((up3, x), <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>训练的时候是random一个timestamp得到噪声,sampling的时候是根据步数进行依次sampling</p><h3 id="control-and-speed-up"><a href="#control-and-speed-up" class="headerlink" title="control and speed up"></a>control and speed up</h3><p>加入context_vector进行控制输出,使用DDIM替换DDPM进行加速samping</p><p><img data-src="https://s2.loli.net/2023/12/29/MAifZF7OlmPtbWs.png" alt="image-20231229152240050"></p><p><img data-src="https://s2.loli.net/2023/12/29/hqbUoyE9iRpdgNA.png" alt="image-20231229152302772"></p><p><img data-src="https://s2.loli.net/2023/12/29/jLaNo19nuCwDJQG.png" alt="image-20231229152531542"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define sampling function for DDIM   </span></span><br><span class="line"><span class="comment"># removes the noise using ddim</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">denoise_ddim</span>(<span class="params">x, t, t_prev, pred_noise</span>):</span></span><br><span class="line">    ab = ab_t[t]</span><br><span class="line">    ab_prev = ab_t[t_prev]</span><br><span class="line">    </span><br><span class="line">    x0_pred = ab_prev.sqrt() / ab.sqrt() * (x - (<span class="number">1</span> - ab).sqrt() * pred_noise)</span><br><span class="line">    dir_xt = (<span class="number">1</span> - ab_prev).sqrt() * pred_noise</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x0_pred + dir_xt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fast sampling algorithm with context</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_ddim_context</span>(<span class="params">n_sample, context, n=<span class="number">20</span></span>):</span></span><br><span class="line">    <span class="comment"># x_T ~ N(0, 1), sample initial noise</span></span><br><span class="line">    samples = torch.randn(n_sample, <span class="number">3</span>, height, height).to(device)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># array to keep track of generated steps for plotting</span></span><br><span class="line">    intermediate = [] </span><br><span class="line">    step_size = timesteps // n</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(timesteps, <span class="number">0</span>, -step_size):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;sampling timestep <span class="subst">&#123;i:3d&#125;</span>&#x27;</span>, end=<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reshape time tensor</span></span><br><span class="line">        t = torch.tensor([i / timesteps])[:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>].to(device)</span><br><span class="line"></span><br><span class="line">        eps = nn_model(samples, t, c=context)    <span class="comment"># predict noise e_(x_t,t)</span></span><br><span class="line">        samples = denoise_ddim(samples, i, i - step_size, eps)</span><br><span class="line">        intermediate.append(samples.detach().cpu().numpy())</span><br><span class="line"></span><br><span class="line">    intermediate = np.stack(intermediate)</span><br><span class="line">    <span class="keyword">return</span> samples, intermediate</span><br></pre></td></tr></table></figure><h2 id="ChatGPT-Prompt-Engineering-for-Developers"><a href="#ChatGPT-Prompt-Engineering-for-Developers" class="headerlink" title="ChatGPT Prompt Engineering for Developers"></a>ChatGPT Prompt Engineering for Developers</h2><p>使用ChatGPT辅助,感觉已经成为现代社会一种普通工具了</p><p><img data-src="https://s2.loli.net/2023/12/28/PmOSaTEFH8pVuqe.png" alt="image-20231228232329050"></p><p><img data-src="https://s2.loli.net/2023/12/28/sh6MfqxQEUnuG5j.png" alt="image-20231228232417399"></p><h2 id="Finetuning-Large-Language-Models"><a href="#Finetuning-Large-Language-Models" class="headerlink" title="Finetuning Large Language Models"></a>Finetuning Large Language Models</h2><p>大模型的finetune,了解原理即可</p><p><img data-src="https://s2.loli.net/2023/12/28/zyAIapuUNi9EeSw.png" alt="image-20231228232508902"></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Andrew Ng的Deep Learning短课程&lt;a href=&quot;https://www.deeplearning.ai/short-courses/&quot;&gt;Short Courses | Learn Generative AI from DeepLearning.AI&lt;/a&gt;,此外还有Cousera上的课程.学的东西比较实用还比较新.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Github_bot创建</title>
    <link href="https://www.sekyoro.top/2023/12/24/Github-bot%E5%88%9B%E5%BB%BA/"/>
    <id>https://www.sekyoro.top/2023/12/24/Github-bot%E5%88%9B%E5%BB%BA/</id>
    <published>2023-12-24T06:50:24.000Z</published>
    <updated>2023-12-24T07:15:26.734Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在看一些开源项目时,会发现一些帮忙处理issue和PR的bot,这些bot都是基于Github的Apps<a href="https://docs.github.com/en/apps/overview">GitHub Apps overview - GitHub Docs</a></p><span id="more"></span><h2 id="GitHub-Apps"><a href="#GitHub-Apps" class="headerlink" title="GitHub Apps"></a>GitHub Apps</h2><blockquote><p>GitHub应用程序是扩展GitHub功能的工具。GitHub应用程序可以在GitHub上做一些事情，比如打开问题、评论拉取请求和管理项目。他们也可以根据GitHub上发生的事件在GitHub之外做事情。例如，当在GitHub上打开问题时，GitHub应用程序可以在Slack上发布。</p></blockquote><p>可以在<a href="https://github.com/marketplace">GitHub Marketplace</a>上查找Github Apps,然后进行安装,有些是需要付费的.</p><p>关于使用直接安装然后看文档进行配置就行了。</p><h3 id="如何开发"><a href="#如何开发" class="headerlink" title="如何开发"></a>如何开发</h3><p><a href="https://github.com/github/github-app-js-sample?tab=readme-ov-file">github/github-app-js-sample: Sample of a GitHub App that comments new pull requests</a></p><p><img data-src="https://i.imgur.com/trK7YAv.png" alt="image-20231224150632938"></p><p>由于本地开发涉及到需要接受github发来的东西,需要涉及到内网穿透啥的,推荐使用smee或者ngrok进行本地开发.建议搭配下面介绍的probot进行开发.<a href="https://probot.github.io/docs/development/#installing-the-app-on-a-repository">probot.github.io/docs/development/#installing-the-app-on-a-repository</a></p><h2 id="Probot"><a href="#Probot" class="headerlink" title="Probot"></a>Probot</h2><blockquote><p>Probot是一个在Node.js中构建GitHub应用程序的框架。它旨在消除所有的繁琐工作，比如接收和验证Webhook，以及进行身份验证倒立，这样你就可以专注于你想要构建的功能。Probet应用程序易于编写、部署和共享。许多最流行的Probet应用程序都是托管的，所以没有什么可供您部署和管理的。</p></blockquote><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = <span class="function">(<span class="params">app</span>) =&gt;</span> &#123;</span><br><span class="line">  app.on(<span class="string">&quot;issues.opened&quot;</span>, <span class="keyword">async</span> (context) =&gt; &#123;</span><br><span class="line">    <span class="keyword">const</span> issueComment = context.issue(&#123;</span><br><span class="line">      <span class="attr">body</span>: <span class="string">&quot;Thanks for opening this issue!&quot;</span>,</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> context.octokit.issues.createComment(issueComment);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  app.onAny(<span class="keyword">async</span> (context) =&gt; &#123;</span><br><span class="line">    context.log.info(&#123; <span class="attr">event</span>: context.name, <span class="attr">action</span>: context.payload.action &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  app.onError(<span class="keyword">async</span> (error) =&gt; &#123;</span><br><span class="line">    app.log.error(error);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="Repo-Automation-Bots"><a href="#Repo-Automation-Bots" class="headerlink" title="Repo Automation Bots"></a>Repo Automation Bots</h2><p><a href="https://github.com/googleapis/repo-automation-bots?tab=readme-ov-file">googleapis/repo-automation-bots: A collection of bots, based on probot, for performing common maintenance tasks across the open-source repos managed by Google on GitHub.</a>一组基于probot的机器人,用于谷歌在GitHub上管理的开源转发中执行常见维护任务。下面是一些可用的bot</p><div class="table-container"><table><thead><tr><th><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/auto-approve">auto-approve</a></th><th>Automatically approves and merges PRs matching user-specified configs</th><th><a href="https://github.com/apps/auto-approve-bot">install</a></th></tr></thead><tbody><tr><td><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/auto-label">auto-label</a></td><td>Automatically labels issues and PRs with product, language, or directory based labels</td><td><a href="https://github.com/apps/product-auto-label">install</a></td></tr><tr><td><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/blunderbuss">blunderbuss</a></td><td>Assigns issues and PRs randomly to a specific list of users</td><td><a href="https://github.com/apps/blunderbuss-gcf">install</a></td></tr><tr><td><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/cherry-pick-bot">cherry-pick-bot</a></td><td>Cherry-pick merged PRs between branches</td><td><a href="https://github.com/apps/gcp-cherry-pick-bot">install</a></td></tr></tbody></table></div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://probot.github.io/docs/">probot.github.io/docs/</a></li><li><a href="https://dev.to/pragativerma18/github-bots-for-every-open-source-project-47hl">GitHub Bots for every open-source project - DEV Community</a></li><li><a href="https://github.com/googleapis/repo-automation-bots?tab=readme-ov-file">googleapis/repo-automation-bots: A collection of bots, based on probot, for performing common maintenance tasks across the open-source repos managed by Google on GitHub.</a></li><li><a href="https://smee.io/dSzRk0AnpSDDOf0T">smee.io | Webhook deliveries</a></li><li><a href="https://ngrok.com/">ngrok | Unified Application Delivery Platform for Developers</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在看一些开源项目时,会发现一些帮忙处理issue和PR的bot,这些bot都是基于Github的Apps&lt;a href=&quot;https://docs.github.com/en/apps/overview&quot;&gt;GitHub Apps overview - GitHub Docs&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>目标检测综述</title>
    <link href="https://www.sekyoro.top/2023/12/22/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/"/>
    <id>https://www.sekyoro.top/2023/12/22/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/</id>
    <published>2023-12-22T11:38:36.000Z</published>
    <updated>2023-12-23T12:04:08.140Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>2023年的目标检测综述<strong>A comprehensive review of object detection with deep learning</strong>以及<strong>3D Object Detection for Autonomous Driving: A Comprehensive Survey</strong>,之前写了一些单阶段和双阶段的2D目标检测,可以好好回顾一下.</p><span id="more"></span><h2 id="Abs"><a href="#Abs" class="headerlink" title="Abs"></a>Abs</h2><p>本综述详细介绍了物体检测及其各个方面。随着用于检测物体的深度学习算法逐渐发展，物体检测模型的性能也有了显著提高。但是，这并不意味着在深度学习出现之前已经发展了几十年的传统物体检测方法已经过时。<strong>在某些情况下，具有全局特征的传统方法是更优的选择</strong>。<strong>本综述论文首先简要概述了物体检测，然后介绍了物体检测框架、骨干卷积神经网络、常见数据集概述以及评估指标</strong>。此外，还详细研究了物体检测问题和应用。还<strong>讨论了设计深度神经网络的一些未来研究挑战</strong>。最后，比较了对象检测模型在 PASCAL VOC 和 MS COCO 数据集上的性能，并得出结论。</p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>物体检测的主要目的是检测特定类别的视觉物体，如电视/显示器、书籍、猫、人类等，并使用边界框定位它们，然后将它们归入特定物体的类别中。</p><p>通用对象检测还有其他几个术语，例如通用对象类别检测、对象类别检测、类别级对象检测和对象类别检测。它也侧重于识别一些预设类别的实例.</p><p>物体检测的发展通常分为两个历史阶段。<strong>2014 年之前是传统方法阶段，2014 年之后则是基于深度学习的方法阶段</strong>。本文将重点讨论基于深度学习的方法。由于 CNN 在物体检测算法的实施中发挥着重要作用，因此本文将利用 CNN 来获得最佳结果。这两个阶段的架构在精度、速度和硬件资源方面各不相同。将 CNN 与传统技术相比，CNN 具有更好的架构和更强的表现力。</p><p>在讨论基于深度学习的物体检测算法之前，重要的是要了解传统技术的工作原理，并知道为什么基于深度学习的方法要优越得多。这将有助于研究人员更好地理解现代物体检测方法。</p><h3 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h3><p>传统目标检测方法分为三个阶段。这些阶段及其各自的缺点如下:</p><p><strong>区域选择</strong> – 由于对象具有不同的大小和纵横比，因此它们可能出现在图像的不同区域。因此，在第一阶段，必须确定物体的区域。因此，使用多尺度滑动窗口方法检查整个图像以检测物体。然而，这种方法的计算成本很高，并且还会导致大量非必要的选择。</p><p><strong>特征提取</strong> – 定位对象后，执行特征提取过程以提供可靠的表示。<strong>HOG、Haar-like 、SIFT</strong> 等方法用于提取特征以进行目标识别，以提供有意义的表示。然而，由于对比鲜明的背景、照明环境和透视差异，手动构建一个能够正确识别各种对象的综合特征描述符是极其困难的。</p><p><strong>分类</strong> – 在这个阶段，使用分类器（如 Adaboost ）来识别目标对象，并构建更有条理、更有意义的视觉感知模型。</p><p>从以上几点可以清楚地看出，<strong>在传统方法中，手工制作的特征并不总是足以正确表示对象</strong>。除此之外，用于生成边界框的滑动窗口方法在计算上成本高昂且效率低下。传统的技术包括HOG、SIFT 、Haar、VJ检测器和其他算法，如。在HOG 中，识别一个物体需要很长时间，因为它采用滑动窗口方法来提取特征。SIFT算法速度极慢，计算成本高，也不擅长光照变化。在VJ检测器中，训练持续时间非常长，仅限于二元分类。因此，深度学习技术正在被用于克服传统方法的问题</p><p>深度学习的出现有可能解决传统技术的一些局限性。最近，深度学习方法在自动从数据中学习特征表示方面变得突出。这些方法显著改善了目标检测。基于深度学习的方法有 <strong>Faster RCNN、SSD、YOLO</strong> 等等。</p><p><img data-src="https://i.imgur.com/lJA5oxG.png" alt="image-20231222203515697"></p><p>由于深度 CNN 具有很高的特征表示能力，因此它们被用于对象检测架构。有两种类型的探测器：两级和一级探测器.</p><p>两阶段目标检测框架<strong>将目标定位和目标分类任务分开</strong>。简单来说，<strong>首先在对象所处的地方生成区域建议，然后根据其特定类别对该区域进行分类</strong>。这就是为什么它被称为两阶段的原因。两级目标探测器的主要优点是检测精度高，缺点是检测速度慢。</p><h4 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h4><p>基于区域的卷积神经网络（RCNN）在使用深度学习方法检测目标方面进行了深入研究。其架构如图所示。RCNN的过程在下面分四个阶段进行解释</p><p><img data-src="https://i.imgur.com/tIKAWn2.png" alt="image-20231222204652846"></p><p>第 1 阶段 :使用<strong>选择性搜索方法提取区域建议</strong>。选择性搜索<strong>根据不同的比例、外壳、纹理和颜色模式来识别这些区域</strong>。它<strong>从每张图像中提取大约 2000 个区域</strong></p><p>第 2 阶段 – 由于全连接层需要固定长度的输入向量，因此<strong>所有这些区域建议都重新缩放为相同的图像大小以匹配 CNN 输入大小</strong>。<strong>使用 CNN 提取每个候选区域的特征</strong>。</p><p>第 3 阶段 – 提取特征后，<strong>使用 SVM 分类器检测对象是否存在于每个区域</strong>中。</p><p>第 4 阶段 – 最后，对于图像中的每个已识别对象，使用线性回归模型在其周围生成更紧密的边界框。尽管RCNN在目标检测方面取得了很大的进步，但仍然存在一些局限性，如目标检测速度慢、多阶段流水线训练和选择性搜索方法的僵化。</p><h4 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h4><p>由于 RCNN 为每张图像生成 2000 个区域建议，因此从这些区域提取 CNN 特征是主要障碍。<strong>固定输入大小的约束只是因为全连接层</strong>。因此，<strong>为了克服这一困难，引入了一种称为空间金字塔池化网络层（SPP-Net）的新技术</strong>。<strong>将 SPP 层添加到最终卷积层的顶部，以生成全连接层的固定长度特征</strong>，无论 RoI（感兴趣区域）的大小如何，并且不会重新缩放它，这可能会导致信息丢失(相当于替代RCNN中的warp操作).</p><p><img data-src="https://i.imgur.com/GyXhKPL.png" alt="image-20231222205054546"></p><p>通过使用SPPNet层，RCNN的速度有了很大的提高，而检测质量没有任何损失。这是因为卷积层<strong>只需要在完整的测试图像上运行一次，就可以为随机大小的区域建议创建固定长度的特征</strong>。这里 SPP 层的输出是 256×M-d 向量。256 是卷积滤波器的数量，M 是bin的数量。全连接层接收固定长度的维向量。</p><h4 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h4><p>尽管SPPNet在效率和准确性方面优于RCNN，但它仍然存在一些问题，例如它大致遵循与RCNN相同的过程，包括网络微调、特征提取和边界框回归。</p><p>Girshick， R. 在 RCNN 和 SPPNet 方面表现出进一步的改进，并提出了一种名为 Fast RCNN 的新探测器 。<strong>它允许对检测器进行端到端训练，同时学习 softmax 分类器和特定于类的边界框回归，同时进行多任务损失，而不是像在 RCNN 和 SPPNet 中那样单独训练它们</strong>。</p><p>在 Fast RCNN 中，它不是对每张图像执行 2000 次 CNN，<strong>而是只运行一次并获取所有感兴趣的区域。然后，在最终卷积层和初始全连接层之间添加RoI池化层，从而提取出所有区域建议的固定长度向量特征</strong>。</p><p>1st – Fast RCNN 获取完整的输入图像并将其传递给 CNN 以生成特征图。</p><p>第 2 个 – 感兴趣区域 （RoI） 是使用选择性搜索方法生成的。</p><p>第三 – 在提取的 RoI 上应用 RoI 池化层以生成固定长度的特征向量。它确保所有区域都具有相同的量级。</p><p>第 4 次 – 然后<strong>将提取的特征发送到全连接层，同时使用 softmax 层和线性回归层进行分类和定位</strong>。</p><p>Fast RCNN消耗的计算时间更少，检测精度更高。然而，<strong>它基于传统的区域建议方法，使用选择性搜索方法，使其非常耗时</strong>。</p><h4 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h4><p>尽管Fast RCNN在速度和准确性方面取得了长足的进步，<strong>但它使用选择性搜索方法生成了2000个region proposals，这是一个非常缓慢的过程</strong>。任，S.等人致力于这个问题，并开发了一种新的检测器，名为Faster RCNN，作为第一个端到端深度学习检测器。<strong>它还通过将传统的region proposal算法（如选择性搜索、多尺度组合分组或边缘框）替换为称为区域建议网络（RPN）的CNN</strong>，提高了Fast RCNN的检测速度。</p><p>a） CNN 将图像作为输入，并提供图像的特征图作为输出。</p><p>b） <strong>RPN 应用于生成的特征图，返回对象建议 （RoI） 及其对象性分数</strong>。</p><p>c） 提取 RoI 后，将 RoI 池化层应用于其，以将所有提案置于固定维度。</p><p>d） <strong>将派生的特征向量提供给连续的全连接层中，顶部有一层 softmax 和回归层，用于对对象的边界框进行分类和输出</strong></p><p><img data-src="https://i.imgur.com/D9dXGsH.png" alt="image-20231222205738677" style="zoom:67%;" /></p><p>RPN 的工作 – 区域提案网络是一个完全卷积网络，它连接到骨干网络的最后一个卷积层 。<strong>它接收特征图，并使用这些特征图上的滑动窗口输出多个对象建议</strong>。<strong>在每个窗口上，网络生成 k 个不同大小和纵横比的锚框</strong>（也称为参考框）。</p><p><strong>只有从锚点框获得的特征是特定于类的，而不是锚点的位置</strong>。</p><p>每个对象提案由 4 个坐标和一个分数组成，用于确定对象是否存在。<strong>每个锚点映射到一个低维向量，并传递给两个全连接层，一个是对象类别分类层，另一个是box回归层</strong></p><h4 id="Feature-pyramid-network"><a href="#Feature-pyramid-network" class="headerlink" title="Feature pyramid network"></a>Feature pyramid network</h4><p>Lin， T. Y. et al. 提出了特征金字塔网络 （FPN）</p><p>DCNN 固有的多尺度金字塔层次结构，以低成本构建特征金字塔。它将任何大小的图像作为输入，并在多个级别输出相同大小的特征图。这种方法在许多应用中显示出相当大的增强。</p><p><img data-src="https://i.imgur.com/or3OwoO.png" alt="image-20231222210741517"></p><p>FPN 不是对象检测器。它是一种特征提取器，与对象检测器结合使用。<strong>FPN的架构使用自上而下的通路和横向连接将语义上较强的低分辨率特征与语义较弱的高分辨率特征相结合。FPN使用CNN架构的序列，通过横向连接构建自下而上的路径和自上而下的路径。在自下而上的路径（红色）中，图像作为输入传递给 CNN，它使用池化层将特征图设置为相同的大小。对于FPN的每个阶段（即每个分辨率级别），定义了一个金字塔级别</strong></p><p>在自上而下的路径（以蓝色显示）中，<strong>通过将特征图上采样回与自下而上部分相同的大小来使用更高分辨率的特征。然后使用横向连接，这些特征通过自下而上途径的特征进行增强</strong>。每个横向连接都从自下而上和自上而下路径组合了相同大小的特征图</p><p>FPN 的过程为生成具有大量语义内容的多尺度特征图提供了广泛的解决方案。F<strong>PN 不依赖于 CNN 的架构，可以强制执行到对象检测的不相同阶段</strong>，例如 RPN、Fast RCNN.尽管DCNN具有强大的表征能力，但<strong>有必要通过金字塔表示来解决多尺度挑战</strong></p><h4 id="Mask-RCNN"><a href="#Mask-RCNN" class="headerlink" title="Mask RCNN"></a>Mask RCNN</h4><p>He， K. et al.设计了一款名为Mask RCNN的目标检测器，这是对Faster RCNN的增强，用于解决进行目标检测和语义分割作业的实例分割问题。这两个任务是自力更生的过程。Mask RCNN 的目标是执行像素级分割。蒙版RCNN检查每个像素并估计它是否是对象的一部分。</p><p>Mask R-CNN 遵循 Faster R-CNN 的架构;两者都使用相同的RPN，<strong>但区别在于掩码RCNN对每个对象提案有三个输出，即.class标签，边界框偏移量和对象检测掩码</strong>。在 Mask RCNN 中，RoIAlign 层用于将提取的特征与对象的输入位置相关联。RoIAlign 层的目的是修复 RoI 池化层中的错位问题。它无需测量 RoI 阈值，而是使用双线性插值来评估每个采样点的实际特征值。Mask RCNN 在实例分割方面实现了最先进的性能</p><p><strong>基于区域提案的框架由各个阶段组成，这些阶段相互连接并分别进行训练。这些是区域建议生成、使用 CNN 提取特征、分类和边界框回归</strong>。尽管这些方法能够实现高精度，但仍存在一些与实时速度相关的问题。这个问题可以通过统一的阶段检测器来克服，<strong>方法是删除区域建议阶段，并在单个CNN中实现特征提取、建议回归和预测</strong></p><p>损失或成本函数，如Hinge损失、L1 和 L2 损失、对数损失 [52]是预期输出和预测输出之间差异的度量。建议读者参考相应的物体检测器论文以获取更多信息</p><h3 id="One-stage-object-detectors"><a href="#One-stage-object-detectors" class="headerlink" title="One-stage object detectors"></a>One-stage object detectors</h3><p>单阶段对象检测框架使用 DCNN <strong>同时进行定位和分类</strong>，而无需将它们划分为两个部分。</p><p>在这种情况下，只需要通过神经网络进行一次传递。它具有前馈神经网络，可<strong>以一次预测所有边界框。它们将图像像素直接映射到边界框坐标和类概率</strong>。</p><h4 id="DetectorNet"><a href="#DetectorNet" class="headerlink" title="DetectorNet"></a>DetectorNet</h4><p>Szegedy， C.等将DetectorNet框架实现为回归问题。</p><p>它能够学习特征进行分类并获取一些几何信息。它<strong>使用 AlexNet 作为骨干网络，并将 softmax 层替换为回归层</strong>。为了预测前景像素，DetectorNet 将输入图像分割成coarse grid。它的训练过程非常缓慢，因为网络要针对每种对象类型和掩码类型进行训练。此外，DetectorNet 无法处理类似类的多个对象。当它与多尺度从粗到细方法结合使用时，基于 DNN 的对象掩码回归会产生出色的结果</p><h4 id="Overfeat"><a href="#Overfeat" class="headerlink" title="Overfeat"></a>Overfeat</h4><p>Sermanet， P.等提出了一种统一的结构，即<strong>使用卷积网络通过多尺度滑动窗口方法进行定位、分类和检测</strong>。它是最强大的目标检测框架之一，应用于 ImageNet 大规模视觉识别挑战赛 2013 （ILSVRC），在检测和定位方面排名第一 。它是<strong>第一个基于全卷积深度网络的单级检测器，它通过全卷积层使用单次前向通道来检测物体</strong>。</p><p>OverFeat 充当后来出现的算法的基础模型，即 YOLO 及其版本、SSD 等。主要区别在于<strong>分类器和回归器的训练是在 OverFeat 中连续完成的</strong></p><h4 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h4><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolo-network-architecture.png" alt="img"></p><p>You Only Look Once（YOLO）是由Redmon， J.等人设计的单级目标检测器，<strong>其中目标检测作为回归问题进行。它预测对象的边界框的坐标，并确定它所关联的类别的可能性</strong>。由于仅使用单个网络，因此可以实现端到端优化。它<strong>使用有限的候选区域选择直接预测检测。与基于区域的方法不同，这些方法使用来自特定区域的特征</strong>，而YOLO广泛使用来自整个图像的特征</p><p>在YOLO目标检测中，图像被划分为S×S网格;每个网格由五个元组（x、y、w、h 和置信度分数）组成。单个对象的置信度分数基于概率。这个分数是给每个类的，无论哪个类的概率很高，该类都会优先。</p><p>边界框的参数宽度 （W） 和高度 （H） 是根据对象的大小来预测的。从重叠的边界框中，选择具有最高 IOU 的框，并删除其余框。</p><p>YOLOv2是YOLOv1的增强版本，由Redmon， J.等人]给出。在这个版本中，应用了不同的思想<strong>，如批量归一化、卷积锚框、高分辨率分类器</strong>、<strong>细粒度特征和多尺度训练</strong>来提高 YOLO 的性能。它使用 Darknet-19 作为包含 19 个卷积层和 5 个最大池化层的骨干分类，这些层需要更少的过程来分析图像，同时实现最佳精度</p><p>YOLOv3 是 YOLOv2  的渐进形式，它使用<strong>逻辑回归来估计每个边界框的客观性分数。边界框中包含多个类，为了预测这些类，使用了多标签分类</strong>。它还使用二进制交叉熵损失、数据增强技术和批量归一化。YOLOv3 使用一个名为 Darknet-53 的健壮特征提取器</p><p>YOLOv4 是一种先进的目标检测器，比以前所有版本的YOLO更准确、更快。它包括一种称为“Bag of freebies”的方法，该方法在不影响推理时间的情况下增加了训练时间。该方法利用<strong>数据增强技术、自对抗训练、交叉小批量归一化 （CmBN）、CIoU 损失 、DropBlock 正则化、余弦退火调度器来改进训练。YOLOv4 还包含了那些只影响推理时间的方法，称为“Bag of specials”;它包括 Mish 激活、多输入加权残差连接 （MiWRC）、SPP 模块 [26]、PAN 路径聚合模块 [58]、跨级部分连接 （CSP）和空间注意力模块模块</strong>。YOLOv4 可以在单个 GPU 上训练，并使用遗传算法来选择超参数</p><p>在 YOLOv4 发布后不久，Ultralytics 公司推出了 YOLOv5 存储库，与以前的 YOLO 模型相比，它有相当大的增强,由于 YOLOv5 不是作为同行评议的研究发表的，因此它引起了许多关于其合法性的争论;但它仍然被用于各种应用，并在产生模型可靠性的同时提供有效的结果。它以 140 fps 的推理速度运行。YOLOv5使用PyTorch，这使得模型的部署更快、更容易、更准确[60]。虽然 YOLOv4 和 YOLOv5 框架相似，因此很难比较它们之间的区别，但后来，YOLOv5 在某些情况下获得了比 YOLOv4 更高的性能。YOLOv5 模型有五种类型：nano、small、medium、large、extralarge。根据数据集选择模型类型。此外，YOLOv5 模型的轻量级模型随 6.0 版本发布;推理速度提高至 1666 fps.</p><h4 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h4><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/SSD-architecture.png" alt="img"></p><p>SSD是一种用于多个类别的快速单次多box检测器，由Liu， W.等人实现。它构建了一个统一的检测器框架</p><p>该框架与 YOLO 一样快，与 Faster-RCNN 一样准确。SSD的设计结合了YOLO模型的回归思想和Faster R-CNN算法的锚定过程。通过使用 YOLO 的回归，SSD 降低了神经网络的计算复杂性，以确保实时性能。通过锚点程序，SSD能够提取各种大小和纵横比的特征，以确保检测精度。SSD 使用 VGG-16 作为骨干检测器</p><p>SSD的过程基于前馈CNN，该CNN为这些框中是否存在对象类实例生成固定大小和对象性分数的边界框，然后应用NMS（非最大抑制）进行最终检测。它还使用RPN的概念来获得快速的检测速度，同时保持高检测质量。通过一些辅助数据增强和硬负挖掘方法，SSD 在各种基准数据集上实现了最先进的性能</p><h3 id="Backbone-networks"><a href="#Backbone-networks" class="headerlink" title="Backbone networks"></a>Backbone networks</h3><p>DCNN作为目标检测模型的骨干网络。为了改善特征表示行为，网络的结构变得更加复杂，这意味着网络层会变得更深，其参数也会增加。骨干CNN用于提取基于DCNN的目标检测系统的特征。</p><p><strong>骨干网络作为目标检测方法的主要特征提取器，将图像作为输入，并为每个输入图像生成特征图作为输出</strong>。根据精度和效率的需要;可以使用密集连接的骨干网，如ResNet 、ResNext等。当需要高精度和构建精确的应用程序时，需要复杂的主干网。</p><p>AlexNet是一种重要的CNN架构，由5个卷积层和3个全连接层组成。在为图像提供固定大小（224 × 224）的输入后，网络一遍又一遍地卷积并汇集激活，然后将结果传输到完全连接的层。该网络在ImageNet上进行训练，并结合了多种正则化方法，例如数据增强，dropout等。为了加速数据处理，提高收敛速度，首次使用了ReLu激活函数和GPU。</p><h3 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h3><p>在AlexNet取得成功之后，研究人员想知道卷积层可视化背后的机制，以了解CNN如何学习特征以及如何检查每层图像特征图的差异。</p><p>因此，Zeiler， M. D. et al. 设计了一种<strong>使用反卷积层、解池层和ReLU非线性来可视化特征图的方法。与 AlexNet 一样，第一层的滤波器大小为 11×11，步幅为 4，但在 ZFNet 中，它减少到 7×7，步幅设置为 2 而不是 4</strong>。这样做的原因是第一层的滤波器包含频率信息的变化;它可以是高的，也可以是低的，并且具有非常小的中频百分比。该方法的性能优于AlexNet，并证明了网络的深度会影响深度学习模型的性能</p><h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p>VGG 进一步将AlexNet的深度扩大到16-19层，从而细化了网络的特征表示。VGG16 和 VGG19 是两种流行的 VGG 网络架构。在每一层中，它采用大小为 3×3 的内核，步幅为 1。小内核和步幅更有利于提取图像中物体位置的细节。它的好处是通过合并额外的卷积层来扩展网络的深度。最小化参数可以提高网络的特征表示能力</p><h4 id="GoogLeNet-或-inception-v1"><a href="#GoogLeNet-或-inception-v1" class="headerlink" title="GoogLeNet 或 inception v1"></a>GoogLeNet 或 inception v1</h4><p>GoogleNet  的主要目的Inception v1 架构旨在通过降低计算成本来实现高精度。向网络添加 1×1 卷积层，其深度增加。这种滤波器大小首先用于名为Network-in-Network的技术，主要用作降维以消除计算瓶颈并增加网络的宽度和高度。</p><p>GoogleNet 是一个 22 层的深度架构，是 ILSVRC 2014 竞赛的获胜者。基于这一思路，作者开发了一个具有降维功能的初始模块。通过使用 inception 模块，GoogLeNet 参数的数量减少了。Inception 模块由 1x1、3x3 和 5x5 滤波器大小的卷积层和相互平行组装的最大池化层组成。Inception v2 系列是第一个提出批量归一化的网络 ，从而实现快速训练</p><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>随着网络深度的增加，可能会出现精度在达到饱和点后下降的情况。这被称为退化问题，为了解决这个问题，提出了一个残差学习（ResNet）模块。与早期设计的架构（如AlexNet 和VGGNet）相比，它的计算复杂度更低。通常使用层数为50和101层的ResNet骨干网络。在 ResNet50 中，使用跳过连接来保留更深层的梯度，并且精度有所提高。在 ResNet101 中，该模块的性能与 VGG 网络相同，但参数数量较少，遵循 GoogLeNet 中的全局平均池化和瓶颈</p><h4 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h4><p>Huang， G. et al. 提出了由密集块组成的 DenseNet 架构，该架构以前馈方式将每一层与其他层连接起来，从而带来特征重用、参数有效性和隐式深度监督等好处。DenseNet 减少了梯度消失的问题</p><h3 id="Problems-of-object-detection-and-its-solutions"><a href="#Problems-of-object-detection-and-its-solutions" class="headerlink" title="Problems of object detection and its solutions"></a>Problems of object detection and its solutions</h3><h4 id="Small-object-detection"><a href="#Small-object-detection" class="headerlink" title="Small object detection"></a>Small object detection</h4><p>检测小尺寸物体是物体检测中最困难的问题之一。Faster RCNN 和 YOLO等目标检测算法在检测小尺寸物体方面不足。在深度卷积神经网络中，由于独立特征层在实际图像中仅占据很小的像素尺寸，因此缺乏足够的知识。由于低分辨率的小尺寸物体携带有限的上下文细节，因此很难检测到它们。为了克服这个问题，可以<strong>通过增强生成更多的数据，或者可以提高模型的输入分辨率</strong>等</p><h4 id="Multi-scale-object-detection"><a href="#Multi-scale-object-detection" class="headerlink" title="Multi-scale object detection"></a>Multi-scale object detection</h4><p>在目标检测领域，多尺度目标检测是一项具有挑战性的任务。<strong>深度CNN的每一层都会生成特征图，而这些特征图生成的信息是相互独立的。多尺度对象的判别细节可以出现在骨干网络的任一层中，而对于小尺度对象，它出现在初始层中，并在后面的层中消散</strong>。在目标检测算法（一级和两级）中，预测是从最顶层进行的，这给检测多尺度对象（通常是小对象）的方式造成了障碍。为了克服这个困难;该文提出<strong>信息融合与DCNNs分层结构相结合的多层检测和特征融合</strong></p><p>代表性方法包括多尺度深度CNN 、深度监督目标检测（DSOD）和SSD。为了提高多尺度目标检测的可靠性，可以合并多层特征融合和多层检测。这包括特征金字塔网络（FPN）、反卷积单次检测器（DSSD）、尺度可转移检测网络（STDN）、与对象先验网络的反向连接（RON）、自上而下的调制（TDM）等几个具有代表性的框架。</p><h4 id="Intraclass-variation"><a href="#Intraclass-variation" class="headerlink" title="Intraclass variation"></a>Intraclass variation</h4><p>类内variation是指<strong>同一类的不同图像之间发生的variation</strong>。<strong>它们的形状、大小、颜色、材料、质地等各不相同</strong>。对象实例看起来很灵活，可以在缩放和旋转方面轻松转换。这些被称为内在因素。外部因素也会产生一些明显的影响。<strong>它包括照明不当、天气条件、照明、低质量相机等。这种差异可能由多种因素引起</strong>，如遮挡、照明、位置、透视等。这个问题可以通过验证训练数据是否具有良好的多样性（包括上述所有因素）来克服</p><h4 id="Class-imbalance"><a href="#Class-imbalance" class="headerlink" title="Class imbalance"></a>Class imbalance</h4><p>类之间的不规则数据分布称为类不平衡。简单来说，<strong>可以说当类包含不成比例数量的实例时，即在一个数据集中比另一个数据集中的标本多</strong>。从对象检测的角度来看，类不平衡可以分为两种类型：前景-背景不平衡和前景-前景不平衡。前者发生在训练过程中，与数据集中的类别数量无关。后者是指在样本数量范围内批次水平的不平衡，涉及正类。<strong>一般来说，一级目标探测器的精度低于两级目标探测器，其背后的原因之一是类别不平衡。为了解决这个问题，可以对类进行上采样和下采样，或者使用合成少数过采样技术（SMOTE）等生成合成数据</strong></p><h4 id="Generalization-issues"><a href="#Generalization-issues" class="headerlink" title="Generalization issues"></a>Generalization issues</h4><p>当模型欠拟合或过拟合时，就会出现目标检测中的泛化问题。欠拟合可以在训练阶段的初始阶段识别出来，这个问题可以通过增加训练周期的数量或模型的复杂性来解决。对于过拟合，我们可以使用重要的方法，例如<strong>增加训练数据、提前停止、正则化方法（L1、L2）或丢弃层</strong></p><h2 id="3D-Object-Detection-for-Autonomous-Driving-A-Comprehensive-Survey"><a href="#3D-Object-Detection-for-Autonomous-Driving-A-Comprehensive-Survey" class="headerlink" title="3D Object Detection for Autonomous Driving: A Comprehensive Survey"></a>3D Object Detection for Autonomous Driving: A Comprehensive Survey</h2><h3 id="abs"><a href="#abs" class="headerlink" title="abs"></a>abs</h3><p>近年来，自动驾驶因其减轻驾驶员负担和提高驾驶安全性的潜力而受到越来越多的关注。在现代自动驾驶管道中，感知系统是不可或缺的组成部分，<strong>旨在准确估计周围环境的状态，并为预测和规划提供可靠的观测结果。3D 物体检测旨在预测自动驾驶汽车附近 3D 物体的位置、大小和类别</strong>，是感知系统的重要组成部分。本文综述了自动驾驶三维目标检测的研究进展。首先，我们<strong>介绍了3D目标检测的背景，并讨论了该任务的挑战。其次，我们从模型和感官输入方面对3D目标检测的进展进行了全面调查，包括基于激光雷达、基于相机和多模态检测方法。我们还对每类方法的潜力和挑战进行了深入分析</strong>。此外，我们还系统地研究了3D目标检测在驾驶系统中的应用。最后，对三维目标检测方法进行了性能分析，进一步总结了多年来的研究趋势，并展望了该领域的未来发展方向。</p><h3 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h3><p>自动驾驶技术已广泛应用于许多场景，包括自动驾驶卡车、机器人出租车、送货机器人等，能够减少人为错误并增强道路安全性。作为自动驾驶系统的核心组成部分，汽车感知帮助自动驾驶汽车通过感官输入了解周围环境。<strong>感知系统通常以多模态数据（摄像头图像、激光雷达扫描仪点云、高清地图等）为输入，预测道路上关键要素的几何和语义信息。高质量的感知结果可作为目标跟踪、轨迹预测和路径规划等后续步骤的可靠观测</strong></p><p><img data-src="https://i.imgur.com/02X39qA.png" alt="image-20231222223259144"></p><p>3D 对象检测旨在根据感官输入预测驾驶场景中 3D 对象的边界框。3D 目标检测的一般公式可以表示为</p><script type="math/tex; mode=display">\begin{equation}\mathcal{B}=f_{det}(\mathcal{I}_{sensor}),\end{equation}</script><p>f~det~ 是 3D 对象检测模型，I~sensor~ 是一个或多个感官输入,B = {B1， · · · ， BN } 是场景中 N 个 3D 对象的集合。</p><p>如何表示 3D 对象 Bi 是此任务中的一个关键问题，因为它决定了应为以下预测和规划步骤提供哪些 3D 信息。在大多数情况下，3D 对象表示为包含此对象的 3D 长方体，</p><script type="math/tex; mode=display">\begin{equation}B=[x_c,y_c,z_c,l,w,h,\theta,class],\end{equation}</script><p>其中 （x~c~， y~c~， z~c~） 是长方体的 3D 中心坐标，l、w、h 分别是长方体的长度、宽度和高度，θ 是长方体在地平面上的航向角，即偏航角，class 表示 3D 对象的类别，例如汽车、卡车、行人、骑自行车的人。此外也有其他模型使用了更多参数的.</p><p><strong>Sensory inputs</strong></p><p>有许多类型的传感器可以为 3D 物体检测提供原始数据。<strong>在传感器中，雷达、摄像头和LiDAR（光探测和测距）传感器是三种最广泛采用的传感类型</strong>。雷达具有较长的探测范围，并且对不同的天气条件具有鲁棒性。由于多普勒效应，雷达可以提供额外的速度测量。摄像头价格便宜且易于获取，对于理解语义（例如交通标志的类型）至关重要。尽管价格便宜，但相机在用于 3D 物体检测方面存在固有的局限性<strong>。相机只能捕获外观信息，无法直接获取场景的 3D 结构信息</strong>。另一方面，<strong>3D物体检测通常需要在3D空间中进行精确定位，而从图像中估计的3D信息（例如深度）通常具有较大的误差</strong>。图像的变形通常<strong>容易受到极端天气和时间条件的影响</strong>。在<strong>夜间或雾天从图像中检测物体比在晴天检测要困难得多</strong>，这导致了实现自动驾驶的足够鲁棒性的挑战。</p><p><img data-src="https://i.imgur.com/lS0F3vq.png" alt="image-20231222225107201"></p><p>作为替代解决方案，<strong>LiDAR 传感器可以通过发射激光束然后测量其反射信息来获得场景的细粒度 3D 结构。</strong>一个激光雷达传感器发射 m 束并在一个扫描周期内进行 n 次测量，可以产生 I~range~ ∈ R^m×n×3^ 的距离图像,其中,范围图像的<strong>每个像素都包含球面坐标系中的距离 r、方位角α和倾角φ以及反射强度</strong>。</p><p><strong>范围(Range)图像是LiDAR传感器获得的原始数据格式，可以通过将球面坐标转换为笛卡尔坐标来进一步转换为点云。</strong></p><p>点云可以表示为 I~point~ ∈ R^N×3^，其中 N 表示场景中的点数，每个点有 3 个 xyz 坐标通道。<strong>距离图像和点云都包含由LiDAR传感器直接获取的精确3D信息</strong>。</p><p>因此，<strong>与相机相比，LiDAR 传感器更适合检测 3D 空间中的物体，并且 LiDAR 传感器也不太容易受到时间和天气变化的影响</strong>。然而，LiDAR 传感器比摄像头贵得多，这可能会限制在驾驶场景中的应用</p><p>2D 目标检测旨在<strong>在图像上生成 2D 边界框</strong>，是计算机视觉中的一个基本问题。</p><p>3D 目标检测方法借鉴了 2D 对应物的许多设计范式：<strong>region proposals生成和细化、锚点、非最大抑制等</strong>。然而，从很多方面来看，3D目标检测并不是2D目标检测方法对3D空间的简单改变。</p><p>（1）3D目标检测方法必须处理异构数据表示<strong>。点云检测需要新型算子和网络来处理不规则的点数据</strong>，而点云和图像的检测需要特殊的融合机制。</p><p>（2） 3D 目标检测方法通常<strong>利用不同的投影视图来生成对象预测</strong>。</p><p>与从透视图检测对象的 2D 对象检测方法相反，<strong>3D 方法必须考虑不同的视图来检测 3D 对象，例如从鸟瞰图、点视图和圆柱视图</strong>。（3）3D物体检测对物体在3D空间中的精确定位有很高的要求。分米级的定位误差可能导致行人和骑自行车的人等小物体的检测失败，而在二维物体检测中，几个像素的定位误差仍可能在预测边界框和地面实况边界框之间保持较高的交并 （IoU）。因此，精确的 3D 几何信息对于从点云或图像进行 3D 物体检测是必不可少的。</p><p>（1） LiDAR 和 RGB-D 传感器的点云分布不同。在室内场景中，点相对均匀地分布在扫描表面上，大多数 3D 对象在其表面上接收到足够数量的点。然而，在驾驶场景中，大多数点都落在 LiDAR 传感器的附近，而那些远离传感器的 3D 物体只会获得几个点。因此，在驾驶场景中，<strong>特别需要处理各种点云密度的三维物体，并准确检测那些远距离和稀疏的物体。</strong></p><p>（2）驾驶场景下的检测对推理时延有特殊要求。<strong>驾驶场景中的感知必须是实时的</strong>，以避免事故发生。因此，这些方法必须具有计算效率，否则它们将无法应用于实际应用。</p><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><p><img data-src="https://i.imgur.com/HiTj4TF.png" alt="image-20231222230257242"></p><h3 id="LiDAR-based-3D-Object-Detection"><a href="#LiDAR-based-3D-Object-Detection" class="headerlink" title="LiDAR-based 3D Object Detection"></a>LiDAR-based 3D Object Detection</h3><p>我们将介绍基于LiDAR数据的3D目标检测方法，即点云或距离图像。回顾和分析了基于不同数据表示的基于 LiDAR 的 3D 目标检测模型，包括<strong>基于点</strong>、<strong>基于网格</strong>、<strong>基于点体素</strong>和<strong>基于距离</strong>的方法。(point-based, grid-based, point-voxel based, and range-based)</p><p><img data-src="https://i.imgur.com/7LLjGj3.png" alt="image-20231222230749845"></p><h4 id="Data-representations-for-3D-object-detection"><a href="#Data-representations-for-3D-object-detection" class="headerlink" title="Data representations for 3D object detection"></a>Data representations for 3D object detection</h4><p><strong>与像素有规律地分布在图像平面上的图像相比，点云是一种稀疏且不规则的 3D 表示</strong>，需要专门设计的模型进行特征提取。<strong>范围图像是一种密集而紧凑的表示形式，但范围像素包含 3D 信息而不是 RGB 值</strong>。因此，在范围图像上直接应用传统的卷积网络可能不是最佳解决方案。另一方面，自动驾驶场景中的检测通常具有实时推理的要求。因此，如何开发一个既<strong>能有效处理点云或范围图像数据又能保持高效率的模型</strong>，仍然是研究界面临的一个公开挑战。</p><h4 id="Point-based-3D-object-detection"><a href="#Point-based-3D-object-detection" class="headerlink" title="Point-based 3D object detection"></a>Point-based 3D object detection</h4><p>基于点的3D目标检测方法通常继承了点云深度学习技术的成功，并<strong>提出了直接从原始点检测3D对象的多种架构</strong>。</p><p>点云首先通过基于<strong>点的骨干网络</strong>，在该网络中，点逐渐采样，点云操作学习特征。然后，根据下采样点和特征预测 3D 边界框。</p><p><img data-src="https://i.imgur.com/Vl1RhDd.png" alt="image-20231222233252147"></p><p>基于点的 3D 对象检测器有两个基本组件：<strong>点云采样</strong>和<strong>特征学习</strong>。</p><p><strong>Point Cloud Sampling</strong>:PointNet++中的<strong>最远点采样（FPS）已被广泛用于基于点的检测器中</strong>，其中最远的点是<strong>从原始点集中依次选择的</strong>。PointRCNN 是一项开创性的工作，<strong>它采用 FPS 逐步对输入点云进行下采样，并从下采样点生成 3D 建议</strong>。类似的设计范式也被用于后续的许多工作，并进行了改进，如分割引导滤波、特征空间采样、随机采样、基于体素的采样(voxel-based sampling)和坐标细化(coordinate refinement)。</p><p><strong>Point Cloud Feature Learning</strong>:具体来说，首先通过球查询(ball query)在预定义的半径内收集上下文点。然后，通过多层感知器和maxpooling对上下文点和特征进行聚合，得到新的特征。还有其他使用不同点云算子的工作，包括图算子，注意力算子和Transformer。</p><p>基于点的检测器的表示能力主要受两个因素的限制：<strong>特征学习中采用的上下文点数和上下文半径</strong>。增加上下文点的数量将获得更多的表示能力，但代价是增加大量的内存消耗。球查询中合适的上下文半径也是一个重要因素：如果半径太小，上下文信息可能不足，如果半径过大，细粒度的 3D 信息可能会丢失。必须仔细确定这两个因素，以平衡检测模型的有效性和效率。</p><p><strong>增加上下文点的数量将获得更多的表示能力，但代价是增加大量的内存消耗</strong>。球查询中合适的上下文半径也是一个重要因素：如果半径太小，上下文信息可能不足，如果半径过大，细粒度的 3D 信息可能会丢失。必须仔细确定这两个因素，以平衡检测模型的有效性和效率。可并行进行随机均匀采样，效率高。然而，考虑到LiDAR扫描中的点不是均匀分布的，<strong>随机均匀采样可能倾向于对那些高点云密度的区域进行过度采样，而对那些稀疏区域进行采样不足，这通常会导致与最远点采样相比性能较差。</strong></p><p><strong>最远点采样及其变体可以通过从现有点集中依次选择最远的点来获得更均匀的采样结果。然而，最远点采样本质上是一种顺序算法，不能变得高度并行</strong>。因此，最远点采样通常很耗时，并且无法进行实时检测。</p><h4 id="Grid-based-3D-object-detection"><a href="#Grid-based-3D-object-detection" class="headerlink" title="Grid-based 3D object detection"></a>Grid-based 3D object detection</h4><p><img data-src="https://i.imgur.com/O8n1SeP.png" alt="image-20231223135445200"></p><p>基于网格的 3D 对象检测器首先<strong>将点云栅格化为离散的网格表示</strong>，即<strong>体素、柱子和鸟瞰图 （BEV） 特征图</strong>。然后，他们<strong>应用传统的 2D 卷积神经网络或 3D 稀疏神经网络</strong>从网格中提取特征。最后，可以从BEV网格单元中检测到3D物体。基于网格的 3D 目标检测图如图  所示。基于网格的检测器有两个基本组件：<strong>基于网格的表示</strong>和<strong>基于网格的神经网络</strong></p><p><strong>Grid-based representations</strong>:</p><p><strong>voxels</strong>。如果<strong>将检测空间栅格化为规则的 3D 格网</strong>，则体素就是格网像元。<strong>如果点云落入此格网像元中，则体素可以为非空。</strong>由于点云分布稀疏，因此 3D 空间中的大多数体素单元格都是空的，不包含任何点。<strong>在实际应用中，只有那些非空体素才会被存储并用于特征提取。</strong>VoxelNet是一项开创性的工作，它利用稀疏的体素网格，提出了一种新的体素特征编码（VFE）层，从体素单元内的点中提取特征。</p><p>随后的一系列工作采用了类似的体素编码策略。此外，还有两类方法试图改进 3D 目标检测的体素表示：（1） <strong>多视图体素</strong>。一些方法从不同的视角提出了动态体素化和融合方案，例如鸟瞰图和透视图、圆柱面和球面视角、距离视角。（2）<strong>多尺度体素</strong>。一些论文生成不同尺度的体素或使用可重构的体素</p><p><strong>Pillars</strong>:柱子可以看作是特殊的体素，<strong>其中体素大小在垂直方向上是无限的</strong>。<strong>支柱特征可以通过PointNet从点聚合，然后散射回来</strong>，构建2D BEV图像进行特征提取。PointPillars 是一部开创性的著作，它引入了Pillar表示</p><p><strong>BEV feature maps</strong>:鸟瞰图特征图是一种密集的 2D 表示，其中<strong>每个像素对应于一个特定区域</strong>，<strong>并对该区域中的点信息进行编码</strong>。BEV特征图可以通过将3D特征投影到鸟瞰图中，从体素和柱子中获取，也可以通过汇总像素区域内的点统计数据，直接从原始点云中获取。</p><p><strong>Grid-based neural networks</strong>:基于网格的网络主要有两种类型：<strong>用于 BEV 特征图</strong>和<strong>Pillar的 2D 卷积神经网络</strong>，以及<strong>用于体素的 3D 稀疏神经网络</strong>。</p><p>2D convolutional neural networks:传统的 2D 卷积神经网络可以应用于 BEV 特征图，以从鸟瞰图检测 3D 对象。在大多数作品中，2D网络架构通常都是从2D目标检测中的成功设计中改编而来的,比如ResNet，区域建议网络（RPN）和特征金字塔网络（FPN）</p><p>3D 稀疏神经网络。3D稀疏卷积神经网络基于两个专门的3D卷积算子：sparse convolutions和submanifold convolutions，<strong>它们只能在那些非空体素上有效地进行3D卷积。与在整个体素空间上执行标准3D卷积相比，稀疏卷积算子效率更高</strong>，可以获得实时推理速度。</p><p>SECOND是一项开创性的工作，它使用基于 GPU 的哈希表实现了这两个稀疏算子，并构建了一个稀疏卷积网络来提取 3D 体素特征。</p><p>这种网络架构已在许多工程中得到应用，并成为基于体素的探测器中使用最广泛的骨干网络。还有一系列工作试图改进稀疏算子，将扩展为两级检测器，并将Transformer架构引入基于体素的检测。</p><p>与 BEV 特征图和Pillar等 2D 表示相比，体素包含更结构化的 3D 信息。此外，<strong>深度体素特征可以通过 3D 稀疏网络学习</strong>。然而，<strong>3D 神经网络会带来额外的时间和内存成本</strong>。<strong>BEV 特征图是最有效的网格表示，可直接将点云投影到 2D 伪图像中，而无需专门的 3D 运算符</strong>，如稀疏卷积或柱状编码。<strong>2D检测技术也可以无缝应用于BEV特征图，无需太多修改。</strong>基于BEV的检测方法通常可以获得高效率和实时推理速度。但是，<strong>简单地汇总像素区域内的点统计数据会丢失太多的 3D 信息</strong>，与基于体素的检测相比，这会导致检测结果的准确性较低。基于Pillar的检测方法利用 PointNet 对Pillar内的 3D 点信息进行编码，然后将特征分散回 2D 伪图像中以实现高效检测，从而平衡了 3D 目标检测的有效性和效率</p><p><strong>challenges of the grid-based detection methods</strong>:所有基于网格的方法都必须面对的一个关键问题是选择适当大小的网格单元。<strong>网格表示本质上是点云的离散格式</strong>，通过将连续的点坐标转换为离散的网格索引。</p><p>量化过程不可避免地会丢失一些 3D 信息<strong>，其有效性很大程度上取决于网格单元的大小：网格尺寸越小，网格就越高分辨率，因此可以保留更细粒度的细节，这对于准确的 3D 对象检测至关重要</strong>,然而，减小网格单元的大小会导致 2D 网格表示（如 BEV 特征图或支柱）的内存消耗呈二次增加。至于像体素这样的 3D 网格表示，问题可能会变得更加严重。因此，<strong>如何平衡较小网格尺寸带来的功效和内存增加影响的效率仍然是所有基于网格的三维目标检测方法面临的一个悬而未决的挑战</strong>。</p><h4 id="Point-voxel-based-3D-object-detection"><a href="#Point-voxel-based-3D-object-detection" class="headerlink" title="Point-voxel based 3D object detection"></a><strong>Point-voxel based 3D object detection</strong></h4><p>基于点体素的方法采用混合架构，<strong>利用点和体素进行 3D 对象检测</strong>。这些方法可以分为两类：单阶段和两阶段检测框架。</p><p><strong>Single-stage point-voxel detection frameworks.</strong></p><p>基于单级点体素的 3D 目标检测器<strong>试图将点和体素的特征与骨干网络中的点到体素和体素到点变换联系起来</strong></p><p><strong>点包含细粒度的几何信息，体素的计算效率很高，在特征提取阶段将它们组合在一起自然会从这两种表示中受益</strong>。在骨干网中利用点-体素特征融合的思想已被许多著作探索，其贡献包括点-体素卷积，辅助点网络和多尺度特征融合.</p><p><strong>Two-stage point-voxel detection frameworks</strong></p><p>基于点体素的两级 3D 对象检测器<strong>针对不同的检测阶段采用不同的数据表示</strong>。</p><p>具体来说，在第一阶段，采用<strong>基于体素的检测框架来生成一组 3D 对象建议</strong>,在第二阶段，<strong>首先从输入点云中对关键点进行采样，然后通过新的点算子从关键点进一步细化3D建议</strong>。</p><p>基于点体素的方法自然可以受益于从点获得的细粒度 3D 形状和结构信息以及体素带来的计算效率。然而，这些方法仍然存在一些挑战。对于混合点-体素骨干网，点-体素特征的融合一般<strong>依赖于体素-点和点-体素变换机制，可以带来不可忽视的时间成本</strong>。对于两阶段点体素检测框架，一个关键的挑战是<strong>如何有效地聚合 3D 提案的点特征，因为现有的模块和运算符通常非常耗时</strong>。综上所述，与纯基于体素的检测方法相比，基于点体素的检测方法可以获得更好的检测精度，但代价是增加了推理时间。</p><h4 id="Range-based-3D-object-detection"><a href="#Range-based-3D-object-detection" class="headerlink" title="Range-based 3D object detection"></a>Range-based 3D object detection</h4><p>范围图像是一种密集而紧凑的 2D 表示，其中<strong>每个像素都包含 3D 距离信息，而不是 RGB 值</strong>。基于距离的方法从两个方面解决了检测问题：<strong>设计适合距离图像的新模型和算子</strong>，以及<strong>选择合适的视图进行检测</strong>。</p><p><img data-src="https://i.imgur.com/r7H1L1T.png" alt="image-20231223162320834" style="zoom:67%;" /></p><p><strong>Range-based detection models</strong></p><p>由于距离图像是与RGB图像一样的2D表示，因此基于范围的3D对象检测器可以自然地借用2D对象检测中的模型来处理范围图像。</p><p>LaserNet 是一项开创性的工作，它利用深层聚合网络 （DLA-Net）从距离图像中获取多尺度特征并检测 3D 对象。一些论文还采用了其他 2D 目标检测架构</p><p><strong>Range-based operators</strong></p><p>距离图像的像素包含 3D 距离信息而不是颜色值，<strong>因此传统 2D 网络架构中的标准卷积算子对于基于范围的检测来说不是最佳选择</strong>，因为滑动窗口中的像素在 3D 空间中可能彼此相距很远。一些工作采用新颖的算子来有效地从范围像素中提取特征，包括范围扩展卷积、图算子和元核卷积</p><p><strong>Views for range-based detection</strong></p><p>范围图像是从范围视图 （RV） 捕获的，理想情况下，范围视图是点云的球面投影。</p><p>然而，从距离视图进行检测时，<strong>不可避免地会受到球面投影带来的遮挡和尺度变化问题的影响</strong>。</p><p>为了规避这些问题，许多方法都在<strong>利用其他视图来预测3D物体，例如中采用的圆柱视图（CYV），在中采用的距离视图、鸟瞰视图（BEV）和/或点视图（PV）的组合</strong></p><p><strong>Analysis: potentials and challenges of the range-based methods</strong></p><p>范围图像是一种密集而紧凑的 2D 表示，因此<strong>传统或专用的 2D 卷积可以无缝地应用于范围图像</strong>，这使得特征提取过程非常高效.然而，<strong>与鸟瞰图检测相比，距离图检测容易受到遮挡和尺度变化的影响</strong>。因此，<strong>从距离视图中提取特征</strong>，<strong>从鸟瞰图进行目标检测</strong>，成为基于距离的3D目标检测最实用的解决方案。</p><h3 id="Learning-objectives-for-3D-object-detection"><a href="#Learning-objectives-for-3D-object-detection" class="headerlink" title="Learning objectives for 3D object detection"></a>Learning objectives for 3D object detection</h3><p>学习目标在对象检测中至关重要。<strong>由于 3D 物体相对于整个检测范围非常小，因此在 3D 检测中非常需要特殊的机制来增强小物体的定位</strong>。另一方面，<strong>考虑到点云稀疏且物体通常具有不完整的形状</strong>，准确估计 3D 物体的中心和大小是一项长期存在的挑战。</p><h4 id="Anchor-based-3D-object-detection"><a href="#Anchor-based-3D-object-detection" class="headerlink" title="Anchor-based 3D object detection"></a>Anchor-based 3D object detection</h4><p>锚点(anchors)是具有固定形状的预定义长方体,可以放置在 3D 空间中。</p><p><img data-src="https://i.imgur.com/jFknBKH.png" alt="image-20231223174714325"></p><p>3D 对象可以基于与真实值具有高交集 （IoU） 的正锚点进行预测。将从锚点配置和损失函数方面介绍基于锚点的三维目标检测方法。</p><p>Anchor configurations:基于锚点的 3D 对象检测方法通常<strong>从鸟瞰图检测 3D 对象</strong>,其中 3D 锚框放置在 BEV 特征图的每个网格单元上。3D 锚点通常对每个类别具有固定大小，因为同一类别的对象具有相似的大小</p><p>Loss functions:基于锚点的方法利用分类损失Lcls来学习正负锚点，利用回归损失Lreg来学习基于正锚点的物体的大小和位置。此外，L~θ~ 用于学习物体的航向角。</p><script type="math/tex; mode=display">\begin{equation}L_{det}=L_{cls}+L_{reg}+L_\theta.\end{equation}</script><p>回归目标可以进一步应用于这些正锚点,以学习 3D 对象的大小和位置.</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}\Delta x&=\frac{x^g-x^a}{d^a},\Delta y=\frac{y^g-y^a}{d^a},\Delta z=\frac{z^g-z^a}{h^a},\\\Delta l&=\log(\frac{l^g}{l^a}),\Delta w=\log(\frac{w^g}{w^a}),\Delta h=\log(\frac{h^g}{h^a}),\end{aligned}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}L_{cls}^{bce}=-[q\cdot\log(p)+(1-q)\cdot\log(1-p)]\end{equation}</script><p>p 是每个锚点的预测概率，如果锚点为正，则目标 q 为 1，否则为 0</p><script type="math/tex; mode=display">\begin{equation}d^a=\sqrt{(l^a)^2+(w^a)^2}\end{equation}</script><p>此外还有使用Focal Loss,</p><script type="math/tex; mode=display">\begin{equation}L_{cls}^{focal}=-\alpha(1-p)^\gamma\log(p),\end{equation}</script><p>使用SmoothL1 loss用于回归</p><script type="math/tex; mode=display">\begin{equation}L_{reg}=\sum_{\begin{array}{c}u\in\{x,y,z,l,w,h\},\\v\in\{\Delta x,\Delta y,\Delta z,\Delta l,\Delta w,\Delta h\}\end{array}}\text{SmoothL1}(u-v).\end{equation}</script><p>为了学习航向角 θ，弧度方向偏移量可以直接用 SmoothL1 损失回归</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}\Delta\theta&=\theta^g-\theta^a,\\L_\theta&=\text{SmoothL}1(\theta-\Delta\theta).\end{aligned}\end{equation}</script><p>然而，由于回归范围较大,直接回归弧度偏移通常很困难,另外<strong>,基于bin的航向估计</strong>是学习航向角的较好解，其中<strong>首先将角度空间划分为bin,并采用基于bin的分类L~dir~和残差回归</strong>.</p><script type="math/tex; mode=display">\begin{equation}L_\theta=L_{dir}+\text{SmoothL}1(\theta-\Delta\theta^{\prime}),\end{equation}</script><p>正弦函数也可用于对弧度偏移进行编码</p><script type="math/tex; mode=display">\begin{equation}\Delta\theta=\sin(\theta^g-\theta^a),\end{equation}</script><p>除了分别学习<strong>物体大小</strong>、<strong>位置</strong>和<strong>方向</strong>的损失函数外，将所有物体参数视为一个整体的交并（IoU）损失也可以应用于3D物体检测</p><script type="math/tex; mode=display">\begin{equation}L_{IoU}=1-IoU(b^g,b),\end{equation}</script><p>其中 C^G^ ~i~ 和 C~I~ 分别是地面实况和预测长方体的第 i 个角。</p><p>基于锚点的方法可以从同一类别的 3D 对象应该具有相似形状的先验知识中受益，因此它们可以在 <strong>3D 锚点的帮助下生成准确的对象预测</strong>。然而，<strong>由于3D物体相对于检测范围相对较小，因此需要大量的锚点来确保整个检测范围的完全覆盖</strong>，例如，在KITTI 数据集的中使用了大约70k个锚点。<strong>此外，对于那些非常小的物体，如行人和骑自行车的人，应用基于锚点的分配可能非常具有挑战性</strong>。考虑到锚点通常放置在每个网格单元的中心，如果网格单元较大而单元中的对象较小，则该单元的锚点可能与小对象具有较低的 IoU，这可能会阻碍训练过程。</p><h3 id="Anchor-free-3D-object-detection"><a href="#Anchor-free-3D-object-detection" class="headerlink" title="Anchor-free 3D object detection"></a>Anchor-free 3D object detection</h3><p>无anchor box方法消除了复杂的anchor box设计，可以灵活地应用于不同的视图，例如鸟瞰图、点视图和范围视图。</p><p><img data-src="https://i.imgur.com/6IcyJdX.png" alt="image-20231223190845168"></p><p>基于锚点和无锚点方法之间的<strong>主要区别在于正样本和负样本的选择</strong>。</p><p><strong>Grid-based assignment</strong>:与依赖于带有锚点的 IoU 来确定正负样本的基于锚点的方法相比，无锚点方法<strong>利用各种基于grid的分配策略来评估 BEV 网格单元、Pillar和体素</strong></p><p>PIXOR是一项开创性的工作，它<strong>利用地面实况 3D 物体内部的网格单元作为正例，而其他则作为负例。</strong>Pillar-based object detection for autonomous driving.采用了这种内部对象分配策略，并在中通过选择最接近对象中心的网格单元进一步改进。CenterPoint利用每个对象中心的高斯核来分配正标签。</p><p>损失函数上,分类损失基本不变.但回归损失改变如下</p><script type="math/tex; mode=display">\begin{equation}\Delta=[dx,dy,z^g,\log(l^g),\log(w^g),\log(h^g),\sin(\theta^g),\cos(\theta^g)],\end{equation}</script><p>DX 和 DY 是正grid cells和对象中心之间的偏移量。</p><p><strong>Point-based assignment.</strong></p><p>大多数基于点的检测方法<strong>采用无锚点和基于点的分配策略</strong>，其中<strong>首先对点进行分割，然后选择 3D 对象内部或附近的前景点作为正样本</strong>，最后从这些前景点中学习 3D 边界框。<strong>大多数基于点的检测器都采用了这种前景点分割策略，并进行了改进，例如增加了中心度分数</strong></p><p><strong>Range-based assignment</strong></p><p>无锚点分配也可以用于范围图像。<strong>一种常见的解决方案是选择 3D 对象内部的范围像素作为正样本</strong>。与其他回归目标基于全局三维坐标系的方法不同，<strong>基于范围的方法采用以对象为中心的坐标系进行回归</strong>。</p><p><strong>Set-to-set assignment.</strong>DETR是一种颇具影响力的 2D 检测方法，它引入了<strong>一种集到集的分配策略</strong>，通过匈牙利算法自动将预测分配给相应的地面实况</p><script type="math/tex; mode=display">\begin{equation}\mathcal{M}^*=\underset{\mathcal{M}}{\operatorname*{argmin}}\sum_{(i\to j)\in\mathcal{M}}L_{det}(b_i^g,b_j),\end{equation}</script><p>其中 M 是从每个阳性样本到 3D 对象的一对一映射。</p><h3 id="3D-object-detection-with-auxiliary-tasks"><a href="#3D-object-detection-with-auxiliary-tasks" class="headerlink" title="3D object detection with auxiliary tasks"></a>3D object detection with auxiliary tasks</h3><p>许多方法都采用辅助任务来增强空间特征，<strong>并为精确的 3D 目标检测提供隐式指导。常用的辅助任务包括语义分割、交集并集预测、对象形状补全和对象部分估计</strong>。</p><p><img data-src="https://i.imgur.com/TkWPitq.png" alt="image-20231223195729269"></p><p><strong>Semantic segmentation</strong>:语义分割可以从3个方面帮助3D目标检测：（1）前景分割可以提供对象位置的隐性信息。在大多数基于点的 3D 目标检测器 中，逐点前景分割已被广泛采用，用于生成提案。（2）空间特征可以通过分割来增强。在文献[347]中，利用语义上下文编码器来增强具有语义知识的空间特征。（3）语义分割可以作为预处理步骤，过滤掉背景样本，使3D目标检测更加高效。</p><p><strong>IoU prediction</strong>:交集并集 （IoU） 可以作为纠正对象置信度分数的有用监督信号。Cia-ssd: Confident iou-aware single-stage object detector from point cloud. In: AAAI<strong>提出了一个辅助分支来预测每个检测到的 3D 对象的 IoU 分数 S~IoU~</strong>。</p><script type="math/tex; mode=display">\begin{equation}S_{conf}=S_{cls}\cdot(S_{IoU})^\beta,\end{equation}</script><p>在推理过程中,来自传统分类分支的原始置信度分数 S~con~f = S~cls~ 被 IoU 分数 SIoU 进一步校正.其中，超参数β控制抑制低 IoU 预测和增强高 IoU 预测的程度。<strong>通过 IoU 校正,更容易选择高质量的 3D 对象作为最终预测</strong>。</p><p><strong>Object shape completion</strong></p><p>由于LiDAR传感器的性质，<strong>远处物体通常只在其表面上接收到几个点，因此3D物体通常是稀疏和不完整的</strong>。提高检测性能的一种直接方法是从稀疏点云中完成物体形状。完整的形状可以为准确和稳健的检测提供更多有用的信息<strong>。在3D检测中已经提出了许多形状补全技术，包括形状解码器、形状特征和概率占用网格</strong></p><p><strong>Object part estimation.</strong></p><p>识别对象内部的零件信息有助于 3D 对象检测，因为它可以显示对象的更细粒度的 3D 结构信息。</p><p>3D 对象检测与许多其他 3D 感知和生成任务具有内在关联性。与独立训练 3D 目标检测器相比，3D 检测和分割的多任务学习更有利，形状补全也有助于 3D 目标检测。还有其他任务可以帮助提高 3D 对象检测器的性能。例如，场景流估计可以识别静态和移动对象，在点云序列中跟踪相同的 3D 对象可以更准确地估计该对象。因此，将更多的感知任务集成到现有的3D目标检测管道中将是有希望的。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;2023年的目标检测综述&lt;strong&gt;A comprehensive review of object detection with deep learning&lt;/strong&gt;以及&lt;strong&gt;3D Object Detection for Autonomous Driving: A Comprehensive Survey&lt;/strong&gt;,之前写了一些单阶段和双阶段的2D目标检测,可以好好回顾一下.&lt;/p&gt;</summary>
    
    
    
    
    <category term="object detection" scheme="https://www.sekyoro.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>Python的工程化之路</title>
    <link href="https://www.sekyoro.top/2023/12/04/Python%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%8C%96%E4%B9%8B%E8%B7%AF/"/>
    <id>https://www.sekyoro.top/2023/12/04/Python%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%8C%96%E4%B9%8B%E8%B7%AF/</id>
    <published>2023-12-04T07:54:52.000Z</published>
    <updated>2023-12-23T12:54:53.563Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在工程化上,Python相比于Java,C#这类语言还是差了不少,不过整个生态还是不错的.</p><span id="more"></span><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>一般有两种,一种称为flat另一种为src.</p><ol><li><blockquote><p>├── sample<br>│   ├── AUTHORS.rst<br>│   ├── docs<br>|   |   ├── conf.py<br>│   │   └── index.rst<br>│   ├── HISTORY.rst<br>│   ├── LICENSE<br>│   ├── makefile<br>│   ├── MANIFEST.in<br>│   ├── README.rst<br>│   ├── requirements.txt<br>│   ├── sample<br>|   |   ├── app.py<br>│   │   └── helper.py<br>|   ├── setup.cfg<br>|   ├── setup.py<br>│   └── tests<br><img data-src="https://s2.loli.net/2023/12/04/zSZesqwjb72IaUD.png" alt="image-20231204170021714"></p></blockquote></li></ol><ol><li><img data-src="https://s2.loli.net/2023/12/04/B5I7NEVSCRilscz.png" alt="image-20231204171740258"></li></ol><p>主要是使用poetry等工具打包的时候需要注意一下,因为<code>pyproject.toml</code>字段不完全相同.</p><h3 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h3><ol><li>ImportError: attempted relative import with no known parent package</li></ol><p>包中的模块使用相对导入时不能直接运行该模块,一般是其他包或顶级模块进行调用</p><h2 id="工具链"><a href="#工具链" class="headerlink" title="工具链"></a>工具链</h2><h3 id="版本管理工具"><a href="#版本管理工具" class="headerlink" title="版本管理工具"></a>版本管理工具</h3><p>Anaconda可以同时解决Python版本和包管理的问题,但如果只是想开发个包,没有必要使用conda,在linux上可以考虑pyenv+poetry,windows上有对应的pyenv-windows+poetry.</p><p>pyenv允许您轻松地在多个版本的Python之间切换。它简单、不引人注目，并且遵循了UNIX传统的单用途工具，可以很好地完成一件事。</p><p><a href="https://github.com/pyenv/pyenv">pyenv/pyenv: Simple Python version management (github.com)</a></p><h3 id="包管理工具"><a href="#包管理工具" class="headerlink" title="包管理工具"></a>包管理工具</h3><p>目前开发Python包我推荐Poetry或者PDM,如果是搞数据计算直接Anaconda.</p><h4 id="Poetry"><a href="#Poetry" class="headerlink" title="Poetry"></a>Poetry</h4><p><a href="https://python-poetry.org/docs/">Introduction | Documentation | Poetry - Python dependency management and packaging made easy (python-poetry.org)</a></p><p>某种程度上告别<code>setup.py</code>,除了一般的虚拟环境和包管理之外,打包和发布到PYPI等都支持,也是现在比较火的工具.</p><p>虚拟环境管理类似conda,会在某个目录下放所有的虚拟环境</p><p><img data-src="https://s2.loli.net/2023/12/04/zg1ChV4DXyoQeEt.png" alt="image-20231204163324338"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poetry init</span><br><span class="line">poetry install </span><br><span class="line">poetry shell</span><br></pre></td></tr></table></figure><p>通过初始化一个新的Poetry项目，这将以交互方式生成一个文件pyproject.toml。该文件将具有所有包依赖项。这与requirements.txt文件类似。</p><p>当参数 <code>virtualenvs.create</code> 为 <code>true</code> 时，执行 <code>poetry install</code> 或 <code>poetry add</code> 时会检测当前项目是否有虚拟环境，没有就自动创建，默认为 <code>true</code>。</p><p>当参数 <code>virtualenvs.in-project</code> 为 <code>true</code> 时，虚拟环境的依赖将会放置于项目的文件夹内，而不是 poetry 默认的 <code>&#123;cache-dir&#125;/virtualenvs</code>，默认为 <code>false</code>。</p><p>我的配置如下:</p><p><img data-src="https://s2.loli.net/2023/12/04/Z1qGakLnrBwdejx.png" alt="image-20231204164441421"></p><blockquote><p>当Poetry完成安装后，它会将所有包及其下载的确切版本写入Poetry.lock文件，从而将项目锁定到这些特定版本。该锁定文件也应包含在您的项目repo中，以便在项目中工作的每个人都被锁定到相同版本的依赖项。</p></blockquote><p><img data-src="https://s2.loli.net/2023/12/04/9rkoJysmI8dFt5b.png" alt="image-20231204163627134"></p><h4 id="PDM"><a href="#PDM" class="headerlink" title="PDM"></a>PDM</h4><p><a href="https://github.com/pdm-project/pdm">pdm-project/pdm: A modern Python package and dependency manager supporting the latest PEP standards (github.com)</a></p><p>支持最新PEP标准的现代Python包和依赖项管理器. Poetry的<code>pyproject.toml</code>与PEP标准不完全符合.</p><p>PDM可以管理项目和集中位置的虚拟环境（venv），类似于Pipenv。它从标准化的pyproject.toml文件中读取项目元数据，并支持锁定文件。用户可以通过插件添加额外的功能，这些功能可以通过将其作为分发版上传来共享。与Poetry和Hatch不同，PDM不局限于特定的构建后端；用户可以自由选择他们喜欢的任何构建后端。</p><h3 id="Formatter"><a href="#Formatter" class="headerlink" title="Formatter"></a>Formatter</h3><p>代码格式化工具,一般用black就够了.</p><h4 id="Black"><a href="#Black" class="headerlink" title="Black"></a>Black</h4><p>Black是不折不扣的Python代码格式化程序。通过使用它，您同意放弃对手工格式化细节的控制。作为回报，Black为您提供了速度、决定论和自由，使您免受pycode风格对格式的唠叨。你会为更重要的事情节省时间和精力。无论您正在阅读的项目是什么，变黑的代码看起来都是一样的。一段时间后，格式将变得透明，您可以转而关注内容。Black通过产生尽可能小的差异来加快代码审查。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install black</span><br><span class="line">black &#123;source_file_or_directory&#125;</span><br></pre></td></tr></table></figure><h4 id="yapf"><a href="#yapf" class="headerlink" title="yapf"></a>yapf</h4><p>YAPF是一个基于clang格式的Python格式化程序（由Daniel Jasper开发）。本质上，该算法采用代码并计算符合配置样式的最佳格式。它省去了维护代码的许多繁琐工作。最终目标是YAPF生成的代码与程序员在遵循样式指南的情况下编写的代码一样好。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install yapf</span><br></pre></td></tr></table></figure><h4 id="autopep8"><a href="#autopep8" class="headerlink" title="autopep8"></a><strong>autopep8</strong></h4><p>autoep8自动格式化Python代码，以符合PEP8样式指南。它使用pycodestyle实用程序来确定需要格式化代码的哪些部分。autoep8能够修复pycodestyle可能报告的大多数格式问题。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade autopep8</span><br><span class="line">autopep8 --in-place --aggressive --aggressive &lt;filename&gt;</span><br></pre></td></tr></table></figure><h3 id="Linter"><a href="#Linter" class="headerlink" title="Linter"></a>Linter</h3><p>一般用pylint足矣,喜欢尝鲜的可以用用Ruff.</p><h4 id="PyLint"><a href="#PyLint" class="headerlink" title="PyLint"></a>PyLint</h4><p>Pylint是Python 2或3的静态代码分析器。最新版本支持Python 3.8.0及以上版本。Pylint在不实际运行代码的情况下分析代码。它检查错误，强制执行编码标准，寻找代码气味，并可以就如何重构代码提出建议。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pylint</span><br></pre></td></tr></table></figure><h4 id="flake8"><a href="#flake8" class="headerlink" title="flake8"></a>flake8</h4><p>Flake8是这些工具的包装：PyFlakespycode样式Ned Batchelder的McCabe脚本Flake8通过启动单个Flake8命令来运行所有工具。它在每个文件的合并输出中显示警告。<a href="https://github.com/PyCQA/flake8">PyCQA/flake8: flake8 is a python tool that glues together pycodestyle, pyflakes, mccabe, and third-party plugins to check the style and quality of some python code. (github.com)</a></p><h4 id="Ruff"><a href="#Ruff" class="headerlink" title="Ruff"></a>Ruff</h4><p>比较新的工具<a href="https://github.com/astral-sh/ruff">astral-sh/ruff: An extremely fast Python linter and code formatter, written in Rust. (github.com)</a>,不只是语法提示器,也可以用于格式化.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install ruff</span><br><span class="line"></span><br><span class="line">ruff path/to/code/to/check.py</span><br><span class="line">ruff path/to/code/</span><br><span class="line">ruff path/to/code/*.py</span><br></pre></td></tr></table></figure><h3 id="类型检查工具"><a href="#类型检查工具" class="headerlink" title="类型检查工具"></a>类型检查工具</h3><p>在Python中使用typing的检查工具,此外与Pydantic<a href="https://docs.pydantic.dev/latest/">Welcome to Pydantic - Pydantic</a>搭配使用效果更佳</p><blockquote><p>Pydantic是Python中使用最广泛的数据验证库。Pydantic快速且可扩展，可以很好地处理您的linters/IDE/brain。</p><p>定义数据应该如何使用纯规范的Python 3.7+；用Pydantic验证它。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delivery</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    timestamp: datetime</span><br><span class="line">    dimensions: <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">m = Delivery(timestamp=<span class="string">&#x27;2020-01-02T03:04:05Z&#x27;</span>, dimensions=[<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">repr</span>(m.timestamp))</span><br><span class="line"><span class="comment">#&gt; datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))</span></span><br><span class="line"><span class="built_in">print</span>(m.dimensions)</span><br><span class="line"><span class="comment">#&gt; (10, 20)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Mypy"><a href="#Mypy" class="headerlink" title="Mypy"></a>Mypy</h4><p><a href="https://github.com/python/mypy">python/mypy: Optional static typing for Python (github.com)</a></p><p>Mypy是Python的静态类型检查器。类型检查器有助于确保您在代码中正确使用变量和函数。</p><p>使用mypy，将类型提示（PEP484）添加到Python程序中，当您错误地使用这些类型时，mypy会发出警告。Python是一种动态语言，所以通常只有当你试图运行它时，你才会在代码中看到错误。Mypy是一个静态检查器，所以它甚至不用运行就可以发现程序中的错误！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install -U mypy</span><br><span class="line">mypy PROGRAM</span><br></pre></td></tr></table></figure><h4 id="Pyright"><a href="#Pyright" class="headerlink" title="Pyright"></a>Pyright</h4><p><a href="https://github.com/microsoft/pyright">microsoft/pyright: Static Type Checker for Python (github.com)</a></p><p>Pyright是一个功能齐全、基于标准的Python静态类型检查器。它是为高性能而设计的，可以与大型Python源代码库一起使用。</p><h3 id="Git-pre-commit-hook"><a href="#Git-pre-commit-hook" class="headerlink" title="Git pre-commit hook"></a>Git pre-commit hook</h3><p>在<code>git commit</code>之前设置hook进行代码检查</p><h3 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h3><p>测试工具</p><h4 id="Pytest"><a href="#Pytest" class="headerlink" title="Pytest"></a>Pytest</h4><p>pytest框架使编写小型可读测试变得容易，并且可以扩展以支持应用程序和库的复杂功能测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U pytest</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://blog.csdn.net/Dontla/article/details/131538693">python项目结构示例（python代码结构、python目录结构）与python部署结构、python部署目录、flask项目结构、flask目录_python项目结构目录结构-CSDN博客</a></li><li><a href="https://blog.csdn.net/captain5339/article/details/128017400">各类Python项目的项目结构及代码组织最佳实践<em>python项目结构__</em>弯弓__的博客-CSDN博客</a></li><li><a href="https://www.cnblogs.com/cuiyubo/p/11756771.html">Python最佳工程实践，建立一个完美的工程项目 - cuiyubo - 博客园 (cnblogs.com)</a></li><li><a href="https://www.hatica.io/blog/pre-commit-git-hooks/">8 Pre-commit Git Hooks You Must Know for Improved Productivity - Hatica</a></li><li><a href="https://pythonguidecn.readthedocs.io/zh/latest/writing/structure.html">结构化您的工程 — The Hitchhiker’s Guide to Python (pythonguidecn.readthedocs.io)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在工程化上,Python相比于Java,C#这类语言还是差了不少,不过整个生态还是不错的.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>设计模式与重构</title>
    <link href="https://www.sekyoro.top/2023/12/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%8E%E9%87%8D%E6%9E%84/"/>
    <id>https://www.sekyoro.top/2023/12/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%8E%E9%87%8D%E6%9E%84/</id>
    <published>2023-12-03T05:08:27.000Z</published>
    <updated>2023-12-23T14:04:25.837Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>软件开发相关知识,主要是一些设计思想.<br><span id="more"></span></p><h2 id="基本设计思想"><a href="#基本设计思想" class="headerlink" title="基本设计思想"></a>基本设计思想</h2><h3 id="开闭原则"><a href="#开闭原则" class="headerlink" title="开闭原则"></a>开闭原则</h3><p>由Bertrand Meyer提出的开闭原则（Open Closed Principle）是指，软件应该对扩展开放，而对修改关闭。这里的意思是在增加新功能的时候，能不改代码就尽量不要改，如果只增加代码就完成了新功能，那是最好的。</p><h3 id="里氏替换原则"><a href="#里氏替换原则" class="headerlink" title="里氏替换原则"></a>里氏替换原则</h3><p>里氏替换原则是Barbara Liskov提出的，这是一种面向对象的设计原则，即如果我们调用一个父类的方法可以成功，那么替换成子类调用也应该完全可以运行。</p><h2 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h2><h3 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a>创建型模式</h3><p>这类模式提供创建对象的机制， 能够提升已有代码的灵活性和可复用性。</p><h4 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h4><blockquote><p>定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method使一个类的实例化延迟到其子类。</p></blockquote><p>工厂方法即Factory Method，是一种对象创建型模式。</p><h4 id="抽象工厂"><a href="#抽象工厂" class="headerlink" title="抽象工厂"></a>抽象工厂</h4><blockquote><p>提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。</p></blockquote><p>抽象工厂模式（Abstract Factory）是一个比较复杂的创建型模式</p><p>抽象工厂模式和工厂方法不太一样，它要解决的问题比较复杂，不但工厂是抽象的，产品是抽象的，而且有多个产品需要创建，因此，这个抽象工厂会对应到多个实际工厂，每个实际工厂负责创建多个实际产品</p><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><blockquote><p>将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。</p></blockquote><p>生成器模式（Builder）是使用多个“小型”工厂来最终创建出一个完整对象。</p><p>当我们使用Builder的时候，一般来说，是因为创建这个对象的步骤比较多，每个步骤都需要一个零部件，最终组合成一个完整的对象。</p><h4 id="原型"><a href="#原型" class="headerlink" title="原型"></a>原型</h4><blockquote><p>用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。</p></blockquote><p>原型模式，即Prototype，是指创建新对象的时候，根据现有的一个原型来创建。</p><h4 id="单例"><a href="#单例" class="headerlink" title="单例"></a>单例</h4><blockquote><p>保证一个类仅有一个实例，并提供一个访问它的全局访问点。</p></blockquote><p>单例模式（Singleton）的目的是为了保证在一个进程中，某个类有且仅有一个实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 静态字段引用唯一实例:</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// private构造方法保证外部无法实例化:</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结构性模式"><a href="#结构性模式" class="headerlink" title="结构性模式"></a>结构性模式</h3><p>这类模式介绍如何将对象和类组装成较大的结构， 并同时保持结构的灵活和高效。</p><h4 id="适配器"><a href="#适配器" class="headerlink" title="适配器"></a>适配器</h4><blockquote><p>将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。</p></blockquote><p>适配器模式是Adapter，也称Wrapper</p><h4 id="桥接"><a href="#桥接" class="headerlink" title="桥接"></a>桥接</h4><blockquote><p>将抽象部分与它的实现部分分离，使它们都可以独立地变化。</p></blockquote><h4 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h4><blockquote><p>将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。</p></blockquote><p>组合模式（Composite）经常用于树形结构，为了简化代码，使用Composite可以把一个叶子节点与一个父节点统一起来处理。</p><p>在XML或HTML中，从根节点开始，每个节点都可能包含任意个其他节点，这些层层嵌套的节点就构成了一颗树。</p><h4 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h4><blockquote><p>动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。</p></blockquote><p>装饰器（Decorator）模式，是一种在运行期动态给某个对象的实例增加功能的方法</p><h4 id="外观"><a href="#外观" class="headerlink" title="外观"></a>外观</h4><blockquote><p>为子系统中的一组接口提供一个一致的界面。Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。</p></blockquote><p>外观模式，即Facade，是一个比较简单的模式。它的基本思想如下：</p><p>如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。所以Facade就相当于搞了一个中介。</p><h4 id="享元"><a href="#享元" class="headerlink" title="享元"></a>享元</h4><blockquote><p>运用共享技术有效地支持大量细粒度的对象。</p></blockquote><p>享元（Flyweight）的核心思想很简单：如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。</p><h4 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h4><blockquote><p>为其他对象提供一种代理以控制对这个对象的访问。</p></blockquote><p>代理模式，即Proxy，它和Adapter模式很类似</p><h3 id="行为模式"><a href="#行为模式" class="headerlink" title="行为模式"></a>行为模式</h3><p>这类模式负责对象间的高效沟通和职责委派。</p><h4 id="责任链"><a href="#责任链" class="headerlink" title="责任链"></a>责任链</h4><blockquote><p>使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。</p></blockquote><p>责任链模式（Chain of Responsibility）是一种处理请求的模式，它让多个处理器都有机会处理该请求，直到其中某个处理成功为止</p><h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><p>命令模式（Command）是指，把请求封装成一个命令，然后执行该命令。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TextEditor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> StringBuilder buffer = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">copy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">paste</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String text = getFromClipBoard();</span><br><span class="line">        add(text);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        buffer.append(s);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (buffer.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            buffer.deleteCharAt(buffer.length() - <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> buffer.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyCommand</span> <span class="keyword">implements</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 持有执行者对象:</span></span><br><span class="line">    <span class="keyword">private</span> TextEditor receiver;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CopyCommand</span><span class="params">(TextEditor receiver)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.receiver = receiver;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.copy();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PasteCommand</span> <span class="keyword">implements</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> TextEditor receiver;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PasteCommand</span><span class="params">(TextEditor receiver)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.receiver = receiver;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        receiver.paste();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h4><p>给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。</p><h4 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h4><p>提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。迭代器模式（Iterator）实际上在Java的集合类中已经广泛使用了。我们以<code>List</code>为例，要遍历<code>ArrayList</code>，即使我们知道它的内部存储了一个<code>Object[]</code>数组，也不应该直接使用数组索引去遍历，因为这样需要了解集合内部的存储结构</p><h4 id="中介模式"><a href="#中介模式" class="headerlink" title="中介模式"></a>中介模式</h4><blockquote><p>用一个中介对象来封装一系列的对象交互。中介者使各个对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。</p></blockquote><p>中介模式（Mediator）又称调停者模式，它的目的是把多方会谈变成双方会谈，从而实现多方的松耦合。</p><p>Mediator模式经常用在有众多交互组件的UI上。为了简化UI程序，MVC模式以及MVVM模式都可以看作是Mediator模式的扩展。</p><h4 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h4><blockquote><p>在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。</p></blockquote><p>备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。</p><p>其实我们使用的几乎所有软件都用到了备忘录模式。最简单的备忘录模式就是保存到文件，打开文件。对于文本编辑器来说，保存就是把<code>TextEditor</code>类的字符串存储到文件，打开就是恢复<code>TextEditor</code>类的状态。对于图像编辑器来说，原理是一样的，只是保存和恢复的数据格式比较复杂而已。Java的序列化也可以看作是备忘录模式。</p><h4 id="观察者"><a href="#观察者" class="headerlink" title="观察者"></a>观察者</h4><blockquote><p>定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。</p></blockquote><p>观察者模式（Observer）又称发布-订阅模式（Publish-Subscribe：Pub/Sub）。它是一种通知机制，让发送通知的一方（被观察方）和接收通知的一方（观察者）能彼此分离，互不影响。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Store</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;ProductObserver&gt; observers = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Product&gt; products = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册观察者:</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addObserver</span><span class="params">(ProductObserver observer)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.observers.add(observer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取消注册:</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeObserver</span><span class="params">(ProductObserver observer)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.observers.remove(observer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addNewProduct</span><span class="params">(String name, <span class="keyword">double</span> price)</span> </span>&#123;</span><br><span class="line">        Product p = <span class="keyword">new</span> Product(name, price);</span><br><span class="line">        products.put(p.getName(), p);</span><br><span class="line">        <span class="comment">// 通知观察者:</span></span><br><span class="line">        observers.forEach(o -&gt; o.onPublished(p));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProductPrice</span><span class="params">(String name, <span class="keyword">double</span> price)</span> </span>&#123;</span><br><span class="line">        Product p = products.get(name);</span><br><span class="line">        p.setPrice(price);</span><br><span class="line">        <span class="comment">// 通知观察者:</span></span><br><span class="line">        observers.forEach(o -&gt; o.onPriceChanged(p));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h4><blockquote><p>允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它的类。</p></blockquote><p>状态模式（State）经常用在带有状态的对象中。</p><h4 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h4><blockquote><p>定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。</p></blockquote><p>策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法</p><h4 id="模板方法"><a href="#模板方法" class="headerlink" title="模板方法"></a>模板方法</h4><blockquote><p>定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。</p></blockquote><p>模板方法（Template Method）是一个比较简单的模式。它的主要思想是，定义一个操作的一系列步骤，对于某些暂时确定不下来的步骤，就留给子类去实现好了，这样不同的子类就可以定义出不同的步骤。</p><h4 id="访问者"><a href="#访问者" class="headerlink" title="访问者"></a>访问者</h4><blockquote><p>表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。</p></blockquote><p>访问者模式（Visitor）是一种操作一组对象的操作，它的目的是不改变对象的定义，但允许新增不同的访问者，来定义新的操作。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1264742167474528">设计模式 - 廖雪峰的官方网站 (liaoxuefeng.com)</a></li><li><a href="https://refactoringguru.cn/design-patterns/catalog">设计模式目录：22种设计模式 (refactoringguru.cn)</a></li><li><a href="https://www.runoob.com/design-pattern/design-pattern-intro.html">设计模式简介 | 菜鸟教程 (runoob.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;软件开发相关知识,主要是一些设计思想.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>图像特征协同感知融合算法</title>
    <link href="https://www.sekyoro.top/2023/11/30/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E5%8D%8F%E5%90%8C%E6%84%9F%E7%9F%A5%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95/"/>
    <id>https://www.sekyoro.top/2023/11/30/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E5%8D%8F%E5%90%8C%E6%84%9F%E7%9F%A5%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95/</id>
    <published>2023-11-30T02:58:03.000Z</published>
    <updated>2024-01-24T14:08:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>除了3D<strong>目标检测</strong>算法外,自动驾驶还需要将获取到的图像数据或者处理后的特征进行<strong>通信</strong>和<strong>融合</strong>,这里介绍相关论文.</p><span id="more"></span><p>重要的几个仓库<a href="https://github.com/coperception/coperception">coperception/coperception: An SDK for multi-agent collaborative perception. (github.com)</a>,<a href="https://github.com/DerrickXuNu/OpenCOOD和[ucla-mobility/V2V4Real">https://github.com/DerrickXuNu/OpenCOOD和[ucla-mobility/V2V4Real</a>: <a href="https://github.com/ucla-mobility/v2v4real">CVPR2023 Highlight] The official codebase for paper “V2V4Real: A large-scale real-world dataset for Vehicle-to-Vehicle Cooperative Perception” (github.com)</a></p><p>此外<a href="https://github.com/Little-Podi/Collaborative_Perception">Little-Podi/Collaborative_Perception: This repository is a paper digest of recent advances in collaborative / cooperative / multi-agent perception for V2I / V2V / V2X autonomous driving scenario. (github.com)</a>会汇总相关领域最新的论文.</p><h2 id="OPV2V-An-Open-Benchmark-Dataset-and-Fusion-Pipeline-for-Perception-with-Vehicle-to-Vehicle-Communication"><a href="#OPV2V-An-Open-Benchmark-Dataset-and-Fusion-Pipeline-for-Perception-with-Vehicle-to-Vehicle-Communication" class="headerlink" title="OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication"></a>OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication</h2><h3 id="abs"><a href="#abs" class="headerlink" title="abs"></a>abs</h3><p>利用车对车通信提高自动驾驶技术的感知性能近年来引起了广泛关注;然而，由于缺乏合适的开放数据集来对算法进行基准测试，因此很难开发和评估协同感知技术。</p><h3 id="融合方法介绍"><a href="#融合方法介绍" class="headerlink" title="融合方法介绍"></a>融合方法介绍</h3><p>论文中融合算法介绍了多种,这里按时间线写一下.</p><p>早期融合有最早的Cooper.</p><p>主要介绍中期融合</p><h4 id="F-cooper"><a href="#F-cooper" class="headerlink" title="F-cooper"></a>F-cooper</h4><p>2019论文中提出了VFF和SFF.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialFusion</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialFusion, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">regroup</span>(<span class="params">self, x, record_len</span>):</span></span><br><span class="line">        cum_sum_len = torch.cumsum(record_len, dim=<span class="number">0</span>)</span><br><span class="line">        split_x = torch.tensor_split(x, cum_sum_len[:-<span class="number">1</span>].cpu())</span><br><span class="line">        <span class="keyword">return</span> split_x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, record_len</span>):</span></span><br><span class="line">        <span class="comment"># x: B, C, H, W, split x:[(B1, C, W, H), (B2, C, W, H)]</span></span><br><span class="line">        split_x = self.regroup(x, record_len)</span><br><span class="line">        out = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> xx <span class="keyword">in</span> split_x:</span><br><span class="line">            xx = torch.<span class="built_in">max</span>(xx, dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">            out.append(xx)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(out, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>最后利用融合后的特征传给cls_head和reg_head</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">psm = self.cls_head(fused_feature)</span><br><span class="line">rm = self.reg_head(fused_feature)</span><br><span class="line">output_dict = &#123;<span class="string">&#x27;psm&#x27;</span>: psm,</span><br><span class="line">               <span class="string">&#x27;rm&#x27;</span>: rm&#125;</span><br></pre></td></tr></table></figure><h3 id="V2VNet-Vehicle-to-Vehicle-Communication-for-Joint-Perception-and-Prediction-2020"><a href="#V2VNet-Vehicle-to-Vehicle-Communication-for-Joint-Perception-and-Prediction-2020" class="headerlink" title="V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction 2020"></a>V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction 2020</h3><h5 id="Abs"><a href="#Abs" class="headerlink" title="Abs"></a>Abs</h5><p>探讨了使用<strong>车对车（V2V）通信来改善自动驾驶汽车的感知和运动预测性能</strong>。通过智能地聚合从附近多辆车接收到的信息，我们可以从不同的视角观察同一场景。这使我们能够<strong>穿透遮挡物并远距离检测参与者，其中观察结果非常稀疏或不存在</strong>。</p><p>SDV 需要对场景进行 3D 推理，识别其他智能体，并预测他们的未来可能如何发展。这些任务通常称为感知和运动预测。强大的感知和运动预测对于 SDV 规划和操纵交通以安全地从一个点到另一个点都至关重要.</p><p>尽管取得了这些进展，但挑战依然存在。例如，<strong>被严重遮挡或距离较远的物体会导致观测稀疏，并对现代计算机视觉系统构成挑战</strong>。</p><p>在本文中，考虑了车对车 （V2V） 通信设置，其中每辆车都可以向附近的车辆（半径 70m 以内）广播和接收信息。请注意，基于现有的通信协议，这个广播范围是现实的。为了在满足现有硬件传输带宽能力的同时，实现具有强大感知和运动预测性能的最佳折衷方案，我们应该发送P&amp;P神经网络的压缩中间表示。因此，我们推导出了一种名为V2VNet的新颖的P&amp;P模型，该模型<strong>利用空间感知图神经网络（GNN）来聚合从附近所有SDV接收到的信息</strong>，使我们能够智能地组合来自不同时间点和场景中视点的信息。</p><p><img data-src="https://s2.loli.net/2024/01/07/MXuJrkjUeywFPf1.png" alt="image-20240107145123567"></p><p><img data-src="https://s2.loli.net/2024/01/07/JMEKzxTutGrfW8h.png" alt="image-20240107145440332"></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>较早的一篇使用全面神经网络探讨V2V协同的目标感知与检测,贡献了V2V-sim仿真数据集.</p><h4 id="DiscoNet"><a href="#DiscoNet" class="headerlink" title="DiscoNet"></a>DiscoNet</h4><p><img data-src="https://s2.loli.net/2024/01/10/kU47aJnKuABtjS3.png" alt="image-20240110151834154"></p><p>涉及到了图和蒸馏的方法,我了解不多.</p><p><img data-src="https://s2.loli.net/2024/01/10/CnGtDVSgHJWEjLd.png" alt="image-20240110151903360"></p><h4 id="CoBEVT-2022"><a href="#CoBEVT-2022" class="headerlink" title="CoBEVT 2022"></a>CoBEVT 2022</h4><p><strong>Abstract</strong></p><p>在本文中，提出了CoBEVT，这是第一个可以<strong>协同生成BEV地图预测的通用多智能体多相机感知框架</strong>。</p><p>为了在底层 Transformer 架构中有效地融合来自多视图和多智能体数据的相机特征，我们设计了一个融合轴向注意力模块 （FAX），该模块可以捕获跨视图和智能体的稀疏局部和全局空间交互.</p><p>将多摄像头视图投射到整体纯电动汽车空间中，在空间和时间上保持道路元素的位置和比例方面具有明显的优势，这对于各种自动驾驶任务（包括场景理解和规划）至关重要</p><p>地图视图（或 BEV）语义分割是一项基本任务,旨在根据单个或多个校准的摄像头输入预测路段。在基于摄像头的精确BEV语义分割方面已经做出了重大努力。最流行的技术之一是利用<strong>深度信息来推断相机视图和规范地图之间的对应关系</strong>。另一个系列使用<strong>基于注意力的模型直接学习摄像头到BEV的空间转换</strong>，无论是隐式还是显式</p><p>尽管取得了令人鼓舞的结果，<strong>但基于视觉的感知系统具有固有的局限性——众所周知，相机传感器对物体遮挡和景深有限很敏感，这可能导致在严重遮挡或远离相机镜头的区域性能较差</strong></p><p><img data-src="https://s2.loli.net/2024/01/02/I1xRkviLBmbnqfQ.png" alt="image-20240102164321954">`</p><h4 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h4><p>最近，V2VNet提出将从3D骨干中提取的中间特征（即中间融合）循环，然后利用空间感知图神经网络进行多智能体特征聚合。遵循类似的传输范式，<strong>OPV2V 采用简单的智能体单头注意力来融合所有特征</strong>。<strong>F-Cooper使用简单的 maxout 操作来融合特征</strong>。</p><p><strong>DiscoNet通过约束中间特征图来匹配早期融合教师模型中的对应关系来探索知识蒸馏。</strong></p><p>与之前的多智能体算法相比,我 CoBEVT 率先<strong>采用稀疏transformer来高效</strong>、详尽地探索车辆之间的相关性。</p><p>此外，以往的方法主要侧重于与激光雷达的协同感知，而我们的目标是提出一种低成本的<strong>基于摄像头</strong>的、<strong>没有激光雷达设备的协同感知解决方案</strong>。</p><blockquote><p>Transformer 最初是为自然语言处理而提出的 。ViT  首次证明，一个纯粹的 Transformer 只是将图像块视为视觉词，通过大规模预训练就足以完成视觉任务。Swin Transformer通过限制局部（移位）窗口中的注意力场，进一步提高了纯 Transformer 的通用性和灵活性。对于高维数据，Video Swin Transformer 将 Swin 方法扩展到移动的 3D 时空窗口，从而实现高性能和低复杂性。</p><p>最近的工作主要集中在<strong>改进注意力模型的结构</strong>上，包括稀疏注意力，扩大的感受野，金字塔设计，有效的替代方案]等。</p></blockquote><h4 id="Fused-Axial-Attention"><a href="#Fused-Axial-Attention" class="headerlink" title="Fused Axial Attention"></a>Fused Axial Attention</h4><p><strong>融合来自多个智能体的 BEV 特征需要跨所有智能体的空间位置进行局部和全局交互</strong>。一方面,相邻的自动驾驶汽车通常对同一物体具有不同的遮挡级别;因此,更关心细节的局部注意力可以帮助在该对象上构建像素到像素的对应关系。</p><p><strong>ego应汇总附近自动驾驶汽车每个位置的所有BEV特征</strong>，以获得可靠的估计。另一方面，<strong>长期的全局情境感知也有助于理解道路拓扑语义或交通状态</strong>——车辆前方的道路拓扑和交通密度通常与后方的道路拓扑和交通密度高度相关。这种全局推理也有利于多相机视图的理解。</p><p>同一辆车被分成多个视图,global attention能够将它们连接起来以进行语义推理</p><p><img data-src="https://s2.loli.net/2024/01/03/w5AtSc4o2gsTzB9.png" alt="image-20240103202226517"></p><p>提出了一种称为融合轴向注意力的新颖 3D 注意力机制,作为 SinBEVT 和 FuseBEVT 的核心组件,可以有效地聚合本地和全局范围内跨代理或相机视图的特征。</p><p><img data-src="https://s2.loli.net/2024/01/05/Sel1ad8xyFHqLfJ.png" alt="image-20240105103533757"></p><p><strong>设 X∈ R^N×H×W×C^ 是来自 N 智能体的空间维度为 H × W 的堆叠 BEV 特征</strong></p><p>在局部特征上<strong>,将特征图划分为 3D 非重叠窗口</strong>,每个窗口的大小为 N × P × P,然后将形状为(H/P× W/P,N × P^2^,C) 的分割张量 输入到自注意力模型中</p><p>在全局特征中,使用统一的 3D 网格 N ×G×G 将特征 X 划分为形状 (N × G^2^,H/G×W /G,C)</p><p>将注意力集中在该张量的第一个轴上,该张量表示关注稀疏采样的标记</p><p><img data-src="https://s2.loli.net/2024/01/03/NVMak8mhlgxeKwo.png" alt="image-20240103203511174"></p><p>将这种 3D 局部和全局注意力与 Transformer 的典型设计相结合 ，包括层归一化 （LN）、MLP  和跳跃连接，形成了提出的 FAX 注意力块</p><h4 id="SinBEVT-for-Single-agent-BEV-Feature-Computation"><a href="#SinBEVT-for-Single-agent-BEV-Feature-Computation" class="headerlink" title="SinBEVT for Single-agent BEV Feature Computation"></a>SinBEVT for Single-agent BEV Feature Computation</h4><p>CVT 使用低分辨率的 BEV 查询，该查询完全交叉关注图像特征，这会导致小物体的性能下降，尽管效率很高。因此，<strong>CoBEVT 学习高分辨率的 BEV 嵌入，然后使用分层结构来优化分辨率降低的 BEV 特征</strong>。为了在高分辨率下有效地查询来自相机编码器的特征，FAX-SA模块进一步扩展为构建FAX交叉关注（FAX-CA）模块，其中查询向量使用BEV嵌入获得，而键/值向量由多视图相机特征投影。</p><h5 id="FuseBEVT-for-Multi-agent-BEV-Feature-Fusion"><a href="#FuseBEVT-for-Multi-agent-BEV-Feature-Fusion" class="headerlink" title="FuseBEVT for Multi-agent BEV Feature Fusion"></a>FuseBEVT for Multi-agent BEV Feature Fusion</h5><p>一旦接收到包含中间BEV表示的广播消息和发送者的姿态,自我车辆就会应用可微分的空间变换算子Γξ,将接收到的特征几何扭曲到ego的坐标系上:H~i~ = Γ~ξ~ (F~i~)∈ R^H×W×C^</p><p>3D FAX-SA 可以处理从多个代理抽取的同一估计区域（红框），以得出最终的聚合表示。此外，稀疏采样token（蓝框）可以全局交互，以获得对地图语义（如道路、交通等）的上下文理解。</p><h5 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h5><p>使用swim transfomer类似架构进行多层级的特征融合.设计了agent_size和window_size.</p><h3 id="Robust-Collaborative-3D-Object-Detection-in-Presence-of-Pose-Errors-CoAlign-2022"><a href="#Robust-Collaborative-3D-Object-Detection-in-Presence-of-Pose-Errors-CoAlign-2022" class="headerlink" title="Robust Collaborative 3D Object Detection in Presence of Pose Errors (CoAlign) 2022"></a>Robust Collaborative 3D Object Detection in Presence of Pose Errors (CoAlign) 2022</h3><h5 id="Abs-1"><a href="#Abs-1" class="headerlink" title="Abs"></a>Abs</h5><p>协作式 3D 目标检测利用多个智能体之间的信息交换，在存在传感器损伤（如遮挡）的情况下提高目标检测的准确性,然而，在实践中，由于定位不完善导致的姿态估计误差会导致空间信息错位，并显著降低协作性能。</p><p>为了减轻姿势错误的不利影响，我们提出了CoAlign，这是一种新颖的混合协作框架，对<strong>未知的姿势错误具有鲁棒性</strong>。所提出的解决方案依赖于一种<strong>新颖的智能体-对象姿态图建模来增强协作智能体之间的姿态一致性</strong>。此外，<strong>采用多尺度数据融合策略，在多个空间分辨率下聚合中间特征</strong>。</p><p>尽管大规模数据集和强大模型的发展速度很快，<strong>但单个智能体的 3D 对象检测仍存在固有的局限性，例如遮挡和远处的物体。通过利用智能体之间的通信，例如驾驶场景中的车联网（V2X），多个智能体可以相互共享互补的感知信息，从而促进更全面的接受领域。</strong></p><p>为了实现这种协作式3D检测，最近的工作<strong>贡献了高质量的数据集</strong>和<strong>有效的协作方法</strong>。但在这个新兴领域仍然存在许多挑战，例如通<strong>信带宽限制</strong>、<strong>延迟</strong>和<strong>对抗性攻击</strong>。这项工作的重点是减轻姿势误差的负面影响。</p><p>由于我们的<strong>智能体-对象姿态图</strong>在优化过程中<strong>没有使用任何训练参数</strong>，因此该方法具有<strong>很强的泛化能力，可以适应任意级别的姿态误差</strong>。为了有效缓解姿态误差的影响，我们进一步考虑了一种<strong>多尺度中间融合策略，该策略在多个空间尺度上全面聚合协作信息。</strong></p><p>我们在仿真和真实数据集上对基于LiDAR的3D目标检测任务进行了广泛的实验，包括<strong>OPV2V 、V2X-Sim 2.0和DAIR-V2X</strong>.所提出的CoAlign在存在姿态误差的协同3D目标检测任务中实现了<strong>至少12%的性能提升</strong>。</p><p>考虑场景中的 N 个代理。每个智能体都具有感知、沟通和检测的能力。目标是通过分布式协作来达到每个智能体更好的 3D 检测能力。</p><p>在以前的文献中，有三种类型的协作：早期协作，传输原始观测数据，中间协作，，传输中间特征，后期协作，传输检测输出。</p><p>设 O~i~ 和 B~i~ 分别是第 i 个智能体的感知观察和检测输出。对于第 i 个代理，基于中间协作的标准 3D 对象检测的工作原理如下</p><script type="math/tex; mode=display">\begin{aligned}&\mathbf{F}_{i}=f_{\mathrm{encoder}}\left(\mathbf{O}_{i}\right), \\&\mathbf{M}_{j\to i}=f_{\mathbf{transform}}\left(\xi_i,(\mathbf{F}_j,\xi_j)\right), \\&\mathbf{F}_{i}^{\prime}=f_{\mathrm{fusion}}\left(\mathbf{F}_{i},\{\mathbf{M}_{j\to i}\}_{j=1,2,\cdots,N}\right), \\&\mathbf{B}_{i}=f_{\mathrm{decoder}}\left(\mathbf{F}_{i}^{\prime}\right),\end{aligned}</script><blockquote><p>在实践中，定位模块估计的每个 6DoF 姿态 ξi 通常是有噪声的。然后，在步骤2中进行姿态变换后，每个消息Mj→i将具有不同的固有坐标系，导致步骤3中的融合错位和步骤4中的检测输出不好。</p><p>这项工作的目标<strong>是通过在步骤2之前引入额外的姿势校正来最大限度地减少姿势错误的影响</strong></p></blockquote><p>CoAlign<strong>结合了中间和后期协作策略。与中间融合相比，这种混合协作可以利用智能体检测到的边界框作为场景地标，并校正智能体之间的相对姿态</strong>。</p><script type="math/tex; mode=display">\begin{gathered}\mathbf{F}_{i},\mathbf{B}_{i} =\quad f_\text{detection}\left(\mathbf{O}_i\right), \text{(2a)} \\\{\xi_{j\rightarrow i}^{\prime}\}_j =\quad f_{\mathrm{correction}}\left(\{\mathbf{B}_{j},\xi_{j}\}_{j=1,2,\cdots,N}\right), (2\mathbf{b}) \\\mathrm{M}_{j\rightarrow i} =\quad f_{\mathrm{transform}}\left(\mathbf{F}_j,\xi_{j\to i}^{\prime}\right), \text{(2c)} \\\mathbf{F}_{i}^{\prime} =\quad f_{\mathrm{fusion}}\left(\{\mathrm{M}_{j\to i}\}_{j=1,2,\cdots,N}\right), \text{(2d)} \\\mathbf{B}_{i}^{\prime} =\quad f_\text{decoder}\left(\mathbf{F}_i^{\prime}\right), \text{(2c)} \end{gathered}</script><p><img data-src="https://s2.loli.net/2024/01/07/Q8ywAZ2N7IcCBSG.png" alt="image-20240107164141678"></p><p>为了实现单智能体 3D 目标检测器 fdetection(·),可以利用现成的设计，例如 PointPillars ,为第 i 个智能体生成中间特征 F~i~ 和估计边界框 B~i~。请注意，对<strong>于每个边界框，我们还估计其不确定性</strong>。</p><p>由于我们后来依靠这些框来纠正姿势错误，因此混乱的检测可能会导致更糟糕的相对姿势。每个框的估计不确定度可以提供有益的置信度信息，以排除不需要的检测。</p><p>每个框的估计不确定度可以提供有益的置信度信息，以排除不需要的检测。</p><h5 id="Agent-Object-Pose-Graph-Optimization"><a href="#Agent-Object-Pose-Graph-Optimization" class="headerlink" title="Agent-Object Pose Graph Optimization"></a>Agent-Object Pose Graph Optimization</h5><p>单智能体检测后，第 i 个智能体共享三类消息，包括 </p><p>i） 其姿态 ξ~i~ 由其自身定位模块估计;</p><p>ii） 第 i 个agent检测到的边界框;</p><p>iii） 其特征图 F~i~</p><p>为了可靠地融合来自其他智能体的特征图,每个智能体都需要校正相对姿态。</p><h5 id="Multiscale-Feature-Fusion"><a href="#Multiscale-Feature-Fusion" class="headerlink" title="Multiscale Feature Fusion"></a>Multiscale Feature Fusion</h5><p>空间对齐后，每个智能体聚合其他智能体的协作信息，并获得信息量更大的特征。但是，即使在相对姿态校正之后，特征图之间的错位可能仍然存在。更精细尺度的特征可以提供更详细的几何和语义信息，而粗尺度的特征对位姿误差的敏感度较低。多尺度结构可以同时发挥优势，并产生信息丰富和强大的功能。</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{F}_{j\to i}^{(1)}& =\quad\mathbf{M}_{j\to i},j=1,2,\cdots N,  \\\mathbf{F}_{j\to i}^{(\ell+1)}& =\quad g_\ell(\mathbf{F}_{j\to i}^{(\ell)}),\ell=1,2,\cdots,L,  \\\mathbf{F}_{i}^{(\ell)}& =\quad\text{Fuse}(\{\mathbf{F}_{j\to i}^{(\ell)}\}_{j=1,2,\cdots,N}),  \\\mathbf{F}_{i}^{\prime}& =\quad\mathrm{Cat}([\mathbf{F}_i^{(1)},u_2(\mathbf{F}_i^{(2)}),\cdots,u_L(\mathbf{F}_i^{(L)})]), \end{aligned}</script><p><strong>总结</strong></p><p>结合了单车的late和intermediate的输出,提出了agent-pose map用于修正pose.使用多尺度融合.CoAlign在融合层面主要使用self-attention和multi-scale(backbone使用了多尺度的ResNet).在代码中使用resnet并下采样得到多尺度的特征,将这些多尺度特征通过融合模块.融合模块种通过warp_affine将特征转换到(H,W)整个感知范围内,再进行self-attention.然后将融合后的多尺度特征通过多级decoder最后concat在一起.</p><p>其中affine操作利用车之间转换矩阵以及affine_grid和affine_sample得到,也就是将特征仿射变换到lidar range.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_pairwise_tfm</span>(<span class="params">pairwise_t_matrix, H, W, discrete_ratio, downsample_rate=<span class="number">1</span></span>):</span></span><br><span class="line">    pairwise_t_matrix = pairwise_t_matrix[:,:,:,[<span class="number">0</span>, <span class="number">1</span>],:][:,:,:,:,[<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>]] <span class="comment"># [B, L, L, 2, 3]</span></span><br><span class="line">    pairwise_t_matrix[...,<span class="number">0</span>,<span class="number">1</span>] = pairwise_t_matrix[...,<span class="number">0</span>,<span class="number">1</span>] * H / W</span><br><span class="line">    pairwise_t_matrix[...,<span class="number">1</span>,<span class="number">0</span>] = pairwise_t_matrix[...,<span class="number">1</span>,<span class="number">0</span>] * W / H</span><br><span class="line">    pairwise_t_matrix[...,<span class="number">0</span>,<span class="number">2</span>] = pairwise_t_matrix[...,<span class="number">0</span>,<span class="number">2</span>] / (downsample_rate * discrete_ratio * W) * <span class="number">2</span></span><br><span class="line">    pairwise_t_matrix[...,<span class="number">1</span>,<span class="number">2</span>] = pairwise_t_matrix[...,<span class="number">1</span>,<span class="number">2</span>] / (downsample_rate * discrete_ratio * H) * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    normalized_affine_matrix = pairwise_t_matrix</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> normalized_affine_matrix</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">warp_affine_simple</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        src, M, dsize,</span></span></span><br><span class="line"><span class="params"><span class="function">        mode=<span class="string">&#x27;bilinear&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        padding_mode=<span class="string">&#x27;zeros&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        align_corners=<span class="literal">False</span></span>):</span></span><br><span class="line">    B, C, H, W = src.size()</span><br><span class="line">    grid = F.affine_grid(M, [B, C, dsize[<span class="number">0</span>], dsize[<span class="number">1</span>]],</span><br><span class="line">                         align_corners=align_corners).to(src)</span><br><span class="line">    <span class="keyword">return</span> F.grid_sample(src, grid, align_corners=align_corners)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Att_w_Warp</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, feature_dims</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Att_w_Warp, self).__init__()</span><br><span class="line">        self.att = ScaledDotProductAttention(feature_dims)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, xx, record_len, normalized_affine_matrix</span>):</span></span><br><span class="line">        _, C, H, W = xx.shape</span><br><span class="line">        B, L = normalized_affine_matrix.shape[:<span class="number">2</span>]</span><br><span class="line">        split_x = regroup(xx, record_len)</span><br><span class="line">        batch_node_features = split_x</span><br><span class="line">        out = []</span><br><span class="line">        <span class="comment"># iterate each batch</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(B):</span><br><span class="line">            N = record_len[b]</span><br><span class="line">            t_matrix = normalized_affine_matrix[b][:N, :N, :, :]</span><br><span class="line">            <span class="comment"># update each node i</span></span><br><span class="line">            i = <span class="number">0</span> <span class="comment"># ego</span></span><br><span class="line">            x = warp_affine_simple(batch_node_features[b], t_matrix[i, :, :, :], (H, W))</span><br><span class="line">            cav_num = x.shape[<span class="number">0</span>]</span><br><span class="line">            x = x.view(cav_num, C, -<span class="number">1</span>).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>) <span class="comment">#  (H*W, cav_num, C), perform self attention on each pixel.</span></span><br><span class="line">            h = self.att(x, x, x)</span><br><span class="line">            h = h.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).view(cav_num, C, H, W)[<span class="number">0</span>, ...]  <span class="comment"># C, W, H before</span></span><br><span class="line">            out.append(h)</span><br><span class="line"></span><br><span class="line">        out = torch.stack(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScaledDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ScaledDotProductAttention, self).__init__()</span><br><span class="line">        self.sqrt_dim = np.sqrt(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, query, key, value</span>):</span></span><br><span class="line">        score = torch.bmm(query, key.transpose(<span class="number">1</span>, <span class="number">2</span>)) / self.sqrt_dim</span><br><span class="line">        attn = F.softmax(score, -<span class="number">1</span>)</span><br><span class="line">        context = torch.bmm(attn, value)</span><br><span class="line">        <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure><h3 id="Learning-for-Vehicle-to-Vehicle-Cooperative-Perception-under-Lossy-Communication-V2VAM-2023"><a href="#Learning-for-Vehicle-to-Vehicle-Cooperative-Perception-under-Lossy-Communication-V2VAM-2023" class="headerlink" title="Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy Communication (V2VAM) 2023"></a>Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy Communication (V2VAM) 2023</h3><h5 id="Abs-2"><a href="#Abs-2" class="headerlink" title="Abs"></a>Abs</h5><p>深度学习已广泛应用于智能车辆驾驶感知系统，如3D目标检测。一种很有前途的技术是协同感知，它利用车对车（V2V）通信在车辆之间共享基于深度学习的特征。然而，大<strong>多数协作感知算法都假设了理想的通信，而没有考虑现实世界中非常常见的有损通信（LC）对特征共享的影响</strong>。</p><p>在本文中探讨了LC对合作感知的影响，并提出了一种新的方法来减轻这些影响。我们的方法包括LC感知维修网络（LCRN）和V2V注意力模块（V2VAM），具有车内注意力和不确定性感知车辆间注意力。</p><p>V2V通信中的信息共享有三种方式：（1）将原始传感器数据共享为早期融合，（2）将基于深度学习的检测网络的中间特征共享为中间融合，（3）将检测结果共享为后期融合。</p><p><strong>最近的研究]表明，中间融合是检测精度和带宽要求之间的最佳权衡</strong>。</p><p>最近提出了许多用于V2V协同感知的中间融合方法;但是，它们都假定了理想的通信。<strong>唯一一项考虑非理想通信的V2V协同感知研究仅关注通信延迟</strong>。迄今为止，尚无研究探讨有损通信（LC）对复杂真实驾驶环境中V2V协同感知的影响</p><p>在城市交通场景中，V2V通信容易受到一系列可能导致有损通信的因素的影响，例如<strong>来自障碍物</strong>（例如建筑物和车辆）的多径效应(电磁波经不同路径传播后，各分量场到达接收端时间不同，按各自相位相互叠加而造成干扰，使得原来的信号失真，或者产生错误)、<strong>快速移动的车辆引入的多普勒频移</strong>、<strong>其他通信网络产生的干扰</strong>.</p><p>该文首先研究了<strong>有损通信在V2V协同感知中的负面影响</strong>，<strong>然后提出了一种新的中间LC感知特征融合方法</strong>。具体而言，所提方法<strong>包括LC感知修复网络</strong>（LCRN）和<strong>专门设计的V2V注意力模块</strong>（V2VAM），以增强自我车辆与其他车辆之间的交互.</p><p>V2VAM包括<strong>ego车辆的车内注意力</strong>和<strong>不确定性感知的车辆间注意力</strong>。在真实驾驶中收集具有有损通信的真实CAV感知数据具有挑战性.</p><blockquote><p>基于LiDAR的检测方法，这些方法通常将LiDAR点转换为体素或柱子，在基于体素的、或基于Pillar的目标检测方法中占主导地位。PointRCNN提出了一种基于原始点云的两阶段策略，即先学习粗略估计，然后用语义属性对其进行细化。一些方法[]建议将空间分割成体素，并为每个体素生成特征。但是，3D 体素的处理成本通常很高。为了解决这个问题，PointPillars建议将沿z轴的所有体素压缩为一个柱子，然后在鸟瞰空间中预测3D框。此外，最近的一些方法结合了基于体素和基于点的方法，以联合检测3D物体。</p></blockquote><p>3D 感知方法的性能很大程度上取决于 3D 点云的精度。然而，LiDAR 摄像头存在折射、遮挡和远距离等问题，因此单车系统在一些具有挑战性的情况下可能会变得不可靠 。近年来，车对车（V2V）/车对基础设施（V2X）协同系统被提出，以克服单车系统使用多辆车的弊端。不同车辆之间的协作使3D感知网络能够融合来自不同来源的信息。</p><p>为了在数据负载和准确性之间找到平衡，<strong>最近的方法侧重于通过共享中间表示来进行中间融合。F-cooper应用体素特征融合和空间特征融合来自两辆车。V2VNet 采用图神经网络来聚合 LiDAR 从每辆车中提取的特征。V2X-ViT 提出了一种视觉 Transformer 架构，用于融合车辆和基础设施的功能。Cui等提出了一种基于点的Transformer进行点云处理，该Transformer可以将协同感知与控制决策相结合</strong></p><p>Tu等提出了一种基于<strong>中间表示的多智能体深度学习系统中高效实用的在线攻击网络</strong>。Luo等利用<strong>注意力模块融合中间特征，增强特征互补性</strong>。Lei等提出了一种<strong>延迟补偿模块，以实现中间特征级同步</strong>。胡(where2comm)等提出了一种空间置信度感知沟通策略，通过关注感知关键领域来使用较少的communication来提高绩效.</p><p><strong>OPV2V利用自注意力模块来融合接收到的中间特征。CoBEVT 提出了局部全局稀疏注意力，可以捕获视图和智能体之间的复杂空间交互，以提高协作感知的性能</strong></p><p>然而，这些融合方法都是以理想通信为前提的，在现实世界中，<strong>有损通信会使性能急剧下降。为了解决这个问题，我们设计了一种特殊的V2V注意力模块（V2VAM），包括ego车辆的车内注意力和不确定性感知的车辆间注意力,以增强V2V交互</strong>。</p><p><img data-src="https://s2.loli.net/2024/01/07/dc81urwk6RBAfoX.png" alt="image-20240107223439462"></p><p>本文主要关注数据传输过程中的有损通信挑战 所以<strong>假设V2V系统中不存在通信延迟或定位错误</strong>。<strong>共享数据也可能在到达目的地之前受到其他信号的干扰或被攻击者修改</strong>，从而导致有损数据。在这项工作中，旨在通过<strong>提出LC感知修复网络</strong>和<strong>提高V2V感知网络的鲁棒性来消除有损通信</strong>。</p><p>该文提出了一种新的中间LCaware特征融合框架。包括五个组件：1）V2V元数据共享，2）激光雷达特征提取，3）特征共享，4）LC感知修复网络和V2V注意力模块，5）分类和回归头。</p><p>LC感知修复网络和V2V注意力模块.从周围其他CAV聚合的中间特征被输入到我们框架的主要组件中,即<strong>LC-Aware修复网络,用于使用张量滤波在有损通信中恢复中间特征图,</strong>以及<strong>V2V注意力模块,用于利用注意力机制进行迭代的车辆间和车辆内特征融合</strong>.</p><p><strong>LC-aware Repair Network</strong></p><p>LC感知修复网络的框架如图3所示，该网络是一种具有跳跃连接的编码器-解码器架构。该网络生成一个特定的每个张量过滤器内核，以共同对齐和恢复输入损坏的特征，以生成输出特征的恢复版本。LC感知修复网络的输入特征为S ∈ R^c×h×w^，然后生成一个张量核K并应用于S，以产生恢复的输出特征ˆ S ∈ R^c×h×w^。</p><p><img data-src="https://s2.loli.net/2024/01/07/zpJc21GkmUEadLO.png" alt="image-20240107231955750"></p><p>LC感知修复网络的输入特征为S ∈ R^c×h×w^，然后生成一个张量核K并应用于S，以产生恢复的输出特征ˆ S ∈ R^c×h×w^。</p><p>LC 感知修复损失函数 L~LC~（ ˆ S， ˆ S^g^） 是遭受有损通信之前的真值原始特征 ˆ S^g^ 与修复特征 ˆ S 之间的张量 L1 距离。</p><p><strong>V2V Attention Module</strong></p><p>自注意力的关键思想是将某个位置的响应计算为所有位置的特征的加权总和，特征之间的相互作用由特征本身决定，而不是像卷积那样由它们的相对位置决定。</p><p>通过考虑有损通信情况，设计了一种定制化的车内和车间注意力融合方法，以增强自我CAV与其他CAV之间的交互.此外,我们在提出的V2V注意力方法中采用了<strong>纵横交错的注意力模块</strong>,可以利用该模块更有效地从全功能依赖关系中捕获上下文信息。</p><p>仅对于ego车辆，车内注意力模块可以使任何位置的特征进行全局感知，从而享受全图像上下文信息，以更好地捕捉代表性特征。从形式上讲，让 H^e^ ∈ R^C×H×W^ 成为自我车辆的输入特征图，它是自我车辆生成的完美数据，不会遭受任何有损通信。</p><script type="math/tex; mode=display">\mathbf{A}^{in\boldsymbol{l}ra}=\mathrm{softmax}\left(\frac{\mathbf{Q}^{e}\mathbf{K}^{e\mathbf{T}}}{\sqrt{d_{k}^{e}}}\right)\mathbf{V}^{e},</script><p>在车内注意力模块中，<strong>特征图H^e^将由三个1×1卷积层计算，分别产生三个特征向量Qe、Ke和Ve</strong>，其中所有特征向量都具有相同的大小，{Q^e^，K^e^，V^e^}∈R^C×H×W^。按照中的缩放点积注意力，我们计算了Q^e^和K^e^的点积，然后使用比例因子（即特征向量的维度）将它们除以，并应用softmax函数来获得V^e^上的权重。</p><p>在V2V协同感知中，从其他CAV聚合而来的中间特征图H^s^∈R^C×H×W^被共享给ego车辆。具有有损通信的共享特征图Hs将被LC感知修复网络恢复，但它们在一定程度上仍然有噪声，而ego特征图H^s^是完美的.</p><p>针对这一问题，该文考虑恢复特征图的不确定性，提出一种不确定性感知的车间注意力融合方法。</p><p>在该模块中,共享特征图将由两个 1 × 1 卷积层计算，分别产生两个特征向量 K^s^ 和 V^s^，其中它们都具有相同的大小，{Ks， Vs} ∈ R^C×H×W^，另一个特征向量 Q^e^ 直接从自我车辆而不是其他车辆获得.</p><script type="math/tex; mode=display">\mathbf{A}^{inter}=\sum_i^N\mathrm{softmax}\left(\frac{\mathbf{Q}^e\mathbf{K}_i^{s\text{T}} }{ \sqrt { d _ k ^ s }}\right)\mathbf{V}_i^s,</script><p><strong>Efficient Implementation</strong></p><p>采用两个连续的纵横交错（CC）注意力模块来实现点云数据中的V2V注意力,而不是缩放的点积注意力,减小计算量.</p><p><strong>在获得车内注意力和车间注意力后，将它们分别输入到最大池化层和平均池化层，以获得丰富的空间信息，然后将它们串联为具有ReLU激活函数的二维卷积层的输入</strong>。</p><p><strong>总结</strong></p><p>感觉融合了cobev和coalign两篇文章.在代码上主要使用了ego的q和其他车的k,v计算注意力,而且计算注意力使用Criss-Cross Attention,然后使用max和mean再通过一个卷积.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">V2V_AttFusion</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, feature_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(V2V_AttFusion, self).__init__()</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        self.cov_att = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=feature_dim, out_channels=feature_dim, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(feature_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.CCNet = CrissCrossAttention(feature_dim)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, record_len</span>):</span></span><br><span class="line"></span><br><span class="line">        split_x = self.regroup(x, record_len)  <span class="comment">#x =[5, 64, 100, 352], record_len=[3,2]</span></span><br><span class="line"></span><br><span class="line">        out = []</span><br><span class="line">        att = []</span><br><span class="line">        <span class="keyword">for</span> xx <span class="keyword">in</span> split_x:<span class="comment">#split_x[0] [num_car, C, W, H]</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27; CCNet: Criss-Cross Attention Module: attention for ego vehicle feature + cav feature &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">            ego_q, ego_k, ego_v = xx[<span class="number">0</span>:<span class="number">1</span>], xx[<span class="number">0</span>:<span class="number">1</span>], xx[<span class="number">0</span>:<span class="number">1</span>] </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(xx[:,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>])):</span><br><span class="line">                att_vehicle = self.CCNet(ego_q, xx[i:i+<span class="number">1</span>], xx[i:i+<span class="number">1</span>])</span><br><span class="line">                att.append(att_vehicle)</span><br><span class="line"></span><br><span class="line">            pooling_max = torch.<span class="built_in">max</span>(torch.cat(att, dim=<span class="number">0</span>), dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">            pooling_ave = torch.mean(torch.cat(att, dim=<span class="number">0</span>), dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            fuse_fea = pooling_max + pooling_ave</span><br><span class="line"></span><br><span class="line">            fuse_att = fuse_fea</span><br><span class="line">            fuse_att = self.cov_att(fuse_att)</span><br><span class="line"></span><br><span class="line">            out.append(fuse_att) <span class="comment">#[[1, 64, 100, 352], [1, 64, 100, 352]]</span></span><br><span class="line">            <span class="comment"># torch.cuda.empty_cache()</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.cat(out, dim=<span class="number">0</span>) <span class="comment">#[2, 64, 100, 352]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">regroup</span>(<span class="params">self, x, record_len</span>):</span></span><br><span class="line">        cum_sum_len = torch.cumsum(record_len, dim=<span class="number">0</span>)</span><br><span class="line">        split_x = torch.tensor_split(x, cum_sum_len[:-<span class="number">1</span>].cpu())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> split_x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrissCrossAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Criss-Cross Attention Module</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    reference: https://github.com/speedinghzl/CCNet</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CrissCrossAttention,self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.query_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">        self.key_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">        self.value_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">3</span>)</span><br><span class="line">        self.INF = INF</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, query, key, value</span>):</span></span><br><span class="line">        m_batchsize, _, height, width = query.size()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        proj_query = self.query_conv(query)</span><br><span class="line">        proj_query_H = proj_query.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        proj_query_W = proj_query.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        proj_key = self.key_conv(key)</span><br><span class="line">        proj_key_H = proj_key.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height)</span><br><span class="line">        proj_key_W = proj_key.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        proj_value = self.value_conv(value)</span><br><span class="line">        proj_value_H = proj_value.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height)</span><br><span class="line">        proj_value_W = proj_value.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width)</span><br><span class="line">        energy_H = (torch.bmm(proj_query_H, proj_key_H)+self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        energy_W = torch.bmm(proj_query_W, proj_key_W).view(m_batchsize,height,width,width)</span><br><span class="line">        concate = self.softmax(torch.cat([energy_H, energy_W], <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        att_H = concate[:,:,:,<span class="number">0</span>:height].permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*width,height,height)</span><br><span class="line">        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width)</span><br><span class="line">        out_H = torch.bmm(proj_value_H, att_H.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)).view(m_batchsize,width,-<span class="number">1</span>,height).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">        out_W = torch.bmm(proj_value_W, att_W.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)).view(m_batchsize,height,-<span class="number">1</span>,width).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.gamma*(out_H + out_W) + value</span><br></pre></td></tr></table></figure><h3 id="Adaptive-Feature-Fusion-for-Cooperative-Perception-using-LiDAR-Point-Clouds-2023"><a href="#Adaptive-Feature-Fusion-for-Cooperative-Perception-using-LiDAR-Point-Clouds-2023" class="headerlink" title="Adaptive Feature Fusion for Cooperative Perception using LiDAR Point Clouds 2023"></a>Adaptive Feature Fusion for Cooperative Perception using LiDAR Point Clouds 2023</h3><h5 id="Abs-3"><a href="#Abs-3" class="headerlink" title="Abs"></a>Abs</h5><p>提出了具有<strong>可训练特征选择模块的自适应特征融合模型</strong>。我们提出的一个模型空间自适应特征融合（S-AdaFusion）在OPV2V数据集的两个子集上优于所有其他最先进的（SOTA）:用于车辆检测的默认CARLA Towns和用于域适应的Culver City.</p><blockquote><p>此外，以前的研究只测试了车辆检测的协同感知。然而，行人在交通事故中受重伤的可能性要大得多。</p><p>我们使用 CODD 数据集评估了车辆和行人检测的协同感知性能。我们的架构在 CODD 数据集上实现了比其他现有模型更高的车辆和行人检测平均精度 （AP）。实验表明，与传统的单车感知过程相比，协同感知也提高了行人检测的准确率。</p></blockquote><p>LiDAR 可以生成包含准确深度信息的点云数据，并且受外部照明条件的影响较小。然而，<strong>远离LiDAR的点云非常稀疏，这使得探测其他物体变得更加困难。</strong></p><p>感知到的信息可以包括 GPS 和各种传感器数据，包括<strong>雷达、摄像头和激光雷达数据</strong>。协同感知有助于弥补当前视觉感知技术的局限性，例如分辨率有限、天气效应和盲点。</p><p>首先，4个CAV处理其LiDAR点云，并在其本地系统中并行提取中间特征图。接下来，其他三个CAV将其提取的特征图连同LiDAR姿态信息一起广播到CAV1。然后，CAV1 将三个特征图投影到自己的坐标系，并将信息与自己的感知信息聚合在一起，用于 3D 目标检测。</p><p>根据CAV之间共享的数据类型，现有文献中发现了三种数据融合方法：1）早期融合聚合了来自其他CAV的原始输入传感器数据;</p><p>2）中间融合聚合了来自其他CAV的处理后的特征图;</p><p>3）后期融合聚合了来自其他CAV的目标检测的预测输出。</p><blockquote><p>在最近的研究中，与早期和晚期融合方法相比，中间特征融合已被证明是最有效的融合方法。我们假设通过实现有效的特征选择和融合模块，降低计算成本，可以进一步改进中间融合方法，以实现实时感知和更高的准确性.</p></blockquote><p>我们提出了几种具有可训练神经网络的特征融合模型，这些模型可以从多个CAV中自适应地选择特征</p><p>这项工作的贡献如下：1）我们创建了一个具有中间融合的轻量级协作感知架构;2）利用3D CNN和自适应特征融合进行协同感知，提出3种可训练的特征融合模型进行协同感知;3）我们使用两个公共合作感知基准数据集（OPV2V数据集[27]和CODD数据集[2]）验证了所提出的模型，用于多个任务，包括a）车辆检测，b）行人检测和c）领域适应;4）我们尝试了不同数量的CAVs，以观察其对合作感知的影响</p><p>从形式上讲，合作感知的问题可以描述如下。我们将来自一组周围 CAV 的原始输入数据（相机数据和 LiDAR 数据）表示为 I = {I1， I2， . . . ， In}，表示为 V = {v1， v2， . . . ， vn}。输入数据的相应提取中间特征集表示为 F = {F1， F2， . . . ， Fn}，其中目标检测器预测的输出集表示为 O = {O1， O2， . . . ， On}。在传统的视觉感知过程中，AV vi 接收来自摄像头和激光雷达等传感器的原始数据 Ii。然后对这些数据进行处理以提取特征图 Fi，以用于计算模型中用于预测对象作为输出 Oi。在协同感知中，应用额外的数据融合步骤来聚合来自其他车辆的数据，以改善感知。</p><p>中间融合是利用已处理的中间特征表示 F 的折衷方案。因此，准确和优化地集成和处理从不同位置获得的信息对于有效的特征融合以实现准确的目标检测至关重要。</p><p>Marvasti等将3D LiDAR点云扭曲为鸟瞰图（BEV），并应用2D CNN提取每个连接的AV中的中间特征。来自 CAV 的特征图被投影到自我车辆的坐标系上。然后将这些与自我车辆的特征图聚合在一起。在中，只使用了两个CAV，求和使重叠具有更大的权重，而在现实生活中，CAV的数量各不相同。我们计算重叠处的平均值。</p><p>Chen等提出了特征级融合方案，选择重叠处的最大值来表示中间特征。</p><p>上面提到的模型使用简单的约简算子，例如求和、最大池化或平均池化。这些算子能够处理重叠处的信息，并以可以忽略不计的计算成本融合特征图。然而，由于缺乏信息选择和数据相关性的识别，所选择的特征不一定是最好的。</p><p>在V2VNe中，应用图神经网络（GNN）基于地质坐标表示CAV地图，以促进数据融合。GNN 将从多辆车接收到的信息与车辆的内部状态（根据其自己的传感器数据计算）聚合在一起，以计算更新的中间表示。</p><p>Xu等提出了AttFuse，并<strong>利用自注意力模型融合了中间特征图</strong>。<strong>V2X-Vit 和 CoBEVT  中使用了 Transformer，用于与中间特征融合的协同感知</strong>。</p><p>我们探索了特征融合模型，这些模型可以有效和高效地利用CAV的多个特征图。</p><p><strong>Feature Learning and Feature Fusion</strong></p><p>注意力机制在解决计算机视觉任务中已经证明了它的实用性。通过在神经网络中加入一个小模块，该模型可以利用通道和/或空间信息，并增强提取的表示。</p><p>在协同感知中，通过特征通道连接中间特征图会随着CAV数量的增加而大大增加计算成本。<strong>因此,与其连接特征图并创建超大型特征提取网络，不如将特征图与几何和地理信息聚合起来更有效</strong>。</p><p><strong>Overview of the Proposed Framework</strong></p><p>整个网络以点云为输入，分5个步骤对数据进行处理：</p><p>1）特征编码利用支柱特征网络（PFN）将点云转换为伪图像;</p><p>2）中间特征提取利用<strong>二维金字塔网络从伪图像中提取多尺度特征</strong>;</p><p>3）<strong>特征投影将CAV的中间特征图投射到与LiDAR姿态信息协调的ego车辆上</strong>;</p><p>4）中间特征融合<strong>生成具有特征融合网络的组合特征图</strong>;</p><p>5）3D目标检测<strong>使用单次检测器（SSD）对边界框进行回归，并预测检测到的对象的类别</strong>。</p><p><strong>Feature Encoding</strong></p><p>维度为（n×4）的输入点云由n个点组成，每个点具有属性（x、y、z）坐标和强度。</p><p>点云被编码为柱子，其高度等于z轴上的点云高度。每个柱子中的点都增加了 5 个额外的属性，包括柱子中所有点的算术平均值的偏移量和柱子中心的偏移量。将点云数据转换为P柱，每个柱子具有N个点和D个特征然后将 PointNet 应用于柱子上以提取特征并生成大小的张量 （C~in~ × P ）。具有 C~in~ 特征的柱子被投射回原始位置，以生成大小的伪像 （C~in~ × 2H × 2W）。我们在这里使用 2H 和 2W，因为我们在下一个特征提取步骤中将特征图下采样为 （C × H × W ）。</p><p><strong>Feature Extraction</strong></p><p>FPN 包含三个用于多分辨率特征提取的下采样模块。每个模块包含一个 2D 卷积层、一个批量归一化层和一个 ReLU 激活函数。</p><p>然后，对从三个下采样模块获得的三个特征图进行上采样和连接。由CNN对得到的多尺度特征图进行细化，以生成大小为F ′ ∈ RC×H×W的特征图。</p><p><img data-src="https://s2.loli.net/2024/01/08/R7C6MQ8PWzI13JK.png" alt="image-20240108181057303"></p><p><strong>Feature Projection</strong></p><p>从<strong>不同CAV中提取的特征图具有不同的地质位置和方向。因此，需要将它们转换为接收机的坐标系，以进行特征融合和目标检测</strong>。CAV 传播特征图及其 LiDAR 姿态信息，其中包含（X、Y、Z、滚动、偏航、俯仰）。一旦自我车辆从相邻的CAV接收到数据，它就会被投射到自我车辆的坐标系和时间戳中。</p><p><strong>Feature Fusion</strong></p><p>来自不同 CAV 的投影中间特征图被扩展为 4D 张量并连接起来进行进一步处理。在特征通道上连接特征图会生成具有 nC 通道的 3D 张量，这将增加计算复杂性和特征融合和细化的成本。因此，<strong>我们将特征图聚合为一个 4D 张量 F ∈ R^n×C×H×W^，其中 n 是 CAV 的最大数量。为了融合地质坐标系中的重叠特征图，我们提出了空间和通道特征融合模型</strong></p><p>我们提出的特征融合模型分为空间特征融合和通道特征融合。</p><p><strong>Spatial-wise Feature Fusion</strong>。为了融合特征图，将直接的约简算子（如Max或Mean）应用于重叠的特征，如图3a所示。本文将这两种融合方法称为MaxFusion和AvgFusion，它们分别在通道轴上计算最大池化和平均池化，得到融合特征图Ffusion ∈ R^1×C×H×W^</p><p>受信道注意力模块<strong>SENet</strong>的启发,提出了一种信道自适应特征融合（C-AdaFusion）模块，该模块可以利用<strong>信道信息选择和融合中间特征图</strong>。</p><p><img data-src="C:\Users\proanimer\AppData\Roaming\Typora\typora-user-images\image-20240108204441345.png" alt="image-20240108204441345"></p><p>首先，通过计算沿第一通道轴的最大池化和平均池化，将输入特征图F ∈ R^n×C×H×W^分解为Smax ∈ R^1×C×H×W^和Savg ∈ R^1×C×H×W^。</p><p>将两个特征图连接在一起，得到一个四维张量F~spatial~ ∈ R^2×C×H×W^，其中包含来自原始级联中间特征图的两种空间信息。然后,利用<strong>具有ReLU激活函数的三维卷积进行进一步的特征选择和降维</strong>,输入通道数和输出通道数分别等于2和1.</p><p><strong>Channel-wise Feature Fusion</strong>CNN 在从表示中提取特征并减小其维度方面表现非常出色。对于输入的 4D 张量 F ∈ R^n×C×H×W^，可以使用 3D CNN 提取通道特征并减少输入特征通道的数量。3D CNN 的输入通道数将等于单个输出通道表示组合特征集的最大 CAV 数。</p><p><img data-src="https://s2.loli.net/2024/01/08/W5qG8EdRyZwz6lM.png" alt="image-20240108204452386"></p><p>根据这两种不同的attention提出了c-AdaFusion.利用 3D 自适应最大池化和平均池化来提取两个通道描述符 C~max~ ∈ R^n×1×1×1^ 和 C~avg~ ∈ R^n×1×1×1^。然后，将两个向量连接起来，分别通过两个具有ReLU和Sigmoid激活函数的线性层。输入特征图F ∈ R^n×C×H×W^ 通道相乘学习的通道权重 F ′ 通道∈ R^n×1×1×1^，以生成新的特征表示 F ′ ∈ R^n×C×H×W^。融合特征图F~fusion~ ∈ R^1×C×H×W^是利用通道缩减3D CNN得到的。</p><p><img data-src="https://s2.loli.net/2024/01/08/9eTsclkiWp3Z4fV.png" alt="image-20240108185354500"></p><p><strong>总结</strong></p><p>主要是利用了通道以及空间的fusion.我是打算再结合transformer做的.</p><h4 id="where2comm-2022"><a href="#where2comm-2022" class="headerlink" title="where2comm 2022"></a>where2comm 2022</h4><h5 id="abs-1"><a href="#abs-1" class="headerlink" title="abs"></a>abs</h5><p>多智能体协同感知可以使智能体通过通信相互共享互补信息，从而显著提升感知性能。</p><p>这不可避免地导致感知性能和通信带宽之间的基本权衡。为了解决这一瓶颈问题，<strong>我们提出了一种空间置信度图，该图反映了感知信息的空间异质性。它使智能体能够只共享空间稀疏但感知上至关重要的信息，从而有助于沟通的位置</strong>。</p><p>基于这种新颖的空间置信度图，我们提出了一种通信效率高的协作感知框架Where2comm。有两个明显的优势：</p><p>i）它考虑了语用压缩，并通过专注于感知关键区域来使用更少的通信来实现更高的感知性能;</p><p>ii）通过动态调整通信所涉及的空间区域，可以处理不同的通信带宽。为了评估 Where2comm，我们考虑了在真实世界和模拟场景中的 3D 目标检测，在四个数据集上使用两种模态（摄像头/激光雷达）和两种代理类型（汽车/无人机）：OPV2V、V2X-Sim、DAIR-V2X 和我们原始的 CoPerception-UAV。</p><h5 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h5><p>协作感知使多个智能体能够相互共享互补的感知信息，从而促进更全面的感知。它提供了一个新的方向，从根本上克服了单智能体感知的一些不可避免的局限性，如遮挡和远距离问题。在广泛的实际应用中迫切需要相关的方法和系统，例如<strong>车联网通信辅助自动驾驶</strong>、<strong>多机器人仓库自动化系统</strong>和用于<strong>搜救</strong>的多无人机。为了实现协作感知，最近的工作贡献了高质量的数据集和有效的协同方法。</p><p>在这个新兴领域,目前最大的挑战是如何优化感知性能和通信带宽之间的权衡。现实世界中的<strong>通信系统总是受到限制,以至于它们几乎无法承受巨大的实时通信消耗</strong>,例如通过完整的原始观测或大量特征。</p><p>以前的工作都做出了一个合理的假设：<strong>一旦两个智能体合作，他们就有义务平等地共享所有空间区域的感知信息。这种不必要的假设会极大地浪费带宽，因为很大一部分空间区域可能包含与感知任务无关的信息</strong>。为了填补这一空白，我们考虑了一种<strong>新颖的空间置信度感知沟通策略</strong>。其<strong>核心思想是为每个智能体启用空间置信度图，其中每个元素都反映了相应空间区域的感知临界水平</strong>。根据此地图，智能体决定要通信的空间区域（位置）。</p><p>Where2comm 包括三个关键模块：</p><p>i） 空间置信度生成器,它<strong>生成空间置信度图以指示感知关键区域</strong>;</p><p>ii）空间置信度感知通信模块,<strong>利用空间置信度图通过新型消息打包决定在何处进行通信</strong>，以及<strong>通过新型通信图构建来向谁进行通信</strong>;</p><p>iii）空间置信感知消息融合模块,<strong>该模块使用新颖的置信感知多头注意力来融合从其他智能体接收到的所有消息,从而升级每个智能体的特征图</strong>。</p><p>Where2comm有两个明显的优势。首先在特征层面促进了语用压缩，并通过专注于感知关键区域，<strong>使用更少的通信来实现更高的感知性能</strong>。其次，<strong>它适应各种通信带宽和通信轮数</strong>，而以前的型号只能处理一个预定义的通信带宽和固定数量的通信轮数。</p><p><strong>问题定义</strong></p><p>考虑场景中的 N 个代理。让 X~i~ 和 Y~i~ 分别是第 i 个智能体的观察和感知监督。协作感知的目标是实现所有智能体的感知性能最大化，作为总通信点 B 和通信轮 K 的函数</p><script type="math/tex; mode=display">\xi_{\Phi}(B,K)=\arg\max_{\theta,\mathcal{P}}\sum_{i=1}^{N}g\left(\Phi_{\theta}\left(\mathcal{X}_{i},\{\mathcal{P}_{i\rightarrow j}^{(K)}\}_{j=1}^{N}\right),\mathcal{Y}_{i}\right),\mathrm{~s.t.~}\sum_{k=1}^{K}\sum_{i=1}^{N}|\mathcal{P}_{i\rightarrow j}^{(k)}|\leq B,</script><p>在这项工作中，我们考虑了3D目标检测的感知任务，并提出了三个贡献：</p><p>i）我们通过设计紧凑的消息和稀疏的通信图使通信更加高效;</p><p>ii）我们通过实施更全面的信息融合来提高感知性能;</p><p>iii） 我们通过动态调整沟通地点和人员，使整个系统能够适应不同的沟通条件。</p><p><img data-src="https://s2.loli.net/2024/01/09/1fg5jPZS6lUhmxz.png" alt="image-20240109171737063"></p><p><strong>observation encoder</strong>从传感器数据中提取特征图。Where2comm 接受单模态/多模态输入，例如 RGB 图像和 3D 点云。这项工作采用鸟瞰图（BEV）中的特征表示，其中所有智能体将其个人感知信息投射到同一个全局坐标系，避免了复杂的坐标变换，并支持更好的共享跨智能体协作。</p><p><strong>Spatial confidence generator</strong>空间置信度图<strong>反映了各个空间区域的感知临界水平</strong>。直观地说,对于物体检测任务,包含<strong>物体的区域比背景区域更关键</strong>。在协作过程中,由于视野有限,有对象的区域可以帮助恢复误检对象;可以<strong>省略背景区域以节省宝贵的带宽。因此,我们用检测置信度图表示空间置信度图，其中感知临界水平高的区域是包含置信度得分高的对象的区域。</strong></p><p>传感器位置编码表示每个智能体的传感器与其观察点之间的物理距离。<strong>它采用以感应距离和特征尺寸为条件的标准位置编码功能</strong>。在输入到transformer之前，将这些特征与每个位置的位置编码相加。</p><p>与现有不使用注意力机制或仅使用智能体级注意力的融合模块相比，所提出的融合所采用的<strong>每位置注意力机制强调位置特异性特征交互。它使特征融合更具针对性</strong>。与同样使用基于每个位置注意力的融合模块的方法相比，所提出的融合模块利用了具有两个额外先验的多头注意力，<strong>包括空间置信度图和感知距离</strong>。两者都有助于注意力学习，以偏爱高质量和关键功能</p><p>空间置信度感知消息融合的目标是通过聚合从其他代理接收到的消息来增强每个代理的功能。为了实现这一点，我们采用了 transformer 架构，该架构利用多头注意力来融合来自每个单独空间位置的多个智能体的相应特征</p><p><strong>Spatial confidence-aware message fusion</strong></p><script type="math/tex; mode=display">\mathbf{C}_i^{(k)}=\Phi_{\mathrm{generator}}(\mathcal{F}_i^{(k)})\in[0,1]^{H\times W}</script><script type="math/tex; mode=display">\mathbf{W}_{j\rightarrow i}^{(k)}=\mathrm{MHA}_{\mathrm{W}}\left(\mathcal{F}_{i}^{(k)},\mathcal{Z}_{j\rightarrow i}^{(k)},\mathcal{Z}_{j\rightarrow i}^{(k)}\right)\odot\mathbf{C}_{j}^{(k)}\in\mathbb{R}^{H\times W},</script><script type="math/tex; mode=display">\mathcal{F}_{i}^{(k+1)}=\mathrm{FFN}\left(\sum_{j\in\mathcal{N}_{i}\bigcup\{i\}}\mathbf{W}_{j\rightarrow i}^{(k)}\odot\mathcal{Z}_{j\rightarrow i}^{(k)}\right)\in\mathbb{R}^{H\times W\times D},</script><p><strong>总结</strong>很好的一篇论文,利用了其他车的输出作为confidence map再结合多头注意力进行协同感知.</p><h3 id="V2X-ViT-Vehicle-to-Everything-Cooperative-Perception-with-Vision-Transformer-2022"><a href="#V2X-ViT-Vehicle-to-Everything-Cooperative-Perception-with-Vision-Transformer-2022" class="headerlink" title="V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer 2022"></a>V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer 2022</h3><p>这篇文章主要强调车与异构设备之间进行协同感知,提出新的改进的注意力机制,所以这里就不着重讲了.</p><ul><li>我们提出了第一个用于V2X感知的统一Transformer架构（V2X-ViT），该架构可以捕获V2X系统的异构性，对各种噪声具有很强的鲁棒性。</li><li>此外，所提模型在具有挑战性的协同检测任务中取得了最先进的性能。– 我们提出了一种新型的异构多智能体注意力模块（HMSA），用于异构智能体之间的自适应信息融合。</li><li>我们提出了一种新的多尺度窗口注意力模块 （MSwin），该模块可同时并行捕获局部和全局空间特征交互。– 我们构建了 V2XSet，这是一个用于 V2X 感知的新的大规模开放仿真数据集，它明确地解释了不完美的现实世界条件。</li></ul><p><strong>OPV2V</strong>本文提出了Attentive Fusion</p><p>由于来自不同联网车辆的传感器观测结果可能带有不同的噪声水平（例如，由于车辆之间的距离），因此，一种<strong>既能关注重要观测值又能忽略中断观测值的方法对于稳健的检测至关重要</strong>。因此，我们提出了一个中间融合管道来捕捉相邻连接车辆特征之间的相互作用，帮助网络关注关键观测。</p><p>首先广播每个CAV的相对姿态和外在性,以构建一个空间图,其中每个节点都是通信范围内的一个CAV,每个边代表一对节点之间的通信通道。</p><p>构建图形后，将在组中选择一辆 ego 车辆. 所有相邻的 CAV 将自己的点云投射到自我车辆的 LiDAR 框架上，并根据投影的点云提取特征。这里的特征提取器可以是现有 3D 对象检测器的backbone.</p><p>采用自注意力模型来融合这些解压缩特征。同一特征图中的每个特征向量（对应于原始点云中的某些空间区域。因此<strong>，简单地展平特征图并计算特征的加权总和将破坏空间相关性。取而代之的是，我们为特征图中的每个特征向量构建一个局部图，其中边是为来自不同连接车辆的相同空间位置的特征向量构建的。</strong></p><h3 id="Cooper-Cooperative-Perception-for-Connected-Autonomous-Vehicles-based-on-3D-Point-Clouds"><a href="#Cooper-Cooperative-Perception-for-Connected-Autonomous-Vehicles-based-on-3D-Point-Clouds" class="headerlink" title="Cooper: Cooperative Perception for Connected Autonomous Vehicles based on 3D Point Clouds"></a>Cooper: Cooperative Perception for Connected Autonomous Vehicles based on 3D Point Clouds</h3><h4 id="Abs-4"><a href="#Abs-4" class="headerlink" title="Abs"></a>Abs</h4><p>自动驾驶汽车可能会因为检测和识别不准确而做出错误的决定。因此，<strong>智能车辆可以将自身数据与其他车辆的数据相结合，增强感知能力，从而提高探测精度和驾驶安全性</strong>。然而，<strong>多车协同感知需要整合真实世界的场景，而原始传感器数据交换的流量远远超过了现有车辆网络的带宽。</strong>据我们所知，我们是<strong>第一个对原始数据层面的合作感知进行研究，以提高自动驾驶系统的检测能力</strong>。</p><p>在这项工作中，我们<strong>以激光雷达三维点云为依托，融合从联网车辆的不同位置和角度收集的传感器数据</strong>。我们提出了一种基于点云的三维物体检测方法，可用于多种对齐点。</p><p>然而，到目前为止，人类驾驶的汽车与自动驾驶汽车之间的大多数比较都是不平衡的，包含各种不公平的因素。自动驾驶汽车不会感到疲劳、情绪衰弱，如愤怒或沮丧。但是，它们无法像细心和经验丰富的人类驾驶员那样，在不确定和模糊的情况下做出熟练的反应或预测</p><h3 id="Proposed-Solution"><a href="#Proposed-Solution" class="headerlink" title="Proposed Solution"></a>Proposed Solution</h3><p>为了解决这个问题，我们研究了其中一个基础类别，即原始数据的低级融合。<strong>原始传感数据是自动驾驶汽车上所有传感器的组成部分，因此非常适合在不同制造商的不同汽车之间传输。因此，不同数据处理算法的异质性不会影响车辆之间共享数据的准确性</strong>。由于自动驾驶本身就是一项至关重要的任务，与车辆的集成度如此之高，即使是一个小小的检测错误也可能导致灾难性的事故。因此，我们需要自动驾驶汽车尽可能清晰地感知环境。为了实现这一最终目标，它们需要一个强大而可靠的感知系统。</p><p>在此过程中，我们要解决以下两个主要问题：(1) 我们需要在车辆之间共享的数据类型，以及 (2) 需要传输的数据量与接收车辆实际需要的数据量。</p><p>第一个问题是<strong>汽车数据集中的可共享数据</strong>。第二个问题<strong>是每辆车产生的数据量巨大。由于每辆自动驾驶汽车每天都会收集超过 1000GB 的数据</strong>，因此只收集区域数据变得更加困难。同样，重建附近感知系统从不同位置和角度收集的共享数据也是另一大挑战。</p><p>在不同类型的原始数据中，我们建议使用激光雷达（LiDAR）点云作为解决方案，原因如下：</p><ul><li>与二维图像和视频相比，<strong>激光雷达点云具有空间维度的优势</strong>。</li><li>在保留感知对象的准确模型的同时，对实体或私人数据（如人脸和车牌号码）进行本机混淆。</li><li>由于数据是由点而不是像素组成的，因此在图像和视频融合过程中具有多功能性。<strong>对于图像或视频融合来说，要求有一个清晰的重叠区，而点云数据则不需要重叠区，这使得点云数据成为一种更稳健的选择，尤其是在考虑到汽车的不同视角时</strong>。</li></ul><h5 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h5><p>不准确的物体检测和识别是实现强大而有效的感知系统的主要障碍。自动驾驶汽车最终会屈服于这种能力，无法实现预期结果，这对自动驾驶是不安全的。为了解决这些问题，我们提出了一种解决方案，即<strong>自动驾驶车辆将自身的感知数据与其他联网车辆的感知数据相结合，以帮助增强感知能力</strong>。我们还认为，如前所述，<strong>数据冗余是解决这一问题的方法，我们可以通过自动驾驶车辆之间的数据共享和组合来实现</strong>。我们提出的 Cooper 系统可以提高探测性能和驾驶体验，从而提供保护和安全。具体来说，我们的贡献如下:</p><ul><li>我们提出了稀疏点云物体检测（SPOD）方法，用于<strong>检测低密度点云数据中的物体</strong>。虽然 SPOD 是针对低密度点云设计的，但它也适用于高密度激光雷达数据。</li><li>我们展示了所提出的 Cooper 系统如何通过扩大感知区域和提高检测精度来超越单个感知。</li><li>我们证明，可以利用现有的车载网络技术来促进车辆之间兴趣区域 (ROI) 激光雷达数据的传输，从而实现合作感知。</li></ul><p>鉴于当前自动驾驶汽车数据融合领域的前景和工作，我们需要更进一步，定义我们眼中的合作传感。我们认为，自动驾驶汽车的合作传感将带来一系列挑战和益处，这将是发展过程中不可避免的一部分。</p><h3 id="F-Cooper-Feature-based-Cooperative-Perception-for-Autonomous-Vehicle-Edge-Computing-System-Using-3D-Point-Clouds"><a href="#F-Cooper-Feature-based-Cooperative-Perception-for-Autonomous-Vehicle-Edge-Computing-System-Using-3D-Point-Clouds" class="headerlink" title="F-Cooper: Feature based Cooperative Perception for Autonomous Vehicle Edge Computing System Using 3D Point Clouds"></a>F-Cooper: Feature based Cooperative Perception for Autonomous Vehicle Edge Computing System Using 3D Point Clouds</h3><h4 id="Abs-5"><a href="#Abs-5" class="headerlink" title="Abs"></a>Abs</h4><p>自动驾驶汽车在很大程度上依赖于传感器来完善对周围环境的感知，然而，就目前的技术水平而言，汽车所使用的数据仅限于来自自身传感器的数据.车辆和/或边缘服务器之间的数据共享受到可用网络带宽和自动驾驶应用严格的实时性限制。</p><p>为了解决这些问题，我们为联网自动驾驶汽车提出了<strong>基于点云特征的合作感知框架</strong>（F-Cooper），以实现更高的目标检测精度。</p><p>基于特征的数据不仅足以满足训练过程的需要，我们还利用特征的固有小尺寸来实现实时边缘计算，而不会面临网络拥塞的风险。</p><p>我们的实验结果表明，通过融合特征，我们能够获得更好的物体检测结果，20 米内的检测结果提高了约 10%，更远距离的检测结果提高了 30%，同时还能以较低的通信延迟实现更快的边缘计算，在某些特征选择中只需 71 毫秒。</p><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>互联自动驾驶汽车（CAV）为改善道路安全提供了一个前景广阔的解决方案。这有赖于车辆能够实时感知路况并精确探测物体。</p><p>然而，准确和实时的感知在现场具有挑战性。它需要处理来自各种传感器的大量连续数据流，并有严格的时间要求。此外，车辆的感知精度往往会受到传感器有限视角和范围的影响。</p><h3 id="Proposed-Solution-1"><a href="#Proposed-Solution-1" class="headerlink" title="Proposed Solution"></a>Proposed Solution</h3><p>我们提出的方法可以提高自动驾驶车辆的检测精度，同时不会带来太多的计算开销。一个有益的启示是，现代自动驾驶车辆的物体检测技术，<strong>无论是基于图像的还是基于三维激光雷达数据的，通常都采用卷积神经网络（CNN）来处理原始数据，并利用区域建议网络（RPN）来检测物体</strong>。我们认为，特征图的能力尚未得到充分挖掘，特别是对于自动驾驶车辆上生成的 3D LiDAR 数据，因为特征图仅用于单个车辆的物体检测。</p><p>为此，我们引入了基于特征的协同感知（FCooper）框架，利用特征级融合实现端到端的三维物体检测，从而提高检测精度。我们的 F-Cooper 框架支持两种不同的融合方案：<strong>体素特征融合和空间特征融合</strong>。</p><p>与原始数据级融合解决方案[3]相比，<strong>前者实现了几乎相同的检测精度提升，而后者则提供了动态调整待传输特征图大小的能力</strong>。F-Cooper 的独特之处在于它可以在车载和路边边缘系统上部署和执行。</p><p>除了能够<strong>提高检测精度</strong>外，<strong>特征融合所需的数据大小仅为原始数据的百分之一</strong>。对于一个典型的激光雷达传感器来说，每个激光雷达帧包含约 100,000 个点，约为 4 MB。对于任何现有的无线网络基础设施来说，如此庞大的数据量都将成为沉重的负担。</p><p>要确认特征对融合的有用性，我们必须回答以下三个基本问题。</p><p>1) 特征是否具备融合的必要手段？<br>2) 我们能否通过特征在自动驾驶车辆之间有效地交流数据？<br>3) 如果特征满足前面两个要求，那么我们从自动驾驶车辆中获取特征图的难度有多大？</p><h4 id="Fusion-Characteristics"><a href="#Fusion-Characteristics" class="headerlink" title="Fusion Characteristics"></a>Fusion Characteristics</h4><p>受致力于融合不同层生成的特征图的研究成果（如特征金字塔网络（FPN） 和级联 R-CNN [2]）的启发，我们发现<strong>在不同的特征图中检测物体是可能的。例如，FPN 采用自上而下的金字塔结构特征图进行检测。这些网络非常善于复合特征融合的效率</strong>。</p><p>从这些著作中汲取灵感，我们假设兼容融合的汽车<strong>将使用相同的检测模型</strong>。这一点非常重要，因为我们看到只有最可靠的检测模型才会被用于自动驾驶。有了这个假设，我们现在来看看融合的特点</p><h4 id="Compression-and-Transmission"><a href="#Compression-and-Transmission" class="headerlink" title="Compression and Transmission"></a>Compression and Transmission</h4><p>与原始数据相比，特征地图的另一个优势在于车辆之间的传输过程。原始数据可能有多种不同的格式，但它们都能达到一个目的，那就是保留所捕获数据的原始状态。例如，从驾驶过程中获取的激光雷达数据将存储驾驶过程中沿途的所有点云。不过，这种存储格式<strong>会将不必要的数据与基本数据一起记录下来</strong>；而特征地图则避免了这一问题.</p><p>在 CNN 网络处理原始数据的过程中，所有无关数据都会被网络过滤掉，只留下可能被网络用于物体检测的信息。<strong>这些特征图存储在稀疏矩阵中，只存储被认为有用的数据，任何被过滤掉的数据在矩阵中都存储为 0。</strong></p><p>通过<strong>无损压缩（如 gzip 压缩方法），数据大小的优势会进一步扩大，如文献[14]所示。再加上稀疏矩阵的特性，我们就能将二者结合起来，实现压缩后的特征数据不超过 1 MB</strong>，使特征数据成为部署 On-Edge 融合的最佳选择。</p><h4 id="Generic-and-Inherent-Properties"><a href="#Generic-and-Inherent-Properties" class="headerlink" title="Generic and Inherent Properties"></a>Generic and Inherent Properties</h4><p>所有自动驾驶车辆都必须根据传感器生成的数据做出决策。<strong>原始数据由车辆上的物理传感器生成，然后传送到车载计算设备。在那里，原始数据通过基于 CNN 的深度学习网络进行处理，最终做出驾驶决策。</strong>在此过程中，<strong>我们可以提取提取的特征进行共享。这样，我们就能有效地获得原始数据的特征图，而无需额外的计算时间或车载计算设备的功率</strong>。迄今为止，几乎所有已知的自动驾驶车辆都使用了基于 CNN 的网络，因此特征提取是通用的，在融合之前无需进一步处理。</p><p>得益于自动驾驶车辆处理数据的方式，我们能够直接从原始激光雷达点云数据中提取处理后的特征图进行融合，因为这本身就提供了位置数据。<strong>只要激光雷达传感器已经按照自动驾驶所需的标准进行了校准，那么我们就能获得能够保留所有物体与车辆相对位置的特征地图</strong>。</p><p>为了融合两辆汽车的三维特征，设计了两种融合范式：体素特征融合和空间特征融合。在范式 I 中，首先融合两组体素特征，然后生成空间特征图。</p><h3 id="Voxel-Features-Fusion"><a href="#Voxel-Features-Fusion" class="headerlink" title="Voxel Features Fusion"></a>Voxel Features Fusion</h3><p>与位图中的像素一样，体素代表三维空间中规则立方体上的一个数值。在一个体素内，可能有零个或多个由激光雷达传感器生成的点云。对于至少包含一个点的任何体素，VoxelNet 的 VFE 层可以生成一个体素特征</p><p>假设原始激光雷达检测区域被划分为一个体素网格。</p><p>在这些体素中，我们将获得绝大多数空体素，而剩余的体素则包含关键信息。所有非空的体素都会通过一系列全连接层进行转换，并转化为长度为 128 的固定大小的矢量。固定大小的向量通常被称为特征图。</p><blockquote><p>为了提高内存/计算效率，我们将非空体素的特征保存到哈希表中，并将体素坐标作为哈希键。由于我们的重点主要是自动驾驶，因此我们只将非空体素存储到哈希表中。</p></blockquote><p>在 VFF 中，我们明确地将来自两个输入的所有体素的特征结合起来。具体来说，来自汽车 1 的体素 3 和来自汽车 2 的体素 5 共享相同的校准位置。</p><blockquote><p>虽然两辆车的物理位置不同，但它们共享同一个配准的三维空间，不同的偏移量表示每辆车在所述三维标定空间中的相对物理位置。为此，我们采用了element-wise maxout来融合体素 3 和体素 5。</p></blockquote><p><img data-src="https://s2.loli.net/2023/11/30/pKu3lxqZ489NEk2.png" alt="image-20231129091921213"></p><p>受卷积神经网络的启发，使用 maxout 进行潜在规模选择，提取明显的特征，同时抑制对三维空间检测无益的特征，从而实现更小的数据量。在我们的实验中，我们使用 maxout 来决定在比较车辆间的数据时哪个特征最突出。</p><h3 id="Spatial-Feature-Fusion"><a href="#Spatial-Feature-Fusion" class="headerlink" title="Spatial Feature Fusion"></a>Spatial Feature Fusion</h3><p>VFF 需要考虑两辆车所有体素的特征，这涉及车辆之间的大量数据交换。<strong>为了进一步减少网络流量，同时保持基于特征融合的优势，我们设计了一种空间特征融合（SFF）方案</strong>。与 VFF 相比，SFF 融合的是空间特征图，与体素特征图相比，空间特征图更为稀疏，因此更容易压缩以进行通信。</p><p>与 VFF 不同，我们对每辆车上的体素特征进行预处理，以获得空间特征。接下来，将两个源空间特征融合在一起，并将融合后的空间特征转发给 RPN，以进行区域建议和目标检测。</p><p><img data-src="https://s2.loli.net/2023/11/29/W7JioLQIcyADPuk.png" alt="image-20231129210539499"></p><p>特征学习网络的输出是一个稀疏张量，其形状为 128 × 10 × 400 × 352。为了整合所有体素特征，我们采用了三个三维卷积层，依次获得语义信息更多的较小特征图，大小为 64 × 2 × 400 × 352。然而，生成的特征无法满足传统区域建议网络的形状要求。为此，必须将输出重新塑造为 128 × 400 × 352 大小的三维特征图，然后才能将其转发给 RPN。</p><p>对于 SFF，我们生成一个更大的检测范围，大小为 W × H，其中 W &gt; W1，H &gt; H1。接下来，对重叠区域进行融合，同时保留非重叠区域的原始特征。假设 GPS 将汽车 1 的实际位置记录为 (x1，y1)，汽车 2 的实际位置记录为 (x2，y2)，如果 x2 + H1, y2 - W1 2 属于 2 号车的特征图，而左上角代表 1 号车的特征图，那么我们就可以得到左上角的位置。那么我们就很容易确定重叠区域。与 VFF 采用 maxout 策略类似，我们在 SFF 中也采用了 maxout 来融合重叠的空间特征。</p><p><img data-src="https://s2.loli.net/2023/11/29/7O2RQfyAFrawYEJ.png" alt="image-20231129215351930" style="zoom:50%;" /></p><p>最后，我们采用区域建议网络在融合特征图上提出潜在区域。</p><blockquote><p>SENet 等最新研究表明，不同的通道具有不同的权重。也就是说，特征图中的某些通道对分类/检测的贡献更大，而其他通道则是多余或不需要的。</p></blockquote><p>选择从全部 128 个通道中选择部分通道进行传输。我们假定自动驾驶汽车装配了与实际应用中相同的训练有素的检测模型。</p><h3 id="使用融合特征进行目标检测"><a href="#使用融合特征进行目标检测" class="headerlink" title="使用融合特征进行目标检测"></a>使用融合特征进行目标检测</h3><p>为了检测车辆，我们将合成特征图输入区域建议网络（RPN）进行对象建议。然后应用损失函数进行网络训练。</p><h4 id="区域建议网络"><a href="#区域建议网络" class="headerlink" title="区域建议网络"></a>区域建议网络</h4><p>RPN:区域建议网络。不管是采用体素融合范式还是空间融合范式，当我们得到空间特征图后，都会将其送入区域提议网络（RPN）。通过 RPN 网络后，我们将得到两个损失函数的输出结果：</p><p>(1) 提议感兴趣区域的概率分数 p∈ [0, 1]；</p><p>(2) 提议区域的位置 P = (Px , Pw , Pz , Pl , Pw , Ph, Pθ ) ，其中 Px , Py , Pz 表示提议区域的中心，(Pl , Pw , Ph, Pθ ) 分别表示长度、宽度、高度和旋转角度。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>损失函数由两部分组成：分类损失 Lcls 和回归损失 Lreg。</p><p><img data-src="https://img-blog.csdnimg.cn/20190827164053851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E4MTIwNzM0Nzk=,size_16,color_FFFFFF,t_70" alt="img"></p><p>ground-truth bounding box,即gt-box表示为G = Gx , Gy, Gz, Gl , Gw , Gh, Gθ 其中，Gx , Gy , Gz 表示方框的中心点，（Gl , Gw , Gh, Gθ ）分别表示长度、宽度、高度和偏航旋转角</p><p>输出的值包括</p><p><img data-src="https://s2.loli.net/2023/11/29/kgRJEplj1QUroaB.png" alt="image-20231129221138541"></p><p><img data-src="https://s2.loli.net/2023/11/29/NVbn6aGFShDjPke.png" alt="image-20231129225123172"></p><p>损失可以表示为</p><p><img data-src="https://s2.loli.net/2023/11/29/oSfcDkQhd3g1zyF.png" alt="image-20231129225143741"></p><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><strong>KITTI</strong></p><p>由于我们的重点是三维物体检测，因此我们使用了 KITTI 数据集提供的三维 Velodyne 点云数据。</p><p>云点数据<strong>每帧提供 100K 个点</strong>，并存储在二进制浮点矩阵中。<strong>数据包括每个点的三维位置和相关的反射率信息</strong>。<strong>但是，由于 KITTI 数据是由单个车辆记录的，我们必须利用同一记录中的不同时间段来模拟由两辆车生成的数据</strong>。因此，KITTI 数据只适用于某些测试场景。</p><p>为了解决这个问题，我们在两辆名为汤姆和杰瑞（T&amp;J）的车辆上安装了必要的传感器，如激光雷达（Velodyne VLP-16）、摄像头（Allied Vision Mako G-319C）、雷达（Delphi ESR 2.5）、IMU&amp;GPS（Xsens MTi-G-710 套件）和边缘计算设备（Nvidia Drive PX2），以便在我们学校的校园内收集所需的数据。我们的车辆配有 16 波束 Velodyn 激光雷达传感器，以二进制原始以太网数据包的形式存储数据。由于我们的车辆可以相互独立移动，因此我们能够用两辆车在真实环境中测试各种场景。</p><h4 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h4><p>在停车场环境中，我们将距离车辆 20 米以内的物体视为高优先级物体，20 米以外的物体视为低优先级物体。</p><p>由于我们的激光雷达传感器只有 16 个光束，因此与更高端的激光雷达传感器相比，得到的点云数据相对稀疏。为了减轻稀疏数据带来的负面影响，我们将探测范围限制在沿 <strong>X、Y 和 Z 轴[0,70.4]X[-40,40] X [-3,1]</strong> 。我们不使用超出探测范围的数据。除了车辆的检测范围外，我们还<strong>将体素大小设置为 vD = 0.4 米、vH = 0.2 米、vW = 0.2 米，因此 D1 = 10、H1 = 400、W1 = 352</strong>。在我们的实验中，F-Cooper 框架在配备 GeForce GTX 1080 Ti GPU 的计算机上运行。</p><p>为了评估 F-Cooper，我们在实验中收集并测试了 200 多组数据。根据处理激光雷达数据的方法，我们将测试分为四类，方法（1）到（3）均来自相同的检测模型：（1）作为基线的非融合，（2）带有 VFF 的 F-Cooper，（3）带有 SFF 的 F-Cooper，以及（4）原始点云融合方法 - Cooper。特征融合在上述四种情况中随机进行，重点放在繁忙的校园停车场，因为由于遮挡物较多，这是最困难的情况。</p><p>后面结合OpenCood这个项目代码学习学习 <a href="https://github.com/DerrickXuNu/OpenCOOD">ICRA 2022] An opensource framework for cooperative detection. Official implementation for OPV2V. (github.com)</a></p><h3 id="Learning-Distilled-Collaboration-Graph-for-Multi-Agent-Perception-2021"><a href="#Learning-Distilled-Collaboration-Graph-for-Multi-Agent-Perception-2021" class="headerlink" title="Learning Distilled Collaboration Graph for Multi-Agent Perception 2021"></a>Learning Distilled Collaboration Graph for Multi-Agent Perception 2021</h3><h4 id="abs-2"><a href="#abs-2" class="headerlink" title="abs"></a>abs</h4><p>为了促进多智能体感知更好的性能-带宽权衡，我们提出了一种新的提取协作图（DiscoGraph）来建模智能体之间的可训练、姿势感知和自适应协作。我们的主要新颖之处在于两个方面。</p><h2 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h2><p>目前找到的数据集还是不少的.</p><h3 id="OPV2V-2022"><a href="#OPV2V-2022" class="headerlink" title="OPV2V 2022"></a>OPV2V 2022</h3><p>推出了首个大规模开放式车对车感知模拟数据集。该数据集包含 70 多个有趣的场景、11,464 个帧和 232,913 个注释三维车辆边界框，<strong>收集自 CARLA 的 8 个城镇和洛杉矶卡尔弗城的一个数字城镇</strong>。然后，我们构建了一个包含 16 个实施模型的综合基准，以评估几种信息融合策略（即早期、后期和中间融合）与最先进的激光雷达检测算法。</p><h3 id="V2XSet-2022"><a href="#V2XSet-2022" class="headerlink" title="V2XSet 2022"></a>V2XSet 2022</h3><p>研究了如何应用 “车对物”（V2X）通信来提高自动驾驶汽车的感知性能。我们利用新颖的视觉转换器（Vision Transformer）提出了一个具有 V2X 通信功能的稳健合作感知框架。具体来说，我们建立了一个整体注意力模型，即 V2X-ViT，以有效融合道路代理（即车辆和基础设施）之间的信息。V2X-ViT 由异构多代理自我注意和多尺度窗口自我注意交替层组成，可捕捉代理间的交互和每个代理的空间关系。这些关键模块采用统一的 Transformer 架构设计，以应对常见的 V2X 挑战，包括异步信息共享、姿势错误和 V2X 组件的异构性。</p><p>车与道路  CARLA和OPENCDA创建的模拟数据集</p><h3 id="DAIR-V2X-2022"><a href="#DAIR-V2X-2022" class="headerlink" title="DAIR-V2X 2022"></a>DAIR-V2X 2022</h3><p>为了加速车辆-基础设施协同自动驾驶（VICAD）的计算机视觉研究和创新，我们发布了 DAIR-V2X 数据集，这是<strong>首个用于 VICAD 的大规模、多模态、多视角真实场景数据集</strong>。</p><h3 id="V2X-Sim-2022"><a href="#V2X-Sim-2022" class="headerlink" title="V2X-Sim 2022"></a>V2X-Sim 2022</h3><p>车对物（V2X）通信技术实现了车辆与邻近环境中许多其他实体之间的协作，可以从根本上改善自动驾驶的感知系统。然而，公共数据集的缺乏极大地限制了协同感知的研究进展。为了填补这一空白，我们提出了 V2X-Sim—一个<strong>用于 V2X 辅助自动驾驶的综合模拟多代理感知数据集</strong>。V2XSim 提供：（1）来自路边装置（RSU）和多辆车的多代理传感器记录，可实现协同感知；（2）多模态传感器流，可促进多模态感知；以及（3）多种地面实况，可支持各种感知任务。同时，我们建立了一个开源测试平台，并在检测、跟踪和分割等三个任务上为最先进的协同感知算法提供了基准。V2X-Sim 试图在现实数据集广泛可用之前，促进自动驾驶的协同感知研究。</p><h3 id="V2V4Real-2023"><a href="#V2V4Real-2023" class="headerlink" title="V2V4Real 2023"></a>V2V4Real 2023</h3><p>最近的研究表明，车对车（V2V）协同感知系统在彻底改变自动驾驶行业方面具有巨大潜力。然而，真实世界数据集的缺乏阻碍了这一领域的发展。为了促进协同感知的发展，我们提出了 V2V4Real，这是首个<strong>大规模真实世界多模态 V2V 感知数据集</strong>。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;除了3D&lt;strong&gt;目标检测&lt;/strong&gt;算法外,自动驾驶还需要将获取到的图像数据或者处理后的特征进行&lt;strong&gt;通信&lt;/strong&gt;和&lt;strong&gt;融合&lt;/strong&gt;,这里介绍相关论文.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>type hints in Python</title>
    <link href="https://www.sekyoro.top/2023/11/24/tip-types-in-python/"/>
    <id>https://www.sekyoro.top/2023/11/24/tip-types-in-python/</id>
    <published>2023-11-24T13:38:14.000Z</published>
    <updated>2023-11-29T11:47:54.547Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Python中的类型系统,使用type hints使得整个开发过程更加顺畅.类似typescript的目的.<br><span id="more"></span></p><h2 id="Type-Theory"><a href="#Type-Theory" class="headerlink" title="Type Theory"></a>Type Theory</h2><p>值得一提的是python目前还在蒸蒸日上,所以一些东西后面可能会有些改变,不过答题的东西是不变的,可以使用mypy<a href="https://github.com/python/mypy">python/mypy: Optional static typing for Python (github.com)</a>(或者pyright<a href="https://github.com/microsoft/pyright">microsoft/pyright: Static Type Checker for Python (github.com)</a>)进行检查,可以使用<a href="https://docs.pydantic.dev/latest/">Welcome to Pydantic - Pydantic</a>作为数据验证,大多数IDE本身也对这个默认支持.</p><p><a href="https://www.python.org/dev/peps/pep-0483/">PEP 483</a> 是这一切的起点.</p><h3 id="Subtypes"><a href="#Subtypes" class="headerlink" title="Subtypes"></a>Subtypes</h3><p>一个重要的概念是subtypes(亚型)。</p><p>形式上，如果以下两个条件成立，我们说T型是U的subtypes：</p><ul><li>来自T的每个值也在U类型的值集合中。</li><li>来自U型的每个函数也在T型函数的集合中。</li></ul><p>这两个条件保证了即使类型T与U不同，类型T的变量也可以总是假装为U。</p><blockquote><p>举个具体的例子，考虑T=bool和U=int。bool类型只取两个值。通常这些名称表示为True和False，但这些名称分别只是整数值1和0的别名：</p></blockquote><h3 id="Covariant-Contravariant-and-Invariant"><a href="#Covariant-Contravariant-and-Invariant" class="headerlink" title="Covariant, Contravariant, and Invariant"></a>Covariant, Contravariant, and Invariant</h3><p>在复合类型中使用子类型时会发生什么？例如，Tuple[bool]是Tuple[int]的一个子类型吗？答案取决于复合类型，以及该类型是协变(Covariant)的、反变(Contravariant)的还是不变(Invariant)的。</p><ul><li>元组是协变(Covariant)的。这意味着它保留了其项类型的类型层次结构：Tuple[bool]是Tuple[int]的子类型，因为bool是int的子类型。</li><li>列表是不变(Invariant)的。不变类型不能保证子类型。虽然List[bool]的所有值都是List[int]的值，但您可以将int附加到List[int]，而不是List[bool。换句话说，子类型的第二个条件不成立，并且List[bool]不是List[int]的子类型。</li><li>Callable在其参数中是反变(Contravariant)的。这意味着它颠倒了类型层次结构。若Callable[[T]，…]作为一个函数，它唯一的参数是T类型。Callable的一个例子[[int]，…]是double()函数。反变意味着，如果期望一个在布尔上操作的函数，那么一个在int上操作的功能是可以接受的。</li></ul><h3 id="内置类型"><a href="#内置类型" class="headerlink" title="内置类型"></a>内置类型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x: <span class="built_in">int</span> = <span class="number">1</span></span><br><span class="line">x: <span class="built_in">float</span> = <span class="number">1.0</span></span><br><span class="line">x: <span class="built_in">bool</span> = <span class="literal">True</span></span><br><span class="line">x: <span class="built_in">str</span> = <span class="string">&quot;test&quot;</span></span><br><span class="line">x: <span class="built_in">bytes</span> = <span class="string">b&quot;test&quot;</span></span><br></pre></td></tr></table></figure><p>在3.8及之前,使用<code>from typing import List,Dict,Set,Tuple</code>  来使用collections,之后可以直接使用list,dict这种.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x: <span class="built_in">list</span>[<span class="built_in">int</span>] = []</span><br><span class="line">x: <span class="built_in">tuple</span>[<span class="built_in">int</span>,...] = (<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">x: <span class="built_in">set</span>[<span class="built_in">int</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line">x: <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>] = &#123;<span class="string">&quot;field&quot;</span>: <span class="number">2.0</span>, <span class="string">&quot;field2&quot;</span>: <span class="string">&quot;a&quot;</span>&#125;</span><br></pre></td></tr></table></figure><p>在3.10+,可以直接使用<code>|</code>代替Union</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x: <span class="built_in">list</span>[<span class="built_in">int</span>|<span class="built_in">str</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="string">&quot;a&quot;</span>]</span><br><span class="line">x: <span class="type">Optional</span>[<span class="built_in">str</span>]</span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">x: <span class="type">Callable</span>[[<span class="built_in">int</span>], <span class="built_in">str</span>] = stringify</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen</span>(<span class="params">n: <span class="built_in">int</span></span>) -&gt; Iterator[<span class="built_in">int</span>]:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">yield</span> i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_email</span>(<span class="params">address: <span class="type">Union</span>[<span class="built_in">str</span>,<span class="built_in">list</span>[<span class="built_in">str</span>],<span class="literal">None</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">    ...</span><br><span class="line"><span class="comment"># This says each positional arg and each keyword arg is a &quot;str&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, *args: <span class="built_in">str</span>, **kwargs: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">    reveal_type(args)  <span class="comment"># Revealed type is &quot;tuple[str, ...]&quot;</span></span><br><span class="line">    reveal_type(kwargs)  <span class="comment"># Revealed type is &quot;dict[str, str]&quot;</span></span><br><span class="line">    request = make_request(*args, **kwargs)</span><br><span class="line">    <span class="keyword">return</span> self.do_api_query(request)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quux</span>(<span class="params">x: <span class="built_in">int</span>,/, y: <span class="built_in">str</span>, z: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">quux(<span class="number">1</span>, <span class="string">&#x27;2&#x27;</span>, z=<span class="number">3.0</span>)</span><br></pre></td></tr></table></figure><blockquote><p>如果你想要函数的调用者在某个参数位置只能使用位置参数而不能使用关键字参数传参，那么你只需要在所需位置后面放置一个/。</p><p>如果你希望强迫调用者使用某些参数，且必须以关键字参数的形式传参，那么你只需要在所需位置的前一个位置放置一个*。</p></blockquote><h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> ClassVar</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BankAccount</span>:</span></span><br><span class="line">    account_name: <span class="built_in">str</span></span><br><span class="line">    balance: <span class="built_in">float</span></span><br><span class="line">    </span><br><span class="line">    count: ClassVar</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, account_name: <span class="built_in">str</span>, initial_balance: <span class="built_in">float</span> = <span class="number">0.0</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.account_name = account_name</span><br><span class="line">        self.balance = initial_balance</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deposit</span>(<span class="params">self, amount: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.balance += amount</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">withdraw</span>(<span class="params">self, amount: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.balance -= amount</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuditedBankAccount</span>(<span class="params">BankAccount</span>):</span></span><br><span class="line">    audit_log: <span class="built_in">list</span>[<span class="built_in">str</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, account_name: <span class="built_in">str</span>, initial_balance: <span class="built_in">float</span> = <span class="number">0.0</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(account_name, initial_balance)</span><br><span class="line">        self.audit_log = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deposit</span>(<span class="params">self, amount: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.audit_log.append(<span class="string">f&quot;Deposited <span class="subst">&#123;amount&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">withdraw</span>(<span class="params">self, amount: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.audit_log.append(<span class="string">f&quot;Withdrew <span class="subst">&#123;amount&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># You can use the ClassVar annotation to declare a class variable</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Car</span>:</span></span><br><span class="line">    seats: ClassVar[<span class="built_in">int</span>] = <span class="number">4</span></span><br><span class="line">    passengers: ClassVar[<span class="built_in">list</span>[<span class="built_in">str</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setattr__</span>(<span class="params">self, key, value</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Setting&quot;</span>, key, <span class="string">&quot;to&quot;</span>, value)</span><br><span class="line">        self.__dict__[key] = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span>(<span class="params">self, key</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Getting&quot;</span>, key)</span><br><span class="line">        <span class="keyword">return</span> self.__dict__[key]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">A</span>):</span></span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br><span class="line">    weight: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name: <span class="built_in">str</span>, age: <span class="built_in">int</span>, weight: <span class="built_in">float</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.weight = weight</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = Person(<span class="string">&quot;John&quot;</span>, <span class="number">30</span>, <span class="number">80.0</span>)</span><br><span class="line"><span class="built_in">print</span>(p.name)</span><br></pre></td></tr></table></figure><h3 id="Forward-references"><a href="#Forward-references" class="headerlink" title="Forward references"></a>Forward references</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># You may want to reference a class before it is defined.</span></span><br><span class="line"><span class="comment"># This is known as a &quot;forward reference&quot;.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">foo: A</span>) -&gt; <span class="built_in">int</span>:</span>  <span class="comment"># This will fail at runtime with &#x27;A&#x27; is not defined</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># However, if you add the following special import:</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> annotations</span><br><span class="line"><span class="comment"># It will work at runtime and type checking will succeed as long as there</span></span><br><span class="line"><span class="comment"># is a class of that name later on in the file</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">foo: A</span>) -&gt; <span class="built_in">int</span>:</span>  <span class="comment"># Ok</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Another option is to just put the type in quotes</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">foo: <span class="string">&#x27;A&#x27;</span></span>) -&gt; <span class="built_in">int</span>:</span>  <span class="comment"># Also ok</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="comment"># This can also come up if you need to reference a class in a type</span></span><br><span class="line">    <span class="comment"># annotation inside the definition of that class</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create</span>(<span class="params">cls</span>) -&gt; A:</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><h3 id="Decorators"><a href="#Decorators" class="headerlink" title="Decorators"></a>Decorators</h3><p>decorator通常是将一个函数作为参数并返回另一个函数的函数。</p><p>用类型来描述这种行为可能有点棘手；我们将展示如何使用TypeVar和一种称为参数规范的特殊类型变量来实现这一点。</p><p>假设我们有装饰器，尚未进行类型注释，它保留了原始函数的签名，只打印装饰函数的名称：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_decorator</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args, **kwds</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Calling&quot;</span>, func)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwds)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure><p>给这个装饰器类型注释</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypeVar, <span class="type">Callable</span>, cast, <span class="type">Any</span></span><br><span class="line">F = TypeVar(<span class="string">&quot;F&quot;</span>, bound=<span class="type">Callable</span>[..., <span class="type">Any</span>])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_decorator</span>(<span class="params">func: F</span>) -&gt; F:</span></span><br><span class="line"><span class="meta">    @wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args: <span class="type">Any</span>, **kwargs: <span class="type">Any</span></span>) -&gt; <span class="type">Any</span>:</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Calling&quot;</span>, func.__name__)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line">    <span class="keyword">return</span> cast(F, wrapper)</span><br></pre></td></tr></table></figure><p>这仍然存在一些不足。首先，我们需要使用不安全的cast()来说服mypy wrapper()与func具有相同的签名。其次，wrapper()函数没有经过严格的类型检查，尽管wrapper函数通常足够小，所以这不是什么大问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Callable</span>, TypeVar</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> ParamSpec</span><br><span class="line"></span><br><span class="line">P = ParamSpec(<span class="string">&#x27;P&#x27;</span>)</span><br><span class="line">T = TypeVar(<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_decorator</span>(<span class="params">func: <span class="type">Callable</span>[P, T]</span>) -&gt; <span class="type">Callable</span>[P, T]:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args: P.args, **kwds: P.kwargs</span>) -&gt; T:</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Calling&quot;</span>, func)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwds)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure><p>可以使用参数规范（ParamSpec）来获得更好的类型注释：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypeVar, <span class="type">Callable</span>, <span class="type">Any</span>,ParamSpec</span><br><span class="line">P = ParamSpec(<span class="string">&quot;P&quot;</span>)</span><br><span class="line">T = TypeVar(<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_decorator</span>(<span class="params">func: <span class="type">Callable</span>[P,T]</span>) -&gt; <span class="type">Callable</span>[P,T]:</span></span><br><span class="line"><span class="meta">    @wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args: P.args, **kwargs: P.kwargs</span>) -&gt; <span class="type">Any</span>:</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Calling&quot;</span>, func.__name__)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure><p>参数规范还允许描述更改输入函数签名的装饰器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Callable</span>, TypeVar</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> Concatenate, ParamSpec</span><br><span class="line"></span><br><span class="line">P = ParamSpec(<span class="string">&#x27;P&#x27;</span>)</span><br><span class="line">T = TypeVar(<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># We reuse &#x27;P&#x27; in the return type, but replace &#x27;T&#x27; with &#x27;str&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stringify</span>(<span class="params">func: <span class="type">Callable</span>[P, T]</span>) -&gt; <span class="type">Callable</span>[P, <span class="built_in">str</span>]:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">*args: P.args, **kwds: P.kwargs</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(func(*args, **kwds))</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta"> @stringify</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">add_forty_two</span>(<span class="params">value: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">     <span class="keyword">return</span> value + <span class="number">42</span></span><br><span class="line"></span><br><span class="line"> a = add_forty_two(<span class="number">3</span>)</span><br><span class="line"> reveal_type(a)      <span class="comment"># Revealed type is &quot;builtins.str&quot;</span></span><br><span class="line"> add_forty_two(<span class="string">&#x27;x&#x27;</span>)  <span class="comment"># error: Argument 1 to &quot;add_forty_two&quot; has incompatible type &quot;str&quot;; expected &quot;int&quot;</span></span><br><span class="line"></span><br><span class="line">P = ParamSpec(<span class="string">&#x27;P&#x27;</span>)</span><br><span class="line">T = TypeVar(<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_decorator</span>(<span class="params">func: <span class="type">Callable</span>[P, T]</span>) -&gt; <span class="type">Callable</span>[Concatenate[<span class="built_in">str</span>, P], T]:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">msg: <span class="built_in">str</span>, /, *args: P.args, **kwds: P.kwargs</span>) -&gt; T:</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Calling&quot;</span>, func, <span class="string">&quot;with&quot;</span>, msg)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwds)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@printing_decorator</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_forty_two</span>(<span class="params">value: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">    <span class="keyword">return</span> value + <span class="number">42</span></span><br><span class="line"></span><br><span class="line">a = add_forty_two(<span class="string">&#x27;three&#x27;</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Any</span>, <span class="type">Callable</span>, TypeVar</span><br><span class="line"></span><br><span class="line">F = TypeVar(<span class="string">&#x27;F&#x27;</span>, bound=<span class="type">Callable</span>[..., <span class="type">Any</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bare_decorator</span>(<span class="params">func: F</span>) -&gt; F:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decorator_args</span>(<span class="params">url: <span class="built_in">str</span></span>) -&gt; <span class="type">Callable</span>[[F], F]:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><h3 id="Generics"><a href="#Generics" class="headerlink" title="Generics"></a>Generics</h3><p>内置集合类是泛型类。泛型类型有一个或多个类型参数，这些参数可以是任意类型。例如，dict[int，str]具有类型参数int和str，list[int]具有类型形参int。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypeVar, <span class="type">Generic</span></span><br><span class="line"></span><br><span class="line">T = TypeVar(<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stack</span>(<span class="params"><span class="type">Generic</span>[T]</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># Create an empty list with items of type T</span></span><br><span class="line">        self.items: <span class="built_in">list</span>[T] = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span>(<span class="params">self, item: T</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.items.append(item)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span>(<span class="params">self</span>) -&gt; T:</span></span><br><span class="line">        <span class="keyword">return</span> self.items.pop()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">empty</span>(<span class="params">self</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.items</span><br></pre></td></tr></table></figure><blockquote><p>类ClassName（Protocol[T]）被允许作为类ClassName的简写class ClassName(Protocol, Generic[T])</p></blockquote><h3 id="TypedDict"><a href="#TypedDict" class="headerlink" title="TypedDict"></a>TypedDict</h3><p>Python程序经常使用带有字符串键的字典来表示对象。TypedDict允许您为表示具有固定架构的对象的字典提供精确的类型，例如｛’id’：1，’items’：〔’x’〕｝。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line">Movie = TypedDict(<span class="string">&#x27;Movie&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="built_in">str</span>, <span class="string">&#x27;year&#x27;</span>: <span class="built_in">int</span>&#125;)</span><br><span class="line"></span><br><span class="line">movie: Movie = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Blade Runner&#x27;</span>, <span class="string">&#x27;year&#x27;</span>: <span class="number">1982</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Movie</span>(<span class="params">TypedDict</span>):</span></span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    year: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookBasedMovie</span>(<span class="params">Movie</span>):</span></span><br><span class="line">    based_on: <span class="built_in">str</span></span><br></pre></td></tr></table></figure><h3 id="Literal"><a href="#Literal" class="headerlink" title="Literal"></a>Literal</h3><p>Literal类型可以指示表达式等于某个特定的primitive 值。</p><p>例如，如果我们用Literal[“foo”]类型注释一个变量，mypy将理解该变量不仅是str类型的，而且具体地等于字符串“foo”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Final, <span class="type">Literal</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expects_literal</span>(<span class="params">x: <span class="type">Literal</span>[<span class="number">19</span>]</span>) -&gt; <span class="literal">None</span>:</span> <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">reveal_type(<span class="number">19</span>)</span><br><span class="line">expects_literal(<span class="number">19</span>)</span><br></pre></td></tr></table></figure><h3 id="更多类型"><a href="#更多类型" class="headerlink" title="更多类型"></a>更多类型</h3><ul><li>NoReturn可以告诉mypy函数永远不会正常返回。</li><li>NewType允许您定义类型的变体，该变体被mypy视为单独的类型，但在运行时与原始类型相同。例如，您可以将UserId作为int的一个变体，它在运行时只是一个int。</li><li>@overload允许您定义一个可以接受多个不同签名的函数。如果您需要对难以正常表达的参数和返回类型之间的关系进行编码，这将非常有用。</li><li>Async 类型允许您使用异步和等待来键入检查程序。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> NoReturn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stop</span>() -&gt; NoReturn:</span></span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">&#x27;no way&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> NewType</span><br><span class="line"></span><br><span class="line">UserId = NewType(<span class="string">&#x27;UserId&#x27;</span>, <span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">name_by_id</span>(<span class="params">user_id: UserId</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">UserId(<span class="string">&#x27;user&#x27;</span>)          <span class="comment"># Fails type check</span></span><br><span class="line"></span><br><span class="line">name_by_id(<span class="number">42</span>)          <span class="comment"># Fails type check</span></span><br><span class="line">name_by_id(UserId(<span class="number">42</span>))  <span class="comment"># OK</span></span><br><span class="line"></span><br><span class="line">num: <span class="built_in">int</span> = UserId(<span class="number">5</span>) + <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://realpython.com/python-type-checking/#type-theory">Python Type Checking (Guide) – Real Python</a></li><li><a href="https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html">Type hints cheat sheet - mypy 1.7.1 documentation</a></li><li><a href="https://python-type-challenges.zeabur.app/">https://python-type-challenges.zeabur.app/</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Python中的类型系统,使用type hints使得整个开发过程更加顺畅.类似typescript的目的.&lt;br&gt;</summary>
    
    
    
    
    <category term="python" scheme="https://www.sekyoro.top/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>图像读取与显示的问题</title>
    <link href="https://www.sekyoro.top/2023/11/16/%E5%9B%BE%E5%83%8F%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://www.sekyoro.top/2023/11/16/%E5%9B%BE%E5%83%8F%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2023-11-16T11:01:33.000Z</published>
    <updated>2023-11-16T14:26:23.920Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>最近在用opencv和matplotlib展示图片,但是遇到了一些问题,这里展开说说<br><span id="more"></span></p><p>首先需要明确的是,opencv和matplotlib读取图片都是通道在最后,而前者默认可见光图像是BGR,后者是RGB.此外还有PIL以及imageio等读取图像的工具,这里不一一赘述.</p><h2 id="Opencv"><a href="#Opencv" class="headerlink" title="Opencv"></a>Opencv</h2><p>对于opencv,使用<code>cv2.imshow</code>,<code>cv2.imread</code>以及<code>cv2.imwrite</code>来读写以及显示.</p><h3 id="imshow"><a href="#imshow" class="headerlink" title="imshow"></a>imshow</h3><blockquote><p>显示图像的缩放取决于图像深度：<br>对 8 位无符号图像，按原样显示；<br>对 16 位无符号或 32 位整数图像，将像素值范围 [0,255*255] 映射到 [0,255] 显示；<br>对 32 位浮点图像，将像素值范围 [0,1] 映射到 [0,255] 显示；</p></blockquote><p>当cv2.imshow()处理图像深度为CV_8U（默认范围为[0,255]）时，按原数据显示；</p><p>当处理图像深度为CV_16U（默认范围为[0,65535]）时，除以256,映射到[0,255]；</p><p>当图像深度为CV_32F和CV_64F时（默认范围为[0,1]），乘以255映射到[0,255],超过255直接饱和；</p><p><strong>当输入负数时，当作0来处理</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = np.zeros((<span class="number">500</span>, <span class="number">500</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(img.dtype)</span><br><span class="line">img[<span class="number">150</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">10</span></span><br><span class="line">img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>] = -<span class="number">1</span></span><br><span class="line">img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>] = -<span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(img[<span class="number">350</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>])</span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><p>由于numpy默认类型float64,浮点数会乘以255,所以只有最上面有一条白线.负值直接黑色</p><p><img data-src="https://i.imgur.com/80ELhGP.png" alt="image-20231116201141606" style="zoom:50%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 新建numpy数组，注意np.zero()创建的数据类型为float64</span></span><br><span class="line">img = np.zeros((<span class="number">500</span>, <span class="number">500</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(img.dtype)</span><br><span class="line">img[<span class="number">150</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">10</span></span><br><span class="line">img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">255</span></span><br><span class="line">img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(img[<span class="number">350</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>])</span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><p><img data-src="C:\Users\proanimer\AppData\Roaming\Typora\typora-user-images\image-20231116201615437.png" alt="image-20231116201615437" style="zoom:50%;" /></p><p>而如果是大于1的浮点数,也是直接饱和.</p><p>如果是uint8,如果超出255,则会被numpy截取,也就是取模</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">img = np.zeros((<span class="number">500</span>, <span class="number">500</span>, <span class="number">1</span>),dtype=np.uint8)</span><br><span class="line"><span class="built_in">print</span>(img.dtype)</span><br><span class="line">img[<span class="number">150</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">10</span></span><br><span class="line">img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">20</span></span><br><span class="line">img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">30</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line"><span class="built_in">print</span>(img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>])</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><p><img data-src="https://i.imgur.com/tL7jHo0.png" alt="image-20231116201823217" style="zoom:50%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">img = np.zeros((<span class="number">500</span>, <span class="number">500</span>, <span class="number">1</span>),dtype=np.uint8)</span><br><span class="line"><span class="built_in">print</span>(img.dtype)</span><br><span class="line">img[<span class="number">150</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">10</span></span><br><span class="line">img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>] =  <span class="number">512</span></span><br><span class="line">img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">255</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line"><span class="built_in">print</span>(img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>])</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><p>打印img[250:270, 150:350]的值发现是0</p><p><img data-src="https://i.imgur.com/B39iVFz.png" alt="image-20231116202123379" style="zoom:50%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">img = np.zeros((<span class="number">500</span>, <span class="number">500</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(img.dtype)</span><br><span class="line">img[<span class="number">150</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">10</span></span><br><span class="line">img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>] =  <span class="number">512</span></span><br><span class="line">img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">255</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line"><span class="built_in">print</span>(img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>])</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><p><img data-src="https://i.imgur.com/QT0dMuS.png" alt="image-20231116202222468" style="zoom:50%;" /></p><p>所以这涉及两个问题,一个是本身numpy的截取另一个是opencv的截取机制.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">img = np.zeros((<span class="number">500</span>, <span class="number">500</span>, <span class="number">1</span>), dtype=np.uint16)</span><br><span class="line"><span class="built_in">print</span>(img.dtype)</span><br><span class="line">img[<span class="number">150</span>:<span class="number">170</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">2</span></span><br><span class="line">img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">255</span>*<span class="number">255</span></span><br><span class="line">img[<span class="number">350</span>:<span class="number">370</span>, <span class="number">150</span>:<span class="number">350</span>] = <span class="number">255</span>*<span class="number">100</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(img[<span class="number">250</span>:<span class="number">270</span>, <span class="number">150</span>:<span class="number">350</span>])</span><br><span class="line">cv2.imwrite(<span class="string">&quot;test.png&quot;</span>, img)</span><br></pre></td></tr></table></figure><p><img data-src="https://i.imgur.com/92aVQEA.png" alt="image-20231116202916344" style="zoom:50%;" /></p><p>如果是16位无符号整数,会除以255.</p><p>最后注意,如果是int32可能会报错</p><h3 id="imwrite"><a href="#imwrite" class="headerlink" title="imwrite"></a>imwrite</h3><p>机制与imshow类似,不过会根据保存文件的后缀进行编码参数.</p><p>cv2.imwrite() 能保存 BGR 3通道图像，或 8 位单通道图像、或 PNG/JPEG/TIFF 16位无符号单通道图像</p><p><strong>注意</strong>:如果保存float32的图像值超过了1,此时会与imshow机制不同,表现为值被归到0-255</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones([<span class="number">255</span>,<span class="number">255</span>,<span class="number">1</span>],dtype=np.float32)</span><br><span class="line">a[<span class="number">0</span>:<span class="number">255</span>,<span class="number">0</span>:<span class="number">255</span>] = <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">cv2.imshow(<span class="string">&quot;img&quot;</span>,a)</span><br><span class="line">cv2.waitKey()</span><br><span class="line">cv2.imwrite(<span class="string">&quot;test.png&quot;</span>,a)</span><br></pre></td></tr></table></figure><p><img data-src="C:\Users\proanimer\AppData\Roaming\Typora\typora-user-images\image-20231116222050856.png" alt="image-20231116222050856"></p><p><img data-src="https://i.imgur.com/kwtCm9Z.png" alt="image-20231116222107874"></p><p>上面有两张图,分别是imwrite的图片与imshow的图片,由于是浮点数,imshow展示时乘了255导致饱和白色.所以会说imwrite对浮点数不友好,不符合imshow的道理,</p><h3 id="imread"><a href="#imread" class="headerlink" title="imread"></a>imread</h3><p>注意如果有通道则通道在最后,可以设置</p><blockquote><p>IMREAD_UNCHANGED            = -1, //如果设置，则返回的数据带有alpha通道（R,G,B,A 四个通道），否则没有alpha通道<br>      IMREAD_GRAYSCALE            = 0,  //如果设置，则将图像转换为单通道灰度图像<br>      IMREAD_COLOR                = 1,  //如果设置，则将图像转换成3通道BGR彩色图像<br>      IMREAD_ANYDEPTH             = 2,  //如果设置，则在输入具有相应深度时返回16位/32位图像，否则将其转换为8位<br>      IMREAD_ANYCOLOR             = 4,  //如果设置，则图像可能以任何颜色格式读取<br>      IMREAD_LOAD_GDAL            = 8,  //如果设置，使用gdal驱动程序加载图像<br>      IMREAD_REDUCED_GRAYSCALE_2  = 16, //如果设置，总是将图像转换为单通道灰度图像且图像大小减少1/2<br>      IMREAD_REDUCED_COLOR_2      = 17, //如果设置，总是将图像转换为3通道BGR彩色图像且图像大小减少1/2<br>      IMREAD_REDUCED_GRAYSCALE_4  = 32, //如果设置，总是将图像转换为单通道灰度图像且图像大小减少1/4<br>      IMREAD_REDUCED_COLOR_4      = 33, //如果设置，总是将图像转换为3通道BGR彩色图像且图像大小减少1/4<br>      IMREAD_REDUCED_GRAYSCALE_8  = 64, //如果设置，总是将图像转换为单通道灰度图像且图像大小减少1/8<br>      IMREAD_REDUCED_COLOR_8      = 65, //如果设置，总是将图像转换为3通道BGR彩色图像且图像大小减少1/8<br>      IMREAD_IGNORE_ORIENTATION   = 128 //如果设置，不会根据EXIF的方向标志旋转图像</p></blockquote><h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><h3 id="imshow-1"><a href="#imshow-1" class="headerlink" title="imshow"></a>imshow</h3><p>主要讲讲matplotlib的imshow</p><blockquote><p>matplotlib在imshow时，如果接收到的是二维矩阵，会自动归一化，映射到彩色。如果输入的矩阵里面值都是一样的，归一化会把他们全部变为255，也就是呈现黑色。</p></blockquote><p>用于在使用 cmap 映射到颜色之前将标量数据缩放到 [0, 1] 范围的归一化方法。默认情况下，使用线性缩放，将最低值映射到 0，将最高值映射到 1。</p><p>imshow的输入</p><blockquote><p>图像数据。支持的数组形状有：(M,N)：具有标量数据的图像。使用归一化和颜色图将值映射到颜色。请参阅参数norm、cmap、vmin、vmax。</p><p>(M, N, 3)：具有 RGB 值（0-1 float 或 0-255 int）的图像。</p><p>(M, N, 4)：具有 RGBA 值（0-1 float 或 0-255 int）的图像，即包括透明度。前两个维度（M、N）定义图像的行和列。超出范围的 RGB(A) 值将被剪裁。</p></blockquote><p>所以如果使用单通道的数据,会默认norm,而这种norm是根据输入值的min-max进行norm,并不是norm到0-255</p><p><img data-src="https://i.imgur.com/1zK0cLv.png" alt="image-20231116210309620"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img = torch.ones(<span class="number">152</span>,<span class="number">152</span>,<span class="number">1</span>,dtype=torch.uint8)*<span class="number">220</span></span><br><span class="line">img = img.numpy()</span><br><span class="line">plt.imshow(img,cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>解决办法是设置vmin=0,vmax=255,当然使用三通道也可以</p><p><img data-src="https://i.imgur.com/4gWVsnC.png" alt="image-20231116210559535"></p><h3 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h3><ol><li><a href="https://blog.csdn.net/zjh12312311/article/details/116209353">matplotlib 可视化图像明明255，结果出来全为黑色的问题<em>plt.imshow 不加vmin和vmax参数是全黑的</em>佳hong的博客-CSDN博客</a></li><li><a href="https://blog.csdn.net/weixin_42216109/article/details/89707220">有关函数cv2.imshow()处理不同图像深度时的数据转化问题_cv2.cv_8u图像深度-CSDN博客</a>这篇文章有点问题,目前opencv将负值作为0处理</li><li><a href="https://www.cnblogs.com/siren27/p/12738571.html">opencv中imwrite对float的处理 - siren27 - 博客园 (cnblogs.com)</a></li><li><a href="https://blog.csdn.net/m0_37579176/article/details/105460265">【精选】使用 tiff/png 文件类型对 uint16_t/float 数据类型存取的无聊实验_float存储方式和uint16-CSDN博客</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在用opencv和matplotlib展示图片,但是遇到了一些问题,这里展开说说&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>transformer family(一):from Bahdanau Attention to transformers</title>
    <link href="https://www.sekyoro.top/2023/11/08/transformer-and-attention/"/>
    <id>https://www.sekyoro.top/2023/11/08/transformer-and-attention/</id>
    <published>2023-11-08T03:14:00.000Z</published>
    <updated>2024-01-23T12:42:28.743Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><del>流行的深度学习模型,其中的思想以及模型在后面其他任务中也经常使用,所以这里介绍一些常用好用的模型.</del>主要介绍attention和transformer系列.</p><span id="more"></span><h2 id="Attention-Is-All-You-Need"><a href="#Attention-Is-All-You-Need" class="headerlink" title="Attention Is All You Need"></a>Attention Is All You Need</h2><h3 id="abs"><a href="#abs" class="headerlink" title="abs"></a>abs</h3><p>主流的序列转换模型基于<strong>复杂的递归或卷积神经网络</strong>，其中<strong>包括一个编码器和一个解码器</strong>。性能最好的模型还通过注意力机制将编码器和解码器连接起来。我们提出了一种新的简单网络架构—“transformer”，它<strong>完全基于注意力机制，无需递归和卷积</strong>。</p><h3 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h3><p>递归神经网络，特别是长短期记忆和门控递归神经网络，已被牢固确立为语言建模和机器翻译等序列建模和转译问题的最先进方法。自此以后，许多人继续努力推动递归语言模型和编码器-解码器架构的发展。</p><p>递归模型通常按照输入和输出序列的符号位置进行计算。将位置与计算时间的步长对齐，它们会生成隐藏状态 h~t~ 的序列，作为前一个隐藏状态 h~t-1~ 和位置 t 的输入的函数。<strong>这种固有的序列性质排除了训练实例内的并行化，而在序列长度较长时，这一点变得至关重要，因为内存约束限制了跨实例的批处理。</strong>最近的研究通过因式分解技巧和条件计算显著提高了计算效率，同时也改善了后者的模型性能。然而，顺序计算的基本限制仍然存在。</p><p>在各种任务中，注意力机制已成为引人注目的序列建模和转导模型的一个组成部分，它可以对依赖关系进行建模，而无需考虑其在输入或输出序列中的距离。然而，除了少数情况，这种注意机制都是与递归网络结合使用的。</p><blockquote><p>比如下图,利用一个双向RNN得到每个token的状态,利用一个简单的ffn聚合这些状态作为输出token的上一个状态</p></blockquote><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/images/encoder-decoder-attention.png" alt="Image showing an encoder/decoder model with an additive attention layer"></p><p>在这项工作中，我们提出了 Transformer 模型架构，<strong>它摒弃了递归</strong>，<strong>而是完全依赖注意力机制来绘制输入和输出之间的全局依赖关系</strong>。Transformer <strong>可以大大提高并行化程度</strong>，在 8 个 P100 GPU 上只需训练 12 个小时，翻译质量就能达到新的水平。</p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>减少顺序计算的目标也是Extended Neural GPU、ByteNet和 ConvS2S的基础，它们都使用<strong>卷积神经网络</strong>作为基本构建模块<strong>，并行计算</strong>所有输入和输出位置的隐藏表示。在这些模型中，将两个任意输入或输出位置的信号联系起来所需的运算次数随位置间距离的增加而增加，<strong>ConvS2S 是线性增加，ByteNet 是对数增加。这就增加了学习远距离位置之间依赖关系的难度</strong>。在 Transformer 中，这将被减少到一个恒定的操作数(O(1))，尽管<strong>代价是由于平均注意力加权位置而降低了有效分辨率</strong>。</p><p>自我注意（有时也称为内部注意）是一种注意机制，它将单个序列的不同位置联系起来，以计算序列的表征。自我注意已成功应用于多种任务中，包括阅读理解、抽象概括、文本引申和学习与任务无关的句子表征。</p><h3 id="model-architecture"><a href="#model-architecture" class="headerlink" title="model architecture"></a>model architecture</h3><p>大多数转导模型都具有编码器-解码器结构.在这里,编码器将输入的符号表示序列 (x1, …, xn) 映射为连续表示序列 z = (z1, …, zn)。 在给定 z 的情况下，解码器会逐个元素生成一个符号输出序列（y1, …, ym）。在每一步中，模型都是自动回归的，在生成下一步时，会消耗之前生成的符号作为额外输入。</p><p><img data-src="https://i.imgur.com/Y7S2I1W.png" alt="image-20231108115505228" style="zoom: 67%;" /></p><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><p>编码器由 N = 6 层相同的层堆叠组成。每一层都有两个子层。第一个是多头自注意机制，第二个是简单的位置全连接前馈网络。我们在两个子层的每个周围都采用了残差连接，然后进行层归一化。也就是说，每个子层的输出都是 LayerNorm(x + Sublayer(x))，其中 Sublayer(x) 是子层本身实现的函数。为了方便这些残差连接，模型中的所有子层以及嵌入层都会产生维数为 dmodel = 512 的输出。</p><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>解码器也由 N = 6 层相同的层堆叠组成。除了每个编码器层中的两个子层外，解码器还插入了第三个子层，对编码器堆栈的输出执行多头关注。</p><p>与编码器类似，我们在每个子层周围采用残差连接，然后进行层归一化。我们还<strong>修改了解码器堆栈中的自我关注子层，以防止位置关注到后续位置</strong>。这种屏蔽，再加上输出嵌入偏移一个位置的事实，确保了对位置 i 的预测只能依赖于小于 i 的位置的已知输出。</p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>注意力函数可以描述为将一个查询和一组键值对映射到一个输出，其中查询、键、值和输出都是向量。<strong>输出结果以值的加权和的形式计算</strong>，<strong>其中分配给每个值的权重是通过查询与相应密钥的兼容性函数计算得出的</strong>。</p><p><img data-src="https://i.imgur.com/DAhCPHu.png" alt="image-20231108120527812"></p><blockquote><p>上图就是一般用的q与k的计算方式,说白了就是矩阵相乘,而其中的mask是为了把其中用不上的token置为-∞,这样后面做softmax权重就是0了. 因为tensor维度都是相同的,q与k,</p></blockquote><h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><p>输入包括维度为 d~k~的query和key,以及维度为 d~v~的value。我们计算query与所有keys的点积，将每个点积除以 √dk，然后应用软最大函数获得值的权重。</p><script type="math/tex; mode=display">\mathrm{Attention}(Q,K,V)=\mathrm{softmax}(\frac{QK^T}{\sqrt{d_k}})V</script><p>最常用的两种注意力函数是<strong>加法注意力</strong>(additive attention)和<strong>点积</strong>(dot production)注意力。点积注意力与我们的算法相同，只是缩放因子为 1 √dk。</p><p>加法注意使用单隐层前馈网络计算相容函数(相当于用一个全连接网络得到一个输出)。虽然两者的理论复杂度相似，但点积注意力在实际应用中速度更快，空间效率更高，因为它可以使用高度优化的矩阵乘法代码来实现。</p><p>虽然在 dk 值较小的情况下，这两种机制的表现类似，但在 d~k~ 值较大的情况下，加法注意比点积注意更胜一筹。我们猜测，对于较大的 d~k~ 值，点积的幅度会越来越大，从而将软最大函数推向梯度极小的区域</p><blockquote><p>也就是说除以d~k~原因是使得梯度更大,效果更好</p></blockquote><h4 id="Multi-Head-attention"><a href="#Multi-Head-attention" class="headerlink" title="Multi-Head attention"></a>Multi-Head attention</h4><p>我们发现，将查询、键值和值分别线性投影到 d~k~、d~k~ 和 d~v~ 维度，而不是对 d~model~ 维度的键、值和查询执行单一的注意函数，这样做是有益的。</p><p>多头注意力允许模型<strong>在不同位置共同关注来自不同表征子空间的信息</strong>。而在单注意头的情况下，平均化会抑制这一点。</p><script type="math/tex; mode=display">MultiHead( Q, K, V) = Concat( \mathrm{head}_1, ..., \mathrm{head}_\mathrm{h} ) W^O \\ where \ head¡=Attention( QW_i^Q, KW_i^K, VW_i^V)</script><p>其中，投影是参数矩阵 W^Q^~i~∈R^dmodel×dk^ , W^K^ ~i~∈R^dmodel×dk^ , W^V^~i~∈R^dmodel×dv^ 和 W O∈R^hdv×dmodel^</p><h3 id="Transformer的应用"><a href="#Transformer的应用" class="headerlink" title="Transformer的应用"></a>Transformer的应用</h3><p>在 “encoder-decoder 注意 “层中,query来自前一个decoder层，而memory keys和memory values则来自encoder的输出。这使得decoder中的每个位置都能关注输入序列中的所有位置。这模仿了序列到序列模型中典型的encoder-decoder注意机制。</p><p>encoder包含自注意层。在自注意层中，所有的键、值和查询都来自同一个地方，在这种情况下，就是encoder中上一层的输出。encoder中的每个位置都可以关注encoder上一层的所有位置。</p><p>同样，解码器中的自关注层允许解码器中的每个位置关注解码器中包括该位置在内的所有位置。<strong>我们需要防止decoder中的信息向左流动，以保持自动回归特性</strong>。</p><p>通过点乘注意力中的mask实现,也就是在输出序列中,把后面的token得到的value设置为-∞,</p><h3 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h3><p>除了注意力子层外，我们的编码器和解码器中的每一层都包含一个全连接的前馈网络，该网络分别对每个位置进行相同的处理。这包括两个线性变换，中间有一个 ReLU 激活。</p><script type="math/tex; mode=display">\text{FFN}(x)=\max(0,xW_1+b_1)W_2+b_2</script><p>虽然不同位置的线性变换相同，但各层使用的参数不同。</p><p>另一种描述方法是<strong>两个内核大小为 1 的卷积</strong>(全卷积)。输入和输出的维度为 d~model~ = 512，内层的维度为 d~ff~= 2048。</p><h3 id="Embedding-and-Softmax"><a href="#Embedding-and-Softmax" class="headerlink" title="Embedding and Softmax"></a>Embedding and Softmax</h3><p>与其他序列转换模型类似，我们使用学习到的嵌入将输入标记和输出标记转换为维度为 d~model~的向量。我们还使用通常学习到的线性变换和softmax，将解码器输出转换为预测的下一个标记词概率，在模型中，我们在两个嵌入层和pre-softmax linear transformation之间共享相同的权重矩阵。</p><p>在嵌入层中，我们将这些权重乘以 √dmodel。</p><h3 id="衍生"><a href="#衍生" class="headerlink" title="衍生"></a>衍生</h3><h4 id="Bert"><a href="#Bert" class="headerlink" title="Bert"></a>Bert</h4><p><img data-src="https://i.imgur.com/PcgRBVU.png" alt="image-20231125145939351"></p><p>BERT（来自 Transformers 的双向编码器表示）是一个非常大的多层 Transformer 网络,BERT-base 有 12 层，BERT-large 有 24 层,其旨在通过在所有层中联合调节左右上下文来预训练未标记文本的深度双向表示。因此，预训练的 BERT 模型只需一个额外的输出层即可进行微调，从而为各种任务（例如问答和语言推理）创建最先进的模型，而无需进行大量任务特定的架构修改。</p><h4 id="Vit"><a href="#Vit" class="headerlink" title="Vit"></a>Vit</h4><p><img data-src="https://i.imgur.com/bmErBND.png" alt="image-20231125145906882"></p><p>在CV领域,注意力要么与卷积网络结合使用,要么用来替换卷积网络的某些组件,整体结构保持不变。本文证明了CV领域不一定依赖CNN,使用纯粹的Transformer用于图片块序列，也可以很好的完成图像分类任务</p><h2 id="Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><a href="#Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows" class="headerlink" title="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"></a>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</h2><p><img data-src="https://s2.loli.net/2024/01/10/SImfCJajrYsKyqO.png" alt="image-20240110092327560"></p><script type="math/tex; mode=display">\begin{aligned}&\hat{\mathbf{z}}^l=\text{W-MSA}\left(\mathrm{LN}\left(\mathbf{z}^{l-1}\right)\right)+\mathbf{z}^{l-1}, \\&\mathbf{z}^{l}=\mathbf{MLP}\left(\mathbf{LN}\left(\hat{\mathbf{z}}^{l}\right)\right)+\hat{\mathbf{z}}^{l}, \\&\hat{\mathbf{z}}^{l+1}=\text{SW-MSA}\left(\mathrm{LN}\left(\mathbf{z}^{l}\right)\right)+\mathbf{z}^{l}, \\&\mathbf{z}^{l+1}=\mathbf{MLP}\left(\mathrm{LN}\left(\hat{\mathbf{z}}^{l+1}\right)\right)+\hat{\mathbf{z}}^{l+1},\end{aligned}</script><p><img data-src="https://s2.loli.net/2024/01/10/Kxgkua1MC7PnrSR.png" alt="image-20240110093609755"></p><h2 id="The-Bahdanau-Attention-Algorithm-2014"><a href="#The-Bahdanau-Attention-Algorithm-2014" class="headerlink" title="The Bahdanau Attention Algorithm 2014"></a>The Bahdanau Attention Algorithm 2014</h2><p>之前的处理NLP任务的方法<a href="https://arxiv.org/abs/1406.1078">[1406.1078] Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation (arxiv.org)</a>和<a href="https://arxiv.org/abs/1409.3215">[1409.3215] Sequence to Sequence Learning with Neural Networks (arxiv.org)</a>将变长源句变为固定长度的向量,这种方式无疑会随着源句变长效果变差.</p><blockquote><p>Bahdanau等人（2014）认为，这种将可变长度输入编码到固定长度向量中的方法会挤压源句子的信息，而不管其长度如何，导致基本编码器-解码器模型的性能随着输入句子长度的增加而迅速恶化。他们提出的方法<strong>用可变长度的矢量代替固定长度的矢量</strong>，以提高基本编码器-解码器模型的翻译性能。 </p></blockquote><p><strong>名词解释</strong>: s~t-1~是上一个time step decoder的隐状态,c~t~是time step t的上下文向量,它是在每个时间步生成用于得到需要的输出y~t~,h~i~是用于捕获包含在整个输入句子中的信息,α~t,i~是每个annotation的权重,e~t,i~是alignment model生成的注意力分数,表示s~t-1~和h~i~匹配程度</p><p><img data-src="https://machinelearningmastery.com/wp-content/uploads/2021/09/bahdanau_1-780x1024.png" alt="img" style="zoom: 50%;" /></p><p>对于encoder目的是生成annotation,采用了双向RNN,</p><script type="math/tex; mode=display">\mathrm{h_{i}=[\stackrel{\rightharpoonup}{h_{i}^{T}};\stackrel{\rightharpoonup}{h_{i}^{T}}]}^{T}</script><p>decoder解码器的作用是通过关注源句子中包含的最相关的信息来产生目标单词。为此，它利用了一种注意力机制。<br>利用注意力机制计算上一步的hidden state和这一步的annotation</p><script type="math/tex; mode=display">e_{t,i}=a(s_{t-1},h_{i})e_{t,i}=a(s_{t-1},h_{i})</script><p>有两种实现方法,一种将输入的encode h与隐状态s concat起来,另一种使用两个W矩阵分别与它们相乘</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{a}(s_{t-1},h_i)&=v^\top tanh(W[h_i;s_{t-1}])\\\mathrm{a}(s_{t-1},h_i)&=v^\top tanh(W_1h_i+W_2s_{t-1})\end{aligned}</script><p>这里v是权重向量.然后做个softmax,这样就得到在某个time step下得到权重</p><script type="math/tex; mode=display">\alpha_{t,i}=\mathrm{softmax(e_{t,i})}</script><p>上下文向量c为α与annotation的weighted sum</p><script type="math/tex; mode=display">c_{t}=\sum_{i=1}^{\top}\alpha_{t,i}h_{i}</script><p>最后y~t~的输出由decoder上一个输出y~t-1~,隐状态s~t-1~和c~t~进行计算</p><p><img data-src="https://s2.loli.net/2024/01/19/O6t3nIfWwr8LTgZ.png" alt="image-20240119120931215"></p><h2 id="The-Luong-Attention-Mechanism-2015"><a href="#The-Luong-Attention-Mechanism-2015" class="headerlink" title="The Luong Attention Mechanism 2015"></a>The Luong Attention Mechanism 2015</h2><p>提出了两种attention机制,包括global attention和local attention.</p><p>全局注意力跟Bahdanau类似但是试图更简化,局部注意力受到软注意力和硬注意影响并且只关注少数位置. 这两种注意力主要差别就是关注的上下文大小不同.</p><p>大致流程如下:</p><ol><li>从输入序列中生成一系列annotations H = h~i~</li><li>decoder的隐状态由上一层的隐状态和上层的decoder的输出决定</li><li>alignment model用于计算一个score,使用隐状态和annotation</li><li>将aliment score做softmax方便作为权重</li><li>计算aliment score与annotation H的weighted sum </li><li>增加了一个隐状态,基于上下文向量和当前解码器隐藏状态的加权级联来计算注意力隐藏状态   </li></ol><script type="math/tex; mode=display">\tilde{s}_{t}=\tanh(W_{c}[c_{t};s_{t}])</script><ol><li>解码器通过向其提供加权的注意力隐藏状态来产生最终输出<script type="math/tex; mode=display">y_t=\operatorname{softmax}(\mathcal{W}_y\hat{s}_t)</script></li></ol><h3 id="global-attention"><a href="#global-attention" class="headerlink" title="global attention"></a>global attention</h3><p>全局注意力模型在生成对齐分数时，并最终在计算上下文向量时，考虑输入句子中的所有源词。</p><script type="math/tex; mode=display">\begin{gathered}a(s_{t},h_{i})=v_{s}^{\top}\tanh(\mathcal{W}_{a}[s_{t};h_{i})] \\\mathbf{a}(\mathbf{s}_{t},\mathbf{h}_{i})=\mathbf{s}_{t}^{\top}\mathbf{h}_{i} \\\mathrm{a(s_{t},h_{i})=s_{t}^{T}W_{a}h_{i}} \end{gathered}</script><p>第一种跟Bahdanau类似,第二种和第三种方法实现的乘法注意</p><h3 id="local-attentiAxialon"><a href="#local-attentiAxialon" class="headerlink" title="local attentiAxialon"></a>local attentiAxialon</h3><p>在处理所有源词时，全局注意力模型在计算上是昂贵的，并且对于翻译较长的句子可能变得不切实际。 </p><p>在计算局部注意力时使用了一个窗口,假设中心是p~t~.</p><script type="math/tex; mode=display">[\mathbf{p}_{t}-\mathbf{D},\mathbf{p}_{t}+\mathbf{D}]</script><p>D是凭经验取,D有两种方法.</p><script type="math/tex; mode=display">p_{t}=t \\\mathbf{p}_{t}=S\cdot\mathrm{sigmoid}(\mathbf{v}_{p}^{\mathrm{T}}\tanh(\mathbf{W}_{p},s_{t}))</script><p>与<strong>Bahdanau Attention</strong>的差别</p><p>1, 计算y使用的隐状态不同</p><p><img data-src="https://machinelearningmastery.com/wp-content/uploads/2021/10/luong_1-1024x426.png" alt="img"></p><p>2.Luong等人放弃了Bahdanau模型使用的双向编码器，而是将LSTM顶层的隐藏状态用于编码器和解码器。 </p><p>3.Luong等人的全局注意模型研究了乘法注意作为Bahdanau加法注意的替代方法的使用。 </p><h3 id="General-Attention-Mechanism"><a href="#General-Attention-Mechanism" class="headerlink" title="General Attention Mechanism"></a>General Attention Mechanism</h3><p>上面讲的是比较早的了,现在很多使用Q,K,V来计算.可以进行类比,上一层的隐状态s~t-1~就是Q,而K,V是H</p><p><img data-src="https://s2.loli.net/2024/01/19/OklsgwpPCe4NvJu.png" alt="image-20240119132119458"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://machinelearningmastery.com/the-transformer-attention-mechanism/">The Transformer Attention Mechanism - MachineLearningMastery.com</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;del&gt;流行的深度学习模型,其中的思想以及模型在后面其他任务中也经常使用,所以这里介绍一些常用好用的模型.&lt;/del&gt;主要介绍attention和transformer系列.&lt;/p&gt;</summary>
    
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/categories/deep-learning/"/>
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>图像融合论文阅读</title>
    <link href="https://www.sekyoro.top/2023/11/02/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <id>https://www.sekyoro.top/2023/11/02/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</id>
    <published>2023-11-02T14:24:07.000Z</published>
    <updated>2023-11-18T08:43:46.828Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>课程作业<br><span id="more"></span></p><h1 id="abs"><a href="#abs" class="headerlink" title="abs"></a>abs</h1><p>介绍图像融合概念，回顾sota模型，其中包括数字摄像图像融合，多模态图像融合，</p><p>接着评估一些代表方法</p><p>介绍一些常见应用，比如RGBT目标跟踪，医学图像检查，遥感监测</p><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>动机：</p><p>由于硬件设备的理论和技术限制，单一传感器或单一拍摄设置所拍摄的图像无法有效、全面地描述成像场景</p><p>图像融合：图像融合能够将不同源图像中的有意义信息结合起来，生成单一图像，该图像包含更丰富的信息，更有利于后续应用</p><p>由于融合图像的优异特性，图像融合作为一种图像增强方法已被广泛应用于许多领域，例如摄影可视化</p><h2 id="传统融合方法："><a href="#传统融合方法：" class="headerlink" title="传统融合方法："></a>传统融合方法：</h2><p>在深度学习盛行之前，图像融合已经得到了深入的研究。早期实现图像融合的方法采用相关的数学变换，在<strong>空间域或变换域</strong>人工分析活动水平并设计融合规则，称为传统融合方法。</p><p>典型的传统融合方法包括基于<strong>多尺度变换</strong>的方法、基于<strong>稀疏表示</strong>的方法、<strong>基于子空间</strong>的方法、基于<strong>显著性</strong>的方法、基于total-variance的方法等。</p><p>传统图像融合方法的缺点：</p><ol><li>为了保证后续图像融合的可行性，传统方法会对不同源的图像采用相同变换来提取特征。这种方法没有考虑到源图像的特征差异，可能导致提取的特征表现力较差。</li><li>融合策略粗糙，表现较差。</li></ol><p>引入深度学习的优势：</p><ol><li><p>可以利用不同的网络实现差异化的特征提取</p></li><li><p>在良好设计的损失函数下，融合策略可以学到更合理的特征</p></li></ol><p>现有的深度学习方法致力于解决图像融合中的三个主要问题：“feature extraction, feature fusion and image reconstruction.” (Zhang 等, 2021, p. 323)</p><p>现有方法可以分为 AutoEncoder-based，CNN- based，GAN-based。</p><h3 id="1-AE-based"><a href="#1-AE-based" class="headerlink" title="1.AE-based"></a>1.AE-based</h3><p>AE 方法通常会预先训练一个自动编码器。然后利用训练好的自编码器实现特征提取和图像重建，中间的特征融合则根据传统的融合规则实现。</p><p>DenseFuse</p><h3 id="2-CNN-based"><a href="#2-CNN-based" class="headerlink" title="2.CNN-based"></a>2.CNN-based</h3><p>他们通常以两种不同的形式将卷积神经网络引入图像融合。一种是通过使用精心设计的损失函数和网络结构，实现端到端的特征提取、特征融合和图像重建</p><p>PMGI。它提出了梯度和强度的比例维护损失，引导网络直接生成融合图像。</p><p>另外还有使用CNN得到融合规则，而使用传统的特征提取和重建方法</p><h3 id="3-GAN-baesd"><a href="#3-GAN-baesd" class="headerlink" title="3.GAN-baesd"></a>3.GAN-baesd</h3><p>GAN 方法依靠生成器和判别器之间的对抗博弈来估计目标的概率分布，从而以隐含的方式共同完成特征提取、特征融合和图像重构</p><p>比如FusionGAN 是基于 GAN 的图像融合的先驱，它在融合图像和可见图像之间建立对抗博弈，以进一步丰富融合图像的纹理细节。由于各种图像融合任务存在显著差异，这些方法在不同融合场景中的实现方式也不尽相同。</p><h2 id="图像融合场景"><a href="#图像融合场景" class="headerlink" title="图像融合场景"></a>图像融合场景</h2><p>digital photography image fusion</p><p>由于数字成像设备的性能限制，传感器无法在单一设置完全表征成像场景中的信息</p><p>例如，数码摄影产生的图像只能承受有限的光照变化，并具有预定的景深。</p><p>多曝光度图像融合和多聚焦图像融合</p><p>以产生高动态范围和完全清晰的效果。</p><p>人们使用摄像机拍摄时,希望可以获得同一场景中所有景物都清晰的图像。但是<strong>摄像机镜头受景深的限制,无法同时聚焦所有目标,因此拍摄的照片中部分区域清晰,部分区域模糊。多聚焦图像融合技术可以将多幅同一场景下聚焦区域不同的图像融合成一幅全清晰的图像</strong>,从而有效地解决这个问题,提高图像的信息利用率。</p><p>multi-modal image fusion</p><p>由于成像原理的限制，单个传感器只能捕捉到部分场景信息。多模态图像融合将多个传感器获取的图像中最重要的信息结合起来，从而实现对场景的有效描述。</p><p>典型的多模态图像融合包括红外和可见光图像融合</p><p>sharpening fusion</p><p>在保证信噪比的前提下，光谱/滤镜与瞬时视场（IFOV）之间存在一定的矛盾。</p><p>换句话说，没有任何传感器能同时捕捉高空间分辨率和高光谱分辨率的图像。</p><p>锐化融合专门用于融合不同空间/光谱分辨率的图像，以生成所需的结果，这些结果不仅具有高空间分辨率，还具有高光谱分辨率。</p><p>典型的锐化融合包括多光谱（MS）锐化和高光谱锐化。从源图像成像的角度来看，锐化融合也属于多模态图像融合。不过，就融合目标而言，锐化融合比上述多模态图像融合要求更高的光谱/空间保真度，能直接提高分辨率。因此，锐化融合将作为一个单独的类别进行讨论。</p><p>多光谱锐化是将低空间分辨率（LRMS）的多光谱图像与全色（PAN）图像融合，生成高空间分辨率的多光谱图像。</p><p>与多光谱图像相比，高光谱图像具有更高的光谱分辨率和更低的空间分辨率。</p><blockquote><p>多光谱: 谱段有多个,可以看做是高光谱的一种情况，即成像的波段数量比高光谱图像少，一般只有几个到十几个。由于光谱信息其实也就对应了色彩信息，所以多波段遥感图像可以得到地物的色彩信息，但是空间分辨率较低。更进一步，光谱通道越多，其分辨物体的能力就越强，即光谱分辨率越高。</p><p>高光谱:高光谱由更窄的波段（10-20 nm）组成，具有较高的光谱分辨率，可以检测物体的光谱特效，可提供更多无形的数据,图像可能有数百或数千个波段</p><p>全色图:全色图像是单通道的，其中全色是指全部可见光波段0.38~0.76um，全色图像为这一波段范围的混合图像。因为是单波段，所以在图上显示为灰度图片。全色遥感图像一般空间分辨率高，但无法显示地物色彩，也就是图像的光谱信息少。</p></blockquote><h3 id="digital-photography-image-fusion"><a href="#digital-photography-image-fusion" class="headerlink" title="digital photography image fusion"></a>digital photography image fusion</h3><p>数字成像设备利用光学镜头捕捉反射的可见光然后采用CCD和CMOS等书子模块记录场景信息。另一方面，由于动态范围有限，这些数字模块无法承受过大的成像曝光差异。</p><p>一方面，由于光学镜头受景深限制，通常无法同时聚焦所有物体。</p><h3 id="Infrared-and-visible-image-fusion”"><a href="#Infrared-and-visible-image-fusion”" class="headerlink" title="Infrared and visible image fusion”"></a>Infrared and visible image fusion”</h3><p>红外图像具有<strong>明显的对比度</strong>，即使在恶劣天气下也能从背景中有效地突出目标。可见光图像包含丰富的纹理细节，更符合人类的视觉感知。红外和可见光图像融合就是要将这两种特性结合起来，生成对比度高、纹理丰富的图像。为了实现这一目标，AE、CNN 和 GAN 方法都被引入到这项任务中。</p><p><strong>高对比度，恶劣条件下也能有效突出目标</strong>。</p><p><strong>可见光图像包含丰富的纹理信息</strong>，更符合人类视觉感知。红外和可见光图像融合就是要<strong>将这两种特性结合起来，生成对比度高、纹理丰富的图像</strong>。为了实现这一目标，AE、CNN 和 GAN 方法都被引入到这项任务中。</p><p>AE方法</p><p>首先使用数据集训练一个autoencoder，训练好的自动编码器自然可以用来解决图像融合中的两个子问题：特征提取和图像重建</p><p>图像融合的关键在于<strong>特征融合策略</strong>的设计。目前，在红外和可见光图像融合中，特征融合的策略仍然是手工计算的，无法学习，如加法、l1-norm [19]、注意力加权等。这种手工计算的融合策略比较粗糙，限制了红外图像和可见光图像融合的进一步改进。</p><p>一种用于红外和可见光图像融合的 CNN 方法是端对端地实现三个子问题。这种CNN结构通常需要残差连接，全连接以及双端结构。</p><p>由于红外图像和可见光图像融合没有ground truth，因此损失函数的设计在于确定<strong>融合结果和源图像之间对比度和纹理的相似性</strong>。</p><p>参与红外和可见光图像融合的另一种 CNN 形式是使用预先训练好的网络（如 VGGNet）从源图像中提取特征，并根据这些特征生成融合权重图。</p><p>从这个角度看，卷积神经网络只实现了融合，而不考虑特征提取和图像重建，带来的融合性能非常有限。</p><h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><p>GAN 方法是目前红外和可见光图像融合领域最流行的方法，它能够以<strong>隐含的方式完成特征提取、特征融合和图像重建</strong>。</p><p>一般来说，GAN 方法依赖于两种损失函数，即内容损失和对抗损失。内容损失与 CNN 方法类似，用于初步融合源图像，而对抗损失则进一步限制信息融合的趋势。</p><p>早期GAN方法 fusionGAN，只是在融合后的图像和可见光图像之间建立对抗博弈，以进一步增强对可见光图像丰富细节的保留。</p><p>为了更好地平衡红外信息和可见光信息，随后的方法 [25,66-69] 开始使用具有<strong>多个分类约束条件的单一判别器或双判别器来同时估计源图像的两种概率分布。</strong></p><p>一般来说，GAN 方法可以产生很好的融合结果。然而，在训练过程中保持生成器和判别器之间的平衡并非易事。</p><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>评估指标包括:EN,SSIM,PSNR,SF,SD,CC,SF,VIF以及融合运行时间等等. </p><h4 id="EN"><a href="#EN" class="headerlink" title="EN"></a>EN</h4><p>熵值</p><p><img data-src="https://i.imgur.com/czqa4Qz.png" alt="image-20231103165404222"></p><p>p~l~是融合图像中相应灰度级的归一化直方图</p><p>熵越大，融合图像包含的信息就越多，融合方法的性能就越好。</p><h4 id="SD"><a href="#SD" class="headerlink" title="SD"></a>SD</h4><p>标准差</p><p><img data-src="https://i.imgur.com/nP1CzPO.png" alt="image-20231103165557350"></p><p>对比度高的区域总是能吸引人的注意力，而对比度高的融合图像往往能产生较大的标清值，这意味着融合图像能达到更好的视觉效果。</p><h4 id="SSIM"><a href="#SSIM" class="headerlink" title="SSIM"></a>SSIM</h4><p>结构相似性,取值[-1,1],<strong>数值越接近1表示结构相似性越高</strong></p><p>SSIM 用于建立图像损失和失真的模型，<strong>衡量源图像和融合图像之间的结构相似性</strong>。SSIM 主要由三部分组成：<strong>相关性损失、亮度失真和对比度失真</strong>。</p><p><img data-src="https://pic4.zhimg.com/80/v2-13bb3c60b27920c3ec834e045ec8756f_720w.webp" alt="img"></p><p>在融合任务中,计算两张源图与融合后图像的SSIM和</p><p><img data-src="https://i.imgur.com/xSMcHqm.png" alt="image-20231103171546346"></p><h4 id="PSNR"><a href="#PSNR" class="headerlink" title="PSNR"></a>PSNR</h4><p>峰值信噪比,衡量图像有效信息与噪声之间的比率,能够反映图像是否失真.<strong>数值越大表示失真越小</strong></p><p><img data-src="https://i.imgur.com/5OAM3nA.png" alt="image-20231103164139843"></p><p>Z表示理想参考图像灰度最大值与最小值之差，通常为255。PSNR的值越大，表示融合图像的质量越好。</p><blockquote><p>PSNR值的范围通常在<strong>0到100之间</strong>，单位为分贝（dB）。 通常情况下，PSNR值越高，表示原始图像与重建图像之间的差异越小，图像质量越接近原始图像。 一般来说，PSNR值在30到40dB之间被认为是可以接受的</p></blockquote><h4 id="CC"><a href="#CC" class="headerlink" title="CC"></a>CC</h4><p>CC 衡量融合图像与源图像的线性相关程度,CC 越大，融合后的图像与源图像越相似，融合效果越好</p><p><img data-src="https://i.imgur.com/EnD6Jys.png" alt="image-20231103172617252"></p><p><img data-src="https://i.imgur.com/FW1COsX.png" alt="image-20231103172623697"></p><h4 id="SF-空间频率"><a href="#SF-空间频率" class="headerlink" title="SF 空间频率"></a>SF 空间频率</h4><p><img data-src="https://i.imgur.com/qczz1P9.png" alt="image-20231103173521300"></p><p>测量图像的梯度分布</p><p><img data-src="https://i.imgur.com/Hqdxy5j.png" alt="image-20231103173745980"></p><p><img data-src="https://i.imgur.com/DmKSSiy.png" alt="image-20231103173758017"></p><p>SF 越大，融合图像的边缘和纹理就越丰富</p><p>​    </p><h4 id="VIF-空间信息保真度"><a href="#VIF-空间信息保真度" class="headerlink" title="VIF 空间信息保真度"></a>VIF 空间信息保真度</h4><p>VIF 衡量融合图像的信息保真度，其计算方法分为四个步骤：首先，将源图像和融合图像划分为不同的区块；然后，评估每个区块在失真和未失真情况下的视觉信息；接着，评估每个子波段的 VIF；最后，根据 VIF 计算总体指标。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>TNO TNO影像融合数据集包含不同军事相关场景的单光谱（增强视觉、近红外和长波红外或热）夜间影像，在不同的多波段camnera系统中注册。</p><p> INO RoadScene MSRS LLVIP MFD</p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>主要关注红外图像与可见光图像融合以及多焦点图像融合,从这些出发,最后到一个统一的图像融合框架.</p><h3 id="FusionGAN"><a href="#FusionGAN" class="headerlink" title="FusionGAN"></a>FusionGAN</h3><p>2019年较早的使用GAN作为图像融合算法融合红外和可见光</p><p><img data-src="https://i.imgur.com/OP6inkz.png" alt="image-20231104161851282"></p><h4 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h4><p><img data-src="https://i.imgur.com/gcNlg22.png" alt="image-20231104161928602"></p><p>注意损失函数设计</p><script type="math/tex; mode=display">\mathcal{L}_G=V_\text{FusionGAN}(G)+\lambda\mathcal{L}_{\mathrm{content}},</script><p>使用了一个对于GAN对抗的融合损失以及一个内容损失,对抗损失,这种想法来源LSGAN,a 和 b 分别表示虚假数据和真实数据的标签，c表示生成器希望鉴别器相信的虚假数据值。</p><script type="math/tex; mode=display">\begin{aligned}\min_DV_{\mathrm{LSGAN}}(D)&=~\frac12\mathbb{E}_{x\sim p_{data}(x)}[(D(x)-b)^2]+\frac12\mathbb{E}_{z\sim p_z(z)}[(D(G(z))-a)^2],\\\min_GV_{\mathrm{LSGAN}}(G)&=~\frac12\mathbb{E}_{z\sim p_z(z)}[(D(G(z))-c)^2],\end{aligned}</script><p>有两种方法可以确定公式中的 a、b 和 c 值。第一种是设置 b - c = 1 和 b - a = 2，从而最小化公式 ，使 P~data~ +P~g~ 与 P~g~ 之间的 Pearson χ2 最小化</p><p>第二种是设置 c = b，使生成器生成的样本尽可能真实。上述两种方法通常能获得相似的性能。</p><script type="math/tex; mode=display">V_{\text{FusionGAN}} ( G ) = \frac 1 N \sum _ { n = 1 }^{N}\left(D_{\theta_D}(I_f^n)-c\right)^2,</script><p>第二项 L~content~代表内容损失，λ 用于在 V~FusionGAN~(G) 和 L~content~之间取得平衡。由于红外图像的热辐射信息由其像素强度表征，而可见光图像的纹理细节信息可部分由其梯度表征. 当然可以有其他用于表征图片的某些特性的指标,比如上面介绍的SSIM等.</p><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{content}}=\frac1{HW}(\|I_f-I_r\|_F^2+\xi\|\nabla I_f-\nabla I_v\|_F^2),</script><p>实际上，如果没有 D~θ~，我们也可以得到融合图像，它可以保留红外图像中的热辐射信息和可见光图像中的梯度信息。</p><p>但这往往还不够，因为仅使用梯度信息无法完全表现可见图像中的纹理细节。因此，我们在生成器 G~θG~和判别器 D~θD~ 之间建立了一个对抗博弈，以调整基于可见光图像 IIv 的融合图像 If。</p><h4 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h4><p>从第一层到第四层，我们在卷积层中使用 3 × 3 滤波器，并将stride设为 2，不带填充。这与生成器网络不同。其根本原因在于，鉴别器是一个分类器，它首先从输入图像中提取特征图，然后进行分类。因此，它的工作方式与池化层相同，将stride设置为 2。</p><p><img data-src="https://i.imgur.com/XZhUCg2.png" alt="image-20231104163811787"></p><script type="math/tex; mode=display">\mathcal{L}_D=\frac{1}{N}\sum_{n=1}^N\left(D_{\theta_D}(I_v)-b\right)^2+\frac{1}{N}\sum_{n=1}^N\left(D_{\theta_D}(I_f)-a\right)^2,</script><p>我使用了这个模型</p><h3 id="TarDAL"><a href="#TarDAL" class="headerlink" title="TarDAL"></a>TarDAL</h3><p>面向检测的融合</p><p>我们采用双层优化公式同时进行图像融合和物体检测，不仅检测精度高，而且融合后的图像视觉效果更好。</p><p>我们设计了一种参数较少的目标感知双对抗学习网络（TarDAL），用于面向检测的融合。这种 “求同存异 “的单生成器双判别器网络可保留红外目标信息和可见光纹理细节。</p><p>我们从双层表述中推导出一种合作训练方案，为快速推理（融合和检测）提供最佳网络参数。</p><p>与以往追求高视觉质量的方法不同，我们认为，IVIF 必须生成既有利于视觉检测又有利于计算机感知的图像，即面向检测的融合。</p><h3 id="问题建模"><a href="#问题建模" class="headerlink" title="问题建模"></a>问题建模</h3><p><img data-src="https://i.imgur.com/Qwko06N.png" alt="image-20231104153245210"></p><p>假设红外图像、可见光图像和融合图像都是大小为 m×n 的灰度图像，分别用列向量 x、y 和 u∈R^mn×1^ 表示。</p><p>L~d~ 是目标检测相关的训练损失,Ψ是一个目标检测网络,f () 是一个基于能量的保真度项，包含融合图像 u 以及源图像 x 和 y，而 g~T~ () 和 g~D~ () 则是两个可行性约束条件,分别定义在红外图像和可见光图像上。</p><p><img data-src="https://i.imgur.com/lv9Mg1o.png" alt="image-20231104154941474"></p><p>引入一个带有学习参数 ω~f~的融合网络 Φ，并将双级优化转换为单级优化. </p><p>因此，我们将优化分解为两个学习网络 Φ 和 Ψ。我们采用 YOLOv53 作为检测网络 Ψ 的主干，其中 L~d~也沿用其设置，并精心设计了融合网络 Φ 。</p><blockquote><p>典型的深度融合方法致力于学习两种不同成像模式的共同特征。相反，我们的融合网络在<strong>学习这两种成像方式互补特征的差异的同时，也在寻求共性</strong>。通常情况下<strong>，红外图像能突出显示目标的独特结构，而可见光图像则能提供背景的纹理细节</strong>。</p></blockquote><h4 id="Target-aware-dual-adversarial-network"><a href="#Target-aware-dual-adversarial-network" class="headerlink" title="Target-aware dual adversarial network"></a>Target-aware dual adversarial network</h4><p><img data-src="https://i.imgur.com/vuIYIRj.png" alt="image-20231107114627598"></p><p>生成器G生成一张逼真的融合图像,目标判别器D~T~使用强度一致性评估红外图像中的目标与G提供的融合图像中被mask的目标.细节判别器 D~D~判别的是可见光梯度分布与融合图像的梯度分布</p><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p>生成器的作用是生成能保留整体结构并保持与源图像相似强度分布的融合图像。常用的结构相似性指数(SSIM)作为损失函数.</p><p>为了平衡源图像的像素强度分布，引入了基于突出度权重（SDW）的像素损失。</p><p>另外提出了一个基于显著性pixel loss</p><script type="math/tex; mode=display">S_{\mathbf{x}(k)}=\sum_{i=0}^{2\text{55}} \boldsymbol { H _ { \mathbf{x}}}(i)|\mathbf{x}(k)-i|,</script><p>其中H~x~(i)表示直方图中i的值,x(k)表示第k个值,因为x为一个大小为mn的vector</p><script type="math/tex; mode=display">\mathscr{L}_{\mathrm{pixe}1}=\|\mathrm{u}-\omega_1\mathrm{x}\|_1+\|\mathrm{u}-\omega_2\mathrm{y}\|_1,</script><p>pixel loss如上,其中</p><script type="math/tex; mode=display">\boldsymbol{\omega}_1=S_\mathbf{x}(k)/[S_\mathbf{x}(k)-S_\mathbf{y}(k)],\boldsymbol{\omega}_\mathbf{2}=1-\boldsymbol{\omega}_\mathbf{1}.</script><p>使用 5 层密集块作为 G 来提取共同特征，然后使用包含三个卷积层的合并块进行特征聚合。每个卷积层由一个卷积运算、批处理归一化和 ReLU 激活函数组成。生成的融合图像 u 与源图像大小相同。</p><h4 id="目标鉴别器与细节鉴别器"><a href="#目标鉴别器与细节鉴别器" class="headerlink" title="目标鉴别器与细节鉴别器"></a>目标鉴别器与细节鉴别器</h4><p>目标判别器 D~T~ 用于将融合结果的前景热目标与红外目标区分开来。而细节判别器 D~D~ 的作用是将融合结果的背景细节与可见光图像的细节区分开来。</p><p>采用了预训练的显著性检测网络从红外图像中计算出目标掩码 m，这样两个判别器就能在各自的区域（目标和背景）进行判别(也就是将图像中的目标与背景分割)</p><p>对抗损失如下,R(x)表示红外图像中的目标,R(u)表示融合后图像中的目标,R^^^则表示背景</p><script type="math/tex; mode=display">\begin{gathered}\mathcal{L}_{D_T}^\mathbf{f}=\mathbb{E}_{x\sim\tilde{p}(\mathcal{R}(\mathbf{x}))}[D(x)]-\mathbb{E}_{\tilde{x}\sim\tilde{p}(\mathcal{R}(\mathbf{u}))}[D(\tilde{x})],\\\mathcal{L}_{D_D}^\mathbf{f}=\mathbb{E}_{x\sim\tilde{p}(\hat{\mathcal{R}}(\nabla\mathbf{y}))}[D(x)]-\mathbb{E}_{\tilde{x}\sim\tilde{p}(\hat{\mathcal{R}}(\nabla\mathbf{u}))}[D(\tilde{x})],\\\mathcal{L}_{\mathbf{f}}^{\mathrm{adv}}=\mathcal{L}_{D_T}^\mathbf{f}+\mathcal{L}_{D_D}^\mathbf{f},\end{gathered}</script><p>R = x*m ,R^^^= 1 − R. m表示使用预训练模型得到mask.</p><p>对于鉴别器,损失分别是</p><script type="math/tex; mode=display">\begin{gathered}\mathcal{L}_{D_T}=\mathcal{L}_{D_T}^\mathbf{f}+k\mathbb{E}_{\tilde{x}\sim\tilde{r}(\mathcal{R}(\mathbf{x}))}[(\|\nabla D_T(\tilde{x})\|)^p], \\\mathcal{L}_{D_{D}}=\mathcal{L}_{D_{D}}^{\mathbf{f}}+k\mathbb{E}_{\tilde{x}\sim\tilde{r}(\hat{\mathcal{R}}(\nabla\mathbf{x}))}[(\|\nabla D_{D}(\tilde{x})\|)^{p}], \end{gathered}</script><p>两个鉴别器 D~T~ 和 D~D~ 具有相同的网络结构，即四个卷积层和一个全连接层。</p><p><img data-src="https://i.imgur.com/A3gJRD2.png" alt="image-20231107131708716"></p><h4 id="合作训练策略"><a href="#合作训练策略" class="headerlink" title="合作训练策略"></a>合作训练策略</h4><script type="math/tex; mode=display">\begin{aligned}\min_{\boldsymbol{\omega}_{\mathbf{d}},\boldsymbol{\omega}_{\mathbf{f}}}\mathcal{L}^{\mathbf{d}}(\Psi(\mathbf{u}^*;\boldsymbol{\omega}_{\mathbf{d}}))+\lambda\mathcal{L}^{\mathbf{f}}\big(\Phi(\mathbf{x},\mathbf{y};\boldsymbol{\omega}_{\mathbf{f}})\big),\\s.t.\mathbf{~u}^*=\Phi(\mathbf{x},\mathbf{y};\boldsymbol{\omega}_{\mathbf{f}}),\end{aligned}</script><p>双层优化自然会衍生出一种合作训练策略，以获得最佳网络参数 ω = (ω~d~, ω~f~)</p><p>引入了一个融合正则因子 L^f^，将受融合约束的检测优化转换为相互优化</p><p>损失函数包含目标检测的损失函数以及融合的损失函数.</p><h3 id="红外与可见光图像的融合结果"><a href="#红外与可见光图像的融合结果" class="headerlink" title="红外与可见光图像的融合结果"></a>红外与可见光图像的融合结果</h3><h4 id="定性比较"><a href="#定性比较" class="headerlink" title="定性比较"></a>定性比较</h4><p>首先，可以很好地保留红外图像中的分辨目标。如图 6（第二组的绿色缠结）所示，我们的方法中的人表现出高对比度和独特的突出轮廓，因此有利于视觉观察.</p><p>其次，我们的结果可以保留可见光图像中丰富的纹理细节（第一组和第三组的绿色缠结），这更符合人类的视觉系统。</p><h4 id="定量比较"><a href="#定量比较" class="headerlink" title="定量比较"></a>定量比较</h4><p>在 400 个图像对（20 个来自 TNO 的图像对、40 个来自 RoadScene 的图像对和 340 个来自 M3FD 的图像对）上对我们的 TarDAL 和上述竞争对手进行了定量比较。</p><p>使用了MI,EN和SD作为评估指标.</p><h3 id="红外与可见光目标检测结果"><a href="#红外与可见光目标检测结果" class="headerlink" title="红外与可见光目标检测结果"></a>红外与可见光目标检测结果</h3><h4 id=""><a href="#" class="headerlink" title=" "></a> </h4><h3 id="多聚焦图像融合"><a href="#多聚焦图像融合" class="headerlink" title="多聚焦图像融合"></a>多聚焦图像融合</h3><h3 id="MFIF-GAN"><a href="#MFIF-GAN" class="headerlink" title="MFIF-GAN"></a>MFIF-GAN</h3><p>针对多焦点图像融合</p><p>在数码摄影领域，有限的景深（DOF）导致单一场景中可能存在多种图像焦点区域，并产生散焦效应（DSE）[1]。作为一种图像增强技术，多焦点图像融合（MFIF）被用来融合图 1(a) 和图 1(b) 所示的多焦点图像，使融合结果（如图 1(c) 所示）能够清晰地保留来源信息。这一操作是各类计算机视觉（CV）任务的前提条件，例如物体检测和定位、识别和分割</p><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p>MFIF-GAN 中的生成器将源彩色图像 IA 和 IB 作为输入，旨在生成焦点图 ̂ F。判别器的输入是 IA、IB 和（真实或生成的）焦点图的连接。生成器的目的是尽可能精确地重建焦点图，而鉴别器的目的是将生成的焦点图与真实的焦点图区分开来。</p><p>G 包括一个编码器、一个张量连接模块和一个解码器。<strong>为了有效处理彩色图像，编码器被设计成六个并行子网络分支，共享源图像每个通道的参数</strong>。</p><h3 id="FuseGAN"><a href="#FuseGAN" class="headerlink" title="FuseGAN"></a>FuseGAN</h3><p>我们的目标是通过构建基于 cGAN 的网络 FuseGAN，学习从源图像到置信度图的映射，从而为融合任务提供重点信息。我们首先详细介绍了该架构，然后分析了其目标函数；最后阐述了融合方案.</p><p>生成器 G：如图所示，生成器 G 由三个部分组成：编码器、张量并合器和解码器。<strong>它将一对多焦点图像作为输入，并输出置信度图</strong>。具体来说，编码器有两个分支，每个分支包含 12 个块。为简单起见，我们将卷积层、批规范层和转置卷积层分别称为 Conv、BN 和 Decov。其中，第一块是 Conv-BN-ReLu，滤波器尺寸较大，为 7×7，步长为 1，目的是粗略提取特征。</p><p><img data-src="https://i.imgur.com/Fgpy1VL.png" alt="image-20231108184311430" style="zoom: 80%;" /></p><p>我们利用 中的 PatchGAN 作为判别器 D。从概念上讲，它试图辨别图像中每个大小为 K×K 的patch是真是假。鉴别器对图像中的所有响应进行卷积平均，最后生成输出。。</p><p><img data-src="https://i.imgur.com/oI8nYfO.png" alt="image-20231108190809183"></p><p>因此，我们利用自适应权重块设计的特定内容损失函数可以自适应地引导融合图像在像素级逼近源图像中重点区域的强度分布和梯度分布</p><p>此外,由于我们的优化目标是<strong>基于每个像素</strong>,<strong>为了避免融合后的图像出现色差,保证整体的自然度,我们增加了 SSIM 损失项</strong>。根据统计学原理,计算每个源图像片段中较大分数的平均值,作为相应 SSIM 损失项的权重。</p><h3 id="MFFGAN"><a href="#MFFGAN" class="headerlink" title="MFFGAN"></a>MFFGAN</h3><p>图像融合的理念是从源图像中提取并组合最有意义的信息。<strong>对于多焦点图像融合来说，最有意义的信息是源图像中的锐利区域，这些区域反映在强度分布和纹理细节上</strong>。自然，在信息提取过程中，应保留锐利区域的这些信息，而摒弃模糊区域的这些信息。</p><p>当然，在信息提取过程中，尖锐区域的信息应该保留，模糊区域的信息应该舍弃。因此，有必要在优化过程中<strong>引入损失函数的调整机制</strong>，以约束网络有选择地提取和重构信息。</p><p>首先，我们设计了一个自适应决策块，它可以根据重复模糊原理评估每个像素的清晰度,也就是说，清晰度较高的图像，经过模糊处理后，像素值变化较大。根据这一观察结果，生成screening map来描述有效信息的位置。screening map作用于我们构建的特定内容损失函数，从而在像素尺度上调整优化目标。</p><p>判定块可以自适应地引导融合结果在像素尺度上逼近清晰源图像的强度分布和梯度分布</p><p>.我们的具体方法是选择分数较大的像素（放弃较小的分数）作为两个源图像相应像素位置的优化目标。在决策块和内容损失的共同作用下，生成器可以得到相对清晰自然的结果。</p><p>我们将联合梯度图定义为真实数据，将融合图像的梯度图定义为假数据。持续的对抗性学习可以引导生成器更专注于纹理的保留。因此，我们可以获得更高质量的融合结果，其中包含更丰富的纹理细节。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损耗函数由生成器损耗L~G~和鉴别器损耗L~D~组成。</p><h4 id="生成器-1"><a href="#生成器-1" class="headerlink" title="生成器"></a>生成器</h4><p>生成器的损失有两部分，即用于提取和重构信息的内容损失L~Gcon~，以及用于增强纹理细节的对抗性损失L~Gadv~。</p><script type="math/tex; mode=display">\mathcal{L}_{G}=\mathcal{L}_{G_{\mathrm{adv}}}+\alpha L_{G_{\mathrm{con}}}</script><script type="math/tex; mode=display">\mathcal{L}_{G_{\mathrm{adv}}}=\frac{1}{N}\sum_{n=1}^{N}(D(\nabla(I_{\mathrm{fused}}^{n}))-a)^2</script><p>其中 N 是训练期间批次中融合图像的数量，a 是生成器期望判别器确定融合图像的概率标签</p><script type="math/tex; mode=display">L_{G_{\mathrm{con}}}=\beta_{1}\mathcal{L}_{\mathrm{int}}+\beta_{2}\mathcal{L}_{\mathrm{grad}}</script><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{int}}=\frac{1}{HW}\sum_{\cdot}\sum_{\cdot}S_{1_{i,j}}\cdot(I_{\mathrm{fused}_{i,j}}-I_{1_{i,j}})^{2}+S_{2_{i,j}}\cdot(I_{\mathrm{fused}_{i,j}}-I_{2_{i,j}})^{2}</script><script type="math/tex; mode=display">\begin{aligned}S_{1_{i,j}}&=\operatorname{sign}(RB(I_{1_{i,j}})-\min(RB(I_{1_{i,j}}),RB(I_{2_{i,j}}))),\\S_{2_{i,j}}&=1-S_{1_{i,j}},\end{aligned}</script><p>重复模糊函数</p><script type="math/tex; mode=display">RB(\cdot)~=~abs(I_{i,j}-LP(I_{i,j}))</script><p>LP （⋅） 表示低通滤波器函数。值得注意的是，S（⋅）的大小也是H × W。</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{\mathrm{grad}}&=\frac1{HW}\sum_i\sum_jS_{\mathbf{1}_{i,j}}\cdot(\nabla I_{\mathrm{fused}_{i,j}}-\nabla I_{\mathbf{1}_{i,j}})^2\\&+S_{2_{i,j}}\cdot(\nabla I_{\mathrm{fused}_{i,j}}-\nabla I_{2_{i,j}})^2.\end{aligned}</script><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>判别器的损失功能使判别器能够准确识别真假数据。在我们的方法中，假数据是融合图像的梯度图。真实数据是我们构建的联合梯度图。</p><script type="math/tex; mode=display">Grad_{\mathrm{fused}}=\mathrm{abs}(\nabla I_{\mathrm{fused}}) \\Grad_{\mathrm{joint}}=\max(\mathrm{abs}(\nabla I_1),\mathrm{abs}(\nabla I_2)),</script><script type="math/tex; mode=display">\mathcal{L}_{D_{\mathrm{adv}}}=\frac1N\sum_{n=1}^{N}[D(Grad_{\mathrm{fused}}^{n})-b]^{2}+[D(Grad_{\mathrm{joint}}^{n})-c]^{2}</script><p>其中 b 是融合图像梯度图的标签，应设置为 0。c 是联合梯度图的标签，应设置为 1。</p><p>也就是说，判别器期望准确地将联合梯度图识别为真实数据，将融合图像的梯度图识别为假数据。在这种约束下，判别器可以引导生成器在信息维护方面的倾向，即有利于强纹理保存.</p><h4 id="总体架构"><a href="#总体架构" class="headerlink" title="总体架构"></a>总体架构</h4><p><img data-src="https://i.imgur.com/WPHLLvv.png" alt="image-20231108222112489"></p><h4 id="生成器架构"><a href="#生成器架构" class="headerlink" title="生成器架构"></a>生成器架构</h4><p>我们将生成器拆分为两条路径来提取信息，对应于两个源图像。生成器网络的设计灵感来自pseudo-Siamese，它擅长处理两种相对不同的输入。由于多焦点图像对在相应的像素位置清晰或模糊，因此pseudo-Siamese网络适用于此类图像</p><p><img data-src="https://i.imgur.com/l2ONRey.png" alt="image-20231108215808309"></p><p>在这两条路径中，都有四个卷积层来提取特征。第一个卷积层使用 5 × 5 卷积核，其余三个卷积层使用 3 × 3 卷积核。它们都使用 Leaky ReLU 作为激活函数。为了防止卷积过程中的信息丢失，我们根据 DenseNet 的思想重用了这些特征.</p><p>同时，为了提取更充分的信息，我们在两条路径之间交换信息。具体来说，交换的信息是通过连接和卷积的方法生成的。然后，交换的信息与所有前一个卷积层的输出连接在一起，作为下一个卷积层的输入。</p><p>最后，我们将两条路径中所有卷积层的输出串联起来，然后通过卷积层生成融合图像。卷积层的核大小为 1 × 1，激活函数为 tanh。值得注意的是，在所有卷积层中，填充模式设置为“SAME”，即特征图的大小在整个卷积过程中没有变化，这与源图像的大小相同。</p><h4 id="判别器架构"><a href="#判别器架构" class="headerlink" title="判别器架构"></a>判别器架构</h4><p><img data-src="https://i.imgur.com/veuN5Um.png" alt="image-20231108222051637"></p><p>判别器中的输入有两种类型，一种是<strong>基于源图像的联合梯度图和融合图像的梯度图</strong>。鉴别器由四个卷积层和一个线性层组成。四个卷积层的卷积核大小为 3 × 3，它们都使用了LeakyReLU 激活函数。这些卷积层的步幅设置为 2。最后一层是用于查找分类概率的线性层。</p><h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><p>我们的实验是在两个数据集上进行的，比如Lytro数据集[34]和我们基于公共数据库构建的MFI-WHU数据集。</p><p>在 Lytro 数据集和 MFI-WHU 数据集上，用于测试的图像对数分别为 10 和 30。对于训练，为了获得更多的训练数据，我们采用了剪裁分解的扩展策略。具体来说，对于 Lytro 数据集，我们将其余图像裁剪为 22,090 个大小为 60 × 60 的图像图块对进行训练;对于 MFI-WHU 数据集，我们将其余图像裁剪为 202,246 个大小为 60 × 60 的图像patch对进行训练。</p><p>batch_size=32,epochs=20,训练一个epoch需要m步数,将一张图片分为多个patch,m设置为所有patch数除以b. 一般考虑训练更多的判别器,训练判别器次数是生成器的p倍.</p><p><img data-src="https://i.imgur.com/TYR6p1y.png" alt="image-20231109104901606"></p><p>我们将图像从 RGB 转换为 YCbCr 色彩空间。由于 Y 通道（亮度通道）可以表示结构细节和亮度变化，因此我们只致力于融合 Y 通道值。对于 Cb 和 Cr 通道（色度通道），我们以传统方式融合它们。然后，将这些通道的融合分量转移到RGB以获得最终结果。</p><h3 id="一些结果"><a href="#一些结果" class="headerlink" title="一些结果"></a>一些结果</h3><h4 id="多焦图像融合"><a href="#多焦图像融合" class="headerlink" title="多焦图像融合"></a>多焦图像融合</h4><p><img data-src="https://i.imgur.com/YrdNz1J.png" alt="image-20231118163720106"></p><p><img data-src="https://i.imgur.com/8y3MF5I.png" alt="image-20231118164233372"></p><h4 id="红外可见光图像融合"><a href="#红外可见光图像融合" class="headerlink" title="红外可见光图像融合"></a>红外可见光图像融合</h4><p><img data-src="https://i.imgur.com/6H8J7CW.png" alt="image-20231118164258767"></p><h3 id="代码链接"><a href="#代码链接" class="headerlink" title="代码链接"></a>代码链接</h3><p><a href="https://github.com/drowning-in-codes/UFGAN">drowning-in-codes/UFGAN: GAN for Image Fusion which is inspired by FusionGAN and U-net (github.com)</a></p><p><a href="https://github.com/drowning-in-codes/MFF-GAN">drowning-in-codes/MFF-GAN: Code of MFF-GAN: An unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion. (github.com)</a></p><p>colab 链接<a href="https://colab.research.google.com/drive/1wcb28gzgF62GphVdx42XkoZ68GxDaRpo#scrollTo=K8FjqBFQxmnR">UFGAN.ipynb - Colaboratory (google.com)</a></p><h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>利用预训练模型提供内容和风格 transfer learning?</p><p>利用cGAN思想? 此外损失函数的设计有必要换成神经网络而不是人工设计的一些值了.可以看看一篇CVPR的TARDAL<a href="http://arxiv.org/abs/2203.16220">http://arxiv.org/abs/2203.16220</a></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><p><a href="https://blog.csdn.net/Chaolei3/article/details/79404806">详细理解RGB图像、全色图像、多光谱图像、高光谱图像-CSDN博客</a></p></li><li><p><a href="https://github.com/Linfeng-Tang/Image-Fusion">Linfeng-Tang/Image-Fusion: Deep Learning-based Image Fusion: A Survey (github.com)</a></p><p><strong>综述</strong></p></li><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253521001342">Image fusion meets deep learning: A survey and perspective - ScienceDirect</a></p></li><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253522001518">Current advances and future perspectives of image fusion: A comprehensive review - ScienceDirect</a></p></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;课程作业&lt;br&gt;</summary>
    
    
    
    
    <category term="image fusion" scheme="https://www.sekyoro.top/tags/image-fusion/"/>
    
  </entry>
  
  <entry>
    <title>目标检测学习_P3</title>
    <link href="https://www.sekyoro.top/2023/11/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%AD%A6%E4%B9%A0-P3/"/>
    <id>https://www.sekyoro.top/2023/11/01/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%AD%A6%E4%B9%A0-P3/</id>
    <published>2023-11-01T13:29:52.000Z</published>
    <updated>2023-11-30T02:45:02.311Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主要写写one-stage的网络模型,涉及到SSD,RetinaNet,YOLO.<br><span id="more"></span></p><h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><p>YOLO模型是构建快速实时物体探测器的第一次尝试。因为YOLO不经历区域建议步骤，并且只在有限数量的边界框上进行预测，所以它能够超快速地进行推理。</p><ol><li><p>残差块</p><p>首先，将图像划分为不同的网格。每个网格的尺寸为S x S。将输入图像转换为网格的过程如下图所示。每个网格单元将检测其中出现的对象。</p></li><li><p>边界框线性回归</p></li></ol><p>边界框是高亮显示图像中具有某些属性（如宽度（bw）、高度（bh）和类别（如人、汽车、红绿灯等）的对象的轮廓，由字母C表示。边界框的中心（bx）。YOLO使用单边界框回归来预测对象的高度、宽度、中心和类别。</p><ol><li><p>IOU</p><p>并集交集（IOU）是一种用于对象检测的工具，用于解释方框如何重叠。YOLO使用IOU完美地围绕对象的完美输出框。网格中的每个单元负责预测边界框及其置信度得分。如果预测的边界框与实际框相同，则IOU等于1。此技术可以消除与实际框不相等的边界框。</p></li></ol><p>YOLOv2:YOLOv2于2017年发布，其架构对YOLO进行了几次迭代改进，包括BatchNorm、更高分辨率和锚盒。</p><p>YOLOv3：于2018年发布，YOLOv3在以前的模型的基础上，为边界框预测添加客观性分数，为主干层添加连接性，并在三个不同的级别进行预测，以提高对较小对象的性能。</p><p>YOLOv4:YOLOv4由Alexey Bochkovskiy于2020年4月发布，其中引入了改进的功能聚合、“免费包”（带增强）、漏洞激活等改进。</p><p>YOLOv5:由Glenn Jocher于2020年6月发布，YOLOv5与之前的所有版本不同，因为它是PyTorch实现，而不是原始暗网的分支。与YOLO v4一样，YOLO v5具有CSP脊椎和PA-NET颈部。主要改进包括马赛克数据扩展和自动学习边界框锚定。</p><p>PP-YOLO：百度基于YOLO v3于2020年8月发布。PP-YOLO的主要目标是实现一种具有相对平衡的效率和有效性的对象检测器，该检测器可以直接用于当前的应用场景，而不是设计新的检测模型。</p><p>Scaled YOLOv4:发布于2020年11月，作者：王、博奇科夫斯基和廖。该模型使用跨阶段部分网络来增加网络大小，同时保持YOLOv4的准确性和速度。</p><p>PP-YOLOv2：再次由百度团队撰写并于2021年4月发布，它对PP-YOLO进行了小修改，以获得更好的性能，包括添加错误激活功能和路径聚合网络。</p><p>流程:</p><ol><li>预训练一个CNN用于图像分类任务</li><li>将输入图像分为SxS的块,如果一个物体的中心落入一个块cell中，该块“负责”检测该物体的存在.包括预测<strong>每个块预测碰撞盒的位置</strong>,<strong>置信度</strong>以及<strong>包含物体的概率</strong></li><li>位置就是(x,y,w,h),x,y是相对于cell的offset,w,h被归一化</li><li>置信度是<code>Pr(containing an object) x IoU(pred, truth)</code>; 其中<code>Pr</code> = 概率</li><li>如果一个cell包含物体,它会预测一个概率,表示这个物体属于每一类的概率Pr(the object belongs to the class C_i | containing an object),在该阶段模型仅预测每个cell的一组类概率,而与bbox无关</li><li>最终,一张图像包含SXSXB个bbox,每个bbox包含四个预测位置以及置信度和K个条件概率.所以预测的值shape是SXSX(5B+K)</li></ol><h3 id="Network-Architecture"><a href="#Network-Architecture" class="headerlink" title="Network Architecture"></a><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolo.png" alt="img">Network Architecture</h3><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolo-network-architecture.png" alt="img"></p><blockquote><p>作为一个单级对象检测器，YOLO速度极快，但由于候选边界框的数量有限，它不善于识别形状不规则的对象或一组小对象。</p></blockquote><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><img data-src="https://s2.loli.net/2023/11/29/63TqhgSLFPbIKki.png" alt="image-20231129233153863"></p><p>损失由两部分组成，边界框偏移预测的定位损失和条件类概率的分类损失。这两部分都计算为误差平方和。</p><p><img data-src="https://s2.loli.net/2023/11/30/AGzmK4HVNhW95rq.png" alt="image-20231130101219411"></p><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolo-responsible-predictor.png" alt="img"></p><h3 id="YOLOV2改进"><a href="#YOLOV2改进" class="headerlink" title="YOLOV2改进"></a>YOLOV2改进</h3><p>应用了多种修改以使YOLO预测更准确、更快，包括：</p><p>1.BatchNorm有助于：在所有卷积层上添加批次范数，从而显著提高收敛性。</p><p>2.图像分辨率很重要：用高分辨率图像微调基本模型可以提高检测性能。</p><p>3.卷积锚盒检测：YOLOv2不是在整个特征图上预测具有完全连接层的边界盒位置，而是使用卷积层来预测锚盒的位置，就像在更快的R-CNN中一样。空间位置的预测和类概率是解耦的。总体而言，这一变化导致mAP略有下降，但召回率有所上升。</p><p>4.框维度的K-均值聚类：与使用手工挑选的锚框大小的更快的R-CNN不同，YOLOv2对训练数据进行K-均值集群，以在锚框维度上找到良好的先验。距离度量是根据IoU分数设计的：</p><p><img data-src="https://s2.loli.net/2023/11/30/nKCZulO46oeVdJb.png" alt="image-20231130103908962"></p><p>通过聚类生成的锚框在固定数量的框的条件下提供更好的平均IoU。</p><p>5.直接位置预测：YOLOv2以一种不会与中心位置偏离太多的方式来制定边界框预测。如果盒子位置预测可以将盒子放置在图像的任何部分，就像在区域提案网络中一样，那么模型训练可能会变得不稳定。</p><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolov2-loc-prediction.png" alt="img" style="zoom:50%;" /></p><p>6.添加细粒度特性：YOLOv2添加了一个直通层，将细粒度特性从早期层带到最后一个输出层。该穿透层的机制类似于ResNet中的身份映射，以从以前的层中提取更高维度的特征。这将使性能提高1%。</p><p>7.多尺度训练：为了训练模型对不同大小的输入图像具有鲁棒性，每10个批次随机采样一个新大小的输入维度。由于YOLOv2的conv层将输入维度下采样因子为32，因此新采样的大小是32的倍数。</p><p>8.轻量级基础模型：为了更快地进行预测，YOLOv2采用了轻量级基础模型DarkNet-19，该模型有19个conv层和5个最大池化层。关键是在3x3 conv层之间插入平均池和1x1 conv滤波器。</p><h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><p>Single Shot Detector（SSD；Liu等人，2016）是<strong>首次尝试使用卷积神经网络的金字塔特征层次来有效检测各种大小的对象之一</strong>。</p><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/SSD-architecture.png" alt="img"></p><p>该模型以图像作为输入，<strong>该图像通过具有不同大小滤波器（10x10、5x5和3x3）的多个卷积层。使用来自网络不同位置的卷积层的特征图来预测边界框</strong>。它们由具有3x3滤波器的特定卷积层处理，称为额外特征层，以产生一组类似于快速R-CNN的锚框的边界框。</p><p>与需要对象建议的方法相比，SSD 非常简单，因为它<strong>完全省去了建议生成和随后的像素或特征重采样阶段</strong>，并将所有计算封装在一个网络中。</p><p><img data-src="https://miro.medium.com/v2/resize:fit:770/1*f0p4it3vSVV_qeTJq5Jv1Q.png" alt="img"></p><p>此模型<strong>主要由基础网络组成，其后是几个多尺度特征块</strong>。 <strong>基本网络用于从输入图像中提取特征，因此它可以使用深度卷积神经网络</strong>。</p><p> 单发多框检测论文中选用了在分类层之前截断的VGG (<a href="http://zh.d2l.ai/chapter_references/zreferences.html#id98">Liu <em>et al.</em>, 2016</a>)，现在也常用ResNet替代。 我们可以设计基础网络，使它输出的高和宽较大。 这样一来，基于该特征图生成的锚框数量较多，可以用来检测尺寸较小的目标。</p><p><strong>接下来的每个多尺度特征块将上一层提供的特征图的高和宽缩小</strong>（如减半），并使特征图中每个单元在输入图像上的感受野变得更广阔。</p><p>通过深度神经网络分层表示图像的多尺度目标检测的设计。 由于接近顶部的多尺度特征图较小，但具有较大的感受野，它们适合检测较少但较大的物体。 简而言之，通过多尺度特征块，单发多框检测生成不同大小的锚框，并通过预测边界框的类别和偏移量来检测大小不同的目标，因此这是一个多尺度目标检测模型。</p><h4 id="default-box的生成"><a href="#default-box的生成" class="headerlink" title="default box的生成"></a>default box的生成</h4><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/SSD-box-scales.png" alt="img"></p><script type="math/tex; mode=display">\begin{aligned}\text{level index: } &\ell = 1, \dots, L \\\text{scale of boxes: } &s_\ell = s_\text{min} + \frac{s_\text{max} - s_\text{min}}{L - 1} (\ell - 1) \\\text{aspect ratio: } &r \in \{1, 2, 3, 1/2, 1/3\}\\\text{additional scale: } & s'_\ell = \sqrt{s_\ell s_{\ell + 1}} \text{ when } r = 1 \text{thus, 6 boxes in total.}\\\text{width: } &w_\ell^r = s_\ell \sqrt{r} \\\text{height: } &h_\ell^r = s_\ell / \sqrt{r} \\\text{center location: } & (x^i_\ell, y^j_\ell) = (\frac{i+0.5}{m}, \frac{j+0.5}{n})\end{aligned}</script><script type="math/tex; mode=display">\mathcal{L}_\text{cls} = -\sum_{i \in \text{pos}} \mathbb{1}_{ij}^k \log(\hat{c}_i^k) - \sum_{i \in \text{neg}} \log(\hat{c}_i^0)\text{, where }\hat{c}_i^k = \text{softmax}(c_i^k)</script><p>其中1表示对于k类bbox与gt-box是否match</p><h4 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h4><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_\text{loc} &= \sum_{i,j} \sum_{m\in\{x, y, w, h\}} \mathbb{1}_{ij}^\text{match} L_1^\text{smooth}(d_m^i - t_m^j)^2\\L_1^\text{smooth}(x) &= \begin{cases}    0.5 x^2             & \text{if } \vert x \vert < 1\\    \vert x \vert - 0.5 & \text{otherwise}\end{cases} \\t^j_x &= (g^j_x - p^i_x) / p^i_w \\t^j_y &= (g^j_y - p^i_y) / p^i_h \\t^j_w &= \log(g^j_w / p^i_w) \\t^j_h &= \log(g^j_h / p^i_h)\end{aligned}</script><p>此外SSD使用了NMS和HHM优化训练过程.</p><blockquote><p>NMS:非最大值抑制有助于避免重复检测同一实例。在我们为同一对象类别获得一组匹配的边界框之后：根据置信度得分对所有边界框进行排序。丢弃置信度分数较低的方框。当存在任何剩余的边界框时，重复以下操作：<strong>贪婪地选择得分最高的边界框。跳过具有高IoU（即大于0.5）的剩余框，使用之前选择的框</strong>。</p><p>HNM:有些负类很容易被错误分类。我们可以在训练循环中明确地找到那些假阳性样本，并将它们包含在训练数据中，以改进分类器。</p></blockquote><h3 id="连结多尺度的预测"><a href="#连结多尺度的预测" class="headerlink" title="连结多尺度的预测"></a>连结多尺度的预测</h3><p><strong>单发多框检测使用多尺度特征图来生成锚框并预测其类别和偏移量</strong>。</p><p>在不同的尺度下,特征图的形状或以同一单元为中心的锚框的数量可能会有所不同。 因此，不同尺度下预测输出的形状可能会有所不同。</p><p>除了批量大小这一维度外，其他三个维度都具有不同的尺寸。 为了将这两个预测输出链接起来以提高计算效率，我们将把这些张量转换为更一致的格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cls_predictor</span>(<span class="params">num_inputs, num_anchors, num_classes</span>):</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(num_inputs, num_anchors * (num_classes + <span class="number">1</span>),</span><br><span class="line">                     kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x, block</span>):</span></span><br><span class="line">    <span class="keyword">return</span> block(x)</span><br><span class="line"></span><br><span class="line">Y1 = forward(torch.zeros((<span class="number">2</span>, <span class="number">8</span>, <span class="number">20</span>, <span class="number">20</span>)), cls_predictor(<span class="number">8</span>, <span class="number">5</span>, <span class="number">10</span>))</span><br><span class="line">Y2 = forward(torch.zeros((<span class="number">2</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>)), cls_predictor(<span class="number">16</span>, <span class="number">3</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten_pred</span>(<span class="params">pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.flatten(pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>), start_dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">concat_preds</span>(<span class="params">preds</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat([flatten_pred(p) <span class="keyword">for</span> p <span class="keyword">in</span> preds], dim=<span class="number">1</span>)</span><br><span class="line">concat_preds([Y1, Y2]).shape</span><br></pre></td></tr></table></figure><h4 id="高和宽减半块"><a href="#高和宽减半块" class="headerlink" title="高和宽减半块"></a>高和宽减半块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down_sample_blk</span>(<span class="params">in_channels, out_channels</span>):</span></span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        blk.append(nn.Conv2d(in_channels, out_channels,</span><br><span class="line">                             kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        blk.append(nn.BatchNorm2d(out_channels))</span><br><span class="line">        blk.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    blk.append(nn.MaxPool2d(<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*blk)</span><br></pre></td></tr></table></figure><h4 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h4><p>Feature Pyramid Networks for Object Detection</p><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/featurized-image-pyramid.png" alt="img"></p><p>在看多尺度特征的时候注意到了这篇文章.提出了一个利用深度卷积神经网络固有的多尺度金字塔结构来以极小的计算量构建特征金字塔的网络结构</p><p><img data-src="https://s2.loli.net/2023/11/29/SaJdTtXjVy5qx7f.png" alt="image-20231129231413439"></p><p><img data-src="https://upload-images.jianshu.io/upload_images/18299912-aa79ebef839e6772.png?imageMogr2/auto-orient/strip|imageView2/2/w/611/format/webp" alt="img"></p><ul><li>自下而上的路径是正常的前馈计算。</li><li>自上而下的路径朝着相反的方向发展，通过横向连接将粗糙但语义更强的特征图添加回更大尺寸的先前金字塔级别。</li></ul><p>首先，更高级别的特征在空间上更粗糙地上采样，使其大2倍。对于图像放大，本文使用了最近邻上采样。虽然有许多图像放大算法，例如使用deconv，但<strong>采用另一种图像缩放方法可能会也可能不会提高RetinaNet的性能</strong>。</p><p>较大的特征图<strong>经过1x1 conv层以减小通道尺寸</strong>。</p><p>最后，通过<strong>元素相加</strong>将这两个特征图合并。</p><p>根据消融研究，特征化图像金字塔设计的组件的重要性等级如下：1x1横向连接&gt;跨多层检测对象&gt;自上而下的富集&gt;金字塔表示（与仅使用最底层相比）。</p><p>与SSD中一样，<strong>通过对每个合并的特征图进行预测，可以在所有金字塔级别中进行检测</strong>。因为预测共享相同的分类器和框回归器，所以它们都形成为具有相同的通道维度d=256。</p><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/retina-net.png" alt="img"></p><h4 id="OverFeat"><a href="#OverFeat" class="headerlink" title="OverFeat"></a>OverFeat</h4><p>[<a href="https://pdfs.semanticscholar.org/f2c2/fbc35d0541571f54790851de9fcd1adde085.pdf">overfeat</a>]</p><p>Overfeat是将目标检测、定位和分类任务集成到一个卷积神经网络中的先驱模型。主要思想是（i）<strong>以滑动窗口的方式在图像的多个尺度的区域上的不同位置进行图像分类</strong>，以及（ii）使用<strong>在相同卷积层上训练的回归器来预测边界框位置</strong>。</p><p>（1）用一个共享的CNN（ConvNet）来同时处理图像分类，定位，检测三个任务，可以提升三个任务的表现。</p><p>（2）用CNN有效地实现了一个多尺度的，滑动窗口的方法，来处理任务。</p><p>（3）提出了一种方法，通过累积预测来求bounding boxes（而不是传统的非极大值抑制）</p><p><a href="https://blog.csdn.net/Gentleman_Qin/article/details/84836122">OverFeat——全卷积首次用于检测问题 (目标检测)(深度学习)(ICLR 2014）_overfeat是做什么的-CSDN博客</a></p><p><img data-src="https://lilianweng.github.io/posts/2017-12-15-object-recognition-part-2/overfeat-training.png" alt="img"></p><h2 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h2><h3 id="Focal-Loss-for-Dense-Object-Detection"><a href="#Focal-Loss-for-Dense-Object-Detection" class="headerlink" title="Focal Loss for Dense Object Detection"></a>Focal Loss for Dense Object Detection</h3><p>在损失函数上进行改进.对象检测模型训练的一<strong>个问题是不包含对象的背景和包含感兴趣对象的前景之间的极端不平衡。焦点损失被设计为在硬的、容易被错误分类的例子（即具有噪声纹理或部分对象的背景）上分配更多的权重，并对容易被加权的例子（例如明显为空的背景）进行加权。</strong></p><h3 id="Abs"><a href="#Abs" class="headerlink" title="Abs"></a>Abs</h3><p>迄今为止，准确率最高的物体检测器都是基于 R-CNN 推广的两阶段方法，即对稀疏的候选物体位置集进行分类。<strong>相比之下，应用于对可能的物体位置进行规则、密集采样的单阶段检测器有可能更快、更简单，但迄今为止，其准确性仍落后于两阶段检测器。在本文中，我们将探讨出现这种情况的原因。</strong></p><p>我们发现，dense detectors训练过程中遇到的前景-背景类别极度不平衡是主要原因。我们建议通过重塑标准交叉熵损失来解决这种类别不平衡问题，从而降低分类良好示例的损失权重。</p><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>焦点损失（Focal Loss）的设计目<strong>的是解决在训练过程中前景类和背景类之间极度不平衡（例如 1:1000）的单阶段物体检测问题</strong>。我们从用于二元分类的交叉熵（CE）损失开始引入焦点损失</p><p><img data-src="https://s2.loli.net/2023/11/29/nHdKf2JCcxV6sry.png" alt="image-20231129231823763"></p><p>在上述公式中，y∈{±1} 表示地面实况类别，p∈[0, 1]是模型对标签 y = 1 的类别的估计概率。</p><p>我们定义 p~t~</p><p><img data-src="https://s2.loli.net/2023/11/29/b1BWorKMJTxf2R4.png" alt="image-20231129231934979"></p><p>重写 CE(p, y) = CE(p~t~) = - log(pt)。</p><p>我们建议在交叉熵损失中加入一个调制因子 (1 - p~t~)γ ，可调聚焦参数 γ ≥ 0。</p><p><img data-src="https://s2.loli.net/2023/11/29/3DqjYcTbewiCrE6.png" alt="image-20231129231711234"></p><p>我们注意到焦点损失的两个特性。(1) 当一个例子被错误分类且 p~t~ 较小时，调制因子接近 1，损失不受影响。</p><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/focal-loss.png" alt="img" style="zoom:67%;" /></p><h4 id="BackBone"><a href="#BackBone" class="headerlink" title="BackBone"></a>BackBone</h4><p>我们采用特征金字塔网络（FPN）作为 RetinaNet 的骨干网络。</p><p>简而言之，FPN 利用自上而下的路径和横向连接增强了标准卷积网络，因此该网络能从单一分辨率的输入图像中有效构建丰富的多尺度特征金字塔。金字塔的每一层都可用于检测不同尺度的物体。<strong>FPN 可以改进全卷积网络 (FCN) [23] 的多尺度预测，这体现在它对 RPN [28] 和 DeepMask 式提案 [24] 以及快速 R-CNN [10] 或 Mask R-CNN [14] 等两阶段检测器的增益上</strong>。继 [20] 之后，我们在 ResNet 架构 [16] 的基础上构建了 FPN。我们构建了一个 P3 到 P7 级的金字塔，其中 l 表示金字塔级别（Pl 的分辨率比输入低 2l）。与文献 [20] 一样，所有金字塔层级都有 C = 256 个通道。虽然许多设计选择并不重要，但我们<strong>强调使用 FPN 主干网才是关键；使用仅来自最后 ResNet 层的特征进行的初步实验得出的 AP 值较低。</strong></p><h4 id="anchors"><a href="#anchors" class="headerlink" title="anchors"></a>anchors</h4><p>我们使用了与中 RPN 变体类似的平移不变锚点框。锚点在金字塔 P3 到 P7 层的面积分别为 32^2^ 到 512^2^。与文献[20]一样，我们在每个金字塔层使用了三种纵横比的锚点{1:2, 1:1, 2:1}。为了获得比[20]更密集的比例覆盖，我们在每个层级添加了尺寸为{2^0^, 2^1/3^, 2^2/3^}的锚点，这些锚点是原始的 3 种宽高比锚点的集合。这改进了我们的 AP 设置。每个级别总共有 A = 9 个锚点，相对于网络的输入图像，这些锚点覆盖了 32-813 个像素的范围。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要写写one-stage的网络模型,涉及到SSD,RetinaNet,YOLO.&lt;br&gt;</summary>
    
    
    
    
    <category term="object detection" scheme="https://www.sekyoro.top/tags/object-detection/"/>
    
  </entry>
  
</feed>
