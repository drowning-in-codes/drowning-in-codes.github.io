<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sekyoro的博客小屋</title>
  
  
  <link href="https://www.sekyoro.top/atom.xml" rel="self"/>
  
  <link href="https://www.sekyoro.top/"/>
  <updated>2023-10-23T15:13:23.953Z</updated>
  <id>https://www.sekyoro.top/</id>
  
  <author>
    <name>Sekyoro</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DDNLP:深入NLP</title>
    <link href="https://www.sekyoro.top/2023/10/23/DDNLP-%E6%B7%B1%E5%85%A5NLP/"/>
    <id>https://www.sekyoro.top/2023/10/23/DDNLP-%E6%B7%B1%E5%85%A5NLP/</id>
    <published>2023-10-23T02:31:33.000Z</published>
    <updated>2023-10-23T15:13:23.953Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>之前学过一段时间NLP,因为其中涉及到一些深度学习常用的知识或者框架,但苦于不系统以及没有任务foucus不能长久.这里借助微软的教程写点东西.<br><span id="more"></span></p><h2 id="tokenization-amp-amp-representation"><a href="#tokenization-amp-amp-representation" class="headerlink" title="tokenization&amp;&amp;representation"></a>tokenization&amp;&amp;representation</h2><p>将一句话中的单词分割就是分词(tokenization),英文分词比较简单.中文就比较麻烦了.需要把握分词的粒度.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchtext</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">tokenizer = torchtext.data.utils.get_tokenizer(<span class="string">&#x27;basic_english&#x27;</span>)</span><br><span class="line">tokenizer(<span class="string">&#x27;He said: hello&#x27;</span>)</span><br></pre></td></tr></table></figure><p>分词之后就需要表示每个分词的含义了,<strong>需要某种方式将文本表示为张量</strong>.可以分为</p><ul><li>字符级表示(<strong>Character-level representation</strong>),当我们通过将每个字符视为一个数字来表示文本时。鉴于我们的文本语料库中有 C (如果是英语也就26个字符)不同的字符，单词 Hello 将由 5xC 张量表示。每个字母将对应于一个独热编码中的张量列。</li><li>单词级表示(<strong>Word-level representation</strong>),其中我们创建文本中所有单词的词汇表(<strong>vocabulary</strong> )，然后使用独热编码表示单词。这种方法在某种程度上更好，因为每个字母本身没有太多意义，因此通过使用更高层次的语义概念 - 单词 - 我们简化了神经网络的任务。但是，鉴于字典大小较大，我们需要处理高维稀疏张量。</li></ul><blockquote><p>无论表示方式如何，我们首先需要将文本转换为一系列标记(<strong>tokens</strong>)，一个标记是字符、单词，有时甚至是单词的一部分(也即是上面说的分词)</p><p>然后，我们将token转换为一个数字，通常使用词汇表(<strong>vocabulary</strong>)(也就是使用单词级表示)，并且可以使用独热编码(one-hot encoding)将这个数字输入神经网络。</p></blockquote><p>常用的方法包括BOW或者N-Grams</p><h4 id="Bag-of-Words"><a href="#Bag-of-Words" class="headerlink" title="Bag-of-Words"></a>Bag-of-Words</h4><p>在解决文本分类等任务时，我们需要能够通过一个固定大小的向量来表示文本，我们将将其用作最终分类器的输入。</p><blockquote><p>最简单的方法之一是组合所有单独的单词表示，例如。通过添加它们。如果我们为每个单词添加独热编码，我们最终会得到一个频率向量，显示每个单词在文本中出现的次数。文本的这种表示称为词袋（BoW）</p><p>BoW 本质上表示文本中出现的单词和数量，这确实可以很好地指示文本的内容</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">counter = collections.Counter()</span><br><span class="line"><span class="keyword">for</span> (label, line) <span class="keyword">in</span> train_dataset:</span><br><span class="line">    counter.update(tokenizer(line))</span><br><span class="line">vocab = torchtext.vocab.vocab(counter, min_freq=<span class="number">1</span>)</span><br><span class="line">vocab_size = <span class="built_in">len</span>(vocab)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Vocab size if <span class="subst">&#123;vocab_size&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">stoi = vocab.get_stoi() <span class="comment"># dict to convert tokens to indices</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [stoi[s] <span class="keyword">for</span> s <span class="keyword">in</span> tokenizer(x)]</span><br><span class="line"></span><br><span class="line">encode(<span class="string">&#x27;I love to play with my words&#x27;</span>)</span><br><span class="line"></span><br><span class="line">vocab_size = <span class="built_in">len</span>(vocab)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_bow</span>(<span class="params">text,bow_vocab_size=vocab_size</span>):</span></span><br><span class="line">    res = torch.zeros(bow_vocab_size,dtype=torch.float32)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> encode(text):</span><br><span class="line">        <span class="keyword">if</span> i&lt;bow_vocab_size:</span><br><span class="line">            res[i] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(to_bow(train_dataset[<span class="number">0</span>][<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>简单来说就是根据原本的语义资料,统计词频先建立一个counter,类似于一个字典,key是词,value是频次.根据counter(或者OrderDict)建立一个vocab. vocab建立一个词汇到index的一个字典,然后根据这个字典获得一个词的index,但是并直接使用index作为词的表示,而是使用类似one-hot encoding,出现了一个词,获取其index,再在一个大小为vocab_size的tensor上的index处加1,这样一个句子的BOW就有了.</p><p><img data-src="https://i.imgur.com/MXAQdkP.png" alt="image-20231023115954650"></p><p><img data-src="https://i.imgur.com/G7ll59u.png" alt="image-20231023115905862"></p><p>BoW 的问题在于某些常用词，例如 and、is 等出现在大多数文本中，并且它们的频率最高，掩盖了真正重要的单词。我们可以通过考虑单词在整个文档集合中出现的频率来降低这些单词的重要性。</p><h4 id="N-Grams"><a href="#N-Grams" class="headerlink" title="N-Grams"></a>N-Grams</h4><p>在自然语言中，单词的精确含义只能在上下文中确定。例如，神经网和钓鱼网.</p><p>一种解决办法是使用单词对(pairs of words)(也就是不使用单个单词而是多个单词,因为单个单词在不同语境下含义由差异),然后将单词对(pairs of words)视为单独的词汇标记。</p><p>这样相当于把一个句子的表示变多了,除了所有单个单词,还有单词对.</p><p>这种方法的问题在于字典大小显着增长，并且像go fishing和go shopping这样的组合由不同的标记呈现，尽管动词相同，但它们没有任何语义相似性。</p><blockquote><p>在某些情况下，我们也可以考虑使用三元语法 - 三个单词的组合。因此，这种方法通常被称为n-grams。此外，使用具有<strong>字符级表示的 n 元语法</strong>是有意义的，在这种情况下，n-gram 将大致对应于不同的音节。</p></blockquote><p>可以使用sklearn或者pytorch库,均能实现.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bigram_vectorizer = CountVectorizer(ngram_range=(<span class="number">1</span>, <span class="number">2</span>), token_pattern=<span class="string">r&#x27;\b\w+\b&#x27;</span>, min_df=<span class="number">1</span>)</span><br><span class="line">corpus = [</span><br><span class="line">        <span class="string">&#x27;I like hot dogs.&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;The dog ran fast.&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Its hot outside.&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line">bigram_vectorizer.fit_transform(corpus)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Vocabulary:\n&quot;</span>,bigram_vectorizer.vocabulary_)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(bigram_vectorizer.vocabulary_))</span><br><span class="line">bigram_vectorizer.transform([<span class="string">&#x27;My dog likes hot dogs on a hot day.&#x27;</span>]).toarray()</span><br></pre></td></tr></table></figure><p><img data-src="https://i.imgur.com/ES1UYjS.png" alt="image-20231023121801392"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">counter = collections.Counter()</span><br><span class="line"><span class="keyword">for</span> (label, line) <span class="keyword">in</span> train_dataset:</span><br><span class="line">    l = tokenizer(line)</span><br><span class="line">    counter.update(torchtext.data.utils.ngrams_iterator(l,ngrams=<span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">bi_vocab = torchtext.vocab.vocab(counter, min_freq=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Bigram vocabulary length = &quot;</span>,<span class="built_in">len</span>(bi_vocab))</span><br></pre></td></tr></table></figure><p><img data-src="https://i.imgur.com/LvNDH2u.png" alt="image-20231023120608981"></p><h4 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h4><p>在 BoW 表示中，无论单词本身如何，单词出现次数都是均匀加权的。但是，很明显，与专业术语相比，常用词（例如a，in等）对于分类的重要性要低得多。事实上，在大多数NLP任务中，有些单词比其他单词更相关。</p><p>TF-IDF 代表术语频率 – 反向文档频率。它是BOW的变体，其中使用浮点值而不是指示单词在文档中出现的二进制 0/1 值，这与语料库中单词出现的频率有关。</p><p>主要引入了document文档概念,如果一个词在多个文档中出现,那么其权重会降低.</p><p><img data-src="https://i.imgur.com/BLTg4Tp.png" alt="image-20231023120917811"></p><p>其中tf~ij~表示在j文档中i词出现的次数,N表示总文档数,df~i~表示出现i这个词的文档数.</p><p>这样就计算出了单个文档中词i的权重,这里的文档也可以是单个句子.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">corpus = [</span><br><span class="line">        <span class="string">&#x27;I like hot dogs.&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;The dog ran fast.&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Its hot outside.&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line">vectorizer = TfidfVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">vectorizer.fit_transform(corpus)</span><br><span class="line">vectorizer.transform([<span class="string">&#x27;My dog likes hot dogs on a hot day.&#x27;</span>]).toarray()</span><br></pre></td></tr></table></figure><p>这里结合了N-gram和TF-IDF. 由于其中使用了TfidfVectorizer,默认参数如下</p><p><img data-src="https://i.imgur.com/W998L4F.png" alt="image-20231023122145845"></p><p>将其中的<code>I,I like</code>去掉了,所以词汇表少了两个.此外sklearn库中的算法与上面的公式也不同.默认为log [ n / df(t) ] + 1(设置<code>smooth_idf=False</code>)</p><p>上面的方法对于句子中词的语义理解能力有限,而且通常维度是整个训练资料的vocab大小,维度高且稀疏.</p><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><p>嵌入的想法是通过<strong>低维密集向量</strong>来表示单词，这在某种程度上<strong>反映了单词的语义</strong>含义。</p><p>也就是从上面简单的text representation中的vocab_size变为embedding_size,输出不是one hot encoding的高维向量了。</p><p>训练方式与BOW类似,但是需要填充.比如一个batch中有多个句子,每个句子长度不同,需要padding成这个batch中最大的句子的encode(就是计算BOW)长度.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmbedClassifier</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embed_dim, num_class</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)</span><br><span class="line">        self.fc = torch.nn.Linear(embed_dim, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;after embedding&quot;</span>,x.shape)</span><br><span class="line">        x = torch.mean(x,dim=<span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(x.shape)</span><br><span class="line">        <span class="keyword">return</span> self.fc(x)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">padify</span>(<span class="params">b</span>):</span></span><br><span class="line">    <span class="comment"># b is the list of tuples of length batch_size</span></span><br><span class="line">    <span class="comment">#   - first element of a tuple = label,</span></span><br><span class="line">    <span class="comment">#   - second = feature (text sequence)</span></span><br><span class="line">    <span class="comment"># build vectorized sequence</span></span><br><span class="line">    v = [encode(x[<span class="number">1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> b]</span><br><span class="line">    <span class="comment"># first, compute max length of a sequence in this minibatch</span></span><br><span class="line">    l = <span class="built_in">max</span>(<span class="built_in">map</span>(<span class="built_in">len</span>,v))</span><br><span class="line">    <span class="keyword">return</span> ( <span class="comment"># tuple of two tensors - labels and features</span></span><br><span class="line">        torch.LongTensor([t[<span class="number">0</span>]-<span class="number">1</span> <span class="keyword">for</span> t <span class="keyword">in</span> b]),</span><br><span class="line">        torch.stack([torch.nn.functional.pad(torch.tensor(t),(<span class="number">0</span>,l-<span class="built_in">len</span>(t)),mode=<span class="string">&#x27;constant&#x27;</span>,value=<span class="number">0</span>) <span class="keyword">for</span> t <span class="keyword">in</span> v])</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">16</span>, collate_fn=padify, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><blockquote><p>需要将所有序列填充到相同的长度，以便将它们放入小批量中。这不是表示可变长度序列的最有效方法.</p><p>另一种选择是使用偏移向量，这将保留存储在一个大向量中的所有序列的偏移量。</p></blockquote><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="constructor">EmbedClassifier(<span class="params">torch</span>.<span class="params">nn</span>.Module)</span>:</span><br><span class="line">    def <span class="constructor">__init__(<span class="params">self</span>, <span class="params">vocab_size</span>, <span class="params">embed_dim</span>, <span class="params">num_class</span>)</span>:</span><br><span class="line">        super<span class="literal">()</span>.<span class="constructor">__init__()</span></span><br><span class="line">        self.embedding = torch.nn.<span class="constructor">EmbeddingBag(<span class="params">vocab_size</span>, <span class="params">embed_dim</span>)</span></span><br><span class="line">        self.fc = torch.nn.<span class="constructor">Linear(<span class="params">embed_dim</span>, <span class="params">num_class</span>)</span></span><br><span class="line"></span><br><span class="line">    def forward(self, text, off):</span><br><span class="line">        x = self.embedding(text, off) <span class="comment">//它以内容向量和偏移向量为输入</span></span><br><span class="line">        return self.fc(x)</span><br><span class="line">        </span><br><span class="line">        def offsetify(b):</span><br><span class="line">    # first, compute data tensor from all sequences</span><br><span class="line">    x = <span class="literal">[<span class="identifier">torch</span>.<span class="identifier">tensor</span>(<span class="identifier">encode</span>(<span class="identifier">t</span>[<span class="number">1</span>]</span>)) <span class="keyword">for</span> t <span class="keyword">in</span> b]</span><br><span class="line">    # now, compute the offsets by accumulating the tensor <span class="keyword">of</span> sequence lengths</span><br><span class="line">    o = <span class="literal">[<span class="number">0</span>]</span> + <span class="literal">[<span class="identifier">len</span>(<span class="identifier">t</span>) <span class="identifier">for</span> <span class="identifier">t</span> <span class="identifier">in</span> <span class="identifier">x</span>]</span></span><br><span class="line">    o = torch.tensor(o<span class="literal">[:-<span class="number">1</span>]</span>).cumsum(dim=<span class="number">0</span>)</span><br><span class="line">    return (</span><br><span class="line">        torch.<span class="constructor">LongTensor([<span class="params">t</span>[0]-1 <span class="params">for</span> <span class="params">t</span> <span class="params">in</span> <span class="params">b</span>])</span>, # labels</span><br><span class="line">        torch.cat(x), # text</span><br><span class="line">        o</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.<span class="constructor">DataLoader(<span class="params">train_dataset</span>, <span class="params">batch_size</span>=16, <span class="params">collate_fn</span>=<span class="params">offsetify</span>, <span class="params">shuffle</span>=True)</span></span><br></pre></td></tr></table></figure><p>可以看到数据集多了一个数据,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">net = EmbedClassifier(vocab_size,<span class="number">32</span>,<span class="built_in">len</span>(classes)).to(device)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch_emb</span>(<span class="params">net,dataloader,lr=<span class="number">0.01</span>,optimizer=<span class="literal">None</span>,loss_fn = torch.nn.CrossEntropyLoss(<span class="params"></span>),epoch_size=<span class="literal">None</span>, report_freq=<span class="number">200</span></span>):</span></span><br><span class="line">    optimizer = optimizer <span class="keyword">or</span> torch.optim.Adam(net.parameters(),lr=lr)</span><br><span class="line">    loss_fn = loss_fn.to(device)</span><br><span class="line">    net.train()</span><br><span class="line">    total_loss,acc,count,i = <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> labels,text,off <span class="keyword">in</span> dataloader:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        labels,text,off = labels.to(device), text.to(device), off.to(device)</span><br><span class="line">        out = net(text, off)</span><br><span class="line">        loss = loss_fn(out,labels) <span class="comment">#cross_entropy(out,labels)</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss+=loss</span><br><span class="line">        _,predicted = torch.<span class="built_in">max</span>(out,<span class="number">1</span>)</span><br><span class="line">        acc+=(predicted==labels).<span class="built_in">sum</span>()</span><br><span class="line">        count+=<span class="built_in">len</span>(labels)</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i%report_freq==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;count&#125;</span>: acc=<span class="subst">&#123;acc.item()/count&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> epoch_size <span class="keyword">and</span> count&gt;epoch_size:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> total_loss.item()/count, acc.item()/count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_epoch_emb(net,train_loader, lr=<span class="number">4</span>, epoch_size=<span class="number">25000</span>)</span><br></pre></td></tr></table></figure><p>在前面的示例中，模型嵌入层学习将单词映射到向量表示，但是这种表示没有太多的语义意义。应该学到的是:相似的单词或同义词将对应于在某些向量距离（例如欧几里得距离）方面彼此接近的向量</p><h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><p>为此，我们需要以特定方式在大量文本上预训练我们的嵌入模型。</p><p>训练语义嵌入的第一种方法称为Word2Vec。它基于两个主要体系结构,用于生成单词的分布式表示,包括COW和Skip-Ngram.</p><p><img data-src="https://i.imgur.com/pOIIEEj.png" alt="image-20231023164434940"></p><p>在CBOW，我们训练模型从周围上下文中预测单词。给定 ngram （W−2，W−1，W0，W1，W2），模型的目标是从 （W−2，W−1，W1，W2） 预测 W0。</p><h4 id="FastText"><a href="#FastText" class="headerlink" title="FastText"></a>FastText</h4><p>通过学习每个单词的向量表示以及每个单词中的字符 n 元语法来构建 Word2Vec。然后在每个训练步骤中将表示值平均为一个向量。虽然这为预训练增加了大量额外的计算，但它使词嵌入能够对子词信息进行编码。</p><h4 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h4><p>GloVe利用分解共现矩阵( co-occurrence matrix)的思想，使用神经方法将共现矩阵分解为更具表现力和非线性的词向量。</p><p><img data-src="https://i.imgur.com/zKMz0Hk.png" alt="image-20231023203859837"></p><p>传统的预训练嵌入表示（如 Word2Vec）的一个关键限制是词义消歧问题。虽然预训练嵌入可以在上下文中捕获单词的某些含义，但单词的每个可能含义都编码到相同的嵌入中。这可能会导致下游模型中出现问题，因为许多单词（例如“play”）具有不同的含义，具体取决于它们使用的上下文。</p><p>为了克服这个限制，我们需要基于语言模型构建嵌入，该语言模型在大量文本语料库上进行训练，并且知道如何在不同上下文中将单词组合在一起(我的理解是相当于自己训练一个专注于自己下游任务的embedding)</p><h3 id="Language-Modeling"><a href="#Language-Modeling" class="headerlink" title="Language Modeling"></a>Language Modeling</h3><p>语言建模背后的主要思想是以<strong>无监督的方式在未标记的数据集上训练它们</strong>。这很重要，因为我们有大量的未标记文本可用，而标记文本的数量始终受到我们可以在标记上花费的工作量的限制。</p><blockquote><p>大多数情况下，我们可以构建可以<strong>预测文本中缺失单词的语言模型</strong>，因为很容易屏蔽文本中的随机单词并将其用作训练样本.</p></blockquote><p>为了建立一个网络来预测下一个单词，我们需要提供相邻单词作为输入，并获取单词编号作为输出。</p><p>CBoW网络的架构如下：</p><p>输入单词通过嵌入层传递。这个嵌入层将是我们的 Word2Vec 嵌入，因此我们将它单独定义为嵌入变量。在这个例子中，我们将使用嵌入大小 = 30，即使你可能想尝试更高的维度（真正的 word2vec 有 300）</p><p>然后，嵌入向量将被传递到预测输出字的线性层。因此它具有vocab_size神经</p><p><img data-src="https://tensorflow.org/text/tutorials/images/word2vec_skipgram.png" alt="word2vec_skipgrams" style="zoom:67%;" /></p><p><img data-src="https://i.imgur.com/GgvayYN.png" alt="image-20231023195917251"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">ngrams = <span class="number">1</span>, min_freq = <span class="number">1</span>, vocab_size = <span class="number">5000</span> , lines_cnt = <span class="number">500</span></span>):</span></span><br><span class="line">    tokenizer = torchtext.data.utils.get_tokenizer(<span class="string">&#x27;basic_english&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Loading dataset...&quot;</span>)</span><br><span class="line">    test_dataset, train_dataset  = torchtext.datasets.AG_NEWS(root=<span class="string">&#x27;./data&#x27;</span>)</span><br><span class="line">    train_dataset = <span class="built_in">list</span>(train_dataset)</span><br><span class="line">    test_dataset = <span class="built_in">list</span>(test_dataset)</span><br><span class="line">    classes = [<span class="string">&#x27;World&#x27;</span>, <span class="string">&#x27;Sports&#x27;</span>, <span class="string">&#x27;Business&#x27;</span>, <span class="string">&#x27;Sci/Tech&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Building vocab...&#x27;</span>)</span><br><span class="line">    counter = collections.Counter()</span><br><span class="line">    <span class="keyword">for</span> i, (_, line) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">        counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line),ngrams=ngrams))</span><br><span class="line">        <span class="keyword">if</span> i == lines_cnt:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    vocab = torchtext.vocab.Vocab(collections.Counter(<span class="built_in">dict</span>(counter.most_common(vocab_size))))</span><br><span class="line">    <span class="keyword">return</span> train_dataset, test_dataset, classes, vocab, tokenizer</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode</span>(<span class="params">x, vocabulary, tokenizer = tokenizer</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [vocabulary[s] <span class="keyword">for</span> s <span class="keyword">in</span> tokenizer(x)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_cbow</span>(<span class="params">sent,window_size=<span class="number">2</span></span>):</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i,x <span class="keyword">in</span> <span class="built_in">enumerate</span>(sent):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">max</span>(<span class="number">0</span>,i-window_size),<span class="built_in">min</span>(i+window_size+<span class="number">1</span>,<span class="built_in">len</span>(sent))):</span><br><span class="line">            <span class="keyword">if</span> i!=j:</span><br><span class="line">                res.append([sent[j],x])</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(to_cbow([<span class="string">&#x27;I&#x27;</span>,<span class="string">&#x27;like&#x27;</span>,<span class="string">&#x27;to&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;networks&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(to_cbow(encode(<span class="string">&#x27;I like to train networks&#x27;</span>, vocab)))</span><br></pre></td></tr></table></figure><p>在设计数据集的时候,得到的就是例如[2,3],[4,3],其中3是预测的词,2,4是其周围的词,这样也不需要padding了.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleIterableDataset</span>(<span class="params">torch.utils.data.IterableDataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, X, Y</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SimpleIterableDataset).__init__()</span><br><span class="line">        self.data = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">            self.data.append( (Y[i], X[i]) )</span><br><span class="line">        random.shuffle(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(self.data)</span><br><span class="line"></span><br><span class="line">ds = SimpleIterableDataset(X, Y)</span><br><span class="line">dl = torch.utils.data.DataLoader(ds, batch_size = <span class="number">256</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">net, dataloader, lr = <span class="number">0.01</span>, optimizer = <span class="literal">None</span>, loss_fn = torch.nn.CrossEntropyLoss(<span class="params"></span>), epochs = <span class="literal">None</span>, report_freq = <span class="number">1</span></span>):</span></span><br><span class="line">    optimizer = optimizer <span class="keyword">or</span> torch.optim.Adam(net.parameters(), lr = lr)</span><br><span class="line">    loss_fn = loss_fn.to(device)</span><br><span class="line">    net.train()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        total_loss, j = <span class="number">0</span>, <span class="number">0</span>, </span><br><span class="line">        <span class="keyword">for</span> labels, features <span class="keyword">in</span> dataloader:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            features, labels = features.to(device), labels.to(device)</span><br><span class="line">            out = net(features)</span><br><span class="line">            loss = loss_fn(out, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            total_loss += loss</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i % report_freq == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>: loss=<span class="subst">&#123;total_loss.item()/j&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss.item()/j</span><br></pre></td></tr></table></figure><p><img data-src="https://i.imgur.com/0xvQ6IJ.png" alt="image-20231023201214794"></p><p>关键是生成了一堆数据,句子中的某个单词由周围N个单词生成(CBOW).模型是简单的embedding层加一个全连接,输出特征大小是vocab_size,用softmax损失,最后就能无监督训练得到一个embedding层.</p><h2 id="RNN-Recurrent-Neural-Networks"><a href="#RNN-Recurrent-Neural-Networks" class="headerlink" title="RNN(Recurrent Neural Networks)"></a>RNN(Recurrent Neural Networks)</h2><blockquote><p>之前直接使用的是全连接层,这种架构的作用是捕获句子中单词的聚合含义，但它没有考虑单词的顺序，因为嵌入之上的聚合操作从原始文本中删除了此信息。由于这些模型无法对单词排序进行建模，因此它们无法解决更复杂或模糊的任务，例如文本生成或问答。</p></blockquote><p>给定标记 X~0~,…,X~n~ 的输入序列，RNN 创建一个神经网络块序列，并使用反向传播端到端地训练该序列。每个网络块将一对（X~i~，S~i~）作为输入，并产生S~i+1~。最终状态 S~n~ 或（输出 Y~n~）进入线性分类器以产生结果。所有网络块共享相同的权重，并使用一个反向传播通道进行端到端训练。</p><p>为了捕捉文本序列的含义，我们需要使用另一种神经网络架构，称为递归神经网络或RNN。在 RNN 中，我们通过<strong>网络一次传递一个符号，网络产生一些状态，然后我们用下一个符号再次传递给网络</strong>。</p><p><img data-src="https://i.imgur.com/FwxIpWX.png" alt="image-20231023222833797"></p><p>pytorch中普通RNN隐状态通过了tanh激活,每一层的隐状态与输出是一样.</p><p><img data-src="https://i.imgur.com/5uUeVVj.png" alt="image-20231023224359316"></p><p>对于一个句子的数据,X是(seq_length,embedding_size),权重W是(embedding_size,hidden_dim),H是(hidden_dim,hidden_dim),S是(seq_length,hidden_dim),S是上一层的输出,也就是W×X~i~+H×S~i-1~+b.</p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/images/rnn.png" alt="RNN"></p><p>由于状态向量 S0,…,Sn 通过网络传递，因此它能够学习单词之间的顺序依赖关系。例如，当单词没有出现在序列中的某个地方时，它可以学习否定状态向量中的某些元素，从而导致否定.</p><p><strong>RNN内部结构</strong></p><p><img data-src="https://i.imgur.com/dk3vOfq.png" alt="image-20231023212717744"></p><p>简单的RNN接受先前的状态 S~i-1~和当前符号 X~i~作为输入，并且必须产生输出状态 S~i~（有时，我们也对其他一些输出 Y~i~ 感兴趣，例如生成网络的情况）</p><p><img data-src="https://i.imgur.com/YwIbQc4.jpg" alt="img"></p><blockquote><p>注意,上面的seq_length是输入的长度,但并不是每一句的长度,因为每一句长度很可能不一样,这样RNN无法计算,是一个batch中vocab最大的长度,也就是在一个batch中padding到最大长度</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">padify</span>(<span class="params">b,voc=<span class="literal">None</span>,tokenizer=tokenizer</span>):</span></span><br><span class="line">    <span class="comment"># b is the list of tuples of length batch_size</span></span><br><span class="line">    <span class="comment">#   - first element of a tuple = label, </span></span><br><span class="line">    <span class="comment">#   - second = feature (text sequence)</span></span><br><span class="line">    <span class="comment"># build vectorized sequence</span></span><br><span class="line">    v = [encode(x[<span class="number">1</span>],voc=voc,tokenizer=tokenizer) <span class="keyword">for</span> x <span class="keyword">in</span> b]</span><br><span class="line">    <span class="comment"># compute max length of a sequence in this minibatch</span></span><br><span class="line">    l = <span class="built_in">max</span>(<span class="built_in">map</span>(<span class="built_in">len</span>,v))</span><br><span class="line">    <span class="keyword">return</span> ( <span class="comment"># tuple of two tensors - labels and features</span></span><br><span class="line">        torch.LongTensor([t[<span class="number">0</span>]-<span class="number">1</span> <span class="keyword">for</span> t <span class="keyword">in</span> b]),</span><br><span class="line">        torch.stack([torch.nn.functional.pad(torch.tensor(t),(<span class="number">0</span>,l-<span class="built_in">len</span>(t)),mode=<span class="string">&#x27;constant&#x27;</span>,value=<span class="number">0</span>) <span class="keyword">for</span> t <span class="keyword">in</span> v])</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">16</span>, collate_fn=padify, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>在许多情况下，输入token在进入 RNN 之前通过嵌入层以降低维度。每一层输出是σ(W×X~i~+H×S~i-1~+b)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">input_size = <span class="number">100</span>   <span class="comment"># 输入数据编码的维度</span></span><br><span class="line">hidden_size = <span class="number">20</span>   <span class="comment"># 隐含层维度</span></span><br><span class="line">num_layers = <span class="number">4</span>     <span class="comment"># 隐含层层数</span></span><br><span class="line"></span><br><span class="line">rnn = nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;rnn:&quot;</span>,rnn)</span><br><span class="line"></span><br><span class="line">seq_len = <span class="number">10</span>        <span class="comment"># 句子长度</span></span><br><span class="line">batch_size = <span class="number">1</span>      </span><br><span class="line">x = torch.randn(seq_len,batch_size,input_size)        <span class="comment"># 输入数据</span></span><br><span class="line">h0 = torch.zeros(num_layers,batch_size,hidden_size)   <span class="comment"># 输入数据</span></span><br><span class="line"></span><br><span class="line">out, h = rnn(x, h0)  <span class="comment"># 输出数据</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;out.shape:&quot;</span>,out.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;h.shape:&quot;</span>,h.shape)</span><br></pre></td></tr></table></figure><p>注意,pytorch RNN默认输入数据是(seq_length,batch_size,embedding_size),除非设置<code>batch_first=True</code></p><h4 id="LSTM-amp-amp-GRU"><a href="#LSTM-amp-amp-GRU" class="headerlink" title="LSTM&amp;&amp;GRU"></a>LSTM&amp;&amp;GRU</h4><p><img data-src="https://i.imgur.com/VYCgrZW.png" alt="image-20231023214516563"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTMClassifier</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embed_dim, hidden_dim, num_class</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)</span><br><span class="line">        self.embedding.weight.data = torch.randn_like(self.embedding.weight.data)-<span class="number">0.5</span></span><br><span class="line">        self.rnn = torch.nn.LSTM(embed_dim,hidden_dim,batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(hidden_dim, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        x,(h,c) = self.rnn(x)</span><br><span class="line">        <span class="keyword">return</span> self.fc(h[-<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">net = LSTMClassifier(vocab_size,<span class="number">64</span>,<span class="number">32</span>,<span class="built_in">len</span>(classes)).to(device)</span><br><span class="line">train_epoch(net,train_loader, lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><p>LSTM增加了三个门用来控制隐状态,输入.</p><ul><li>忘记门采用隐藏的向量并确定我们需要忘记向量 c 的哪些分量，以及要通过哪些分量。</li><li>输入门从输入和隐藏向量中获取一些信息，并将其插入状态。</li><li>输出门通过具有tanh激活的某个线性层转换状态，然后使用隐藏向量H~i~选择其部分组件以产生新的状态c~i + 1~。</li></ul><p>而GRU结构要简单一些,支持隐状态的门控. 重置门允许我们控制“可能还想记住”的过去状态的数量, 更新门将允许我们控制新状态中有多少个是旧状态的副本。</p><p><img data-src="https://i.imgur.com/v83gWCu.png" alt="image-20231023214736240"></p><p><img data-src="https://i.imgur.com/eMlaE2s.png" alt="image-20231023214808081"></p><p><img data-src="https://i.imgur.com/r4xeKjo.png" alt="image-20231023214906219"></p><p><img data-src="C:\Users\proanimer\AppData\Roaming\Typora\typora-user-images\image-20231023214919424.png" alt="image-20231023214919424"></p><p><img data-src="https://i.imgur.com/8r65rwW.png" alt="image-20231023214931931"></p><p>我们必须用零向量填充小批量中的所有序列。虽然这会导致一些内存浪费，但对于 RNN,为填充的输入项创建额外的 RNN 单元更为重要，这些输入项参与训练，但不携带任何重要的输入信息。<strong>仅将 RNN 训练到实际序列大小会好得多</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pad_length</span>(<span class="params">b</span>):</span></span><br><span class="line">    <span class="comment"># build vectorized sequence</span></span><br><span class="line">    v = [encode(x[<span class="number">1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> b]</span><br><span class="line">    <span class="comment"># compute max length of a sequence in this minibatch and length sequence itself</span></span><br><span class="line">    len_seq = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">len</span>,v))</span><br><span class="line">    l = <span class="built_in">max</span>(len_seq)</span><br><span class="line">    <span class="keyword">return</span> ( <span class="comment"># tuple of three tensors - labels, padded features, length sequence</span></span><br><span class="line">        torch.LongTensor([t[<span class="number">0</span>]-<span class="number">1</span> <span class="keyword">for</span> t <span class="keyword">in</span> b]),</span><br><span class="line">        torch.stack([torch.nn.functional.pad(torch.tensor(t),(<span class="number">0</span>,l-<span class="built_in">len</span>(t)),mode=<span class="string">&#x27;constant&#x27;</span>,value=<span class="number">0</span>) <span class="keyword">for</span> t <span class="keyword">in</span> v]),</span><br><span class="line">        torch.tensor(len_seq)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">train_loader_len = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">16</span>, collate_fn=pad_length, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSTMPackClassifier</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embed_dim, hidden_dim, num_class</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)</span><br><span class="line">        self.embedding.weight.data = torch.randn_like(self.embedding.weight.data)-<span class="number">0.5</span></span><br><span class="line">        self.rnn = torch.nn.LSTM(embed_dim,hidden_dim,batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(hidden_dim, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, lengths</span>):</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        pad_x = torch.nn.utils.rnn.pack_padded_sequence(x,lengths,batch_first=<span class="literal">True</span>,enforce_sorted=<span class="literal">False</span>)</span><br><span class="line">        pad_x,(h,c) = self.rnn(pad_x)</span><br><span class="line">        x, _ = torch.nn.utils.rnn.pad_packed_sequence(pad_x,batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.fc(h[-<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">net = LSTMPackClassifier(vocab_size,<span class="number">64</span>,<span class="number">32</span>,<span class="built_in">len</span>(classes)).to(device)</span><br><span class="line">train_epoch_emb(net,train_loader_len, lr=<span class="number">0.001</span>,use_pack_sequence=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>要生成打包序列，我们可以使用<code>torch.nn.utils.rnn.pack_padded_sequence</code>函数。所有循环层，包括RNN，LSTM和GRU，都支持打包序列作为输入，并产生可以使用<code>torch.nn.utils.rnn.pad_packed_sequence</code>解码打包输出。</p><p>训练时,传入<code>len_seq = list(map(len,v))</code>,使用<code>torch.nn.utils.rnn.pack_padded_sequence</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pad_x = torch.nn.utils.rnn.pack_padded_sequence(x,lengths,batch_first=<span class="literal">True</span>,enforce_sorted=<span class="literal">False</span>)</span><br><span class="line">pad_x,(h,c) = self.rnn(pad_x)</span><br></pre></td></tr></table></figure><p>再使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x, _ = torch.nn.utils.rnn.pad_packed_sequence(pad_x,batch_first=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>可以解码打包的输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch_emb</span>(<span class="params">net,dataloader,lr=<span class="number">0.01</span>,optimizer=<span class="literal">None</span>,loss_fn = torch.nn.CrossEntropyLoss(<span class="params"></span>),epoch_size=<span class="literal">None</span>, report_freq=<span class="number">200</span>,use_pack_sequence=<span class="literal">False</span></span>):</span></span><br><span class="line">    optimizer = optimizer <span class="keyword">or</span> torch.optim.Adam(net.parameters(),lr=lr)</span><br><span class="line">    loss_fn = loss_fn.to(device)</span><br><span class="line">    net.train()</span><br><span class="line">    total_loss,acc,count,i = <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> labels,text,off <span class="keyword">in</span> dataloader:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        labels,text = labels.to(device), text.to(device)</span><br><span class="line">        <span class="keyword">if</span> use_pack_sequence:</span><br><span class="line">            off = off.to(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            off = off.to(device)</span><br><span class="line">        out = net(text, off)</span><br><span class="line">        loss = loss_fn(out,labels) <span class="comment">#cross_entropy(out,labels)</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss+=loss</span><br><span class="line">        _,predicted = torch.<span class="built_in">max</span>(out,<span class="number">1</span>)</span><br><span class="line">        acc+=(predicted==labels).<span class="built_in">sum</span>()</span><br><span class="line">        count+=<span class="built_in">len</span>(labels)</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i%report_freq==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;count&#125;</span>: acc=<span class="subst">&#123;acc.item()/count&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> epoch_size <span class="keyword">and</span> count&gt;epoch_size:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> total_loss.item()/count, acc.item()/count</span><br></pre></td></tr></table></figure><blockquote><p>目前，pack_padded_sequence函数要求长度序列张量位于CPU设备上，因此训练函数在训练时需要避免将长度序列数据移动到GPU。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> use_pack_sequence:</span><br><span class="line">            off = off.to(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            off = off.to(device)</span><br></pre></td></tr></table></figure><h4 id="Bidirectional-and-Multilayer-RNNs"><a href="#Bidirectional-and-Multilayer-RNNs" class="headerlink" title="Bidirectional and Multilayer RNNs"></a>Bidirectional and Multilayer RNNs</h4><p>由于在许多实际情况下，我们可以随机访问输入序列，因此在两个方向上运行循环计算可能是有意义的。这样的网络被称为双向RNN。在处理双向网络时，我们需要两个隐藏状态向量，每个方向一个。</p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/images/multi-layer-lstm.jpg" alt="Image showing a Multilayer long-short-term-memory- RNN"></p><p>与卷积网络一样，可以在第一层之上构建另一个循环层，以捕获更高级别的模式，并从第一层提取的低级模式进行构建。这导致我们得出多层RNN的概念，它由两个或多个循环网络组成，其中前一层的输出作为输入传递到下一层。</p><h2 id="GRN-Generative-Recurrent-Networks"><a href="#GRN-Generative-Recurrent-Networks" class="headerlink" title="GRN(Generative Recurrent Networks)"></a>GRN(Generative Recurrent Networks)</h2><p>递归神经网络（RNN）及其门控细胞变体，如长短期记忆细胞（LSTM）和门控循环单元（GRU）为语言建模提供了一种机制，因为它们可以学习单词顺序并为序列中的下一个单词提供预测。这使我们能够将 RNN 用于生成任务，例如<strong>普通文本生成、机器翻译，甚至图像字幕</strong>。</p><p>每个 RNN 单元产生下一个隐藏状态作为输出。但是，我们也可以为每个循环单元添加另一个输出，这将允许我们输出一个序列（长度等于原始序列）。此外，我们可以使用在每一步都不接受输入的 RNN 单元，只需获取一些初始状态向量，然后生成一系列输出。分别对应多对多与一对多.</p><p><img data-src="https://i.imgur.com/srjJVXN.png" alt="image-20231023223320804"></p><p><img data-src="https://i.imgur.com/SeTNrFy.png" alt="image-20231023223412819"></p><ul><li>一对一是一个输入和一个输出的传统神经网络</li><li>一对多是一种生成式体系结构，它接受一个输入值，并生成一系列输出值。例如，如果我们想训练一个图像字幕网络来生成图片的文本描述，我们可以将图片作为输入，通过CNN传递以获得其隐藏状态，然后让循环链逐字生成标题。</li><li>多对一对应于我们在上一个单元中描述的 RNN 架构，例如文本分类</li><li>多对多或<strong>序列到序列</strong>对应于机器翻译等任务，其中我们首先让 RNN 将所有信息从输入序列收集到隐藏状态，另一个 RNN 链将此状态展开到输出序列中。</li></ul><h3 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h3><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;之前学过一段时间NLP,因为其中涉及到一些深度学习常用的知识或者框架,但苦于不系统以及没有任务foucus不能长久.这里借助微软的教程写点东西.&lt;br&gt;</summary>
    
    
    
    
    <category term="Deep Learning" scheme="https://www.sekyoro.top/tags/Deep-Learning/"/>
    
    <category term="NLP" scheme="https://www.sekyoro.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>目标检测_初识</title>
    <link href="https://www.sekyoro.top/2023/10/21/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-%E5%88%9D%E8%AF%86/"/>
    <id>https://www.sekyoro.top/2023/10/21/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-%E5%88%9D%E8%AF%86/</id>
    <published>2023-10-21T13:22:20.000Z</published>
    <updated>2023-10-21T13:23:15.893Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>需要一些基本的cv知识<br><span id="more"></span></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;需要一些基本的cv知识&lt;br&gt;</summary>
    
    
    
    
    <category term="object detection" scheme="https://www.sekyoro.top/tags/object-detection/"/>
    
    <category term="cv" scheme="https://www.sekyoro.top/tags/cv/"/>
    
  </entry>
  
  <entry>
    <title>Python并行计算</title>
    <link href="https://www.sekyoro.top/2023/10/20/Python%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    <id>https://www.sekyoro.top/2023/10/20/Python%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/</id>
    <published>2023-10-20T12:20:56.000Z</published>
    <updated>2023-10-21T08:52:53.594Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主要是因为Python库的设计很不错,通过这门语言进一步学习并行,涉及到进程线程以及异步编程等.建议是对性能有要求的利用其他语言实现,但是基本的思想、方法是一样的.<br><span id="more"></span></p><h2 id="创建进程-amp-amp-线程"><a href="#创建进程-amp-amp-线程" class="headerlink" title="创建进程&amp;&amp;线程"></a>创建进程&amp;&amp;线程</h2><ul><li>进程可以包含多个并行运行的线程。</li><li>通常，操作系统创建和管理线程比进程更能节省CPU的资源。线程用于一些小任务，进程用于繁重的任务——运行应用程序。</li><li>同一个进程下的线程共享地址空间和其他资源，进程之间相互独立</li></ul><p>进程有自己的地址空间，数据栈和其他的辅助数据来追踪执行过程；系统会管理所有进程的执行，通过调度程序来分配计算资源等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## The following modules must be imported</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">## this is the code to execute</span></span><br><span class="line">program = <span class="string">&quot;python&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Process calling&quot;</span>)</span><br><span class="line">arguments = [<span class="string">&quot;called_Process.py&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## we call the called_Process.py script</span></span><br><span class="line">os.execvp(program, (program,) + <span class="built_in">tuple</span>(arguments))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Good Bye!!&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello Python Parallel Cookbook!!&quot;</span>)</span><br><span class="line">closeInput = <span class="built_in">input</span>(<span class="string">&quot;Press ENTER to exit&quot;</span>)</span><br><span class="line"><span class="built_in">print</span><span class="string">&quot;Closing calledProcess&quot;</span></span><br></pre></td></tr></table></figure><p>线程创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># To use threads you need import Thread using the following code:</span></span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"><span class="comment"># Also we use the sleep function to make the thread &quot;sleep&quot;</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># To create a thread in Python you&#x27;ll want to make your class work as a thread.</span></span><br><span class="line"><span class="comment"># For this, you should subclass your class from the Thread class</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CookBook</span>(<span class="params">Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        Thread.__init__(self)</span><br><span class="line">        self.message = <span class="string">&quot;Hello Parallel Python CookBook!!\n&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># this method prints only the message</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_message</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(self.message)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The run method prints ten times the message</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Thread Starting\n&quot;</span>)</span><br><span class="line">        x = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> (x &lt; <span class="number">10</span>):</span><br><span class="line">            self.print_message()</span><br><span class="line">            sleep(<span class="number">2</span>)</span><br><span class="line">            x += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Thread Ended\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># start the main process</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Process Started&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create an instance of the HelloWorld class</span></span><br><span class="line">hello_Python = CookBook()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print the message...starting the thread</span></span><br><span class="line">hello_Python.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># end the main process</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Process Ended&quot;</span>)</span><br></pre></td></tr></table></figure><p>Python解释器并不完全是线程安全的。为了支持多线程的Python程序，CPython使用了一个叫做全局解释器锁（Global Interpreter Lock， GIL）的技术。这意味着同一时间只有一个线程可以执行Python代码；执行某一个线程一小段时间之后，Python会自动切换到下一个线程。GIL并没有完全解决线程安全的问题，如果多个线程试图使用共享数据，还是可能导致未确定的行为。</p><h2 id="线程的并行"><a href="#线程的并行" class="headerlink" title="线程的并行"></a>线程的并行</h2><blockquote><p>在软件应用中使用最广泛的并发编程范例是多线程。通常，一个应用有一个进程，分成多个独立的线程，并行运行、互相配合，执行不同类型的任务。</p><p>线程是独立的处理流程，可以和系统的其他线程并行或并发地执行。多线程可以共享数据和资源，利用所谓的共享内存空间。线程和进程的具体实现取决于你要运行的操作系统，但是总体来讲，我们可以说线程是包含在进程中的，同一进程的多个不同的线程可以共享相同的资源。相比而言，进程之间不会共享资源。</p><p>每一个线程基本上包含3个元素：程序计数器，寄存器和栈。与同一进程的其他线程共享的资源基本上包括数据和系统资源。每一个线程也有自己的运行状态，可以和其他线程同步，这点和进程一样。线程的状态大体上可以分为ready,running,blocked。线程的典型应用是应用软件的并行化——为了充分利用现代的多核处理器，使每个核心可以运行单个线程。相比于进程，使用线程的优势主要是性能。相比之下，在进程之间切换上下文要比在统一进程的多线程之间切换上下文要重的多。</p></blockquote><p>多线程编程一般使用共享内容空间进行线程间的通讯。这就使管理内容空间成为多线程编程的重点和难点。</p><p>使用Python的<code>threading</code>模块管理多线程.</p><p>线程被创建之后并不会马上运行，需要手动调用 <code>start()</code> ， <code>join()</code> 让调用它的线程一直等待直到执行结束</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;function called by thread %i&quot;</span> % i)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">slowProcess</span>():</span></span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;slow process done&quot;</span>)</span><br><span class="line"></span><br><span class="line">t = threading.Thread(target=slowProcess, args=())</span><br><span class="line">t.start()</span><br><span class="line">t.join()</span><br><span class="line">t = threading.Thread(target=func, args=(<span class="number">1</span>,))</span><br><span class="line">t.start()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;process quit&quot;</span>)</span><br></pre></td></tr></table></figure><p>设置<code>t = threading.Thread(target=slowProcess, args=(),name=&quot;slowp&quot;)</code>线程名称</p><p>线程被创建之后并不会马上运行，需要手动调用 <code>start()</code>.此外<code>join()</code> 让<strong>调用它的线程一直等待直到执行结束</strong>（即阻塞调用它的主线程， <code>t</code> 线程执行结束，主线程才会继续执行）</p><p><code>threading.current_thread().name</code>访问执行当前代码的线程的名称.</p><p>主线程是<code>MainThread</code>. 实现多线程可以选择继承threading.Thread类或者直接使用<code>threading.Thread</code>方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">exitFlag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myThread</span>(<span class="params">threading.Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, threadID, name, counter</span>):</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.threadID = threadID</span><br><span class="line">        self.name = name</span><br><span class="line">        self.counter = counter</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;starting &quot;</span> + self.name)</span><br><span class="line">        print_time(self.name, self.counter, <span class="number">5</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;exiting &quot;</span> + self.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_time</span>(<span class="params">threadName, delay, counter</span>):</span></span><br><span class="line">    <span class="keyword">while</span> counter:</span><br><span class="line">        <span class="keyword">if</span> exitFlag:</span><br><span class="line">            _thread.exit()</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;%s:%s&quot;</span> % (threadName, time.ctime(time.time())))</span><br><span class="line">        counter -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">thread1 = myThread(<span class="number">1</span>, <span class="string">&quot;thread-1&quot;</span>, <span class="number">1</span>)</span><br><span class="line">thread2 = myThread(<span class="number">2</span>, <span class="string">&quot;thread-2&quot;</span>, <span class="number">2</span>)</span><br><span class="line">thread1.start()</span><br><span class="line">thread2.start()</span><br><span class="line">thread1.join()</span><br><span class="line">thread2.join()</span><br></pre></td></tr></table></figure><p><code>threading</code> 模块是创建和管理线程的首选形式。每一个线程都通过一个继承 <code>Thread</code> 类，重写 <code>run()</code> 方法来实现逻辑，这个方法是线程的入口。在主程序中，我们创建了多个 <code>myThread</code> 的类型实例，然后执行 <code>start()</code> 方法启动它们。调用 <code>Thread.__init__</code> 构造器方法是必须的，通过它我们可以给线程定义一些名字或分组之类的属性。调用 <code>start()</code> 之后线程变为活跃状态，并且持续直到 <code>run()</code> 结束，或者中间出现异常。所有的线程都执行完成之后，程序结束。</p><h3 id="线程的同步"><a href="#线程的同步" class="headerlink" title="线程的同步"></a>线程的同步</h3><p>当两个或以上对共享内存的操作发生在并发线程中，并且至少有一个可以改变数据，又没有同步机制的条件下，就会产生竞争条件，可能会导致执行无效代码、bug、或异常行为。</p><h4 id="Lock锁同步"><a href="#Lock锁同步" class="headerlink" title="Lock锁同步"></a>Lock锁同步</h4><p>竞争条件最简单的解决方法是使用锁。锁的操作非常简单，当一个线程需要访问部分共享内存时，它必须先获得锁才能访问。此线程对这部分共享资源使用完成之后，该线程必须释放锁，然后其他线程就可以拿到这个锁并访问这部分资源了。</p><p>使用lock同步线程,通过它我们可以将共享资源某一时刻的访问限制在单一线程或单一类型的线程上，线程必须得到锁才能使用资源，并且之后必须允许其他线程使用相同的资源。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">shared_resource_with_lock = <span class="number">0</span></span><br><span class="line">shared_resource_with_no_lock = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">COUNT = <span class="number">1000000</span></span><br><span class="line"></span><br><span class="line">shared_resource_lock = threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increment_with_lock</span>():</span></span><br><span class="line">    <span class="keyword">global</span> shared_resource_with_lock</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(COUNT):</span><br><span class="line">        shared_resource_lock.acquire()</span><br><span class="line">        shared_resource_with_lock += <span class="number">1</span></span><br><span class="line">        shared_resource_lock.release()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decrement_with_lock</span>():</span></span><br><span class="line">    <span class="keyword">global</span> shared_resource_with_lock</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(COUNT):</span><br><span class="line">        shared_resource_lock.acquire()</span><br><span class="line">        shared_resource_with_lock  -=<span class="number">1</span></span><br><span class="line">        shared_resource_lock.release()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increment_without_lock</span>():</span></span><br><span class="line">    <span class="keyword">global</span> shared_resource_with_no_lock</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(COUNT):</span><br><span class="line">        shared_resource_with_no_lock +=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decrement_without_lock</span>():</span></span><br><span class="line">    <span class="keyword">global</span> shared_resource_with_no_lock</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(COUNT):</span><br><span class="line">        shared_resource_with_no_lock -=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    t1 = threading.Thread(target=increment_with_lock)</span><br><span class="line">    t2 = threading.Thread(target=decrement_with_lock)</span><br><span class="line">    t3 = threading.Thread(target=increment_without_lock)</span><br><span class="line">    t4 = threading.Thread(target=decrement_without_lock)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t3.start()</span><br><span class="line">    t4.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    t3.join()</span><br><span class="line">    t4.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;the value of shared variable with lock management is %s&quot;</span> % shared_resource_with_lock)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;the value of shared variable with race condition is %s&quot;</span> % shared_resource_with_no_lock)</span><br></pre></td></tr></table></figure><ul><li>锁有两种状态： locked（被某一线程拿到）和unlocked（可用状态）</li><li><p>我们有两个方法来操作锁： <code>acquire()</code> 和 <code>release()</code></p></li><li><p>如果状态是unlocked， 可以调用 <code>acquire()</code> 将状态改为locked</p></li><li>如果状态是locked， <code>acquire()</code> 会被block直到另一线程调用 <code>release()</code> 释放锁</li><li>如果状态是unlocked， 调用 <code>release()</code> 将导致 <code>RuntimError</code> 异常</li><li>如果状态是locked， 可以调用 <code>release()</code> 将状态改为unlocked</li></ul><blockquote><p>尽管理论上行得通，但是锁的策略不仅会导致有害的僵持局面。还会对应用程序的其他方面产生负面影响。这是一种保守的方法，经常会引起不必要的开销，也会限制程序的可扩展性和可读性。更重要的是，有时候需要对多进程共享的内存分配优先级，使用锁可能和这种优先级冲突。最后，从实践的经验来看，使用锁的应用将对debug带来不小的麻烦。所以，最好使用其他可选的方法确保同步读取共享内存，避免竞争条件。</p></blockquote><p>事实上我执行这段代码时跟线程是否join有关,基本上上面代码是否加锁都没有出问题</p><h4 id="RLock锁同步"><a href="#RLock锁同步" class="headerlink" title="RLock锁同步"></a>RLock锁同步</h4><p>如果你想让只有拿到锁的线程才能释放该锁，那么应该使用 <code>RLock()</code> 对象。和 <code>Lock()</code> 对象一样， <code>RLock()</code> 对象有两个方法： <code>acquire()</code> 和 <code>release()</code> 。当你需要在类外面保证线程安全，又要在类内使用同样方法的时候 <code>RLock()</code> 就很实用了</p><blockquote><p>RLock其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比Lock有是三个特点：1. 谁拿到谁释放。如果线程A拿到锁，线程B无法释放这个锁，只有A可以释放；2. 同一线程可以多次拿到该锁，即可以acquire多次；3. acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>:</span></span><br><span class="line">    lock = threading.RLock()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.total_items = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">self,n</span>):</span></span><br><span class="line">        Box.lock.acquire()</span><br><span class="line">        self.total_items += n</span><br><span class="line">        Box.lock.release()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self</span>):</span></span><br><span class="line">        Box.lock.acquire()</span><br><span class="line">        self.execute(<span class="number">1</span>)</span><br><span class="line">        Box.lock.release()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove</span>(<span class="params">self</span>):</span></span><br><span class="line">        Box.lock.acquire()</span><br><span class="line">        self.execute(-<span class="number">1</span>)</span><br><span class="line">        Box.lock.release()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adder</span>(<span class="params">box, items</span>):</span></span><br><span class="line">    <span class="keyword">while</span> items &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;adding 1 item in the box&quot;</span>)</span><br><span class="line">        box.add()</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        items -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remover</span>(<span class="params">box, items</span>):</span></span><br><span class="line">    <span class="keyword">while</span> items &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;removing 1 item in the box&quot;</span>)</span><br><span class="line">        box.remove()</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        items -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    items = <span class="number">5</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;putting %s items in the box &quot;</span> % items)</span><br><span class="line">    box = Box()</span><br><span class="line">    t1 = threading.Thread(target=adder, args=(box, items))</span><br><span class="line">    t2 = threading.Thread(target=remover, args=(box, items))</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s items still remain in the box &quot;</span> % Box().total_items)</span><br></pre></td></tr></table></figure><p>相比于Lock有一些更稳定的设定.</p><h4 id="信号量同步"><a href="#信号量同步" class="headerlink" title="信号量同步"></a>信号量同步</h4><p>信号量是一个内部数据，用于标明当前的共享资源可以有多少并发读取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">semaphore = threading.Semaphore(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;consumer is waiting.&quot;</span>)</span><br><span class="line">    semaphore.acquire()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;consumer notify: consumed item number %s &quot;</span> % item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">producer</span>():</span></span><br><span class="line">    <span class="keyword">global</span> item</span><br><span class="line">    time.sleep(<span class="number">10</span>)</span><br><span class="line">    item = random.randint(<span class="number">0</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;producer notify:produced item number %s&quot;</span> % item)</span><br><span class="line">    semaphore.release()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">        t1 = threading.Thread(target=producer)</span><br><span class="line">        t2 = threading.Thread(target=consumer)</span><br><span class="line">        t1.start()</span><br><span class="line">        t2.start()</span><br><span class="line">        t1.join()</span><br><span class="line">        t2.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;program terminated&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>信号量的一个特殊用法是互斥量。互斥量是初始值为1的信号量，可以实现数据、资源的互斥访问。</p><p>信号量在支持多线程的编程语言中依然应用很广，然而这可能导致死锁的情况。例如，现在有一个线程t1先等待信号量s1，然后等待信号量s2，而线程t2会先等待信号量s2，然后再等待信号量s1，这样就可能会发生死锁，导致t1等待s2，但是t2在等待s1。</p></blockquote><h4 id="条件进行同步"><a href="#条件进行同步" class="headerlink" title="条件进行同步"></a>条件进行同步</h4><p>条件指的是应用程序状态的改变。这是另一种同步机制，其中某些线程在等待某一条件发生，其他的线程会在该条件发生的时候进行通知。一旦条件发生，线程会拿到共享资源的唯一权限</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread, Condition</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">items = []</span><br><span class="line">condition = Condition()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">consumer</span>(<span class="params">Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        Thread.__init__(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">consume</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">global</span> condition</span><br><span class="line">        <span class="keyword">global</span> items</span><br><span class="line">        condition.acquire()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(items) == <span class="number">0</span>:</span><br><span class="line">            condition.wait()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;consumer notify: no item to consume&quot;</span>)</span><br><span class="line">        items.pop()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;consumer notify: consumed 1 item&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;consumer notify: items to consume are &quot;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(items)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">20</span>):</span><br><span class="line">            time.sleep(<span class="number">10</span>)</span><br><span class="line">            self.consume()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">producer</span>(<span class="params">Thread</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        Thread.__init__(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">produce</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">global</span> condition</span><br><span class="line">        <span class="keyword">global</span> items</span><br><span class="line">        condition.acquire()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(items) == <span class="number">10</span>:</span><br><span class="line">            condition.wait()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Producer notify : items producted are &quot;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(items)))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Producer notify : stop the production!!&quot;</span>)</span><br><span class="line">        items.append(<span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Producer notify : total items producted &quot;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(items)))</span><br><span class="line">        condition.notify()</span><br><span class="line">        condition.release()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">20</span>):</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            self.produce()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    producer = producer()</span><br><span class="line">    consumer = consumer()</span><br><span class="line">    producer.start()</span><br><span class="line">    consumer.start()</span><br><span class="line">    producer.join()</span><br><span class="line">    consumer.join()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="事件同步"><a href="#事件同步" class="headerlink" title="事件同步"></a>事件同步</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread,Event</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">items = []</span><br><span class="line">event = Event()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">consumer</span>(<span class="params">Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,items,event</span>):</span></span><br><span class="line">        Thread.__init__(self)</span><br><span class="line">        self.items = items</span><br><span class="line">        self.event = event</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            time.sleep(<span class="number">10</span>)</span><br><span class="line">            self.event.wait()</span><br><span class="line">            item = self.items.pop()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;consumer notify: consumed 1 item&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">producer</span>(<span class="params">Thread</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, items, event</span>):</span></span><br><span class="line">        Thread.__init__(self)</span><br><span class="line">        self.items = items</span><br><span class="line">        self.event = event</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">global</span> item</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line">            item = random.randint(<span class="number">0</span>, <span class="number">256</span>)</span><br><span class="line">            self.items.append(item)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Producer notify : item N° %d appended to list by %s&#x27;</span> % (item, self.name))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Producer notify : event set by %s&#x27;</span> % self.name)</span><br><span class="line">            self.event.<span class="built_in">set</span>()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Produce notify : event cleared by %s &#x27;</span>% self.name)</span><br><span class="line">            self.event.clear()</span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t1 = producer(items, event)</span><br><span class="line">    t2 = consumer(items, event)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br></pre></td></tr></table></figure><p><img data-src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/event.png" alt="../_images/event.png" style="zoom:67%;" /></p><h4 id="使用with简化"><a href="#使用with简化" class="headerlink" title="使用with简化"></a>使用with简化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.DEBUG, <span class="built_in">format</span>=<span class="string">&#x27;(%(threadName)-10s) %(message)s&#x27;</span>,)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">threading_with</span>(<span class="params">statement</span>):</span></span><br><span class="line">    <span class="keyword">with</span> statement:</span><br><span class="line">        logging.debug(<span class="string">&#x27;%s acquired via with&#x27;</span> % statement)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">threading_not_with</span>(<span class="params">statement</span>):</span></span><br><span class="line">    statement.acquire()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        logging.debug(<span class="string">&#x27;%s acquired directly&#x27;</span> % statement )</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        statement.release()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># let&#x27;s create a test battery</span></span><br><span class="line">    lock = threading.Lock()</span><br><span class="line">    rlock = threading.RLock()</span><br><span class="line">    condition = threading.Condition()</span><br><span class="line">    mutex = threading.Semaphore(<span class="number">1</span>)</span><br><span class="line">    threading_synchronization_list = [lock, rlock, condition, mutex]</span><br><span class="line">    <span class="comment"># in the for cycle we call the threading_with e threading_no_with function</span></span><br><span class="line">    <span class="keyword">for</span> statement <span class="keyword">in</span> threading_synchronization_list :</span><br><span class="line">       t1 = threading.Thread(target=threading_with, args=(statement,))</span><br><span class="line">       t2 = threading.Thread(target=threading_not_with, args=(statement,))</span><br><span class="line">       t1.start()</span><br><span class="line">       t2.start()</span><br><span class="line">       t1.join()</span><br><span class="line">       t2.join()</span><br></pre></td></tr></table></figure><p>此外,当线程之间共享资源时,可以利用上面的原语,也可以使用queue.队列操作起来更容易，也使多线程编程更安全，因为队列可以将资源的使用通过单线程进行完全控制，并且允许使用更加整洁和可读性更高的设计模式。</p><p>Queue常用的方法有以下四个：</p><ul><li><code>put()</code>: 往queue中放一个item</li><li><code>get()</code>: 从queue删除一个item，并返回删除的这个item</li><li><code>task_done()</code>: 每次item被处理的时候需要调用这个方法</li><li><code>join()</code>: 所有item都被处理之前一直阻塞</li></ul><h3 id="进程的并行"><a href="#进程的并行" class="headerlink" title="进程的并行"></a>进程的并行</h3><p>由父进程创建子进程。父进程既可以在产生子进程之后继续异步执行，也可以暂停等待子进程创建完成之后再继续执行.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;called function in process:%s&#x27;</span> % i)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    Process_jobs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        p = multiprocessing.Process(target=foo, args=(i,))</span><br><span class="line">        Process_jobs.append(p)</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br></pre></td></tr></table></figure><p>使用进程对象调用 <code>join()</code> 方法。如果没有 <code>join()</code> ，主进程退出之后子进程会留在idle中，必须手动杀死它们。</p><p>进程名字与获取与线程类似.</p><h4 id="后台运行进程"><a href="#后台运行进程" class="headerlink" title="后台运行进程"></a>后台运行进程</h4><blockquote><p>如果需要处理比较巨大的任务，又不需要人为干预，将其作为后台进程执行是个非常常用的编程模型。此进程又可以和其他进程并发执行。通过Python的multiprocessing模块的后台进程选项，我们可以让进程在后台运行</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    name = multiprocessing.current_process().name</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting %s \n&quot;</span> % name)</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Exiting %s \n&quot;</span> % name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    background_process = multiprocessing.Process(name=<span class="string">&quot;background_process&quot;</span>, target=foo)</span><br><span class="line">    background_process.daemon = <span class="literal">True</span></span><br><span class="line">    no_background_process = multiprocessing.Process(name=<span class="string">&quot;no_background_process&quot;</span>, target=foo)</span><br><span class="line">    no_background_process.daemon = <span class="literal">False</span></span><br><span class="line">    background_process.start()</span><br><span class="line">    no_background_process.start()</span><br></pre></td></tr></table></figure><p>为了在后台运行进程，我们设置 <code>daemon</code> 参数为 <code>True</code></p><p>在非后台运行的进程会看到一个输出，后台运行的没有输出，<strong>后台运行进程在主进程结束之后会自动结束</strong></p><blockquote><p>注意，后台进程不允许创建子进程。否则，当后台进程跟随父进程退出的时候，子进程会变成孤儿进程。另外，它们并不是Unix的守护进程或服务（daemons or services），所以当非后台进程退出，它们会被终结。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;i=&#123;&#125;,foo thread daemon is &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i, threading.current_thread().daemon))</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = threading.Thread(target=foo, name=<span class="string">&#x27;foo_thread&#x27;</span>, daemon=<span class="literal">True</span>) <span class="comment"># set daemon to True to make it a daemon thread which will exit when the main thread exits</span></span><br><span class="line">t.start()</span><br><span class="line"><span class="comment"># t.join() important otherwise the main thread will exit before the foo thread</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Main thread daemon is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(threading.current_thread().daemon))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Main Thread Exit.&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="杀掉进程"><a href="#杀掉进程" class="headerlink" title="杀掉进程"></a>杀掉进程</h4><p>可以使用 <code>terminate()</code> 方法立即杀死一个进程。另外，我们可以使用 <code>is_alive()</code> 方法来判断一个进程是否还存活。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting function&quot;</span>)</span><br><span class="line">    time.sleep(<span class="number">0.1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Finished function&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    p = multiprocessing.Process(target=foo)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process before execution:&#x27;</span>, p, p.is_alive())</span><br><span class="line">    p.start()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process running:&#x27;</span>, p, p.is_alive())</span><br><span class="line">    p.terminate()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process terminated:&#x27;</span>, p, p.is_alive())</span><br><span class="line">    p.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process joined:&#x27;</span>, p, p.is_alive())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Process exit code:&#x27;</span>, p.exitcode)</span><br></pre></td></tr></table></figure><p>进程的 <code>ExitCode</code> 状态码（status code）验证进程已经结束， <code>ExitCode</code> 可能的值如下：</p><ul><li>== 0: 没有错误正常退出</li><li>> 0: 进程有错误，并以此状态码退出</li><li>&lt; 0: 进程被 <code>-1 *</code> 的信号杀死并以此作为 ExitCode 退出</li></ul><h4 id="子类中使用进程"><a href="#子类中使用进程" class="headerlink" title="子类中使用进程"></a>子类中使用进程</h4><p>实现一个自定义的进程子类，需要以下三步：</p><ul><li>定义 <code>Process</code> 的子类</li><li>覆盖 <code>__init__(self [,args])</code> 方法来添加额外的参数</li><li>覆盖 <code>run(self, [.args])</code> 方法来实现 <code>Process</code> 启动的时候执行的任务</li></ul><p>创建 <code>Porcess</code> 子类之后，你可以创建它的实例并通过 <code>start()</code> 方法启动它，启动之后会运行 <code>run()</code> 方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 自定义子类进程</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyProcess</span>(<span class="params">multiprocessing.Process</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">                <span class="built_in">print</span> (<span class="string">&#x27;called run method in process: %s&#x27;</span> % self.name)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    timestart = timeit.default_timer()</span><br><span class="line">    jobs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            p = MyProcess()</span><br><span class="line">            jobs.append(p)</span><br><span class="line">            p.start()</span><br><span class="line">            p.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Time elapsed:&#x27;</span>, (timeit.default_timer() - timestart))</span><br></pre></td></tr></table></figure><p><code>join()</code> 命令可以让主进程等待其他进程结束最后退出。</p><h4 id="进程中交换对象"><a href="#进程中交换对象" class="headerlink" title="进程中交换对象"></a>进程中交换对象</h4><blockquote><p>并行应用常常需要在进程之间交换数据。Multiprocessing库有两个Communication Channel可以交换对象：队列(queue)和管道（pipe）</p></blockquote><p><img data-src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/communication-channel.png" alt="../_images/communication-channel.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span>(<span class="params">multiprocessing.Process</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, queue</span>):</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.queue = queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            item = random.randint(<span class="number">0</span>, <span class="number">256</span>)</span><br><span class="line">            self.queue.put(item)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Process Producer : item %d appended to queue %s&quot;</span> % (item, self.name))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;The size of queue is %s&quot;</span> % self.queue.qsize())</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span>(<span class="params">multiprocessing.Process</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, queue</span>):</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.queue = queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> self.queue.empty():</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;the queue is empty&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                time.sleep(<span class="number">2</span>)</span><br><span class="line">                item = self.queue.get()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Process Consumer : item %d popped from by %s \n&#x27;</span> % (item, self.name))</span><br><span class="line">                time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    queue = multiprocessing.Queue()</span><br><span class="line">    process_producer = Producer(queue)</span><br><span class="line">    process_consumer = Consumer(queue)</span><br><span class="line">    process_producer.start()</span><br><span class="line">    process_consumer.start()</span><br><span class="line">    process_producer.join()</span><br><span class="line">    process_consumer.join()</span><br></pre></td></tr></table></figure><p>队列还有一个 <code>JoinableQueue</code> 子类，它有以下两个额外的方法：</p><ul><li><code>task_done()</code>: 此方法意味着之前入队的一个任务已经完成，比如， <code>get()</code> 方法从队列取回item之后调用。所以此方法只能被队列的消费者调用。</li><li><code>join()</code>: 此方法将进程阻塞，直到队列中的item全部被取出并执行。</li></ul><p>此外还可以通过Pipe交换对象.</p><h4 id="进程同步"><a href="#进程同步" class="headerlink" title="进程同步"></a>进程同步</h4><p>多个进程可以协同工作来完成一项任务。通常需要共享数据。所以在多进程之间保持数据的一致性就很重要了。需要共享数据协同的进程必须以适当的策略来读写数据。相关的同步原语和线程的库很类似。</p><p>进程的同步原语如下：</p><ul><li><strong>Lock</strong>: 这个对象可以有两种装填：锁住的（locked）和没锁住的（unlocked）。一个Lock对象有两个方法， <code>acquire()</code> 和 <code>release()</code> ，来控制共享数据的读写权限。</li><li><strong>Event</strong>: 实现了进程间的简单通讯，一个进程发事件的信号，另一个进程等待事件的信号。 <code>Event</code> 对象有两个方法， <code>set()</code> 和 <code>clear()</code> ，来管理自己内部的变量。</li><li><strong>Condition</strong>: 此对象用来同步部分工作流程，在并行的进程中，有两个基本的方法： <code>wait()</code> 用来等待进程， <code>notify_all()</code> 用来通知所有等待此条件的进程。</li><li><strong>Semaphore</strong>: 用来共享资源，例如，支持固定数量的共享连接。</li><li><strong>Rlock</strong>: 递归锁对象。其用途和方法同 <code>Threading</code> 模块一样。</li><li><strong>Barrier</strong>: 将程序分成几个阶段，适用于有些进程必须在某些特定进程之后执行。处于障碍（Barrier）之后的代码不能同处于障碍之前的代码并行。</li></ul><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing</span><br><span class="line">from multiprocessing import Barrier, Lock, Process</span><br><span class="line">from time import time</span><br><span class="line">from datetime import datetime</span><br><span class="line"></span><br><span class="line">def test<span class="constructor">_with_barrier(<span class="params">synchronizer</span>, <span class="params">serializer</span>)</span>:</span><br><span class="line">    name = multiprocessing.current<span class="constructor">_process()</span>.name</span><br><span class="line">    synchronizer.wait<span class="literal">()</span></span><br><span class="line">    now = time<span class="literal">()</span></span><br><span class="line">    <span class="keyword">with</span> serializer:</span><br><span class="line">        print(<span class="string">&quot;process %s ----&gt; %s&quot;</span> % (name, datetime.fromtimestamp(now)))</span><br><span class="line"></span><br><span class="line">def test<span class="constructor">_without_barrier()</span>:</span><br><span class="line">    name = multiprocessing.current<span class="constructor">_process()</span>.name</span><br><span class="line">    now = time<span class="literal">()</span></span><br><span class="line">    print(<span class="string">&quot;process %s ----&gt; %s&quot;</span> % (name, datetime.fromtimestamp(now)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__<span class="operator"> == </span>&#x27;__main__&#x27;:</span><br><span class="line">    synchronizer = <span class="constructor">Barrier(2)</span></span><br><span class="line">    serializer = <span class="constructor">Lock()</span></span><br><span class="line">    <span class="constructor">Process(<span class="params">name</span>=&#x27;<span class="params">p1</span> - <span class="params">test_with_barrier</span>&#x27;, <span class="params">target</span>=<span class="params">test_with_barrier</span>, <span class="params">args</span>=(<span class="params">synchronizer</span>,<span class="params">serializer</span>)</span>).start<span class="literal">()</span></span><br><span class="line">    <span class="constructor">Process(<span class="params">name</span>=&#x27;<span class="params">p2</span> - <span class="params">test_with_barrier</span>&#x27;, <span class="params">target</span>=<span class="params">test_with_barrier</span>, <span class="params">args</span>=(<span class="params">synchronizer</span>,<span class="params">serializer</span>)</span>).start<span class="literal">()</span></span><br><span class="line">    <span class="constructor">Process(<span class="params">name</span>=&#x27;<span class="params">p3</span> - <span class="params">test_without_barrier</span>&#x27;, <span class="params">target</span>=<span class="params">test_without_barrier</span>)</span>.start<span class="literal">()</span></span><br><span class="line">    <span class="constructor">Process(<span class="params">name</span>=&#x27;<span class="params">p4</span> - <span class="params">test_without_barrier</span>&#x27;, <span class="params">target</span>=<span class="params">test_without_barrier</span>)</span>.start<span class="literal">()</span></span><br></pre></td></tr></table></figure><h4 id="进程之间管理状态"><a href="#进程之间管理状态" class="headerlink" title="进程之间管理状态"></a>进程之间管理状态</h4><p>Python的多进程模块提供了在所有的用户间管理共享信息的管理者(Manager)。一个管理者对象控制着持有Python对象的服务进程，并允许其它进程操作共享对象。</p><p>管理者有以下特性：</p><ul><li>它控制着管理共享对象的服务进程</li><li>它确保当某一进程修改了共享对象之后，所有的进程拿到额共享对象都得到了更新</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">worker</span>(<span class="params">dictionary,key,item</span>):</span></span><br><span class="line">    dictionary[key] = item</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;key = %d value = %d&quot;</span> %(key,item))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    mgr = multiprocessing.Manager()</span><br><span class="line">    dictionary = mgr.<span class="built_in">dict</span>()</span><br><span class="line">    jobs = [ multiprocessing.Process(target=worker,args=(dictionary,i,i*<span class="number">2</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> jobs:</span><br><span class="line">        j.start()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span>  jobs:</span><br><span class="line">        j.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Results:&#x27;</span>,dictionary)</span><br></pre></td></tr></table></figure><h4 id="使用进程池"><a href="#使用进程池" class="headerlink" title="使用进程池"></a>使用进程池</h4><p>多进程库提供了 <code>Pool</code> 类来实现简单的多进程任务。 <code>Pool</code> 类有以下方法：</p><ul><li><code>apply()</code>: 直到得到结果之前一直阻塞。</li><li><code>apply_async()</code>: 这是 <code>apply()</code> 方法的一个变体，返回的是一个result对象。这是一个异步的操作，在所有的子类执行之前不会锁住主进程。</li><li><code>map()</code>: 这是内置的 <code>map()</code> 函数的并行版本。在得到结果之前一直阻塞，此方法将可迭代的数据的每一个元素作为进程池的一个任务来执行。</li><li><code>map_async()</code>: 这是 <code>map()</code> 方法的一个变体，返回一个result对象。如果指定了回调函数，回调函数应该是callable的，并且只接受一个参数。当result准备好时会自动调用回调函数（除非调用失败）。回调函数应该立即完成，否则，持有result的进程将被阻塞。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_square</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Hi&quot;</span>)</span><br><span class="line">    time.sleep(<span class="number">12</span>)</span><br><span class="line">    result = data*data</span><br><span class="line">    <span class="built_in">print</span>(multiprocessing.current_process().pid)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inputs = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">100</span>))</span><br><span class="line">    pool = multiprocessing.Pool(<span class="number">2</span>)</span><br><span class="line">    pool_outputs = pool.map_async(function_square, inputs)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Pool:&#x27;</span>, pool_outputs)</span><br><span class="line">    <span class="comment"># p.daemon = True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="异步编程"><a href="#异步编程" class="headerlink" title="异步编程"></a>异步编程</h3><h4 id="concurrent-futures"><a href="#concurrent-futures" class="headerlink" title="concurrent.futures"></a>concurrent.futures</h4><p><code>concurrent.futures</code> 模块，这个模块具有线程池和进程池、管理并行编程任务、处理非确定性的执行流程、进程/线程同步等功能。</p><p>此模块由以下部分组成：</p><ul><li><code>concurrent.futures.Executor</code>: 这是一个虚拟基类，提供了异步执行的方法。</li><li><code>submit(function, argument)</code>: 调度函数（可调用的对象）的执行，将 <code>argument</code> 作为参数传入。</li><li><code>map(function, argument)</code>: 将 <code>argument</code> 作为参数执行函数，以 <strong>异步</strong> 的方式。</li><li><code>shutdown(Wait=True)</code>: 发出让执行者释放所有资源的信号。</li><li><code>concurrent.futures.Future</code>: 其中包括函数的异步执行。Future对象是submit任务（即带有参数的functions）到executor的实例。</li></ul><p>Executor是抽象类，可以通过子类访问，即线程或进程的 <code>ExecutorPools</code> 。因为，线程或进程的实例是依赖于资源的任务，所以最好以“池”的形式将他们组织在一起，作为可以重用的launcher或executor。</p><blockquote><p>线程池或进程池是用于在程序中优化和简化线程/进程的使用。通过池，你可以提交任务给executor。池由两部分组成，一部分是内部的队列，存放着待执行的任务；另一部分是一系列的进程或线程，用于执行这些任务。池的概念主要目的是为了重用：让线程或进程在生命周期内可以多次使用。它减少了创建创建线程和进程的开销，提高了程序性能。重用不是必须的规则，但它是程序员在应用中使用池的主要原因。</p></blockquote><p><img data-src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/pooling-management.png" alt="../_images/pooling-management.png" style="zoom:67%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">number_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_item</span>(<span class="params">x</span>):</span></span><br><span class="line">    result_item = count(x)</span><br><span class="line">    <span class="keyword">return</span> result_item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span>(<span class="params">number</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10000000</span>):</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> i * number</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> number_list:</span><br><span class="line">        <span class="built_in">print</span>(evaluate_item(item))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Sequential execution in &quot;</span> + <span class="built_in">str</span>(time.time() - start_time), <span class="string">&quot;seconds&quot;</span>)</span><br><span class="line">    start_time_1 = time.time()</span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> executor:</span><br><span class="line">        futures = [executor.submit(evaluate_item, item) <span class="keyword">for</span> item <span class="keyword">in</span> number_list]</span><br><span class="line">        <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(futures):</span><br><span class="line">            <span class="built_in">print</span>(future.result())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Thread pool execution in &quot;</span> + <span class="built_in">str</span>(time.time() - start_time_1), <span class="string">&quot;seconds&quot;</span>)</span><br><span class="line">    start_time_2 = time.time()</span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> executor:</span><br><span class="line">        futures = [executor.submit(evaluate_item, item) <span class="keyword">for</span> item <span class="keyword">in</span> number_list]</span><br><span class="line">        <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(futures):</span><br><span class="line">            <span class="built_in">print</span>(future.result())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Process pool execution in &quot;</span> + <span class="built_in">str</span>(time.time() - start_time_2), <span class="string">&quot;seconds&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个计算平方的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个ThreadPoolExecutor对象，设置线程池中的线程数量为2</span></span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor(max_workers=<span class="number">2</span>) <span class="keyword">as</span> executor:</span><br><span class="line">    <span class="comment"># 提交任务给线程池，并获取Future对象</span></span><br><span class="line">    future1 = executor.submit(square, <span class="number">5</span>)</span><br><span class="line">    future2 = executor.submit(square, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取任务的执行结果</span></span><br><span class="line">    result1 = future1.result()</span><br><span class="line">    result2 = future2.result()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Result 1: <span class="subst">&#123;result1&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Result 2: <span class="subst">&#123;result2&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Asyncio管理事件循环"><a href="#Asyncio管理事件循环" class="headerlink" title="Asyncio管理事件循环"></a>Asyncio管理事件循环</h4><p>Python的Asyncio模块提供了管理事件、协程、任务和线程的方法，以及编写并发代码的原语。此模块的主要组件和概念包括：</p><ul><li><strong>事件循环</strong>: 在Asyncio模块中，每一个进程都有一个事件循环。</li><li><strong>协程</strong>: 这是子程序的泛化概念。协程可以在执行期间暂停，这样就可以等待外部的处理（例如IO）完成之后，从之前暂停的地方恢复执行。</li><li><strong>Futures</strong>: 定义了 <code>Future</code> 对象，和 <code>concurrent.futures</code> 模块一样，表示尚未完成的计算。</li><li><strong>Tasks</strong>: 这是Asyncio的子类，用于封装和管理并行模式下的协程。</li></ul><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable"><span class="keyword">while</span></span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="variable">events</span> = <span class="function"><span class="title">getEvents</span>();</span></span><br><span class="line"><span class="function">    <span class="variable">for</span> (<span class="variable">e</span> <span class="variable"><span class="keyword">in</span></span> <span class="variable">events</span>)</span></span><br><span class="line">        <span class="function"><span class="title">processEvent</span>(<span class="variable">e</span>);</span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>可以产生事件的实体叫做事件源</strong>，<strong>能处理事件的实体叫做事件处理者</strong>。此外，<strong>还有一些第三方实体叫做事件循环</strong>。它的作用是管理所有的事件，在整个程序运行过程中不断循环执行，追踪事件发生的顺序将它们放到队列中，当主线程空闲的时候，调用相应的事件处理者处理事件。</p></blockquote><p>Asyncio提供了一下方法来管理事件循环：</p><ul><li><code>loop = get_event_loop()</code>: 得到当前上下文的事件循环。</li><li><code>loop.call_later(time_delay, callback, argument)</code>: 延后 <code>time_delay</code> 秒再执行 <code>callback</code> 方法。</li><li><code>loop.call_soon(callback, argument)</code>: 尽可能快调用 <code>callback</code>, <code>call_soon()</code> 函数结束，主线程回到事件循环之后就会马上调用 <code>callback</code> 。</li><li><code>loop.time()</code>: 以float类型返回当前时间循环的内部时间。</li><li><code>asyncio.set_event_loop()</code>: 为当前上下文设置事件循环。</li><li><code>asyncio.new_event_loop()</code>: 根据此策略创建一个新的时间循环并返回。</li><li><code>loop.run_forever()</code>: 在调用 <code>stop()</code> 之前将一直运行。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_1</span>(<span class="params">end_time,loop</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;function_1 called&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (loop.time() + <span class="number">1.0</span>) &lt; end_time:</span><br><span class="line">        loop.call_later(<span class="number">1</span>, function_2, end_time,loop)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loop.stop()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_2</span>(<span class="params">end_time,loop</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;function_2 called&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> loop.time() + <span class="number">1.0</span> &lt; end_time:</span><br><span class="line">        loop.call_later(<span class="number">1</span>, function_3, end_time,loop)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_3</span>(<span class="params">end_time, loop</span>):</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;function_3 called&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (loop.time() + <span class="number">1.0</span>) &lt; end_time:</span><br><span class="line">        loop.call_later(<span class="number">1</span>, function_1, end_time, loop)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loop.stop()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_4</span>(<span class="params">end_time, loop</span>):</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;function_5 called&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (loop.time() + <span class="number">1.0</span>) &lt; end_time:</span><br><span class="line">        loop.call_later(<span class="number">1</span>, function_4, end_time, loop)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loop.stop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    end_loop = loop.time() + <span class="number">9.0</span></span><br><span class="line">    loop.call_soon(function_1, end_loop,loop)</span><br><span class="line">    loop.run_forever()</span><br><span class="line">    loop.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Asyncio管理协程"><a href="#Asyncio管理协程" class="headerlink" title="Asyncio管理协程"></a>Asyncio管理协程</h4><p>子程序不能单独执行，只能在主程序的请求下执行，主程序负责协调使用各个子程序。协程就是子程序的泛化。和子程序一样的事，协程只负责计算任务的一步</p><p>和子程序不一样的是，协程没有主程序来进行调度。这是因为协程通过管道连接在一起，没有监视函数负责顺序调用它们。在协程中，执行点可以被挂起，可以被从之前挂起的点恢复执行。通过协程池就可以插入到计算中：运行第一个任务，直到它返回(yield)执行权，然后运行下一个，这样顺着执行下去。</p><p>协程的另外一些重要特性如下：</p><ul><li>协程可以有多个入口点，并可以yield多次</li><li>协程可以将执行权交给其他协程</li></ul><p>yield表示协程在此暂停，并且将执行权交给其他协程。因为协程可以将值与控制权一起传递给另一个协程，所以“yield一个值”就表示将值传给下一个执行的协程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">StartState</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Start State called \n&quot;</span>)</span><br><span class="line">    input_value = randint(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> input_value == <span class="number">0</span>:</span><br><span class="line">        result = <span class="keyword">await</span> State2(input_value)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = <span class="keyword">await</span> State1(input_value)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Resume of the Transition : \nStart State calling &quot;</span> + result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">State2</span>(<span class="params">transition_value</span>):</span></span><br><span class="line">    outputValue = <span class="built_in">str</span>(<span class="string">&quot;State 2 with transition value = %s \n&quot;</span> % transition_value)</span><br><span class="line">    input_value = randint(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;...Evaluating...&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (input_value == <span class="number">0</span>):</span><br><span class="line">        result = <span class="keyword">await</span> State1(input_value)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = <span class="keyword">await</span> State3(input_value)</span><br><span class="line">    <span class="keyword">return</span> outputValue + <span class="built_in">str</span>(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">EndState</span>(<span class="params">transition_value</span>):</span></span><br><span class="line">    outputValue = <span class="built_in">str</span>(<span class="string">&quot;End State with transition value = %s \n&quot;</span> % transition_value)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;...Stop Computation...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> outputValue</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">State3</span>(<span class="params">transition_value</span>):</span></span><br><span class="line">    outputValue = <span class="built_in">str</span>(<span class="string">&quot;State 3 with transition value = %s \n&quot;</span> % transition_value)</span><br><span class="line">    input_value = randint(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;...Evaluating...&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> input_value == <span class="number">0</span>:</span><br><span class="line">        result = <span class="keyword">await</span> State1(input_value)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = <span class="keyword">await</span> EndState(input_value)</span><br><span class="line">    <span class="keyword">return</span> outputValue + <span class="built_in">str</span>(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">State1</span>(<span class="params">transition_value</span>):</span></span><br><span class="line">    outputValue = <span class="built_in">str</span>(<span class="string">&quot;State 1 with transition value = &quot;</span> + <span class="built_in">str</span>(transition_value) + <span class="string">&quot; \n&quot;</span>)</span><br><span class="line">    input_value = randint(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;...Evaluating...&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> input_value == <span class="number">0</span>:</span><br><span class="line">        result = <span class="keyword">await</span> State3(input_value)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = <span class="keyword">await</span> State2(input_value)</span><br><span class="line">    result = <span class="string">&quot;State 1 calling &quot;</span> + result</span><br><span class="line">    <span class="keyword">return</span> outputValue + <span class="built_in">str</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    loop.run_until_complete(StartState())</span><br><span class="line">    loop.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>object async_generator can&#39;t be used in &#39;await&#39; expression</code> async函数中如果使用了yield相当于<code>async_generator</code>,后者中不能使用await.</p><h4 id="Asyncio控制任务"><a href="#Asyncio控制任务" class="headerlink" title="Asyncio控制任务"></a>Asyncio控制任务</h4><blockquote><p>Asyncio是用来处理事件循环中的异步进程和并发任务执行的。它还提供了 <code>asyncio.Task()</code> 类，可以在任务中使用协程。它的作用是，在同一事件循环中,运行某一个任务的同时可以并发地运行多个任务。当协程被包在任务中，它会自动将任务和事件循环连接起来，当事件循环启动的时候，任务自动运行。这样就提供了一个可以自动驱动协程的机制。</p></blockquote><p><code>asyncio.Task(coroutine)</code> 方法来处理计算任务，它可以调度协程的执行。任务对协程对象在事件循环的执行负责。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">factorial</span>(<span class="params">number</span>):</span></span><br><span class="line">    f = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, number + <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Asyncio.Task: Compute factorial(%s)&quot;</span> % (i))</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">        f *= i</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Asyncio.Task: factorial(%s) = %s&quot;</span> % (number, f))</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fibonacci</span>(<span class="params">number</span>):</span></span><br><span class="line">    a,b = <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(number):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Asyncio.Task: Compute fibonacci(%s)&quot;</span> % (i))</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">        a,b = b, a + b</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Asyncio.Task: fibonacci(%s) = %s&quot;</span> % (number, a))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tasks = [asyncio.Task(factorial(<span class="number">10</span>)), asyncio.Task(fibonacci(<span class="number">10</span>))]</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line">    loop.close()</span><br></pre></td></tr></table></figure><h4 id="使用asyncio和futures"><a href="#使用asyncio和futures" class="headerlink" title="使用asyncio和futures"></a>使用asyncio和futures</h4><blockquote><p>Asyncio 模块的另一个重要的组件是 <code>Future</code> 类。它和 <code>concurrent.futures.Futures</code> 很像，但是针对Asyncio的事件循环做了很多定制。 <code>asyncio.Futures</code> 类代表还未完成的结果（有可能是一个Exception）。所以综合来说，它是一种抽象，代表还没有做完的事情。</p></blockquote><ul><li><code>cancel()</code>: 取消future的执行，调度回调函数</li><li><code>result()</code>: 返回future代表的结果</li><li><code>exception()</code>: 返回future中的Exception</li><li><code>add_done_callback(fn)</code>: 添加一个回调函数，当future执行的时候会调用这个回调函数</li><li><code>remove_done_callback(fn)</code>: 从“call whten done”列表中移除所有callback的实例</li><li><code>set_result(result)</code>: 将future标为执行完成，并且设置result的值</li><li><code>set_exception(exception)</code>: 将future标为执行完成，并设置Exception</li></ul><p>类似于js的Promise?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">future = asyncio.Future</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">first_coroutine</span>(<span class="params">future, N</span>):</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N + <span class="number">1</span>):</span><br><span class="line">        count += i</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">3</span>)</span><br><span class="line">    future.set_result(<span class="string">&quot;First coroutine total count: &quot;</span> + <span class="built_in">str</span>(count))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">second_coroutine</span>(<span class="params">future, N</span>):</span></span><br><span class="line">    count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, N + <span class="number">1</span>):</span><br><span class="line">        count *= i</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    future.set_result(<span class="string">&quot;Second coroutine total count: &quot;</span> + <span class="built_in">str</span>(count))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">got_result</span>(<span class="params">future</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(future.result())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    N = <span class="built_in">int</span>(sys.argv[<span class="number">1</span>])</span><br><span class="line">    future1 = asyncio.Future()</span><br><span class="line">    future2 = asyncio.Future()</span><br><span class="line">    tasks = [</span><br><span class="line">        first_coroutine(future1, N),</span><br><span class="line">        second_coroutine(future2, N)</span><br><span class="line">    ]</span><br><span class="line">    future1.add_done_callback(got_result)</span><br><span class="line">    future2.add_done_callback(got_result)</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line">    loop.close()</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/01_Introduction.html">1. 介绍 — python-parallel-programming-cookbook-cn 1.0 文档 (python-parallel-programmning-cookbook.readthedocs.io)</a></li><li><a href="https://blog.csdn.net/weixin_45665318/article/details/106686332">[Python 多线程] 详解daemon属性值None,False,True的区别_daemon=true-CSDN博客</a></li><li><a href="https://ruanyifeng.com/blog/2019/11/python-asyncio.html">Python 异步编程入门 - 阮一峰的网络日志 (ruanyifeng.com)</a></li><li><a href="https://www.freecodecamp.org/chinese/news/introduction-to-python-threading/">介绍 Python 线程及其实现 (freecodecamp.org)</a></li><li><a href="https://medium.com/dev-bits/a-minimalistic-guide-for-understanding-asyncio-in-python-52c436c244ea">A minimalistic guide for understanding asyncio in Python | by Naren Yellavula | Dev bits | Medium</a></li><li><a href="https://tutorialedge.net/python/concurrency/getting-started-with-asyncio-python/">Getting Started with Asyncio in Python | TutorialEdge.net</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要是因为Python库的设计很不错,通过这门语言进一步学习并行,涉及到进程线程以及异步编程等.建议是对性能有要求的利用其他语言实现,但是基本的思想、方法是一样的.&lt;br&gt;</summary>
    
    
    
    
    <category term="parallel" scheme="https://www.sekyoro.top/tags/parallel/"/>
    
  </entry>
  
  <entry>
    <title>目标检测学习_P2</title>
    <link href="https://www.sekyoro.top/2023/10/17/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%AD%A6%E4%B9%A0-P2/"/>
    <id>https://www.sekyoro.top/2023/10/17/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%AD%A6%E4%B9%A0-P2/</id>
    <published>2023-10-17T02:21:51.000Z</published>
    <updated>2023-10-22T10:53:23.127Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>R-CNN家族。它们都是基于区域的目标检测算法。它们可以实现高精度，但对于自动驾驶等特定应用来说可能太慢。</p><span id="more"></span><p>R-CNN家族中的模型都是基于regions的。检测分为两个阶段：</p><p>（1）首先，该模型通过<strong>选择搜索</strong>或<strong>区域建议网络</strong>来提出一组感兴趣的区域。所提出的区域是稀疏的，因为潜在的边界框候选者可以是无限的。</p><p>（2） 然后分类器只处理候选区域。</p><p>这里深入细节实现R-CNN系列的检测网络.</p><h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><blockquote><p>R-CNN (<a href="https://arxiv.org/abs/1311.2524">Girshick et al., 2014</a>) is short for “Region-based Convolutional Neural Networks”. The main idea is composed of two steps. First, using <a href="https://lilianweng.github.io/posts/2017-10-29-object-recognition-part-1/#selective-search">selective search</a>, it identifies a manageable number of bounding-box object region candidates (“region of interest” or “RoI”). And then it extracts CNN features from each region independently for classification.</p></blockquote><p><img data-src="https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/RCNN.png" alt="img"></p><h4 id="选择算法-selective-search"><a href="#选择算法-selective-search" class="headerlink" title="选择算法(selective search)"></a>选择算法(selective search)</h4><p>主要涉及到选择算法,用于提供可能包含对象的区域建议。它建立在图像分割输出的基础上，并使用基于区域的特征（注意：不仅仅是单个像素的属性）来进行自下而上的分层分组。</p><ol><li>在初始化阶段，首先应用Felzenszwalb和Huttenlocher的基于图的图像分割算法来创建区域。</li><li>使用贪婪算法迭代地将区域分组在一起：<ul><li>首先计算所有相邻区域之间的相似性。</li><li>将两个最相似的区域分组在一起，并计算得到的区域与其相邻区域之间的新相似性。</li></ul></li><li>重复对最相似区域进行分组的过程（步骤2），直到整个图像变成单个区域。</li></ol><p>可以使用颜色,材质,大小和形状作为相似度量.</p><p><img data-src="https://lilianweng.github.io/posts/2017-10-29-object-recognition-part-1/selective-search-algorithm.png" alt="img" style="zoom:67%;" /></p><h4 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h4><p>R-CNN流程:</p><ol><li><p>使用一个预训练CNN网络,假设网络输出是K类.</p></li><li><p>通过选择性搜索提出与类别无关的感兴趣区域（每个图像约2k个候选）。这些区域可能包含目标对象，并且它们具有不同的大小。</p></li><li><p>区域被扭曲成一个固定大小.</p></li><li><p>对于第K+1类,在一个扭曲的候选区域上微调CNN(附加的一个类指的是背景（没有感兴趣的对象)）。在微调阶段，我们应该使用更小的学习率，并且小批量对阳性病例进行过采样，因为大多数提出的区域只是背景。</p></li><li><p>给定每个图像区域，通过CNN的一次正向传播生成一个特征向量。然后，该特征向量输入针对每个类独立训练的二进制SVM。</p><p>正样本是IoU&gt;=0.3的区域，而负样本是不相关的其他区域。</p></li><li><p>为了减少定位误差，训练回归模型来使用CNN特征校正边界框校正偏移上的预测检测窗口。</p></li></ol><p><img data-src="https://i.imgur.com/8NYb1o7.png" alt="image-20231022172302856"></p><h4 id="常用技巧"><a href="#常用技巧" class="headerlink" title="常用技巧"></a>常用技巧</h4><ol><li>Non-Maximum Suppression</li></ol><p>模型可能能够为同一对象找到多个边界框。非极大值抑制有助于避免重复检测同一实例。在我们为同一对象类别获得一组匹配的边界框之后：根据置信度得分对所有边界框进行排序。丢弃置信度分数较低的方框。当存在任何剩余的边界框时，重复以下操作：<strong>贪婪地选择得分最高的边界框。然后跳过与这个边界框具有高IoU（即大于0.5）的剩余框,重复这个过程直到挑选出需要数量的bbox</strong></p><blockquote><p>非极大值抑制的方法是：先假设有6个矩形框，根据分类器的类别分类概率做排序，假设从小到大属于人脸的概率 分别为A、B、C、D、E、F。</p><ol><li>从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值;</li><li>假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。</li><li>从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。</li><li>就这样一直重复，找到所有被保留下来的矩形框。</li></ol></blockquote><ol><li>Hard Negative Mining</li></ol><p>我们将没有对象的边界框视为Negative示例。</p><p>并非所有的Negative例子都同样难以识别。例如，如果它包含纯空背景，那么它很可能是一个“容易否定的”；但是，如果盒子中包含奇怪的嘈杂纹理或部分对象，可能很难被识别，这些都是“硬阴性”。严厉的反面例子很容易被错误分类。我们可以在训练循环中明确地找到那些假阳性样本，并将它们包含在训练数据中，以改进分类器。</p><blockquote><p>也就说增加容易被FP的数据</p></blockquote><p>通过查看R-CNN的学习步骤，您可以很容易地发现训练R-CNN模型既昂贵又缓慢，因为以下步骤需要大量工作：</p><ol><li>运行选择性搜索，为每个图像提出2000个区域候选</li><li>为每个图像区域生成CNN特征向量（N个图像*2000）</li><li>整个过程分别涉及三个模型，没有太多的共享计算：用于图像分类和特征提取的卷积神经网络；用于识别目标对象的顶部SVM分类器；以及用于收紧区域边界框的回归模型。</li></ol><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>opencv实现了选择性算法.</p><p>可以参考<a href="https://github.com/Hulkido/RCNN/tree/master">Hulkido/RCNN: FULL Implementation of RCNN from scratch (github.com)</a></p><h4 id="生成Region-proposals"><a href="#生成Region-proposals" class="headerlink" title="生成Region proposals"></a>生成Region proposals</h4><blockquote><p>区域建议(Region proposals)只是图像的较小区域，可能包含我们在输入图像中搜索的对象。为了减少R-CNN中的区域建议，使用了一种称为选择性搜索的贪婪算法。</p></blockquote><p>首先需要定义IoU计算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculating dimension of common area between these two boxes.</span></span><br><span class="line">x_left = <span class="built_in">max</span>(bb1[<span class="string">&#x27;x1&#x27;</span>], bb2[<span class="string">&#x27;x1&#x27;</span>])</span><br><span class="line">y_bottom = <span class="built_in">max</span>(bb1[<span class="string">&#x27;y1&#x27;</span>], bb2[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">x_right = <span class="built_in">min</span>(bb1[<span class="string">&#x27;x2&#x27;</span>], bb2[<span class="string">&#x27;x2&#x27;</span>])</span><br><span class="line">y_top = <span class="built_in">min</span>(bb1[<span class="string">&#x27;y2&#x27;</span>], bb2[<span class="string">&#x27;y2&#x27;</span>])</span><br><span class="line"><span class="comment"># if there is no overlap output 0 as intersection area is zero.</span></span><br><span class="line"><span class="keyword">if</span> x_right &lt; x_left <span class="keyword">or</span> y_bottom &lt; y_top:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"><span class="comment"># calculating intersection area.</span></span><br><span class="line"><span class="comment"># 计算交集</span></span><br><span class="line">intersection_area = (x_right - x_left) * (y_top - y_bottom)</span><br><span class="line"><span class="comment"># individual areas of both these bounding boxes.</span></span><br><span class="line"><span class="comment"># 计算各自区域面积</span></span><br><span class="line">bb1_area = (bb1[<span class="string">&#x27;x2&#x27;</span>] - bb1[<span class="string">&#x27;x1&#x27;</span>]) * (bb1[<span class="string">&#x27;y2&#x27;</span>] - bb1[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">bb2_area = (bb2[<span class="string">&#x27;x2&#x27;</span>] - bb2[<span class="string">&#x27;x1&#x27;</span>]) * (bb2[<span class="string">&#x27;y2&#x27;</span>] - bb2[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line"><span class="comment"># union area = area of bb1_+ area of bb2 - intersection of bb1 and bb2.</span></span><br><span class="line"><span class="comment"># 并集就是各自之和减去交集</span></span><br><span class="line">iou = intersection_area / <span class="built_in">float</span>(bb1_area + bb2_area - intersection_area)</span><br></pre></td></tr></table></figure><p>遍历选择性搜索得到的区域,计算每个区域与对应bbox(bounding box)的IoU.</p><p>然后将iou大于阈值(这里设置为0.7)的定为region proposal,同时resize这个区域建议.</p><blockquote><p>本身应该是warp,但我觉得差别不大.另外region proposal和ROI差别其实也不大,有说法是<strong>region proposal是对图像而言的，roi是针对feature map上的</strong>.</p></blockquote><p><img data-src="https://i.imgur.com/j8O2rCN.png" alt="image-20231022171507221"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">cv2.setUseOptimized(<span class="literal">True</span>);</span><br><span class="line">ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()</span><br><span class="line">ss.setBaseImage(image)   <span class="comment"># setting given image as base image</span></span><br><span class="line">            ss.switchToSelectiveSearchFast()     <span class="comment"># running selective search on bae image</span></span><br><span class="line">            ssresults = ss.process()     <span class="comment"># processing to get the outputs</span></span><br><span class="line">            imout = image.copy()</span><br><span class="line">            counter = <span class="number">0</span></span><br><span class="line">            falsecounter = <span class="number">0</span></span><br><span class="line">            flag = <span class="number">0</span></span><br><span class="line">            fflag = <span class="number">0</span></span><br><span class="line">            bflag = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">                <span class="keyword">if</span> e &lt; <span class="number">2000</span> <span class="keyword">and</span> flag == <span class="number">0</span>:     <span class="comment"># till 2000 to get top 2000 regions only</span></span><br><span class="line">                    <span class="keyword">for</span> gtval <span class="keyword">in</span> gtvalues:</span><br><span class="line">                        x,y,w,h = result</span><br><span class="line">                        iou = get_iou(gtval,&#123;<span class="string">&quot;x1&quot;</span>:x,<span class="string">&quot;x2&quot;</span>:x+w,<span class="string">&quot;y1&quot;</span>:y,<span class="string">&quot;y2&quot;</span>:y+h&#125;)  <span class="comment"># calculating IoU for each of the proposed regions</span></span><br><span class="line">                        <span class="keyword">if</span> counter &lt; <span class="number">30</span>:       <span class="comment"># getting only 30 psoitive examples</span></span><br><span class="line">                            <span class="keyword">if</span> iou &gt; <span class="number">0.70</span>:     <span class="comment"># IoU or being positive is 0.7</span></span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                train_images.append(resized)</span><br><span class="line">                                train_labels.append(<span class="number">1</span>)</span><br><span class="line">                                counter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            fflag =<span class="number">1</span>              <span class="comment"># to insure we have collected all psotive examples</span></span><br><span class="line">                        <span class="keyword">if</span> falsecounter &lt;<span class="number">30</span>:      <span class="comment"># 30 negatve examples are allowed only</span></span><br><span class="line">                            <span class="keyword">if</span> iou &lt; <span class="number">0.3</span>:         <span class="comment"># IoU or being negative is 0.3</span></span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                train_images.append(resized)</span><br><span class="line">                                train_labels.append(<span class="number">0</span>)</span><br><span class="line">                                falsecounter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            bflag = <span class="number">1</span>             <span class="comment">#to ensure we have collected all negative examples</span></span><br><span class="line">                    <span class="keyword">if</span> fflag == <span class="number">1</span> <span class="keyword">and</span> bflag == <span class="number">1</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;inside&quot;</span>)</span><br><span class="line">                        flag = <span class="number">1</span>        <span class="comment"># to signal the complition of data extaction from a particular image</span></span><br></pre></td></tr></table></figure><p>上面一共最多遍历生成的2000个ROI,选取其中的正例(超过阈值)的30,负例30.</p><p>下面是一张图像与其得到的正例和负例</p><p><img data-src="https://i.imgur.com/elheTvF.png" alt="image-20231022174714613"></p><p><img data-src="https://i.imgur.com/YTCcKjA.png" alt="image-20231022174748063"></p><h4 id="使用CNN模型二分类"><a href="#使用CNN模型二分类" class="headerlink" title="使用CNN模型二分类"></a>使用CNN模型二分类</h4><p>一般直接使用预训练模型,这里使用keras,加载VGG16模型.这里只做目标是否在而不做具体分类,所以输出单个值作为二分类.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vgg = tf.keras.applications.vgg16.VGG16(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>, input_tensor=<span class="literal">None</span>, input_shape=<span class="literal">None</span>, pooling=<span class="literal">None</span>, classes=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> vgg.layers[:-<span class="number">2</span>]:</span><br><span class="line">  layer.trainable = <span class="literal">False</span></span><br><span class="line">x = vgg.get_layer(<span class="string">&#x27;fc2&#x27;</span>)</span><br><span class="line">last_output =  x.output</span><br><span class="line">x = tf.keras.layers.Dense(<span class="number">1</span>,activation = <span class="string">&#x27;sigmoid&#x27;</span>)(last_output)</span><br><span class="line">model = tf.keras.Model(vgg.<span class="built_in">input</span>,x)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&quot;adam&quot;</span>,</span><br><span class="line">              loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line">model.fit(X_new,Y_new,batch_size = <span class="number">64</span>,epochs = <span class="number">3</span>, verbose = <span class="number">1</span>,validation_split=<span class="number">.05</span>,shuffle = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="预训练模型提取特征再使用SVM二分类"><a href="#预训练模型提取特征再使用SVM二分类" class="headerlink" title="预训练模型提取特征再使用SVM二分类"></a>预训练模型提取特征再使用SVM二分类</h4><p>原文中为每一类使用了一个二分类的SVM(毕竟一般的一个SVM只能二分类)</p><p>可以再上面的预训练模型只使用特征提取层,然后加个SVM</p><h4 id="bbox-regression"><a href="#bbox-regression" class="headerlink" title="bbox regression"></a>bbox regression</h4><p>最后需要求的bbox的回归用于修正误差.</p><blockquote><p>回归后得到四个参数，即x，y中心点偏移量和高、宽缩放因子，利用这四个参数对剩余的高质量目标建议框进行调整，取得分最高的称为Bounding Box，完成定位任务。</p></blockquote><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p>为了使R-CNN更快，Girshick（2015）通过将三个独立的模型统一到一个联合训练的框架中并增加共享计算结果（称为Fast R-CNN）来改进训练过程。</p><p>不同于R-CNN对于每个region proposals提取特征,，而是将它们聚合到整个图像上的一个 CNN 前向传递中，并且区域提案共享此特征矩阵。然后，将相同的特征矩阵分支出来，用于学习对象分类器和边界框回归器。总之，计算共享加速了R-CNN。</p><p>以上都是two-stage  detector,另一种不同的方法跳过区域建议阶段，直接在可能位置的密集采样上运行检测。这就是单阶段目标检测算法的工作原理。这更快、更简单，但可能会降低performance。</p><p>在One-stage中对象检测是一个简单的回归问题，需要输入并学习概率类和边界框坐标。YOLO、YOLO v2、SSD、RetinaNet等属于一个相位检测器。对象检测是图像分类的一种高级形式，其中神经网络预测图像中的对象，并以边界框的形式引起人们的注意。</p><h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><p>YOLO模型是构建快速实时物体探测器的第一次尝试。因为YOLO不经历区域建议步骤，并且只在有限数量的边界框上进行预测，所以它能够超快速地进行推理。</p><ol><li><p>残差块</p><p>首先，将图像划分为不同的网格。每个网格的尺寸为S x S。将输入图像转换为网格的过程如下图所示。每个网格单元将检测其中出现的对象。</p></li><li><p>边界框线性回归</p></li></ol><p>边界框是高亮显示图像中具有某些属性（如宽度（bw）、高度（bh）和类别（如人、汽车、红绿灯等）的对象的轮廓，由字母C表示。边界框的中心（bx）。YOLO使用单边界框回归来预测对象的高度、宽度、中心和类别。</p><ol><li><p>IOU</p><p>并集交集（IOU）是一种用于对象检测的工具，用于解释方框如何重叠。YOLO使用IOU完美地围绕对象的完美输出框。网格中的每个单元负责预测边界框及其置信度得分。如果预测的边界框与实际框相同，则IOU等于1。此技术可以消除与实际框不相等的边界框。</p></li></ol><p>YOLOv2:YOLOv2于2017年发布，其架构对YOLO进行了几次迭代改进，包括BatchNorm、更高分辨率和锚盒。</p><p>YOLOv3：于2018年发布，YOLOv3在以前的模型的基础上，为边界框预测添加客观性分数，为主干层添加连接性，并在三个不同的级别进行预测，以提高对较小对象的性能。</p><p>YOLOv4:YOLOv4由Alexey Bochkovskiy于2020年4月发布，其中引入了改进的功能聚合、“免费包”（带增强）、漏洞激活等改进。</p><p>YOLOv5:由Glenn Jocher于2020年6月发布，YOLOv5与之前的所有版本不同，因为它是PyTorch实现，而不是原始暗网的分支。与YOLO v4一样，YOLO v5具有CSP脊椎和PA-NET颈部。主要改进包括马赛克数据扩展和自动学习边界框锚定。</p><p>PP-YOLO：百度基于YOLO v3于2020年8月发布。PP-YOLO的主要目标是实现一种具有相对平衡的效率和有效性的对象检测器，该检测器可以直接用于当前的应用场景，而不是设计新的检测模型。</p><p>Scaled YOLOv4:发布于2020年11月，作者：王、博奇科夫斯基和廖。该模型使用跨阶段部分网络来增加网络大小，同时保持YOLOv4的准确性和速度。</p><p>PP-YOLOv2：再次由百度团队撰写并于2021年4月发布，它对PP-YOLO进行了小修改，以获得更好的性能，包括添加错误激活功能和路径聚合网络。</p><p>流程:</p><ol><li>预训练一个CNN用于图像分类任务</li><li>将输入图像分为SxS的块,如果一个物体的中心落入一个块细胞中，该块“负责”检测该物体的存在.包括预测<strong>每个块预测碰撞盒的位置</strong>,<strong>置信度</strong>,</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/">Object Detection Part 4: Fast Detection Models | Lil’Log (lilianweng.github.io)</a></li><li><a href="https://www.analyticsvidhya.com/blog/2022/09/object-detection-using-yolo-and-mobilenet-ssd/?utm_source=reading_list&amp;utm_medium=https://www.analyticsvidhya.com/blog/2021/09/a-beginners-guide-to-image-processing-with-opencv-and-python/">Object Detection Using YOLO And Mobilenet SSD Computer Vision - (analyticsvidhya.com)</a></li><li><a href="https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/">Object Detection for Dummies Part 3: R-CNN Family | Lil’Log (lilianweng.github.io)</a></li><li><a href="https://tjmachinelearning.com/lectures/1718/obj/">Object Detection | TJHSST Machine Learning Club (tjmachinelearning.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;R-CNN家族。它们都是基于区域的目标检测算法。它们可以实现高精度，但对于自动驾驶等特定应用来说可能太慢。&lt;/p&gt;</summary>
    
    
    
    
    <category term="SSD" scheme="https://www.sekyoro.top/tags/SSD/"/>
    
    <category term="YOLO" scheme="https://www.sekyoro.top/tags/YOLO/"/>
    
  </entry>
  
  <entry>
    <title>DDS学习与实战</title>
    <link href="https://www.sekyoro.top/2023/10/14/DDS%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    <id>https://www.sekyoro.top/2023/10/14/DDS%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AE%9E%E6%88%98/</id>
    <published>2023-10-14T07:03:24.000Z</published>
    <updated>2023-10-15T10:18:34.534Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>数据分发服务（DDS）是一种以数据为中心的通信协议，用于分布式软件应用程序通信。它描述了实现数据提供者和数据消费者之间通信的通信应用程序编程接口（API）和通信语义。</p><span id="more"></span><h3 id="DDS"><a href="#DDS" class="headerlink" title="DDS"></a>DDS</h3><p>在实现过程中定义了三个关键的应用实体：</p><ol><li>发布实体(publication entities)，定义了信息生成对象及其属性；</li><li>订阅实体(subscription entities)，定义信息消费对象及其属性；</li><li>配置实体(configuration entities)，其定义作为主题传输的信息类型，并创建具有其服务质量（QoS）属性的发布者和订阅者，从而确保上述实体的正确性能。</li></ol><p>DDS使用QoS来定义DDS实体的行为特征。QoS由单独的QoS策略（从QoSPolicy派生的类型的对象）组成</p><p>在DCPS模型中，为通信应用程序系统的开发定义了四个基本元素。</p><p><strong>Publisher</strong>:它是DCPS实体，负责创建和配置它所实现的DataWriters。DataWriter是负责实际发布消息的实体。每个都将有一个指定的主题，在该主题下发布消息.</p><p><strong>Subscriber</strong>:DCPS实体负责接收在其订阅的主题下发布的数据。它为一个或多个DataReader对象提供服务，这些对象负责将新数据的可用性传达给应用程序</p><p><strong>Topic</strong>:它是绑定发布和订阅的实体。它在DDS域中是唯一的。通过TopicDescription，它可以统一发布和订阅的数据类型。</p><p><strong>Domain</strong>:这是一个用于链接属于一个或多个应用程序的所有发布者和订阅者的概念，这些应用程序在不同的主题下交换数据。这些参与域的单独应用程序称为DomainParticipant。DDS域由域ID标识。DomainParticipant定义域ID以指定其所属的DDS域。具有不同ID的两个DomainParticipants不知道对方在网络中的存在。因此，可以创建几个通信信道。这适用于涉及多个DDS应用程序的场景，它们各自的DomainParticipants相互通信，但这些应用程序不得干扰。DomainParticipant充当其他DCPS实体的容器，充当发布服务器、订阅服务器和主题实体的工厂，并在域中提供管理服务</p><p><img data-src="https://fast-dds.docs.eprosima.com/en/latest/_images/dds_domain.svg" alt=""></p><h3 id="RTPS"><a href="#RTPS" class="headerlink" title="RTPS"></a>RTPS</h3><p>为支持DDS应用程序而开发的实时发布-订阅（RTPS）协议是一种通过UDP/IP等尽力传输的发布-订阅通信中间件。此外，Fast DDS还支持TCP和共享内存（SHM）传输。</p><p>它被设计为同时支持单播和多播通信。在继承自DDS的RTPS的顶部，可以找到Domain，它定义了一个单独的通信平面。多个域可以同时独立共存。域包含任意数量的RTPSP参与者，即能够发送和接收数据的元素。为此，RTPSP参与者使用他们的终点：</p><p>域表示一个单独的通信平面。它在共享公共通信基础设施的实体之间创建了逻辑分离。从概念上讲，它可以被视为一个虚拟网络，将运行在同一域上的所有应用程序链接起来，并将它们与运行在不同域上的应用程序隔离开来。通过这种方式，几个独立的分布式应用程序可以共存于同一物理网络中，而不会发生干扰，甚至不会相互了解。每个域都有一个唯一的标识符，称为domainId，它被实现为uint32值。共享此domainId的应用程序属于同一个域，并且能够进行通信。</p><p>DomainParticipant是应用程序到域的入口点。每个DomainParticipant从创建起就链接到一个域，并包含与该域相关的所有实体。它还充当发布服务、订阅服务和主题的工厂。DomainParticipant的行为可以使用DomainParticipantQos上指定的QoS值进行修改。</p><p>发布是通过DataWriter与发布服务(Publisher)的关联来定义的。若要开始发布数据实例的值，应用程序将在发布服务器中创建一个新的DataWriter。此DataWriter将绑定到描述正在传输的数据类型的Topic。与此主题匹配的远程订阅将能够从DataWriter接收数据值更新。</p><p>订阅是通过DataReader与订阅服务(subscriber)的关联来定义的。若要开始接收发布的更新，应用程序将在订阅服务器中创建一个新的DataReader。此DataReader将绑定到描述将要接收的数据类型的Topic。然后，DataReader将开始接收来自与此主题匹配的远程发布的数据值更新。当订阅服务器接收到数据时，它会通知应用程序新数据可用。然后，应用程序可以使用DataReader来获取接收到的数据。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;数据分发服务（DDS）是一种以数据为中心的通信协议，用于分布式软件应用程序通信。它描述了实现数据提供者和数据消费者之间通信的通信应用程序编程接口（API）和通信语义。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>目标检测(Object Detection)学习_P1</title>
    <link href="https://www.sekyoro.top/2023/10/11/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Object-Detection-%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/10/11/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Object-Detection-%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-10-11T11:56:21.000Z</published>
    <updated>2023-10-23T09:54:14.304Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>目标检测也是属于cv热点方向之一,但之前我做得并不多,这里通过微软的教程以及d2l学习一下.<br><span id="more"></span></p><blockquote><p>在图像分类任务中，我们假设图像中只有一个主要物体对象，我们只关注如何识别其类别。 然而，很多时候图像里有多个我们感兴趣的目标，我们不仅想知道它们的类别，还想得到它们在图像中的具体位置。 在计算机视觉里，我们将这类任务称为<em>目标检测</em>（object detection）或<em>目标识别</em>（object recognition）</p></blockquote><p>目标检测在无人驾驶和机器人、摄像头里用得很多.</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="bouding-box"><a href="#bouding-box" class="headerlink" title="bouding box"></a>bouding box</h3><p>在目标检测中，我们通常使用<em>边界框</em>（bounding box）来描述对象的空间位置。 边界框是矩形的，由矩形左上角的以及右下角的x和y坐标决定。 另一种常用的边界框表示方法是边界框中心的(x,y)轴坐标以及框的宽度和高度</p><p><img data-src="http://zh.d2l.ai/_images/output_bounding-box_d6b70e_70_0.svg" alt=""></p><blockquote><p>目标检测算法通常会在输入图像中采样大量的区域，然后判断这些区域中是否包含我们感兴趣的目标，并调整区域边界从而更准确地预测目标的<em>真实边界框</em>（ground-truth bounding box）。 不同的模型使用的区域采样方法可能不同。 这里我们介绍其中的一种方法：以每个像素为中心，生成多个缩放比和宽高比（aspect ratio）不同的边界框。 这些边界框被称为<em>锚框</em>（anchor box）</p></blockquote><p>也就是采样区域的设置方式,这里使用不同的缩放比和宽高比生成锚框,假设缩放比为有n个,m个宽高比,比较简单的组合就是</p><script type="math/tex; mode=display">(s_1,r_1),(s_1,r_2),\ldots,(s_1,r_m),(s_2,r_1),(s_3,r_1),\ldots,(s_n,r_1).</script><p><img data-src="http://zh.d2l.ai/_images/output_anchor_f592d1_66_0.svg" alt=""></p><p>可以通过杰卡德系数,也就是交并比IoU衡量锚框与真实边界框之间的相似性</p><script type="math/tex; mode=display">J(\mathcal{A},\mathcal{B})=\frac{|\mathcal{A}\cap\mathcal{B}|}{|\mathcal{A}\cup\mathcal{B}|}.</script><p>在训练集中，我们需要给每个锚框两种类型的标签。一个是与锚框中目标检测的类别，另一个是锚框相对于真实边界框的偏移量。</p><p>在预测时，我们为每个图像生成多个锚框，预测所有锚框的类别和偏移量，根据预测的偏移量调整它们的位置以获得预测的边界框，最后只输出符合特定条件的预测边界框</p><h4 id="Naive-approach"><a href="#Naive-approach" class="headerlink" title="Naive approach"></a>Naive approach</h4><p>假设我们想在照片上找到一只猫，一种非常简单的物体检测方法如下：</p><ol><li>将图片分解为多个平铺(tiles)</li><li>对每个平铺运行图像分类。</li><li>那些识别率较高的tiles可以被认为包含所讨论的对象。</li></ol><p>然而，这种方法远非理想，因为它只允许算法非常不精确地定位对象的边界框(bounding box )。为了获得更精确的位置，我们需要运行某种回归(<strong>regression</strong>)来预测边界框的坐标——为此，我们需要特定的数据集。</p><h3 id="目标检测的指标"><a href="#目标检测的指标" class="headerlink" title="目标检测的指标"></a>目标检测的指标</h3><h5 id="Intersection-over-Union"><a href="#Intersection-over-Union" class="headerlink" title="Intersection over Union"></a>Intersection over Union</h5><p>指的就是上面的交并比</p><blockquote><p>虽然对于图像分类，很容易测量算法的性能，但对于对象检测，我们需要测量类的正确性以及推断的边界框位置的精度。对于后者，我们使用所谓的并集交集（IoU），它测量两个bouding box（或两个任意区域）重叠的程度。</p></blockquote><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/11-ObjectDetection/images/iou_equation.png" alt="IoU" style="zoom:50%;" /></p><p>们用两个图形的并集面积来划分两个图形之间的相交面积。对于两个相同的区域，IoU将是1，而对于完全不相交的区域，它将是0。否则，它将在0到1之间变化。我们<strong>通常只考虑IoU超过某个值的边界框。</strong></p><h5 id="Average-Precision"><a href="#Average-Precision" class="headerlink" title="Average Precision"></a>Average Precision</h5><p>PR(Precision-Recall)曲线下的面积,这与混淆矩阵相关.</p><ol><li>考虑精度-召回曲线显示了取决于检测阈值（从0到1）的精度。</li><li>根据阈值的不同，我们会得到或多或少的图像中检测到的对象，以及不同的精度和召回率值。</li></ol><p><img data-src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png" alt="img" style="zoom:67%;" /></p><p>计算多个不同阈值(threshold)的precision.比如设置10个均分的阈值</p><script type="math/tex; mode=display">AP=\frac1{11}\sum_{i=0}^{10}\text{Precision}(\mathrm{Recall}=\frac i{10})</script><h5 id="AP与IoU"><a href="#AP与IoU" class="headerlink" title="AP与IoU"></a>AP与IoU</h5><p>我们将仅考虑IoU高于特定值的那些检测。包括计算AP时也只考虑IoU高于阈值的</p><p><img data-src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png" alt="img" style="zoom:67%;" /></p><h4 id="Mean-Average-Precision-mAP"><a href="#Mean-Average-Precision-mAP" class="headerlink" title="Mean Average Precision - mAP"></a>Mean Average Precision - mAP</h4><p>目标检测的主要指标称为平均精度（mAP）。它是Average Precision的值，是所有对象类的平均值，有时也计算在给定的几个IoU阈值上的均值.</p><h5 id="Different-Object-Detection-Approaches"><a href="#Different-Object-Detection-Approaches" class="headerlink" title="Different Object Detection Approaches"></a>Different Object Detection Approaches</h5><p>对象检测算法有两大类：<strong>Region Proposal Networks</strong> （R-CNN、Fast R-CNN、Faster R-CNN）.主要思想是生成ROI(Regions of Interests),在每个ROI上运行CNN.</p><p><strong>One-pass</strong> (YOLO, SSD, RetinaNet) 在这些体系结构中，我们设计网络以一次性预测类和ROI.</p><h4 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h4><p>R-CNN使用选择性搜索<a href="http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf">rcnn_pami.pdf (ulsan.ac.kr)</a><a href="https://arxiv.org/pdf/1311.2524.pdf">1311.2524.pdf (arxiv.org)</a>生成ROI区域的分层结构，然后通过CNN特征提取器和SVM分类器来确定对象类别，并通过线性回归来确定边界框坐标</p><p>选择性搜索<a href="https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf">UijlingsIJCV2013.pdf (uva.nl)</a>：</p><p>1.生成初始子分割，我们生成许多候选区域</p><p>2.使用贪婪算法递归地将相似的区域组合成更大的区域</p><p>3.使用生成的区域来生成最终的候选区域提案</p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*REPHY47zAyzgbNKC6zlvBQ.png" alt="img"></p><p>得到2000个区域proposals后,CNN充当特征提取器，并且输出密集层由从图像中提取的特征组成，并且提取的特征被馈送到SVM中以对该候选区域提议内的对象的存在进行分类。除了预测区域建议内对象之外，该算法还预测四个值，这些值是偏移值，以增加边界框的精度。例如，给定一个区域提案，该算法本来可以预测一个人的存在，但该区域提案中那个人的脸可能会被减半。</p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/11-ObjectDetection/images/rcnn2.png" alt="RCNN-1"></p><h5 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h5><ul><li>训练网络仍然需要大量的时间，因为每张图像需要对2000个区域建议进行分类。它不能实时实现，因为每个测试图像大约需要47秒。</li><li>选择性搜索算法是一种固定的算法。因此，在那个阶段没有学习。这可能导致产生糟糕的候选地区proposals。</li></ul><h4 id="F-RCNN"><a href="#F-RCNN" class="headerlink" title="F-RCNN"></a>F-RCNN</h4><p>这种方法类似于R-CNN，但ROI区域是在应用卷积层后定义的。</p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/11-ObjectDetection/images/f-rcnn.png" alt="FRCNN"></p><p>将输入图像提供给CNN以生成卷积特征图。从卷积特征图中识别proposal regions，并通过使用RoI池化层将其扭曲(warp )成正方形，我们将其重塑为固定大小，以便将其馈送到完全连接的层中。</p><p>根据RoI特征向量，我们使用softmax层来预测所提出区域的类别以及边界框的偏移值</p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*0pMP3aY8blSpva5tvWbnKA.png" alt="img"></p><p>可以看出,生成proposal regions的算法效率很重要,R-CNN使用过选择性搜索算法,F-RCNN通过先将图像通过卷积层得到feature map,在feature map上进行生成region of proposals 并warp成相同大小的ROI再输入到FC进行分类.</p><blockquote><p>“Fast R-CNN”比R-CNN快的原因是，你不必每次向卷积神经网络提供2000个区域建议。相反，每个图像只进行一次卷积运算，并从中生成特征图。</p></blockquote><h4 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h4><p>这种方法的主要思想是使用神经网络来预测ROI，即所谓的区域建议网络。</p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/11-ObjectDetection/images/faster-rcnn.png" alt="FasterRCNN" style="zoom:67%;" /></p><p>上述两种算法（R-CNN和Fast R-CNN）都使用选择性搜索来找出区域建议。选择性搜索是一个缓慢而耗时的过程，会影响网络的性能。<a href="https://arxiv.org/pdf/1506.01497v1.pdf">1506.01497v1.pdf (arxiv.org)</a>提出了一种对象检测算法，该算法没有使用选择性搜索算法，并让网络学习区域建议。</p><p>类似于Fast R-CNN，图像被提供作为卷积网络的输入，该卷积网络提供卷积特征图。不是在特征图上使用选择性搜索算法来识别区域建议，而是使用单独的网络来预测区域建议。</p><p>不是在特征图上使用选择性搜索算法来识别区域建议，而是使用单独的网络来预测区域建议。然后使用RoI池化层对预测的区域建议进行整形，该RoI池层随后用于对建议区域内的图像进行分类并预测边界框的偏移值。</p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*4gGddZpKeNIPBoVxYECd5w.png" alt="img"></p><h4 id="R-FCN-Region-Based-Fully-Convolutional-Network"><a href="#R-FCN-Region-Based-Fully-Convolutional-Network" class="headerlink" title="R-FCN: Region-Based Fully Convolutional Network"></a>R-FCN: Region-Based Fully Convolutional Network</h4><ol><li>我们使用ResNet-101提取特征</li><li>特征由<strong>Position-Sensitive Score Map</strong>处理,每个类对应的对象由k*k个块构成,也就是说通过一个特征图得到一个d<em>C\</em>k*k的输出,d表示d个regional proposals,d中的每一块可能对应图像中的某一部分,相当于把每一部分分为大小相同且对应不同类的特征,然后通过pool.</li><li>对于k*k区域的每一块,对每一个对象类vote(其实就是计算类概率),最大值就是对应的类.</li></ol><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/11-ObjectDetection/images/r-fcn.png" alt="r-fcn image"></p><h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3><p>YOLO是一种实时one-pass算法</p><ol><li>图像被分成SXS块</li><li>对于每块区域,CNN预测n个可能的类,bounding box坐标,以及置信度(置信度=概率*IoU)</li></ol><p>YOLO的工作原理是，我们拍摄一张图像，并将其分割成一个SxS网格，在每个网格中我们取m个边界框。对于每个边界框，网络输出该边界框的类概率和偏移值。具有高于阈值的类概率的边界框被选择并用于在图像内定位对象。</p><p>YOLO算法的局限性在于它很难处理图像中的小物体，例如，它可能很难检测到一群鸟。这是由于算法的空间约束。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491">Object detection with neural networks — a simple tutorial using keras | by Johannes Rieke | Towards Data Science</a></li><li><a href="https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/4-ComputerVision/11-ObjectDetection/README.md">AI-For-Beginners/lessons/4-ComputerVision/11-ObjectDetection/README.md at main · microsoft/AI-For-Beginners (github.com)</a></li><li><a href="http://zh.d2l.ai/chapter_computer-vision/anchor.html">13.4. 锚框 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></li><li><a href="https://github.com/jrieke/shape-detection">jrieke/shape-detection: 🟣 Object detection of abstract shapes with neural networks (github.com)</a></li><li><a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms | by Rohith Gandhi | Towards Data Science</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;目标检测也是属于cv热点方向之一,但之前我做得并不多,这里通过微软的教程以及d2l学习一下.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>cmake学习</title>
    <link href="https://www.sekyoro.top/2023/10/11/cmake%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/10/11/cmake%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-10-11T09:26:00.000Z</published>
    <updated>2023-10-14T11:40:36.351Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在Windows上开发c++相比Linux还是有点不方便,这里介绍CMake,跨平台的构建工具.<br><span id="more"></span></p><p>在Windows上可选择的构建后端有vs,codeblocks这种软件的文件结构,或者单纯的Makefiles以及Ninja.相当于忽略了几个项目构建的差异.</p><p><img data-src="https://i.imgur.com/0mXZUbA.png" alt="image-20231013105520974" style="zoom:50%;" /></p><h2 id="常用变量"><a href="#常用变量" class="headerlink" title="常用变量"></a>常用变量</h2><p><code>PROJECT_BINARY_DIR</code></p><p>编译生成项目的目录</p><p><code>PROJECT_SOURCE_DIR</code></p><p>顶层目录</p><p><code>EXECUTABLE_OUTPUT_PATH</code>以及<code>LIBRARY_OUTPUT_PATH</code></p><p>分别用来重新定义最终结果的存放目录</p><p><code>CMAKE_ARCHIVE_OUTPUT_DIRECTORY</code>：默认存放静态库的文件夹位置；</p><p><code>CMAKE_LIBRARY_OUTPUT_DIRECTORY</code>：默认存放动态库的文件夹位置；</p><p><code>LIBRARY_OUTPUT_PATH</code>：默认存放库文件的位置，如果产生的是静态库并且没有指定 CMAKE_ARCHIVE_OUTPUT_DIRECTORY 则存放在该目录下，动态库也类似；</p><p><code>CMAKE_RUNTIME_OUTPUT_DIRECTORY</code>：存放可执行软件的目录；</p><p><code>CMAKE_CXX_FLAGS</code>和<code>CMAKE_C_FLAGS</code></p><p>设置C/ C++编译选项,<code>CMAKE_C_COMPILER</code>设置对应编译器路径.</p><p><code>BUILD_SHARED_LIBS</code></p><p>用来控制默认的库编译方式,如果不进行设置,使用ADD_LIBRARY 并没有指定库类型的情况下,默认编译生成的库都是静态库.</p><p>此外还有一些系统信息</p><p><img data-src="https://i.imgur.com/cozY007.png" alt="image-20231013163518609"></p><p>使用$ENV{}调用系统变量.</p><h2 id="指定生成程序"><a href="#指定生成程序" class="headerlink" title="指定生成程序"></a>指定生成程序</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_library</span>(&lt;name&gt; [STATIC | SHARED | MODULE]</span><br><span class="line">            [EXCLUDE_FROM_ALL]</span><br><span class="line">            source1 [source2 ...])</span><br></pre></td></tr></table></figure><p>将源码source构建成一个库， 供他人使用</p><p><code>[STATIC | SHARED | MODULE]</code> ：类型有三种</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>(&lt; name&gt; [WIN32] [MACOSX_BUNDLE]</span><br><span class="line">                [EXCLUDE_FROM_ALL]  source1 source2 … sourceN)</span><br></pre></td></tr></table></figure><p>使用给定的源文件，为工程引入一个可执行文件。引入一个名为&lt; name&gt;的可执行目标，该目标会由调用该命令时在源文件列表中指定的源文件来构建</p><h2 id="添加头文件目录和库"><a href="#添加头文件目录和库" class="headerlink" title="添加头文件目录和库"></a>添加头文件目录和库</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">include_directories</span>([AFTER|BEFORE] [SYSTEM]  dir1  dir2 ...)</span><br><span class="line"><span class="keyword">target_include_directories</span>()</span><br></pre></td></tr></table></figure><p>将给定目录 dir1 dir2 加给编译器搜索到的包含文件 .默认情况下，加到目录列表的最后,target_include_directories可以指定针对目标文件添加头文件目录.</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">target_link_libraries</span>(&lt;<span class="keyword">target</span>&gt; [item1] [item2] [...]</span><br><span class="line">                      [[debug|optimized|general] &lt;item&gt;] ...)</span><br></pre></td></tr></table></figure><p>该指令的作用为将目标文件与库文件进行链接。</p><p>上述指令中的<code>&lt;target&gt;</code>是指通过add_executable()和add_library()指令生成已经创建的目标文件.</p><p>可以使用<code>&lt;a&gt;_FOUND</code>检查是否通过find加载成功,之后使用target_link_libraries连接.</p><h2 id="find-package-amp-find-path-amp-find-library"><a href="#find-package-amp-find-path-amp-find-library" class="headerlink" title="find_package&amp;find_path&amp;find_library"></a>find_package&amp;find_path&amp;find_library</h2><p>find_path和find_library分别用来找头文件和库.找到之后可以使用include_directory或者target_link_libraries用来使用.</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FIND_PATH</span>(myCeres NAMES ceress.h PATHS /ceres/<span class="keyword">include</span>/ceres NO_DEFAULT_PATH)</span><br><span class="line"><span class="keyword">INCLUDE_DIRECTORIES</span>(<span class="variable">$&#123;myCeres&#125;</span>)</span><br></pre></td></tr></table></figure><h2 id="编译时消息输出"><a href="#编译时消息输出" class="headerlink" title="编译时消息输出"></a>编译时消息输出</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">MESSAGE</span>(STATUS <span class="string">&quot;HELLO&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="设置变量"><a href="#设置变量" class="headerlink" title="设置变量"></a>设置变量</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_LIBRARY_OUTPUT_DIRECTORY <span class="variable">$&#123;CMAKE_SOURCE_DIR&#125;</span>/lib/x86)</span><br></pre></td></tr></table></figure><p>set设置变量,后续使用${}使用变量</p><h2 id="控制结构"><a href="#控制结构" class="headerlink" title="控制结构"></a>控制结构</h2><p>if elseif else endif</p><p>文件中可以使用条件,循环等控制语句.可以用来判断构建时系统的一些环境.</p><p>比如</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># include dynamic link path</span></span><br><span class="line"><span class="keyword">if</span>(CMAKE_SYSTEM_PROCESSOR <span class="keyword">MATCHES</span> <span class="string">&quot;x86&quot;</span>)</span><br><span class="line">    <span class="keyword">link_directories</span>(<span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/../nwpu_std_msgs/lib/x86)</span><br><span class="line">    <span class="keyword">link_directories</span>(<span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/../nwpucutils/lib/x86)</span><br><span class="line"><span class="keyword">elseif</span>(CMAKE_SYSTEM_PROCESSOR <span class="keyword">MATCHES</span> <span class="string">&quot;arm&quot;</span>)</span><br><span class="line">    <span class="keyword">link_directories</span>(<span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/../nwpu_std_msgs/lib/arm)</span><br><span class="line">    <span class="keyword">link_directories</span>(<span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/../nwpucutils/lib/arm)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure><h2 id="添加其他子目录"><a href="#添加其他子目录" class="headerlink" title="添加其他子目录"></a>添加其他子目录</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_subdirectory</span>(source_dir [binary_dir] [EXCLUDE_FROM_ALL] [SYSTEM])</span><br></pre></td></tr></table></figure><p><strong>添加一个子目录并构建该子目录</strong>。source_dir指定源CMakeLists.txt和代码文件所在的目录。</p><p>一般用在嵌套的项目中,顶层CMakeLists.txt文件添加子目录,让子目录先构建完成之后添加其中生成的库和头文件.</p><h2 id="获取文件"><a href="#获取文件" class="headerlink" title="获取文件"></a>获取文件</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FILE</span> (GLOB ALL_SOURCES <span class="string">&quot;*.cpp&quot;</span> <span class="string">&quot;*.c&quot;</span> <span class="string">&quot;./AFolder/*.cpp&quot;</span> )</span><br></pre></td></tr></table></figure><p>使用正则匹配响应文件并存到一个变量中</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">aux_source_directory</span>(dir VAR) </span><br></pre></td></tr></table></figure><p>发现一个目录下所有的<strong>源代码文件</strong>并将列表存储在一个变量中.</p><h2 id="vs中显示头文件"><a href="#vs中显示头文件" class="headerlink" title="vs中显示头文件"></a>vs中显示头文件</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">file</span>(GLOB_RECURSE pipe_header_files  <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/<span class="keyword">include</span>/*.h )</span><br><span class="line"><span class="keyword">source_group</span>(<span class="string">&quot;Header Files&quot;</span> FILES <span class="variable">$&#123;pipe_header_files&#125;</span>) </span><br></pre></td></tr></table></figure><p>使用source_group增加文件</p><p>并添加到生成目标中</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_library</span>( lib_pipe_shared SHARED <span class="variable">$&#123;pipe_src&#125;</span> <span class="variable">$&#123;pipe_header_files&#125;</span>)</span><br></pre></td></tr></table></figure><h2 id="option与add-definitions"><a href="#option与add-definitions" class="headerlink" title="option与add_definitions"></a>option与add_definitions</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">option</span>(&lt;variable&gt; <span class="string">&quot;&lt;help_text&gt;&quot;</span> [value])</span><br></pre></td></tr></table></figure><p>可以在cmake命令中指定该值.</p><p>而add_definition用于指定编译器参数，比如<code>add_definitions(&quot;-Wall -g&quot;)</code>,此外更推荐使用add_compile_definitions将预处理器定义添加到编译器命令行,使用add_compile_options命令添加其它选项。</p><p>比如下面文件,使用add_definition定义了TEST_DEBUG,option定义为OFF并在cmake执行时指定为on,然后在cmake文件中指定option为on,这样就执行了<code>add_definitions(-DTEST_DEBUG)</code>,定义了该宏.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">cmake -DTEST_DEBUG=ON .</span><br><span class="line">cmake --build .</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">project</span>(<span class="keyword">test</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">option</span>(TEST_DEBUG <span class="string">&quot;option for debug&quot;</span> <span class="keyword">OFF</span>)</span><br><span class="line"><span class="keyword">if</span> (TEST_DEBUG)</span><br><span class="line"><span class="keyword">add_definitions</span>(-DTEST_DEBUG)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;test.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> TEST_DEBUG</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>CMake中的命令特别多,事实上并不需要去一个一个记住,通常只要知道一个项目的大致构建流程以及可能需要的命令就行了.</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://blog.csdn.net/llffss/article/details/120121617">cmake指令汇总_cmake命令大全_nuosen123的博客-CSDN博客</a></li><li><a href="https://www.runoob.com/w3cnote/cpp-static-library-and-dynamic-library.html">C++静态库与动态库 | 菜鸟教程 (runoob.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/578843962">使用C++创建并调用动态链接库(dll) - 知乎 (zhihu.com)</a></li><li><a href="https://blog.csdn.net/Op_chaos/article/details/110476264?spm=1001.2101.3001.6650.7&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-7-110476264-blog-120121617.235^v38^pc_relevant_anti_t3_base&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-7-110476264-blog-120121617.235^v38^pc_relevant_anti_t3_base&amp;utm_relevant_index=11">CMake指令详解_cmake -d-CSDN博客</a></li><li><a href="https://blog.csdn.net/qq_25160757/article/details/79813428">VS的包含目录、库目录、引用目录、可执行目录解释_vs包含目录和引用目录-CSDN博客</a></li><li><a href="https://www.cnblogs.com/pandamohist/p/13674438.html">cmake之Visual studio无法显示头文件 - mohist - 博客园 (cnblogs.com)</a></li><li><a href="https://blog.csdn.net/sandalphon4869/article/details/100589747">Linux之cmake的指令以及内部构建和外部构建_cmake 外部编译-CSDN博客</a></li><li><a href="https://www.cnblogs.com/guoshuai-ouc/p/cmake_variable.html">cmake 常用变量和常用环境变量 - 小果子啊 - 博客园 (cnblogs.com)</a></li><li><a href="https://blog.csdn.net/qq_38410730/article/details/102477162">【CMake】CMakeLists.txt的超傻瓜手把手教程（附实例源码）_【cmake】cmakelists.txt的超傻瓜手把手教程(附实例源码)-CSDN博客</a></li><li><a href="https://developer.aliyun.com/article/243229#:~:text=官网不推荐使用l,aries使用。">make的link_directories命令不起作用-阿里云开发者社区 (aliyun.com)</a></li><li><a href="https://cmake.org/cmake/help/latest/">CMake Reference Documentation — CMake 3.28.0-rc1 Documentation</a></li><li><a href="https://blog.csdn.net/afei__/article/details/81201039">CMakeLists.txt 语法介绍与实例演练-CSDN博客</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在Windows上开发c++相比Linux还是有点不方便,这里介绍CMake,跨平台的构建工具.&lt;br&gt;</summary>
    
    
    
    
    <category term="CMake" scheme="https://www.sekyoro.top/tags/CMake/"/>
    
  </entry>
  
  <entry>
    <title>stable_diffusion学习</title>
    <link href="https://www.sekyoro.top/2023/10/04/stable-diffusion%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/10/04/stable-diffusion%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-10-04T06:30:57.000Z</published>
    <updated>2023-10-04T08:31:01.778Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>比较火的text-img的模型,看一下其中的模块和流程.<br><span id="more"></span><br><a href="https://course.fast.ai/Lessons/lesson9.html以及[The">https://course.fast.ai/Lessons/lesson9.html以及[The</a> Illustrated Stable Diffusion – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io)](<a href="https://jalammar.github.io/illustrated-stable-diffusion/)都是比较好的资料">https://jalammar.github.io/illustrated-stable-diffusion/)都是比较好的资料</a>.</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>stable diffusion前身是latent diffusion<a href="https://arxiv.org/abs/2112.10752">[2112.10752] High-Resolution Image Synthesis with Latent Diffusion Models (arxiv.org)</a></p><blockquote><p>扩散模型已经显示出在生成图像数据方面实现了最先进的结果。但扩散模型的一个缺点是反向去噪过程很慢。此外，这些模型消耗了大量内存，因为它们在像素空间中工作，在生成高分辨率图像时，像素空间变得不合理地昂贵。因此，训练这些模型并将其用于推理是具有挑战性的。</p></blockquote><p>latent diffusion可以通过在<strong>低维潜在空间上应用扩散过程</strong>而不是使用实际像素空间来降低内存和计算复杂性。这是标准扩散和潜在扩散模型之间的关键区别：<strong>在潜在扩散中，模型被训练以生成图像的潜在（压缩）表示</strong></p><p>潜在扩散有三个主要成分。 一种自动编码器(VAE),U-Net,text-encoder，例如CLIP的文本编码器。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/article-Figure3-1-1536x762.png" alt="img"></p><h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><p>VAE模型有两个部分，一个编码器和一个解码器。</p><p>编码器用于将图像转换为低维的潜在表示，该低维潜在表示将用作U-Net模型的输入。相反，解码器将潜在的表示转换回图像。</p><p>在潜在扩散训练期间，编码器用于获得前向扩散过程的图像的潜在表示（latent），前向扩散在每一步应用越来越多的噪声。</p><p>在推断过程中，使用VAE解码器将反向扩散过程生成的去噪潜伏时间转换回图像。正如我们将在推理过程中看到的，我们只需要VAE解码器。</p><h3 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a>U-Net</h3><p><img data-src="https://img1.imgtp.com/2023/10/04/0K8yjheX.png" alt="image-20231004151321726"></p><p>U-Net具有编码器部分和解码器部分，两者都由ResNet块组成。编码器将图像表示压缩成较低分辨率的图像表示，并且解码器将较低分辨率图像表示解码回假定噪声较小的原始较高分辨率图像表示。更具体地，<strong>U-Net输出预测可用于计算预测的去噪图像表示的噪声残差</strong>。</p><p>该体系结构的一些亮点包括：</p><ul><li>该模型预测与输入大小相同的图像</li><li>该模型使输入图像经过几个ResNet层块</li><li>这些层将图像大小减半2然后通过相同数量的块再次对其进行上采样。</li><li>skip connections将下采样路径上的特征链接到上采样路径中的相应层。</li></ul><p>为了防止U-Net在下采样时丢失重要信息，<strong>通常在编码器的下采样ResNet和解码器的上采样ResNets之间添加short-cut connections</strong>。</p><p>此外，稳定扩散U-Net能够通过跨注意力层将其输出条件设置在文本嵌入上。交叉注意层被添加到U-Net的编码器和解码器部分，通常在ResNet块之间。</p><h3 id="Text-encoder"><a href="#Text-encoder" class="headerlink" title="Text-encoder"></a>Text-encoder</h3><p>Text-encoder负责将输入提示（例如“一个骑马的天文数字”）转换为U-Net可以理解的嵌入空间。它通常是一个简单的基于转换器的编码器，将输入token序列映射到潜在文本嵌入序列。</p><p>Stable Diffusion在训练期间不训练Text-encoder，而是简单地使用CLIP的已经训练的文本编码器</p><p>由于潜在扩散模型的U-Net在低维空间上运行，与像素空间扩散模型相比，它大大降低了内存和计算需求。</p><h2 id="diffusion-process"><a href="#diffusion-process" class="headerlink" title="diffusion process"></a>diffusion process</h2><p>扩散过程包括<strong>取所需输出大小的随机噪声</strong>，并将其通过模型多次。该过程在<strong>给定数量的步骤</strong>后结束，并且输出图像应该表示根据模型的训练数据分布的样本，例如蝴蝶的图像。</p><p>在训练过程中，我们展示了许多给定分布的样本，例如蝴蝶的图像。经过训练后，该模型将能够处理随机噪声，生成类似的蝴蝶图像。</p><p>该模型通常不会被训练成直接预测噪声稍低的图像，而是预测“噪声残差”，即<strong>噪声较低的图像和输入图像之间的差异</strong>（对于称为“DDPM”的扩散模型），或者类似地，两个时间步长之间的梯度（如称为“Score VE”的扩散模式）。也就是说Unet被训练为一个去噪器,被用于输出噪声差异.</p><p>因此，为了进行去噪过程，需要一种特定的噪声调度算法，并包裹(wrap)模型，以定义推理需要多少扩散步骤，以及如何从模型的输出中计算噪声较小的图像。扩散器库的不同<strong>调度器</strong>在这里发挥作用。</p><p>在训练时,我们给定text,图像</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-autoencoder.png" alt="img"></p><p>首先将图像通过encoder得到潜在变量用于后续处理,这也是为了内存和计算资源.这种压缩（以及后来的解压缩）是通过自动编码器完成的。自动编码器使用其编码器将图像压缩到潜在空间中，然后使用解码器仅使用压缩信息来重建图像。</p><p>现在，正向扩散过程是在压缩的compressed latents上完成的。噪声应用于那些latents的噪声，而不是应用于本身的像素图像的噪声。因此，<strong>噪声预测器实际上被训练来预测压缩表示（潜在空间）中的噪声</strong>。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-latent-forward-process-v2.png" alt="img"></p><p>正向过程（使用自动编码器的编码器）是我们生成数据以训练噪声预测器的方式。一旦经过训练，我们就可以通过运行反向过程（使用自动编码器的解码器）来生成图像。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-forward-and-reverse-process-v2.png" alt="img"></p><p>通过一张图片(潜在变量)以及添加与一个值(noise amount)相关的噪声,得到新的数据.</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-forward-diffusion-training-example-2.png" alt="img"></p><p>有了这个数据集，我们可以训练噪声预测器，并最终获得一个出色的噪声预测器。当在特定配置下运行时，它实际上可以创建图像</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-u-net-noise-training-step.png" alt="img"></p><p>我们目的是得到一个噪声预测器,通过之前得到的带有噪声的图像数据集以及相应的加噪声的值,这个预测器将这些作为输入,输出就是噪声,将带噪声图像数据集减去噪声看是否与原图一样,这样就得到一个noise predictor.</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-denoising-step-2v2.png" alt="img" style="zoom:50%;" /></p><p>Dall-E2和谷歌的Imagen也是类似原理.</p><p>注意上面的输入并没有加入text embedding,Transformer语言模型被用作语言理解组件，该组件接受文本提示并生成 token embeddings。发布的stable diffusion使用ClipText（一种基于GPT的模型），而论文中使用的BERT。</p><h3 id="CLIP训练"><a href="#CLIP训练" class="headerlink" title="CLIP训练"></a>CLIP训练</h3><p>CLIP是在图像及其字幕的数据集上进行训练的。想象一下这样的数据集，只有4亿张图像和它们的标题(captions)</p><blockquote><p>事实上，CLIP是根据从网络上抓取的图像及其“alt”标签进行训练的。</p></blockquote><p>CLIP是图像编码器和文本编码器的组合。它的训练过程可以简化为拍摄图像及其说明(caption)。我们分别用图像和文本编码器对它们进行编码。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/clip-training-step-1.png" alt="img" style="zoom: 50%;" /></p><p>然后，我们使用<strong>余弦相似性</strong>来比较结果嵌入。当我们开始训练过程时，即使文本正确地描述了图像，相似度也会很低。我们更新这两个模型，以便下次嵌入它们时，得到的嵌入是相似的。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/clip-training-step-3.png" alt="img" style="zoom:50%;" /></p><p>通过在数据集中重复，并使用大批量，我们最终发现编码器能够生成狗的图像和句子“狗的照片”相似的嵌入。就像在word2vec中一样，训练过程也需要包括不匹配的图像和描述(captions )的负面示例，并且模型需要为它们分配低相似度分数。</p><blockquote><p>captions本身是字幕的意思,这里表示图像的类似标签,标题,名字的含义.</p></blockquote><h3 id="加入text信息"><a href="#加入text信息" class="headerlink" title="加入text信息"></a>加入text信息</h3><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-unet-inputs-v2.png" alt="img" style="zoom:67%;" /></p><p>为了使文本成为图像生成过程的一部分，我们必须调整我们的噪声预测器，以使用文本作为输入。</p><p>现在的数据集包括编码文本。由于我们在潜在空间中操作，输入图像和预测噪声都在潜在空间内。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/stable-diffusion-text-dataset-v2.png" alt="img"></p><h4 id="如果不包含text信息"><a href="#如果不包含text信息" class="headerlink" title="如果不包含text信息"></a>如果不包含text信息</h4><p>在Unet中,如果没有text信息,那么结构如下</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/unet-inputs-outputs-v2.png" alt="img"></p><ol><li>Unet是一系列用于转换latents数组的层</li><li>每个层对上一层的输出进行操作</li><li>一些输出（通过residual connections）被馈送到网络中稍后的处理中</li><li>时间步长(timestep)被转换为时间步长嵌入向量( time step embedding vector)，</li></ol><p><img data-src="https://jalammar.github.io/images/stable-diffusion/unit-resnet-steps-v2.png" alt="img"></p><h4 id="如果包含text信息"><a href="#如果包含text信息" class="headerlink" title="如果包含text信息"></a>如果包含text信息</h4><p>需要对结构进行的主要更改是在ResNet块之间添加一个注意力层，以添加对文本输入的支持。</p><p><img data-src="https://jalammar.github.io/images/stable-diffusion/unet-with-text-steps-v2.png" alt="img"></p><p>请注意，ResNet块不会直接查看文本。但注意力层将这些文本表示合并到了latents中。现在，下一个ResNet可以在处理过程中利用合并的文本信息。</p><h2 id="Stable-Diffusion-during-inference"><a href="#Stable-Diffusion-during-inference" class="headerlink" title="Stable Diffusion during inference"></a>Stable Diffusion during inference</h2><p>训练时通过一个prompt,也就是text文本,然后通过一个laten seed随机生成一个潜变量图像(正态分布噪声),这些作为unet的输入</p><p><img data-src="https://img1.imgtp.com/2023/10/04/kHc7pOee.png" alt="image-20231004150708585"></p><p>代码如下,使用hugging face的diffusers库.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch_device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> CLIPTextModel, CLIPTokenizer</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> AutoencoderKL, UNet2DConditionModel, PNDMScheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Load the autoencoder model which will be used to decode the latents into image space.</span></span><br><span class="line">vae = AutoencoderKL.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;vae&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Load the tokenizer and text encoder to tokenize and encode the text.</span></span><br><span class="line">tokenizer = CLIPTokenizer.from_pretrained(<span class="string">&quot;openai/clip-vit-large-patch14&quot;</span>)</span><br><span class="line">text_encoder = CLIPTextModel.from_pretrained(<span class="string">&quot;openai/clip-vit-large-patch14&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. The UNet model for generating the latents.</span></span><br><span class="line">unet = UNet2DConditionModel.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;unet&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> diffusers <span class="keyword">import</span> LMSDiscreteScheduler</span><br><span class="line"></span><br><span class="line">scheduler = LMSDiscreteScheduler.from_pretrained(<span class="string">&quot;CompVis/stable-diffusion-v1-4&quot;</span>, subfolder=<span class="string">&quot;scheduler&quot;</span>)</span><br><span class="line">vae = vae.to(torch_device)</span><br><span class="line">text_encoder = text_encoder.to(torch_device)</span><br><span class="line">unet = unet.to(torch_device)</span><br><span class="line">prompt = [<span class="string">&quot;a photograph of an astronaut riding a horse&quot;</span>]</span><br><span class="line"></span><br><span class="line">height = <span class="number">512</span>                        <span class="comment"># default height of Stable Diffusion</span></span><br><span class="line">width = <span class="number">512</span>                         <span class="comment"># default width of Stable Diffusion</span></span><br><span class="line"></span><br><span class="line">num_inference_steps = <span class="number">100</span>            <span class="comment"># Number of denoising steps</span></span><br><span class="line"></span><br><span class="line">guidance_scale = <span class="number">7.5</span>                <span class="comment"># Scale for classifier-free guidance</span></span><br><span class="line"></span><br><span class="line">generator = torch.manual_seed(<span class="number">32</span>)   <span class="comment"># Seed generator to create the inital latent noise</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">text_input = tokenizer(prompt, padding=<span class="string">&quot;max_length&quot;</span>, max_length=tokenizer.model_max_length, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[<span class="number">0</span>]</span><br><span class="line">  max_length = text_input.input_ids.shape[-<span class="number">1</span>]</span><br><span class="line">uncond_input = tokenizer(</span><br><span class="line">    [<span class="string">&quot;&quot;</span>] * batch_size, padding=<span class="string">&quot;max_length&quot;</span>, max_length=max_length, return_tensors=<span class="string">&quot;pt&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[<span class="number">0</span>]</span><br><span class="line">  text_embeddings = torch.cat([uncond_embeddings, text_embeddings])</span><br><span class="line">  latents = torch.randn(</span><br><span class="line">  (batch_size, unet.in_channels, height // <span class="number">8</span>, width // <span class="number">8</span>),</span><br><span class="line">  generator=generator,</span><br><span class="line">)</span><br><span class="line">latents = latents.to(torch_device)</span><br><span class="line">scheduler.set_timesteps(num_inference_steps)</span><br><span class="line">latents = latents * scheduler.init_noise_sigma</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> autocast</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> tqdm(scheduler.timesteps):</span><br><span class="line">  <span class="comment"># expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.</span></span><br><span class="line">  latent_model_input = torch.cat([latents] * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">  latent_model_input = scheduler.scale_model_input(latent_model_input, t)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># predict the noise residual</span></span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample</span><br><span class="line"></span><br><span class="line">  <span class="comment"># perform guidance</span></span><br><span class="line">  noise_pred_uncond, noise_pred_text = noise_pred.chunk(<span class="number">2</span>)</span><br><span class="line">  noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># compute the previous noisy sample x_t -&gt; x_t-1</span></span><br><span class="line">  latents = scheduler.step(noise_pred, t, latents).prev_sample</span><br><span class="line">  <span class="comment"># scale and decode the image latents with vae</span></span><br><span class="line">latents = <span class="number">1</span> / <span class="number">0.18215</span> * latents</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  image = vae.decode(latents).sample</span><br><span class="line">  image = (image / <span class="number">2</span> + <span class="number">0.5</span>).clamp(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">image = image.detach().cpu().permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).numpy()</span><br><span class="line">images = (image * <span class="number">255</span>).<span class="built_in">round</span>().astype(<span class="string">&quot;uint8&quot;</span>)</span><br><span class="line">pil_images = [Image.fromarray(image) <span class="keyword">for</span> image <span class="keyword">in</span> images]</span><br></pre></td></tr></table></figure><p>本人水平有限,如果上文中关于diffusion过程有错误,还请斧正.</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ol><li><a href="https://colab.research.google.com/drive/1MOY7vkpKUosqPSk993g0o4VLjJKAJrwK#scrollTo=BBsdAj9pDPOv">stable_diffusion.ipynb - Colaboratory (google.com)</a></li><li><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb">Diffusers.ipynb - Colaboratory (google.com)</a></li><li><a href="https://jalammar.github.io/illustrated-stable-diffusion/">The Illustrated Stable Diffusion – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io)</a></li><li><a href="https://rekil156.github.io/rekilblog/posts/lesson9_stableDissufion/Lesson9.html">rekilblog - A different way to look at Stable Diffusion (rekil156.github.io)</a></li><li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models? | Lil’Log (lilianweng.github.io)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;比较火的text-img的模型,看一下其中的模块和流程.&lt;br&gt;</summary>
    
    
    
    
    <category term="stable diffusion" scheme="https://www.sekyoro.top/tags/stable-diffusion/"/>
    
  </entry>
  
  <entry>
    <title>深度学习训练tricks</title>
    <link href="https://www.sekyoro.top/2023/10/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83tricks/"/>
    <id>https://www.sekyoro.top/2023/10/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83tricks/</id>
    <published>2023-10-04T02:47:08.000Z</published>
    <updated>2023-10-06T09:35:34.770Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>最近在看微软的AI for Beginners,质量比较高,这里相当于将其中的一篇文章写过来加点自己的理解.</p><span id="more"></span><p>模型的训练的一个主要问题是梯度爆炸或者梯度消失,前者会导致训练不稳定,表现出来就是损失值不稳定,一直都处在较高值降不下去,后者就是更新缓慢.下面介绍一些技巧</p><h3 id="将值保持在合理的范围"><a href="#将值保持在合理的范围" class="headerlink" title="将值保持在合理的范围"></a>将值保持在合理的范围</h3><p>为了让数值运算更稳定,我们希望确保神经网络中的所有值都在合理的范围内，通常为[-1,1]或[0,1]. <strong>浮点计算的本质是，不同大小的值不能精确地一起操作</strong>.这样做是为了避免原本非常大或非常小的值进行传播时使得梯度爆炸或者消失,当保持在[-1,1]后数值比较稳定.</p><blockquote><p>例如，如果我们将10^-10^和10^10^相加，我们很可能得到10^10^，因为较小的值将被“转换”为与较大的值相同的order(这涉及到计算机的浮点数运算)，因此尾数将丢失。</p></blockquote><p>此外,大多数激活函数在[-1,1]附近具有非线性，因此将所有输入数据缩放到[-1,1]或[0,1]间隔是有意义的。</p><p>所以在预处理数据时通常会Normalize.</p><h2 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h2><p>理想情况下,我们希望这些值在通过网络层后处于相同的范围内。因此,初始化权重以保持输入值前后的分布方式是很重要的。</p><p>我的理解就是weight不能太大或太小或者其他情况,这影响到输出的分布.</p><p>正态分布N(0,1)不是一个好主意，因为如果我们有n个输入,输出的标准差将是n，并且值可能跳出[0,1]区间。也就是说如果输入是(B,C)的数据,B表示一个batch,C是特征数,进行正态分布权重初始化,假设w矩阵shape是(C,2)服从标准正态分布,得到值标准差为n(因为有n个特征,每个特征乘以一个正态分布,然后将每个特征相加)</p><p>所以不能使用标准正态分布初始化权重,通常使用以下初始化:</p><ul><li>均匀分布—uniform,也就是在一个范围内值相同.</li><li>N（0,1/N） 正态分布,使得输出尽量符合N(0,1)</li><li>N（0,1/√N_in）保证对于N(0,1)的输入，将保持相同的平均值和标准差.</li><li>N（0，√2/（N_in+N_out））——所谓的Xavier初始化（glorot）,它有助于在前向和后向传播过程中保持信号在一定范围内</li></ul><p>在pytorch中默认是N（0,1/√N_in）初始化,当然这可以自己设置.</p><h3 id="批量规范化"><a href="#批量规范化" class="headerlink" title="批量规范化"></a>批量规范化</h3><p>即使进行了适当的权重初始化，在训练过程中权重也可能变得任意大或小，并且它们会使信号超出适当的范围。</p><p>我们可以通过使用一种归一化技术来恢复信号。虽然有几种（权重规格化、层规格化），但最常用的是批量规格化。批量归一化的思想是考虑整个小批量的所有值，并根据这些值执行归一化（即减去平均值并除以标准差）。它被实现为网络层，在应用权重之后但在激活函数之前进行这种归一化。因此，我们可能会看到更高的最终准确性和更快的训练。</p><p>除了batchnormal之外还有layernormal和instancenormal等等,这些不同的方式应用在不同的任务上.</p><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Dropout是一种有趣的技术，可以在训练过程中去除一定比例的随机神经元。它也被实现为一个具有一个参数（要去除的神经元的百分比，通常为10%-50%）的层,在训练过程中，它将输入向量的随机元素归零，然后将其传递到下一层。</p><p>这种影响可以用几种方式来解释：</p><ul><li>它可以被认为是模型的一个随机冲击因素，它使优化超出了局部最小值</li><li>它可以被认为是隐式模型平均(implicit model averaging)，因为我们可以说，在dropout时，我们训练的模型略有不同</li></ul><p>在Pytorch实现中,在训练过程会去除一定比例神经元然后将剩余的神经元权重乘以去除比例的倒数,测试时正常传播.</p><p>下图横线不同的值表示dropout的比例</p><p><img data-src="https://s2.loli.net/2023/10/06/6KLalAzGQZuR7Dc.png" alt="image-20231006173527028"></p><p>这东西没有好的数学支撑,但是效果不错.我没记错的话就是hinton提出的,这人有认知心理学领域的知识,所以会提出这些东西.</p><h2 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h2><p>深度学习的一个非常重要的方面就是能够防止过度拟合。虽然使用非常强大的神经网络模型可能很诱人，但我们应该始终<strong>平衡模型参数的数量与训练样本的数量</strong>。</p><p>有几种方法可以防止过度拟合：</p><ol><li><p>早期停止(early stopping)——持续监控验证集上的错误，并在验证错误开始增加时停止训练。</p></li><li><p>显式权重衰减/正则化(explicit weight decay/regularization)-<strong>为权重的高绝对值的损失函数添加额外的惩罚</strong>，这可以防止模型获得非常不稳定的结果. </p><p>权重衰减/正则化指的是损失函数加上weight的正则化系数,以希望权重减小.</p><blockquote><p>在WGAN中其实还有gradient penalty,将梯度的Norm加到损失函数中</p></blockquote></li><li><p>模型平均(model averaging)——训练几个模型，然后对结果进行平均。这有助于最小化差异。</p></li><li><p>Dropout（隐式模型平均值）</p></li></ol><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>训练的另一个重要方面是选择好的训练算法。虽然经典的梯度下降(每次选取一个样本)是一个合理的选择，但它有时可能太慢，或导致其他问题.</p><p>在深度学习中，我们使用随机梯度下降（SGD），这是一种应用于从训练集中随机选择的小批量的梯度下降。使用以下公式调整权重：</p><script type="math/tex; mode=display">w^{t+1}=w^{t}-\eta\nabla{\cal L}</script><h3 id="引入动量"><a href="#引入动量" class="headerlink" title="引入动量"></a>引入动量</h3><p>在动量SGD中，我们保持了之前步骤的一部分梯度。这类似于当我们带着惯性在某个地方移动时，我们受到了不同方向的冲击，我们的轨迹不会立即改变，而是保持了原始运动的一部分。在这里，我们引入另一个向量v来表示速度：</p><script type="math/tex; mode=display">\begin{array}{cc}{\bullet}&{ {v^{t+1}=\gamma v^{t}-\eta\nabla{\cal L}  } }\\{\bullet}&{ {w^{t+1}=w^{t}+v^{t+1} } }\\\end{array}</script><p>这里，参数γ表示我们考虑惯性的程度：γ=0对应于经典SGD；γ=1是一个纯运动方程</p><h3 id="Adam-Adagrad"><a href="#Adam-Adagrad" class="headerlink" title="Adam,Adagrad"></a>Adam,Adagrad</h3><p>由于在每一层中，我们将信号乘以某个矩阵W~i~，这取决于||Wi||，因此梯度可以减小并接近0，也可以无限上升。它是梯度消失/爆炸问题的本质。</p><p>一种解决方法就是计算梯度时,只使用损失梯度的方向，忽略绝对值.</p><script type="math/tex; mode=display">w^{t+1}=w^t-\eta(\nabla\mathcal{L}/||\nabla\mathcal{L}||)\text{,where}||\nabla\mathcal{L}||=\sqrt{\Sigma(\nabla\mathcal{L})^2}</script><p>还是要学好数学基础,这里梯度矩阵求一个L-2 Norm,计算类似归一化值(像单位向量一样).这样保持了梯度的分布,同时减小了梯度的值避免了梯度爆炸.</p><p>这个算法被称为Adagrad。另一个使用相同思想的算法：RMSProp，Adam.</p><p>其实优化器的选择还是要看具体任务.</p><h3 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h3><p>梯度剪裁是上述思想的扩展。当ℒ|| ≤ θ、 我们在权重优化中考虑原始梯度，当ℒ|| &gt; θ-我们将梯度除以它的范数。这里θ是一个参数，在大多数情况下，我们可以取θ=1或θ=10。</p><h3 id="学习率递减"><a href="#学习率递减" class="headerlink" title="学习率递减"></a>学习率递减</h3><p>训练的成功往往取决于学习率参数η。合理的假设是，η的值越大，训练越快，这是我们在训练开始时通常想要的，然后η的值就越小，我们就可以微调网络。因此，在大多数情况下，我们希望在训练过程中降低η。这可以通过在每个训练时期后将η乘以某个数字（例如0.98）来实现，或者通过使用更复杂的学习率scheduler来实现。</p><p>所以学习率一开始可以设置大一点,后面进行减小.</p><p>Pytorch中有learning rate scheduler用于调度学习率.</p><h2 id="使用不同的网络架构"><a href="#使用不同的网络架构" class="headerlink" title="使用不同的网络架构"></a>使用不同的网络架构</h2><p><a href="https://www.topbots.com/a-brief-history-of-neural-network-architectures/">A Brief History Of Neural Network Architectures (topbots.com)</a></p><p>网络架构需要跟具体任务相关,通常，我们会采用一种已被证明适用于我们特定任务（或类似任务）的架构</p><p><img data-src="https://topb0ts.wpenginepowered.com/wp-content/uploads/2017/06/neural_network_architectures_800x350px_web-1.png" alt="Neural Network Architectures Eugenio Culurciello" style="zoom:67%;" /></p><p>另一个好方法是使用能够自动调整到所需复杂性的体系结构。在某种程度上，ResNet架构和Inception是自我调整的.</p><p>本人能力有限,如果上面写的有误,还请评论指出,敬请赐教.</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在看微软的AI for Beginners,质量比较高,这里相当于将其中的一篇文章写过来加点自己的理解.&lt;/p&gt;</summary>
    
    
    
    
    <category term="DeepLearning" scheme="https://www.sekyoro.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>HFNLP学习</title>
    <link href="https://www.sekyoro.top/2023/09/29/HFNLP%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/09/29/HFNLP%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-09-29T04:57:12.000Z</published>
    <updated>2023-10-06T09:34:39.921Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>深度学习中常用的技术,这里结合一些tutorial简单学习一下.<br><span id="more"></span><br>首先需要了解一些简单概念<a href="https://www.zhihu.com/tardis/zm/art/138310401?source_id=1005">深度学习推荐系统 | Embedding，从哪里来，到哪里去 (zhihu.com)</a>这里使用hugging face的相关库,我也建议多看看这个社区以及其相关的工具,我觉得这些工具很棒,这个开源社区也很棒.此外也有LangChain等工具.</p><h2 id="transformers模型"><a href="#transformers模型" class="headerlink" title="transformers模型"></a>transformers模型</h2><p>transformers库是利用基于transformer模型处理任务的库.transfomers模型架构上有过很多大模型.</p><p><img data-src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" alt="Architecture of a Transformers models"></p><p><img data-src="https://img1.imgtp.com/2023/09/29/bxBzfQw2.png" alt="image-20230929145450463" style="zoom:80%;" /></p><p>在hugging face中,有transformers库帮助我们处理一系列nlp任务.下面介绍一下这个库.</p><p>transformers库中最基本的对象.Transformers库是pipeline（）函数。它将模型与其必要的预处理和后处理步骤连接起来，使我们能够直接输入任何文本并获得可理解的答案.默认情况下，此pipeline选择一个特定的预训练模型，该模型已针对英语情感分析进行了微调。创建<strong>classifier</strong>对象时，将下载并缓存模型。如果您重新运行该命令，则将使用缓存的模型，无需再次下载模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">classifier = pipeline(<span class="string">&quot;sentiment-analysis&quot;</span>)</span><br><span class="line">classifier(</span><br><span class="line">    [</span><br><span class="line">        <span class="string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,</span><br><span class="line">        <span class="string">&quot;I hate this so much!&quot;</span>,</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="symbol">&#x27;label</span><span class="symbol">&#x27;:</span> <span class="symbol">&#x27;POSITIVE</span>&#x27;, <span class="symbol">&#x27;score</span><span class="symbol">&#x27;:</span> <span class="number">0.9598048329353333</span>&#125;,</span><br><span class="line"> &#123;<span class="symbol">&#x27;label</span><span class="symbol">&#x27;:</span> <span class="symbol">&#x27;NEGATIVE</span>&#x27;, <span class="symbol">&#x27;score</span><span class="symbol">&#x27;:</span> <span class="number">0.9994558691978455</span>&#125;]</span><br></pre></td></tr></table></figure><p>将一些文本传递到pipeline时，主要涉及三个步骤：</p><ol><li>文本被预处理为模型能够理解的格式。</li><li>经过预处理的输入被传递给模型。 </li><li>模型的预测是经过后处理的，因此您可以理解它们。</li></ol><p>pipeline函数可用的任务参数有</p><ul><li><p><code>feature-extraction</code> (get the vector representation of a text)</p></li><li><p><code>fill-mask</code></p></li><li><p><code>ner</code> (named entity recognition)</p></li><li><p><code>question-answering</code></p></li><li><p><code>sentiment-analysis</code></p></li><li><p><code>summarization</code></p></li><li><p><code>text-generation</code></p></li><li><p><code>translation</code></p></li><li><p><code>zero-shot-classification</code></p><p><img data-src="https://img1.imgtp.com/2023/09/29/Q6Mjp3xk.png" alt="image-20230929151703649"></p></li></ul><p>由于NLP的一些任务我不是很熟悉,有必要做一些大概了解.</p><h4 id="Zero-shot-classification"><a href="#Zero-shot-classification" class="headerlink" title="Zero-shot classification"></a>Zero-shot classification</h4><p>我们需要对尚未标记的文本进行分类。这是实际项目中的常见场景，因为注释文本通常很耗时并且需要领域专业知识。对于这项任务<strong>zero-shot-classification</strong>pipeline非常强大：它允许您直接指定用于分类的标签，因此您不必依赖预训练模型的标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">classifier = pipeline(<span class="string">&quot;zero-shot-classification&quot;</span>)</span><br><span class="line">classifier(</span><br><span class="line">    <span class="string">&quot;This is a course about the Transformers library&quot;</span>,</span><br><span class="line">    candidate_labels=[<span class="string">&quot;education&quot;</span>, <span class="string">&quot;politics&quot;</span>, <span class="string">&quot;business&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>由于pipeline没有指定model和tokenizer,会默认下载model和tokenizer.这里模型本身携带了tokenizer.后者就是生成embedding的.</p><h4 id="Text-generation"><a href="#Text-generation" class="headerlink" title="Text generation"></a>Text generation</h4><p>模型将通过生成剩余的文本来自动完成整段话。这类似于许多手机上的预测文本功能。文本生成涉及随机性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">generator = pipeline(<span class="string">&quot;text-generation&quot;</span>)</span><br><span class="line">generator(<span class="string">&quot;In this course, we will teach you how to&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="comment"># 指定模型</span></span><br><span class="line">generator = pipeline(<span class="string">&quot;text-generation&quot;</span>, model=<span class="string">&quot;distilgpt2&quot;</span>)</span><br><span class="line">generator(</span><br><span class="line">    <span class="string">&quot;In this course, we will teach you how to&quot;</span>,</span><br><span class="line">    max_length=<span class="number">30</span>,</span><br><span class="line">    num_return_sequences=<span class="number">2</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="Mask-filling"><a href="#Mask-filling" class="headerlink" title="Mask filling"></a>Mask filling</h4><p>这项任务的目的是填补给定文本中的空白：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">unmasker = pipeline(<span class="string">&quot;fill-mask&quot;</span>)</span><br><span class="line">unmasker(<span class="string">&quot;This course will teach you all about &lt;mask&gt; models.&quot;</span>, top_k=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h4 id="Named-entity-recognition"><a href="#Named-entity-recognition" class="headerlink" title="Named entity recognition"></a>Named entity recognition</h4><p>命名实体识别 (NER) 是一项任务，其中模型必须找到输入文本的哪些部分对应于诸如人员、位置或组织之类的实体</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">ner = pipeline(<span class="string">&quot;ner&quot;</span>, grouped_entities=<span class="literal">True</span>)</span><br><span class="line">ner(<span class="string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Question-answering"><a href="#Question-answering" class="headerlink" title="Question answering"></a>Question answering</h4><p>给定上下文中的信息回答问题</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">question_answerer = pipeline(<span class="string">&quot;question-answering&quot;</span>)</span><br><span class="line">question_answerer(</span><br><span class="line">    question=<span class="string">&quot;Where do I work?&quot;</span>,</span><br><span class="line">    context=<span class="string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">summarizer = pipeline(<span class="string">&quot;summarization&quot;</span>)</span><br><span class="line">summarizer(</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    America has changed dramatically during recent years. Not only has the number of </span></span><br><span class="line"><span class="string">    graduates in traditional engineering disciplines such as mechanical, civil, </span></span><br><span class="line"><span class="string">    electrical, chemical, and aeronautical engineering declined, but in most of </span></span><br><span class="line"><span class="string">    the premier American universities engineering curricula now concentrate on </span></span><br><span class="line"><span class="string">    and encourage largely the study of engineering science. As a result, there </span></span><br><span class="line"><span class="string">    are declining offerings in engineering subjects dealing with infrastructure, </span></span><br><span class="line"><span class="string">    the environment, and related issues, and greater concentration on high </span></span><br><span class="line"><span class="string">    technology subjects, largely supporting increasingly complex scientific </span></span><br><span class="line"><span class="string">    developments. While the latter is important, it should not be at the expense </span></span><br><span class="line"><span class="string">    of more traditional engineering.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Rapidly developing economies such as China and India, as well as other </span></span><br><span class="line"><span class="string">    industrial countries in Europe and Asia, continue to encourage and advance </span></span><br><span class="line"><span class="string">    the teaching of engineering. Both China and India, respectively, graduate </span></span><br><span class="line"><span class="string">    six and eight times as many traditional engineers as does the United States. </span></span><br><span class="line"><span class="string">    Other industrial countries at minimum maintain their output, while America </span></span><br><span class="line"><span class="string">    suffers an increasingly serious decline in the number of engineering graduates </span></span><br><span class="line"><span class="string">    and a lack of well-educated engineers.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line">translator = pipeline(<span class="string">&quot;translation&quot;</span>, model=<span class="string">&quot;Helsinki-NLP/opus-mt-fr-en&quot;</span>)</span><br><span class="line">translator(<span class="string">&quot;Ce cours est produit par Hugging Face.&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p><img data-src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" alt="The full NLP pipeline"></p><h4 id="Preprocessing-with-a-tokenizer"><a href="#Preprocessing-with-a-tokenizer" class="headerlink" title="Preprocessing with a tokenizer"></a>Preprocessing with a tokenizer</h4><p>与其他神经网络一样，Transformer模型无法直接处理原始文本， 因此我们pipeline的第一步是将文本输入转换为模型能够理解的数字。 为此，我们使用<em>tokenizer</em>(标记器)，负责：</p><ul><li>将输入拆分为单词、子单词或符号（如标点符号），称为标记(<em>token</em>)</li><li>将每个标记(token)映射到一个整数</li><li>添加可能对模型有用的其他输入</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from transformers import AutoTokenizer</span><br><span class="line"></span><br><span class="line">checkpoint = &quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line">raw_inputs = [</span><br><span class="line">    &quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;,</span><br><span class="line">    &quot;I hate this so much!&quot;,</span><br><span class="line">]</span><br><span class="line">inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=&quot;pt&quot;)</span><br><span class="line">print(inputs)</span><br></pre></td></tr></table></figure><h4 id="Going-through-the-model"><a href="#Going-through-the-model" class="headerlink" title="Going through the model"></a>Going through the model</h4><p>我们可以像下载标记器一样下载我们的预训练模型。 Transformers提供了一个AutoModel类，该类还具有from_pretrained（）方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel</span><br><span class="line"></span><br><span class="line">checkpoint = <span class="string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span></span><br><span class="line">model = AutoModel.from_pretrained(checkpoint)</span><br></pre></td></tr></table></figure><p>这里说一下embedding现在常用的生成方式,这与transformer有关,关于Hugging Face的使用以及其教程后续继续更新.</p><h3 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h3><p>在语义上用数字表示,模型能够理解.</p><p><img data-src="https://s2.loli.net/2023/10/06/SwhFHVLiNbeOIc8.png" alt="image-20231006173438026"></p><p>一句话如何embedding</p><p>简单的方法:单独地embed每个word,然后计算所有word的embedding的均值或和.但这样无法区分顺序.</p><p>现在常用的办法:使用transformer网络计算每个word的context-aware的表示,然后计算每个表示的均值.或者为每个token计算embedding而不是word.或者再利用transformer在自己的数据上继续训练,使得相似的句子相似度更高.</p><p>多模态嵌入也是比较新的东西,将图像与文本都嵌入到一个域内.比如CLIP模型.</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://huggingface.co/learn/nlp-course">https://huggingface.co/learn/nlp-course</a></li><li><a href="https://learn.deeplearning.ai/google-cloud-vertex-ai">https://learn.deeplearning.ai/google-cloud-vertex-ai</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;深度学习中常用的技术,这里结合一些tutorial简单学习一下.&lt;br&gt;</summary>
    
    
    
    
    <category term="Embedding" scheme="https://www.sekyoro.top/tags/Embedding/"/>
    
  </entry>
  
  <entry>
    <title>大模型微调</title>
    <link href="https://www.sekyoro.top/2023/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"/>
    <id>https://www.sekyoro.top/2023/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</id>
    <published>2023-09-28T12:15:47.000Z</published>
    <updated>2023-10-06T09:30:13.202Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这段时间非常火的topic,大模型参数多,占用体积大训练困难,而且一般需要微调技术用于特定任务.<br><span id="more"></span></p><p><a href="https://colab.research.google.com/drive/14MCMope8tjZkg5H5mXKSr_g2lYi5woVU#scrollTo=_Gw1sj7sagEE&amp;uniqifier=1">AnimeBot.ipynb - Colaboratory (google.com)</a>我的完整代码</p><h2 id="什么是大模型LLM"><a href="#什么是大模型LLM" class="headerlink" title="什么是大模型LLM"></a>什么是大模型LLM</h2><blockquote><p>LLM是大型语言模型的缩写，是人工智能和机器学习领域的最新创新。2022年12月，随着ChatGPT的发布，这种强大的新型人工智能在网上疯传。对于那些足够开明的人来说，生活在人工智能的嗡嗡声和科技新闻周期之外，ChatGPT是一个在名为GPT-3的LLM上运行的聊天界面。</p></blockquote><p>最近的大模型就是Meta的llama2当然还有openai的GPT4,google的PaLM2.国内有清华的ChatGLM等等.</p><p>而大模型微调就是在此基础上更改其参数或者一些层使得更好应对一些下游任务.当你想将预先存在的模型适应特定的任务或领域时，微调模型在机器学习中至关重要。微调模型的决定取决于您的目标，这些目标通常是特定于领域或任务的。</p><p><img data-src="https://s2.loli.net/2023/10/06/EVg6Y5wI4bORafU.png" alt="image-20231006172946171"></p><p>现在关于微调的技术有很多,这些技术都是为了解决自己的specified task,一般需要特定的数据.</p><p>一般涉及三种方法。Prompt Engineering,embedding以及finetune也就是微调.</p><h3 id="Prompt-Engineering"><a href="#Prompt-Engineering" class="headerlink" title="Prompt Engineering"></a>Prompt Engineering</h3><p>简单来说就是跟模型对话时提前给一些已知的信息.</p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*aeek418WCndtt1491JHK7w.png" alt="Chat GPT responds to the query using custom data (revenue numbers) provided in the prompt." style="zoom:67%;" /></p><p>这种方法简单,但是由于将大文本传递到LLM的提示大小和相关成本的限制，使用大文档集或网页作为LLM的输入不是最佳方式。</p><h3 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h3><p>嵌入是一种将信息（无论是文本、图像还是音频）表示为数字形式的方式</p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*bYy116KZAanbxXta4PCkjQ.png" alt="img"></p><p>当需要将大量文档或网页传递给LLM时，嵌入效果很好。例如，当聊天机器人被构建为向用户提供一组策略文档的响应时，这种方法会很好地工作。</p><p>使用时需要将文本等内容生成embedding,这就需要seq2seq模型得到嵌入了.当用户想要查询LLM时，嵌入将从向量存储中检索并传递给LLM。LLM使用嵌入从自定义数据生成响应。</p><h3 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine tuning"></a>Fine tuning</h3><p><img data-src="https://s2.loli.net/2023/10/06/bJK6SC3Pq5AT7FV.png" alt="image-20231006172959467"></p><p>微调是教模型如何处理输入查询以及如何表示响应的一种方式。例如，LLM可以通过提供有关客户评价和相应情绪的数据来进行微调。</p><p>微调通常用于为特定任务调整LLM，并在该范围内获得响应。该任务可以是电子邮件分类、情绪分析、实体提取、基于规格生成产品描述等</p><p>具体的微调技术有Lora,QLora,Peft等等</p><h4 id="Fine-tuning技术"><a href="#Fine-tuning技术" class="headerlink" title="Fine tuning技术"></a>Fine tuning技术</h4><h4 id="old-school"><a href="#old-school" class="headerlink" title="old school"></a>old school</h4><p>在老派的方法中，有各种方法可以微调预先训练的语言模型，每种方法都是根据特定需求和资源限制量身定制的。</p><ul><li>基于特征：它使用预先训练的LLM作为特征提取器，将输入文本转换为固定大小的数组。一个单独的分类器网络预测NLP任务中文本的分类概率。在训练中，只有分类器的权重会改变，这使得它对资源友好，但可能性能较差。</li><li>微调I：微调I通过添加额外的密集层来增强预先训练的LLM。在训练期间，只调整新添加的层的权重，同时保持预先训练的LLM权重冻结。在实验中，<strong>它显示出比基于特征的方法略好的性能</strong>。</li><li>微调II：在这种方法中，整个模型，包括预先训练的语言模型（LLM），都被解冻进行训练，允许更新所有模型权重。然而，它可能会导致<strong>灾难性的遗忘</strong>，新的特征会覆盖旧的知识。微调II是资源密集型的，但在需要最大性能时可提供卓越的结果。通用语言模型微调</li><li>ULMFiT是一种可应用于NLP任务的迁移学习方法。它涉及一个3层的AWD-LSTM体系结构来进行表示。ULMFiT是一种用于为特定下游任务微调预先训练的语言模型的方法。</li><li>基于梯度的参数重要性排序：这些方法用于对模型中特征或参数的重要性进行排序。在基于梯度的排序中，参数的重要性取决于排除参数时精度降低的程度。在基于随机森林的排序中，可以对每个特征的杂质减少进行平均，并根据该度量对特征进行排序。</li></ul><p><img data-src="https://s2.loli.net/2023/10/06/nGVmIryLvM3AZEY.png" alt="image-20231006173008820"></p><h4 id="LLM微调的前沿策略"><a href="#LLM微调的前沿策略" class="headerlink" title="LLM微调的前沿策略"></a>LLM微调的前沿策略</h4><ul><li>低秩自适应（LoRA）：LoRA是一种微调大型语言模型的技术。它使用低秩近似方法来降低将具有数十亿参数的模型（如GPT-3）适应特定任务或领域的计算和财务成本。</li><li>量化LoRA（QLoRA）：QLoRA是一种适用于大型语言模型（LLM）的高效微调方法，可显著减少内存使用，同时保持完整的16位微调性能。它通过将冻结的4位量化预训练语言模型的梯度反向传播到低秩适配器中来实现这一点。</li><li>参数高效微调（PEFT）：PEFT是一种NLP技术，<strong>通过只微调一小组参数</strong>，降低计算和存储成本，使预先训练的语言模型有效地适应各种应用。<strong>它可以消除灾难性的遗忘，为特定任务调整关键参数，并提供与图像分类和稳定扩散dreambooth等模式的全面微调相当的性能。这是一种在最小可训练参数的情况下实现高性能的有价值的方法。</strong></li><li>DeepSpeed:DeepSpeed是一个深度学习软件库，用于加速大型语言模型的训练。它包括ZeRO（零冗余优化器），这是一种用于分布式训练的内存高效方法。DeepSpeed可以自动优化使用Hugging Face的Trainer API的微调作业，并提供一个替代脚本来运行现有的微调脚本。</li><li>ZeRO：ZeRO是一组内存优化技术，能够有效训练具有数万亿参数的大型模型，如GPT-2和图灵NLG 17B。ZeRO的一个主要吸引力是不需要修改模型代码。这是一种内存高效的数据并行形式，可以让您访问所有可用GPU设备的聚合GPU内存，而不会因数据并行中的数据复制而导致效率低下。</li></ul><p>现在一般用lora及其衍生方法以及PEFT.</p><p>微调用的数据集可以自己做也可以到处找,比如hugging face上或者Google dataset,github上.</p><p>至于模型一般使用hugging face或者langchain等工具库直接调用,没有必要手动下载.获取到一般的语言或者其他类型的数据之后,一般都需要embedding等预处理步骤.embedding模型一般要与处理任务的模型有一定对应关系.</p><p>下面使用Hugging Face的transformers等库进行大模型微调.常常使用<code>AutoModel</code>,<code>AutoTokenizer</code>以及<code>AutoConfig</code>,通过调用<code>from_pretrained</code>获取相关信息.下面是一般训练流程.</p><h4 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Transformers installation</span></span><br><span class="line">pip install transformers datasets</span><br><span class="line"><span class="comment"># To install from source instead of the last release, comment the command above and uncomment the following one.</span></span><br><span class="line">pip install git+https://github.com/huggingface/transformers.git</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;yelp_review_full&quot;</span>)</span><br><span class="line"><span class="comment">#dataset[&quot;train&quot;][100]</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_function</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;text&quot;</span>], padding=<span class="string">&quot;max_length&quot;</span>, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">tokenized_datasets = dataset.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">small_train_dataset = tokenized_datasets[<span class="string">&quot;train&quot;</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line">small_eval_dataset = tokenized_datasets[<span class="string">&quot;test&quot;</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(output_dir=<span class="string">&quot;test_trainer&quot;</span>)</span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=small_train_dataset,</span><br><span class="line">    eval_dataset=small_eval_dataset,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><p>上面的<code>compute_metrics</code>用于评估模型.<code>training_args</code>是训练时设置参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    logits, labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure><p>可以使用<code>trainer.push_to_hub()</code>推送到自己的仓库.这样会自动将训练超参数、训练结果和框架版本添加到您的模型卡中</p><h4 id="PEFT训练adapters"><a href="#PEFT训练adapters" class="headerlink" title="PEFT训练adapters"></a>PEFT训练adapters</h4><p>使用PEFT训练的适配器通常也比完整模型小一个数量级，便于共享、存储和加载。通常搭配Lora模型.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">peft_model_id = <span class="string">&quot;ybelkada/opt-350m-lora&quot;</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(peft_model_id)</span><br></pre></td></tr></table></figure><p>加载和使用PEFT适配器型,请确保Hub存储库或本地目录包含adapter_config.json文件和adapter weights.</p><p>也可以先加载基础model,再使用<code>load_adapter</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&quot;facebook/opt-350m&quot;</span></span><br><span class="line">peft_model_id = <span class="string">&quot;ybelkada/opt-350m-lora&quot;</span></span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_id)</span><br><span class="line">model.load_adapter(peft_model_id)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>load_in_8bit</code>以及<code>device_map</code>涉及到将模型放哪和占用大小.</p><p>增加<code>adapter</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftConfig</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&quot;facebook/opt-350m&quot;</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_id)</span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>],</span><br><span class="line">    init_lora_weights=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.add_adapter(lora_config, adapter_name=<span class="string">&quot;adapter_1&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>训练一个adapter</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">    lora_alpha=<span class="number">16</span>,</span><br><span class="line">    lora_dropout=<span class="number">0.1</span>,</span><br><span class="line">    r=<span class="number">64</span>,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">)</span><br><span class="line">model.add_adapter(peft_config)</span><br><span class="line">trainer = Trainer(model=model, ...)</span><br><span class="line">trainer.train()</span><br><span class="line">model.save_pretrained(save_dir)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(save_dir)</span><br></pre></td></tr></table></figure><p>每个 PEFT方法由<code>PeftConfig</code>类定义，该类存储用于构建<code>PeftModel</code>的所有重要参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, TaskType</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=<span class="literal">False</span>, r=<span class="number">8</span>, lora_alpha=<span class="number">32</span>, lora_dropout=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">    r=lora_r,</span><br><span class="line">    lora_alpha=lora_alpha,</span><br><span class="line">    lora_dropout=lora_dropout,</span><br><span class="line">    target_modules=lora_target_modules,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>使用<code>get_peft_model</code>函数包装基本模型和peft_config以创建PeftModel.并使用<code>print_trainable_parameters</code>打印需要更新的参数.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> get_peft_model</span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&quot;bigscience/mt0-large&quot;</span></span><br><span class="line">tokenizer_name_or_path = <span class="string">&quot;bigscience/mt0-large&quot;</span></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)</span><br><span class="line"></span><br><span class="line">model = get_peft_model(model, peft_config)</span><br><span class="line">model.print_trainable_parameters()</span><br></pre></td></tr></table></figure><p><strong>保存并推送模型到仓库</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;output_dir&quot;</span>)</span><br><span class="line">model.push_to_hub(<span class="string">&quot;my_awesome_peft_model&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>这只会保存增量经过训练的PEFT重量，这意味着它在存储、转移和装载方面非常高效。例如，在RAFT数据集的twitter_complaints子集上使用LoRA训练的bigscience/To_3B模型只包含两个文件：adapter_config.json和adapter_model.bin。</p></blockquote><p><strong>下载模型</strong></p><p>下面的方法是逻辑是首先通过PeftConfig得到peft的配置,从中得到基础模型位置,利用基础模型得到其模型和tokenizer,最后利用PeftModel得到model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel, PeftConfig</span><br><span class="line"></span><br><span class="line">peft_model_id = <span class="string">&quot;smangrul/twitter_complaints_bigscience_T0_3B_LORA_SEQ_2_SEQ_LM&quot;</span></span><br><span class="line">config = PeftConfig.from_pretrained(peft_model_id)</span><br><span class="line">  model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)</span><br><span class="line">model = PeftModel.from_pretrained(model, peft_model_id)</span><br><span class="line">  tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)</span><br><span class="line"></span><br><span class="line">  model = model.to(device)</span><br><span class="line">  model.<span class="built_in">eval</span>()</span><br><span class="line">  inputs = tokenizer(<span class="string">&quot;Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. Label :&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">      outputs = model.generate(input_ids=inputs[<span class="string">&quot;input_ids&quot;</span>].to(<span class="string">&quot;cuda&quot;</span>), max_new_tokens=<span class="number">10</span>)</span><br><span class="line">      <span class="built_in">print</span>(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=<span class="literal">True</span>)[<span class="number">0</span>])</span><br><span class="line">  <span class="string">&#x27;complaint&#x27;</span></span><br></pre></td></tr></table></figure><p>也可以简单地使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModelForCausalLM</span><br><span class="line">peft_model = AutoPeftModelForCausalLM.from_pretrained(<span class="string">&quot;ybelkada/opt-350m-lora&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModel</span><br><span class="line">model = AutoPeftModel.from_pretrained(peft_model_id)</span><br></pre></td></tr></table></figure><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><h4 id="下载所需包"><a href="#下载所需包" class="headerlink" title="下载所需包"></a>下载所需包</h4><p>一般是hugging face的transformers,datasets以及xformers,accelerate,trl,bitsandbytes,peft等库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">!pip install -Uqqq pip --progress-bar off</span><br><span class="line">!pip install -qqq torch==2.0.1 --progress-bar off</span><br><span class="line">!pip install -qqq transformers==4.32.1 --progress-bar off</span><br><span class="line">!pip install -qqq datasets==2.14.4 --progress-bar off</span><br><span class="line">!pip install -qqq peft==0.5.0 --progress-bar off</span><br><span class="line">!pip install -qqq bitsandbytes==0.41.1 --progress-bar off</span><br><span class="line">!pip install -qqq trl==0.7.1 --progress-bar off</span><br></pre></td></tr></table></figure><h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><p>数据处理方式特别多,有很多实现方式.这里主要使用pandas与datasets处理csv数据.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">animes_dataset = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files = <span class="string">&quot;/content/animes.csv&quot;</span>) </span><br><span class="line">reviews_dataset = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files = <span class="string">&quot;/content/reviews.csv&quot;</span>) </span><br><span class="line">animes_df = pd.DataFrame(animes_dataset[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">reviews_df = pd.DataFrame(reviews_dataset[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">merged_df = pd.merge(animes_df,reviews_df,left_on=<span class="string">&quot;uid&quot;</span>,right_on=<span class="string">&quot;anime_uid&quot;</span>)</span><br><span class="line"><span class="comment"># remove /n/r</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span>(<span class="params">x</span>):</span></span><br><span class="line">  <span class="comment">#remove multiple whitespace</span></span><br><span class="line">  new_string = <span class="built_in">str</span>(x).strip()</span><br><span class="line">  pattern = <span class="string">r&quot;\s&#123;3,&#125;&quot;</span></span><br><span class="line">  new_string = re.sub(pattern, <span class="string">&quot; &quot;</span>, new_string)</span><br><span class="line">  <span class="comment">#remove \r \n \t</span></span><br><span class="line">  pattern = <span class="string">r&quot;[\n\r\t]&quot;</span></span><br><span class="line">  new_string  = re.sub(pattern,<span class="string">&quot;&quot;</span>, new_string)</span><br><span class="line">  <span class="keyword">return</span> new_string</span><br><span class="line">merged_df[<span class="string">&quot;synopsis&quot;</span>] = merged_df[<span class="string">&quot;synopsis&quot;</span>].<span class="built_in">map</span>(clean_text)</span><br><span class="line">merged_df[<span class="string">&quot;text&quot;</span>] = merged_df[<span class="string">&quot;text&quot;</span>].<span class="built_in">map</span>(clean_text)</span><br><span class="line"><span class="comment"># split merged_df into train and test</span></span><br><span class="line">train_df, test_df = train_test_split(merged_df, test_size=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">dataset_dict = DatasetDict(&#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: Dataset.from_pandas(train_df),</span><br><span class="line">    <span class="string">&quot;validation&quot;</span>: Dataset.from_pandas(test_df)</span><br><span class="line">&#125;)</span><br><span class="line">DEFAULT_SYSTEM_PROMPT = <span class="string">&quot;Below is a name of an anime,write some intro about it&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">DEFAULT_SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT.strip()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_training_prompt</span>(<span class="params">data_point</span>):</span></span><br><span class="line">  <span class="comment"># 去除字符串中的方括号和空格</span></span><br><span class="line">  genres = data_point[<span class="string">&quot;genre&quot;</span>].strip(<span class="string">&quot;[]&quot;</span>).replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;\&#x27;&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">  synopsis_len = <span class="built_in">len</span>(data_point[<span class="string">&quot;synopsis&quot;</span>])</span><br><span class="line">  split_len = random.randint(<span class="number">1</span>,synopsis_len)</span><br><span class="line">  synopsis_input = data_point[<span class="string">&quot;synopsis&quot;</span>][<span class="number">1</span>:split_len]</span><br><span class="line"></span><br><span class="line">  <span class="built_in">input</span> = data_point[<span class="string">&quot;title&quot;</span>]+genres+synopsis_input</span><br><span class="line">  output = data_point[<span class="string">&quot;synopsis&quot;</span>]+data_point[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">      <span class="string">&quot;text&quot;</span>:<span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;DEFAULT_SYSTEM_PROMPT&#125;</span></span></span><br><span class="line"><span class="string">            ### Input:</span></span><br><span class="line"><span class="string">            <span class="subst">&#123;<span class="built_in">input</span>.strip()&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            ### Response:</span></span><br><span class="line"><span class="string">            <span class="subst">&#123;output.strip()&#125;</span></span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span>.strip()</span><br><span class="line">  &#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_dataset</span>(<span class="params">data: Dataset</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        data.shuffle(seed=<span class="number">42</span>)</span><br><span class="line">        .<span class="built_in">map</span>(generate_training_prompt)</span><br><span class="line">        .remove_columns(</span><br><span class="line">              [</span><br><span class="line">                <span class="string">&quot;uid_x&quot;</span>,</span><br><span class="line">                <span class="string">&quot;aired&quot;</span>,</span><br><span class="line">                <span class="string">&quot;members&quot;</span>,</span><br><span class="line">                <span class="string">&quot;img_url&quot;</span>,</span><br><span class="line">                <span class="string">&quot;uid_y&quot;</span>,</span><br><span class="line">                <span class="string">&quot;profile&quot;</span>,</span><br><span class="line">                <span class="string">&quot;anime_uid&quot;</span>,</span><br><span class="line">                <span class="string">&quot;score_y&quot;</span>,</span><br><span class="line">                <span class="string">&quot;link_y&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">dataset_dict[<span class="string">&quot;train&quot;</span>] = process_dataset(dataset_dict[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">dataset_dict[<span class="string">&quot;validation&quot;</span>] = process_dataset(dataset_dict[<span class="string">&quot;validation&quot;</span>])</span><br></pre></td></tr></table></figure><p>这里处理逻辑其实复杂了,只需要使用pandas读取数据,然后分为训练集和测试集然后转为Dataset即可.中间需要对dataframe的数据去除一些空白字符等.</p><h4 id="训练设置"><a href="#训练设置" class="headerlink" title="训练设置"></a>训练设置</h4><p>由于使用了PEFT</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">lora_r = <span class="number">16</span></span><br><span class="line">lora_alpha = <span class="number">64</span></span><br><span class="line">lora_dropout = <span class="number">0.1</span></span><br><span class="line">lora_target_modules = [</span><br><span class="line">    <span class="string">&quot;q_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;up_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;k_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;down_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;gate_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;v_proj&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">    r=lora_r,</span><br><span class="line">    lora_alpha=lora_alpha,</span><br><span class="line">    lora_dropout=lora_dropout,</span><br><span class="line">    target_modules=lora_target_modules,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>设置trainingArgument,使用trl进行训练.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">OUTPUT_DIR = <span class="string">&quot;experiments&quot;</span></span><br><span class="line">training_arguments = TrainingArguments(</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    gradient_accumulation_steps=<span class="number">4</span>,</span><br><span class="line">    optim=<span class="string">&quot;paged_adamw_32bit&quot;</span>,</span><br><span class="line">    logging_steps=<span class="number">1</span>,</span><br><span class="line">    learning_rate=<span class="number">1e-4</span>,</span><br><span class="line">    fp16=<span class="literal">True</span>,</span><br><span class="line">    max_grad_norm=<span class="number">0.3</span>,</span><br><span class="line">    num_train_epochs=<span class="number">2</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    eval_steps=<span class="number">0.2</span>,</span><br><span class="line">    warmup_ratio=<span class="number">0.05</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    group_by_length=<span class="literal">True</span>,</span><br><span class="line">    output_dir=OUTPUT_DIR,</span><br><span class="line">    report_to=<span class="string">&quot;tensorboard&quot;</span>,</span><br><span class="line">    save_safetensors=<span class="literal">True</span>,</span><br><span class="line">    lr_scheduler_type=<span class="string">&quot;cosine&quot;</span>,</span><br><span class="line">    seed=<span class="number">42</span>,</span><br><span class="line">)</span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model=model,</span><br><span class="line">    train_dataset=dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=dataset[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    peft_config=peft_config,</span><br><span class="line">    dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length=<span class="number">4096</span>,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    args=training_arguments,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="训练与后续评估测试"><a href="#训练与后续评估测试" class="headerlink" title="训练与后续评估测试"></a>训练与后续评估测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModelForCausalLM</span><br><span class="line"><span class="comment"># Load Lora adapter</span></span><br><span class="line"><span class="comment"># model = PeftModel.from_pretrained(</span></span><br><span class="line"><span class="comment">#     base_model,</span></span><br><span class="line"><span class="comment">#     &quot;/content/Finetuned_adapter&quot;,</span></span><br><span class="line"><span class="comment">#     )</span></span><br><span class="line"><span class="comment"># merged_model = model.merge_and_unload()</span></span><br><span class="line">trained_model = AutoPeftModelForCausalLM.from_pretrained(</span><br><span class="line">    OUTPUT_DIR,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">merged_model = base_model.merge_and_unload()</span><br><span class="line">merged_model.save_pretrained(<span class="string">&quot;merged_model&quot;</span>, safe_serialization=<span class="literal">True</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;merged_model&quot;</span>)</span><br><span class="line"><span class="comment"># trainer.push_to_hub(&quot;anime_chatbot&quot;)</span></span><br><span class="line">merged_model.push_to_hub(<span class="string">&quot;anime_chatbot&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Pushed to hub&quot;</span>)</span><br><span class="line"><span class="comment"># @title test fine tune model</span></span><br><span class="line"><span class="comment"># @title test base model</span></span><br><span class="line">DEFAULT_SYSTEM_PROMPT = <span class="string">&quot;Below is a name of an anime,write some intro about it&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">DEFAULT_SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT.strip()</span><br><span class="line">user_prompt = <span class="keyword">lambda</span> <span class="built_in">input</span>:<span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;DEFAULT_SYSTEM_PROMPT&#125;</span></span></span><br><span class="line"><span class="string">            ### Input:</span></span><br><span class="line"><span class="string">            <span class="subst">&#123;<span class="built_in">input</span>.strip()&#125;</span></span></span><br><span class="line"><span class="string">            ### Response:</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span>.strip()</span><br><span class="line">pipe = pipeline(<span class="string">&#x27;text-generation&#x27;</span>,model=merged_model,tokenizer=tokenizer,max_length=<span class="number">150</span>)</span><br><span class="line"></span><br><span class="line">result = pipe(user_prompt(<span class="string">&quot;please introduce shingekinokyojin&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(result[<span class="number">0</span>][<span class="string">&#x27;generated_text&#x27;</span>])</span><br></pre></td></tr></table></figure><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">model_base = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;facebook/opt-350m&quot;</span>, torch_dtype=torch.bfloat16)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;facebook/opt-350m&quot;</span>)</span><br></pre></td></tr></table></figure><p>这里model_base是</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">OPTForCausalLM(</span><br><span class="line">  (model): OPTModel(</span><br><span class="line">    (decoder): OPTDecoder(</span><br><span class="line">      (embed_tokens): Embedding(50272, 512, <span class="attribute">padding_idx</span>=1)</span><br><span class="line">      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)</span><br><span class="line">      (project_out): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (project_in): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (layers): ModuleList(</span><br><span class="line">        (0-23): 24 x OPTDecoderLayer(</span><br><span class="line">          (self_attn): OPTAttention(</span><br><span class="line">            (k_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (v_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (q_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (out_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          (activation_fn): ReLU()</span><br><span class="line">          (self_attn_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc1): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc2): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (final_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (lm_head): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=50272, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> get_peft_model</span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>],</span><br><span class="line">    init_lora_weights=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line">peft_model = get_peft_model(peft_model_base, lora_config)</span><br><span class="line">peft_model.print_trainable_parameters()</span><br></pre></td></tr></table></figure><p>使用lora_config获取到peft_model</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">PeftModel(</span><br><span class="line">  (base_model): LoraModel(</span><br><span class="line">    (model): OPTForCausalLM(</span><br><span class="line">      (model): OPTModel(</span><br><span class="line">        (decoder): OPTDecoder(</span><br><span class="line">          (embed_tokens): Embedding(50272, 512, <span class="attribute">padding_idx</span>=1)</span><br><span class="line">          (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)</span><br><span class="line">          (project_out): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">          (project_in): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">          (layers): ModuleList(</span><br><span class="line">            (0-23): 24 x OPTDecoderLayer(</span><br><span class="line">              (self_attn): OPTAttention(</span><br><span class="line">                (k_proj): Linear(</span><br><span class="line">                  <span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span></span><br><span class="line">                  (lora_dropout): ModuleDict(</span><br><span class="line">                    (default): Identity()</span><br><span class="line">                  )</span><br><span class="line">                  (lora_A): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=8, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_B): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=8, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_embedding_A): ParameterDict()</span><br><span class="line">                  (lora_embedding_B): ParameterDict()</span><br><span class="line">                )</span><br><span class="line">                (v_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">                (q_proj): Linear(</span><br><span class="line">                  <span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span></span><br><span class="line">                  (lora_dropout): ModuleDict(</span><br><span class="line">                    (default): Identity()</span><br><span class="line">                  )</span><br><span class="line">                  (lora_A): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=8, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_B): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=8, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_embedding_A): ParameterDict()</span><br><span class="line">                  (lora_embedding_B): ParameterDict()</span><br><span class="line">                )</span><br><span class="line">                (out_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">              )</span><br><span class="line">              (activation_fn): ReLU()</span><br><span class="line">              (self_attn_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">              (fc1): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">              (fc2): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">              (final_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (lm_head): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=50272, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>使用<code>peft_model.merge_and_unload()</code>得到融合后的model</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">OPTForCausalLM(</span><br><span class="line">  (model): OPTModel(</span><br><span class="line">    (decoder): OPTDecoder(</span><br><span class="line">      (embed_tokens): Embedding(50272, 512, <span class="attribute">padding_idx</span>=1)</span><br><span class="line">      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)</span><br><span class="line">      (project_out): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (project_in): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (layers): ModuleList(</span><br><span class="line">        (0-23): 24 x OPTDecoderLayer(</span><br><span class="line">          (self_attn): OPTAttention(</span><br><span class="line">            (k_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (v_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (q_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (out_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          (activation_fn): ReLU()</span><br><span class="line">          (self_attn_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc1): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc2): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (final_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (lm_head): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=50272, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="遇到的一些问题"><a href="#遇到的一些问题" class="headerlink" title="遇到的一些问题"></a>遇到的一些问题</h4><ol><li>数据集的处理,微调的template该如何写</li></ol><p>找到的例子</p><p><a href="https://colab.research.google.com/github/curiousily/Get-Things-Done-with-Prompt-Engineering-and-LangChain/blob/master/14.fine-tuning-llama-2-7b-on-custom-dataset.ipynb#scrollTo=eRbskn48QNfW">14.fine-tuning-llama-2-7b-on-custom-dataset.ipynb - Colaboratory (google.com)</a></p><p><a href="https://colab.research.google.com/drive/1Ud2vVdjxs18qPCXG334E5rZfvo9b3nUN?usp=sharing#scrollTo=KfPuoMSrDD5-">Fine_tuned_Llama_PEFT_QLora.ipynb - Colaboratory (google.com)</a></p><p>在训练时使用一个template</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DEFAULT_SYSTEM_PROMPT = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Below is a conversation between a human and an AI agent. Write a summary of the conversation.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>.strip()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_training_prompt</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    conversation: <span class="built_in">str</span>, summary: <span class="built_in">str</span>, system_prompt: <span class="built_in">str</span> = DEFAULT_SYSTEM_PROMPT</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;system_prompt&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;conversation.strip()&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;summary&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>.strip()</span><br></pre></td></tr></table></figure><p>测试时</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_prompt</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    conversation: <span class="built_in">str</span>, system_prompt: <span class="built_in">str</span> = DEFAULT_SYSTEM_PROMPT</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;system_prompt&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;conversation.strip()&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>.strip()</span><br></pre></td></tr></table></figure><ol><li><p>训练后得到的model是peftmodel还是什么类型的模型</p><p>一种方法是</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">repo_id = <span class="string">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span></span><br><span class="line">use_ram_optimized_load=<span class="literal">False</span></span><br><span class="line"></span><br><span class="line">base_model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    repo_id,</span><br><span class="line">    device_map=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">    trust_remote_code=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">base_model.config.use_cache = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p><code>base_model</code>是一个<code>LlamaForCausalLM</code>类,训练完后使用</p><p><code>trainer.save_model(&quot;Finetuned_adapter&quot;)</code>保存模型,然后使用<code>PeftModel.from_pretrained</code>得到PeftModel</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = PeftModel.from_pretrained(</span><br><span class="line">    base_model,</span><br><span class="line">    <span class="string">&quot;/content/Finetuned_adapter&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">merged_model = model.merge_and_unload()</span><br></pre></td></tr></table></figure><p>然后保存模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">merged_model.save_pretrained(<span class="string">&quot;/content/Merged_model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;/content/Merged_model&quot;</span>)</span><br></pre></td></tr></table></figure><p>另一种是使用<code>AutoPeftModelForCausalLM</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModelForCausalLM</span><br><span class="line"></span><br><span class="line">trained_model = AutoPeftModelForCausalLM.from_pretrained(</span><br><span class="line">    OUTPUT_DIR,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">merged_model = model.merge_and_unload()</span><br><span class="line">merged_model.save_pretrained(<span class="string">&quot;merged_model&quot;</span>, safe_serialization=<span class="literal">True</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;merged_model&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://medium.com/walmartglobaltech/training-large-language-model-llm-on-your-data-2139eaad5f4f">Training Large Language Model (LLM) on your data | by Mohit Soni | Walmart Global Tech Blog | Aug, 2023 | Medium</a></li><li><a href="https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148">A Practical Introduction to LLMs | By: Shawhin Talebi | Towards Data Science</a></li><li><a href="https://www.lakera.ai/insights/llm-fine-tuning-guide">The Ultimate Guide to LLM Fine Tuning: Best Practices &amp; Tools | Lakera – Protecting AI teams that disrupt the world.</a></li><li>tutorial <a href="https://learn.deeplearning.ai/finetuning-large-language-models">https://learn.deeplearning.ai/finetuning-large-language-models</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;这段时间非常火的topic,大模型参数多,占用体积大训练困难,而且一般需要微调技术用于特定任务.&lt;br&gt;</summary>
    
    
    
    
    <category term="llm" scheme="https://www.sekyoro.top/tags/llm/"/>
    
    <category term="finetune" scheme="https://www.sekyoro.top/tags/finetune/"/>
    
  </entry>
  
  <entry>
    <title>风格迁移</title>
    <link href="https://www.sekyoro.top/2023/09/26/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"/>
    <id>https://www.sekyoro.top/2023/09/26/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/</id>
    <published>2023-09-26T03:00:48.000Z</published>
    <updated>2023-10-06T09:33:42.610Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>将一个图像中的风格应用在另一图像之上，即<em>风格迁移</em>（style transfer）这里我们需要两张输入图像：一张是<em>内容图像</em>，另一张是<em>风格图像</em>。 我们将使用神经网络修改内容图像，使其在风格上接近风格图像。 </p><span id="more"></span><h2 id="使用预训练模型进行迁移"><a href="#使用预训练模型进行迁移" class="headerlink" title="使用预训练模型进行迁移"></a>使用预训练模型进行迁移</h2><p><img data-src="https://zh.d2l.ai/_images/neural-style.svg" alt="风格迁移"></p><p>首先，我们初始化合成图像，例如将其初始化为内容图像。 </p><p>该合成图像是风格迁移过程中唯一需要更新的变量，即风格迁移所需迭代的模型参数。 然后，我们选择一个预训练的卷积神经网络来抽取图像的特征，其中的模型参数在训练中无须更新。 这个深度卷积神经网络凭借多个层逐级抽取图像的特征，我们可以选择其中某些层的输出作为内容特征或风格特征。 </p><p>接下来，我们通过前向传播（实线箭头方向）计算风格迁移的损失函数，并通过反向传播（虚线箭头方向）迭代模型参数，即不断更新合成图像。 风格迁移常用的损失函数由3部分组成：</p><ol><li><em>内容损失</em>使合成图像与内容图像在内容特征上接近；</li><li><em>风格损失</em>使合成图像与风格图像在风格特征上接近；</li><li><em>全变分损失</em>则有助于减少合成图像中的噪点。</li></ol><p>最后，当模型训练结束时，我们输出风格迁移的模型参数，即得到最终的合成图像。</p><p>使用一个预训练模型,比如VGG提取内容与特征.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pretrained_net = torchvision.models.vgg19(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>为了抽取图像的内容特征和风格特征，我们可以选择VGG网络中某些层的输出。</p><p> 一般来说，<strong>越靠近输入层，越容易抽取图像的细节信息；反之，则越容易抽取图像的全局信息。</strong> <strong>为了避免合成图像过多保留内容图像的细节，我们选择VGG较靠近输出的层，即<em>内容层</em>，来输出图像的内容特征</strong>。</p><p> 我们从VGG中选择不同层的输出来匹配局部和全局的风格，这些图层也称为<em>风格层</em>。 VGG网络使用了5个卷积块。可以选择第四卷积块的最后一个卷积层作为内容层，选择每个卷积块的第一个卷积层作为风格层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">style_layers, content_layers = [<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">19</span>, <span class="number">28</span>], [<span class="number">25</span>]</span><br><span class="line">net = nn.Sequential(*[pretrained_net.features[i] <span class="keyword">for</span> i <span class="keyword">in</span></span><br><span class="line">                      <span class="built_in">range</span>(<span class="built_in">max</span>(content_layers + style_layers) + <span class="number">1</span>)])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span>(<span class="params">X, content_layers, style_layers</span>):</span></span><br><span class="line">    contents = []</span><br><span class="line">    styles = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(net)):</span><br><span class="line">        X = net[i](X)</span><br><span class="line">        <span class="comment"># forward pass 如果是选定的风格层或者是内容层 添加到列表中</span></span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> style_layers:</span><br><span class="line">            styles.append(X)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> content_layers:</span><br><span class="line">            contents.append(X)</span><br><span class="line">    <span class="keyword">return</span> contents, styles</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_contents</span>(<span class="params">image_shape, device</span>):</span></span><br><span class="line">    content_X = preprocess(content_img, image_shape).to(device)</span><br><span class="line">    contents_Y, _ = extract_features(content_X, content_layers, style_layers)</span><br><span class="line">    <span class="keyword">return</span> content_X, contents_Y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_styles</span>(<span class="params">image_shape, device</span>):</span></span><br><span class="line">    style_X = preprocess(style_img, image_shape).to(device) <span class="comment"># 得到tensor数据 放入网络中 将输出这张图像的内容和风格</span></span><br><span class="line">    _, styles_Y = extract_features(style_X, content_layers, style_layers)</span><br><span class="line">    <span class="keyword">return</span> style_X, styles_Y</span><br></pre></td></tr></table></figure><p><code>get_contents</code>函数对内容图像抽取内容特征； <code>get_styles</code>函数对风格图像抽取风格特征。 因为在训练时无须改变预训练的VGG的模型参数，所以我们可以在训练开始之前就提取出内容特征和风格特征。 </p><p>由于合成图像是风格迁移所需迭代的模型参数，我们只能在训练过程中通过调用<code>extract_features</code>函数来抽取合成图像的内容特征和风格特征.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">rgb_mean = torch.tensor([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">rgb_std = torch.tensor([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">img, image_shape</span>):</span></span><br><span class="line">    transforms = torchvision.transforms.Compose([</span><br><span class="line">        torchvision.transforms.Resize(image_shape),</span><br><span class="line">        torchvision.transforms.ToTensor(),</span><br><span class="line">        torchvision.transforms.Normalize(mean=rgb_mean, std=rgb_std)])</span><br><span class="line">    <span class="keyword">return</span> transforms(img).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postprocess</span>(<span class="params">img</span>):</span></span><br><span class="line">    img = img[<span class="number">0</span>].to(rgb_std.device)</span><br><span class="line">    img = torch.clamp(img.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>) * rgb_std + rgb_mean, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> torchvision.transforms.ToPILImage()(img.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>preprocess与postprocess分别将PIL数据转为tensor,tensor转为PIL数据.</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><strong>内容损失</strong></p><p>容损失通过平方误差函数衡量合成图像与内容图像在内容特征上的差异。 平方误差函数的两个输入均为<code>extract_features</code>函数计算所得到的内容层的输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">content_loss</span>(<span class="params">Y_hat, Y</span>):</span></span><br><span class="line">    <span class="comment"># 我们从动态计算梯度的树中分离目标：</span></span><br><span class="line">    <span class="comment"># 这是一个规定的值，而不是一个变量。</span></span><br><span class="line">    <span class="keyword">return</span> torch.square(Y_hat - Y.detach()).mean()</span><br></pre></td></tr></table></figure><p><strong>风格损失</strong></p><p>风格损失与内容损失类似，也通过平方误差函数衡量合成图像与风格图像在风格上的差异。 为了表达风格层输出的风格，我们先通过<code>extract_features</code>函数计算风格层的输出。 假设该输出的样本数为1，通道数为c，高和宽分别为h和w，我们可以将此输出转换为矩阵X，其有c行和hw列。 这个矩阵可以被看作由c个长度为hw的向量x1,…,xc组合而成的。其中向量xi代表了通道i上的风格特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram</span>(<span class="params">X</span>):</span></span><br><span class="line">    num_channels, n = X.shape[<span class="number">1</span>], X.numel() // X.shape[<span class="number">1</span>]</span><br><span class="line">    X = X.reshape((num_channels, n))</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X, X.T) / (num_channels * n)</span><br></pre></td></tr></table></figure><p>风格损失的平方误差函数的两个格拉姆矩阵输入分别基于合成图像与风格图像的风格层输出。这里假设基于风格图像的格拉姆矩阵<code>gram_Y</code>已经预先计算好了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span>(<span class="params">Y_hat, gram_Y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.square(gram(Y_hat) - gram_Y.detach()).mean()</span><br></pre></td></tr></table></figure><p><strong>全变分损失</strong></p><p>有时候，我们学到的合成图像里面有大量高频噪点，即有特别亮或者特别暗的颗粒像素。 一种常见的去噪方法是<em>全变分去噪</em>（total variation denoising）： 假设xi,j表示坐标(i,j)处的像素值，降低全变分损失<code>∑i,j|xi,j−xi+1,j|+|xi,j−xi,j+1|</code></p><p>能够尽可能使邻近的像素值相似。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tv_loss</span>(<span class="params">Y_hat</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span> * (torch.<span class="built_in">abs</span>(Y_hat[:, :, <span class="number">1</span>:, :] - Y_hat[:, :, :-<span class="number">1</span>, :]).mean() +torch.<span class="built_in">abs</span>(Y_hat[:, :, :, <span class="number">1</span>:] - Y_hat[:, :, :, :-<span class="number">1</span>]).mean())</span><br></pre></td></tr></table></figure><p><strong>损失函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">content_weight, style_weight, tv_weight = <span class="number">1</span>, <span class="number">1e3</span>, <span class="number">10</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span>(<span class="params">X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram</span>):</span></span><br><span class="line">    <span class="comment"># 分别计算内容损失、风格损失和全变分损失</span></span><br><span class="line">    contents_l = [content_loss(Y_hat, Y) * content_weight <span class="keyword">for</span> Y_hat, Y <span class="keyword">in</span> <span class="built_in">zip</span>(contents_Y_hat, contents_Y)]</span><br><span class="line">    styles_l = [style_loss(Y_hat, Y) * style_weight <span class="keyword">for</span> Y_hat, Y <span class="keyword">in</span> <span class="built_in">zip</span>(styles_Y_hat, styles_Y_gram)]</span><br><span class="line">    tv_l = tv_loss(X) * tv_weight</span><br><span class="line">    <span class="comment"># 对所有损失求和</span></span><br><span class="line">    l = <span class="built_in">sum</span>(<span class="number">10</span> * styles_l + contents_l + [tv_l])</span><br><span class="line">    <span class="keyword">return</span> contents_l, styles_l, tv_l, l</span><br></pre></td></tr></table></figure><p>contents_l表示内容损失,</p><h3 id="初始化合成图像"><a href="#初始化合成图像" class="headerlink" title="初始化合成图像"></a>初始化合成图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_inits</span>(<span class="params">X, device, lr, styles_Y</span>):</span></span><br><span class="line">    gen_img = SynthesizedImage(X.shape).to(device)</span><br><span class="line">    gen_img.weight.data.copy_(X.data)</span><br><span class="line">    trainer = torch.optim.Adam(gen_img.parameters(), lr=lr)</span><br><span class="line">    styles_Y_gram = [gram(Y) <span class="keyword">for</span> Y <span class="keyword">in</span> styles_Y]</span><br><span class="line">    <span class="keyword">return</span> gen_img(), styles_Y_gram, trainer <span class="comment"># 返回与内容图像一样的数据与计算的风格gram特征</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SynthesizedImage</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img_shape, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SynthesizedImage, self).__init__(**kwargs)</span><br><span class="line">        self.weight = nn.Parameter(torch.rand(*img_shape))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.weight</span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch</span>):</span></span><br><span class="line">    X, styles_Y_gram, trainer = get_inits(X, device, lr, styles_Y) <span class="comment">#生成原本图片 作为变量 并计算风格特征</span></span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_decay_epoch, <span class="number">0.8</span>)</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, ylabel=<span class="string">&#x27;loss&#x27;</span>,</span><br><span class="line">                            xlim=[<span class="number">10</span>, num_epochs],</span><br><span class="line">                            legend=[<span class="string">&#x27;content&#x27;</span>, <span class="string">&#x27;style&#x27;</span>, <span class="string">&#x27;TV&#x27;</span>],</span><br><span class="line">                            ncols=<span class="number">2</span>, figsize=(<span class="number">7</span>, <span class="number">2.5</span>))</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        contents_Y_hat, styles_Y_hat = extract_features(</span><br><span class="line">            X, content_layers, style_layers) <span class="comment"># 获取内容和风格</span></span><br><span class="line">        contents_l, styles_l, tv_l, l = compute_loss(</span><br><span class="line">            X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram)</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()</span><br><span class="line">        scheduler.step()</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            animator.axes[<span class="number">1</span>].imshow(postprocess(X))</span><br><span class="line">            animator.add(epoch + <span class="number">1</span>, [<span class="built_in">float</span>(<span class="built_in">sum</span>(contents_l)),</span><br><span class="line">                                     <span class="built_in">float</span>(<span class="built_in">sum</span>(styles_l)), <span class="built_in">float</span>(tv_l)])</span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device, image_shape = d2l.try_gpu(), (<span class="number">300</span>, <span class="number">450</span>)</span><br><span class="line">net = net.to(device)</span><br><span class="line">content_X, contents_Y = get_contents(image_shape, device)</span><br><span class="line">_, styles_Y = get_styles(image_shape, device) <span class="comment"># 获取content_image和内容特征 内容特征就是传到预训练模型得到的相应层输出  以及style_image的样式特征</span></span><br><span class="line">output = train(content_X, contents_Y, styles_Y, device, <span class="number">0.3</span>, <span class="number">500</span>, <span class="number">50</span>) <span class="comment"># 训练传入X和其内容与样式特征</span></span><br></pre></td></tr></table></figure><p>合成图像保留了内容图像的风景和物体，并同时迁移了风格图像的色彩。例如，合成图像具有与风格图像中一样的色彩块，其中一些甚至具有画笔笔触的细微纹理</p><h3 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h3><p><img data-src="https://s2.loli.net/2023/10/06/W4Ey98RPmMslXwJ.png" alt="image-20231006173228071"></p><p><img data-src="https://s2.loli.net/2023/10/06/S5DUiCZE8K9cwnA.png" alt="image-20231006173234821"></p><p><img data-src="https://s2.loli.net/2023/10/06/9UaWgiykmJt5Lfz.png" alt="image-20231006173243962"></p><p>可以尝试改动style_weight,看看风格变换.比如style_weight增大,发现style loss太小了,而且会影响content loss</p><p><img data-src="https://s2.loli.net/2023/10/06/H2QAYtzVKRXMNmw.png" alt="image-20231006173251615"></p><ul><li>风格迁移常用的损失函数由3部分组成：（1）<strong>内容损失使合成图像与内容图像在内容特征上接近</strong>；（2）<strong>风格损失令合成图像与风格图像在风格特征上接近</strong>；（3）<strong>全变分损失则有助于减少合成图像中的噪点</strong>。</li><li>我们<strong>可以通过预训练的卷积神经网络来抽取图像的特征</strong>，并通过最小化损失函数来不断更新合成图像来作为模型参数。</li><li>我们使用<strong>gram矩阵表达风格层输出的风格</strong></li></ul><h2 id="使用GAN进行风格迁移"><a href="#使用GAN进行风格迁移" class="headerlink" title="使用GAN进行风格迁移"></a>使用GAN进行风格迁移</h2><p>GANs是生成艺术图像的好方法。另一种有趣的技术是所谓的风格转换，它获取一个内容图像，然后用不同的风格重新绘制，从风格图像中应用过滤器。</p><p>工作方式如下:</p><p>我们从随机噪声图像开始（或从内容图像开始，但为了理解起见，从随机噪声开始更容易）</p><p>我们的目标是创建这样一个图像，<strong>它将接近内容图像和风格图像</strong>。这将由两个损失函数确定：基于CNN在<strong>当前图像和内容图像的某些层提取的特征来计算内容损失</strong>,<strong>使用Gram矩阵巧妙地计算当前图像和风格图像之间的风格损失</strong></p><p>为了使图像更平滑并去除噪声，我们还引入了全变分损失，它计算相邻像素之间的平均距离</p><p>优化方式使用梯度下降（或一些其他优化算法）调整当前图像，以最小化总损失，总损失是所有三个损失的加权和。</p><p>在代码上与之前的差别是使用高斯分布采样得到的噪音作为需要优化的参数,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">img_style = load_image(<span class="string">&#x27;images/style.jpg&#x27;</span>)</span><br><span class="line">img_content = load_image(<span class="string">&#x27;images/image.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">img_result = np.random.uniform(size=(img_size,img_size,<span class="number">3</span>))</span><br><span class="line">vgg = tf.keras.applications.VGG16(include_top=<span class="literal">False</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">vgg.trainable = <span class="literal">False</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_extractor</span>(<span class="params">layers</span>):</span></span><br><span class="line">    outputs = [vgg.get_layer(x).output <span class="keyword">for</span> x <span class="keyword">in</span> layers]</span><br><span class="line">    model = tf.keras.Model([vgg.<span class="built_in">input</span>],outputs)</span><br><span class="line">    <span class="keyword">return</span> model </span><br><span class="line">content_layers = [<span class="string">&#x27;block4_conv2&#x27;</span>] </span><br><span class="line">content_extractor = layer_extractor(content_layers)</span><br><span class="line"></span><br><span class="line">content_target = content_extractor(preprocess_input(tf.expand_dims(img_content,axis=<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">content_loss</span>(<span class="params">img</span>):</span></span><br><span class="line">    z = content_extractor(preprocess_input(tf.expand_dims(<span class="number">255</span>*img,axis=<span class="number">0</span>))) </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span>*tf.reduce_sum((z-content_target)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">x</span>):</span></span><br><span class="line">  result = tf.linalg.einsum(<span class="string">&#x27;bijc,bijd-&gt;bcd&#x27;</span>, x, x)</span><br><span class="line">  input_shape = tf.shape(x)</span><br><span class="line">  num_locations = tf.cast(input_shape[<span class="number">1</span>]*input_shape[<span class="number">2</span>], tf.float32)</span><br><span class="line">  <span class="keyword">return</span> result/(num_locations)</span><br><span class="line"></span><br><span class="line">style_layers = [<span class="string">&#x27;block1_conv1&#x27;</span>,<span class="string">&#x27;block2_conv1&#x27;</span>,<span class="string">&#x27;block3_conv1&#x27;</span>,<span class="string">&#x27;block4_conv1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_extractor</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [gram_matrix(x) <span class="keyword">for</span> x <span class="keyword">in</span> layer_extractor(style_layers)(img)]</span><br><span class="line"></span><br><span class="line">style_target = style_extractor(preprocess_input(tf.expand_dims(img_style,axis=<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span>(<span class="params">img</span>):</span></span><br><span class="line">    z = style_extractor(preprocess_input(tf.expand_dims(<span class="number">255</span>*img,axis=<span class="number">0</span>)))</span><br><span class="line">    loss = tf.add_n([tf.reduce_mean((x-target)**<span class="number">2</span>) </span><br><span class="line">                           <span class="keyword">for</span> x,target <span class="keyword">in</span> <span class="built_in">zip</span>(z,style_target)])</span><br><span class="line">    <span class="keyword">return</span> loss / <span class="built_in">len</span>(style_layers)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variation_loss</span>(<span class="params">img</span>):</span></span><br><span class="line">  img = tf.cast(img,tf.float32)</span><br><span class="line">  x_var = img[ :, <span class="number">1</span>:, :] - img[ :, :-<span class="number">1</span>, :]</span><br><span class="line">  y_var = img[ <span class="number">1</span>:, :, :] - img[ :-<span class="number">1</span>, :, :]</span><br><span class="line">  <span class="keyword">return</span> tf.reduce_sum(tf.<span class="built_in">abs</span>(x_var)) + tf.reduce_sum(tf.<span class="built_in">abs</span>(y_var))</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_loss_var</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="keyword">return</span> content_loss(img)+<span class="number">150</span>*style_loss(img)+<span class="number">30</span>*variation_loss(img)</span><br><span class="line"></span><br><span class="line">img.assign(clip(np.random.normal(-<span class="number">0.3</span>,<span class="number">0.3</span>,size=img_content.shape)+img_content/<span class="number">255.0</span>))</span><br><span class="line"></span><br><span class="line">train(img,loss_fn=total_loss_var)</span><br></pre></td></tr></table></figure><p>注意,提取风格的层数一般选择每个特征块的前面几层,而提取内容的层数一般选择特征块的后面几块.</p><p>风格迁移与迁移学习存在不可区分的关系,因为我们将一些知识从一个神经网络模型转移到另一个。在迁移学习中，我们通常从预先训练的模型开始，该模型已经在一些大型图像数据集（如ImageNet）上进行了训练。</p><p>预训练模型比如:</p><ul><li>VGG-16/VGG-19，它们是相对简单的模型，仍然提供良好的精度。经常将VGG作为第一次尝试是了解迁移学习如何运作的好选择。</li><li>ResNet是微软研究院于2015年提出的一系列模型。它们有更多的层，因此占用更多的资源。</li><li>MobileNet是一系列尺寸较小的型号，适用于移动设备。如果你缺乏资源，并且可能会牺牲一点准确性，那么就使用它们。</li></ul><p>使用pytorch加载预训练模型.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vgg = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">vgg</span><br></pre></td></tr></table></figure><p>结构如下,可以看见有<code>features</code>,<code>avgpool</code>以及<code>classifier</code></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (4): MaxPool2d(<span class="attribute">kernel_size</span>=2, <span class="attribute">stride</span>=2, <span class="attribute">padding</span>=0, <span class="attribute">dilation</span>=1, <span class="attribute">ceil_mode</span>=<span class="literal">False</span>)</span><br><span class="line">    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (6): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (8): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (9): MaxPool2d(<span class="attribute">kernel_size</span>=2, <span class="attribute">stride</span>=2, <span class="attribute">padding</span>=0, <span class="attribute">dilation</span>=1, <span class="attribute">ceil_mode</span>=<span class="literal">False</span>)</span><br><span class="line">    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (11): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (13): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (15): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (16): MaxPool2d(<span class="attribute">kernel_size</span>=2, <span class="attribute">stride</span>=2, <span class="attribute">padding</span>=0, <span class="attribute">dilation</span>=1, <span class="attribute">ceil_mode</span>=<span class="literal">False</span>)</span><br><span class="line">    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (18): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (20): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (22): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (23): MaxPool2d(<span class="attribute">kernel_size</span>=2, <span class="attribute">stride</span>=2, <span class="attribute">padding</span>=0, <span class="attribute">dilation</span>=1, <span class="attribute">ceil_mode</span>=<span class="literal">False</span>)</span><br><span class="line">    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (25): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (27): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (29): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (30): MaxPool2d(<span class="attribute">kernel_size</span>=2, <span class="attribute">stride</span>=2, <span class="attribute">padding</span>=0, <span class="attribute">dilation</span>=1, <span class="attribute">ceil_mode</span>=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Linear(<span class="attribute">in_features</span>=25088, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">    (1): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (2): Dropout(<span class="attribute">p</span>=0.5, <span class="attribute">inplace</span>=<span class="literal">False</span>)</span><br><span class="line">    (3): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">    (4): ReLU(<span class="attribute">inplace</span>=<span class="literal">True</span>)</span><br><span class="line">    (5): Dropout(<span class="attribute">p</span>=0.5, <span class="attribute">inplace</span>=<span class="literal">False</span>)</span><br><span class="line">    (6): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1000, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><strong>查看每一层后的结果</strong></p><p>利用<code>torchinfo</code>库查看</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">summary(vgg,input_size=(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>))</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2023/10/06/Pg1q59j4WnuSCIo.png" alt="image-20231006173311040"></p><p>可以看到输入一张3通道224的图像特征层输出是512通道的宽高为7的特征</p><p><strong>提取图像特征</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res = vgg.features(sample_image).cpu()</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">plt.imshow(res.detach().view(<span class="number">512</span>,-<span class="number">1</span>).T)</span><br><span class="line"><span class="built_in">print</span>(res.size())</span><br></pre></td></tr></table></figure><p>利用feature层提取特征,然后利用预训练模型提取的特征,直接拿一个简单的Linear层作为分类器进行训练,比如:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vgg_dataset = torch.utils.data.TensorDataset(feature_tensor,label_tensor.to(torch.long))</span><br><span class="line">train_ds, test_ds = torch.utils.data.random_split(vgg_dataset,[<span class="number">700</span>,<span class="number">100</span>])</span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_ds,batch_size=<span class="number">32</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_ds,batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">net = torch.nn.Sequential(torch.nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>,<span class="number">2</span>),torch.nn.LogSoftmax()).to(device)</span><br><span class="line"></span><br><span class="line">history = train(net,train_loader,test_loader)</span><br></pre></td></tr></table></figure><p>net就是简单的线性层加一个激活函数</p><p><strong>常用的加载数据流程</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">std_normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                          std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">trans = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(), </span><br><span class="line">        std_normalize])</span><br><span class="line">dataset = torchvision.datasets.ImageFolder(<span class="string">&#x27;data/PetImages&#x27;</span>,transform=trans)</span><br><span class="line">trainset, testset = torch.utils.data.random_split(dataset,[<span class="number">20000</span>,<span class="built_in">len</span>(dataset)-<span class="number">20000</span>])</span><br></pre></td></tr></table></figure><p>如果图像在一个文件夹中,利用<code>ImageFolder</code>得到dataset.然后使用<code>dl = torch.utils.data.DataLoader(dataset,batch_size=bs,shuffle=True)</code>用于循环每个batch处理.</p><p>可以在训练过程中使用原始VGG-16网络作为一个整体来避免手动预计算特征.如下</p><ul><li><strong>将最终分类器替换为将产生所需数量的类的分类</strong>器。</li><li><strong>冻结卷积特征提取器的权重，使得它们不被训练</strong>。建议最初进行这种冻结，因为否则未经训练的分类器层可能会破坏卷积提取器的原始预训练权重。冻结权重可以通过将所有参数的requires_grad属性设置为False来实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> vgg.features.parameters():</span><br><span class="line">    x.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>如果您的对象在视觉上与普通的ImageNet图像不同，则这种功能组合可能无法发挥最佳效果。因此，开始训练卷积层也是有意义的。 为此，我们可以解冻之前冻结的卷积滤波器参数。不过一般都会采用一些微调方法,比如LoRA等.</p><h3 id="其他方向"><a href="#其他方向" class="headerlink" title="其他方向"></a>其他方向</h3><p>domain knowledge,domain adaption或者是transfer learning,本质上都是像提取一些特征,这种特征能在多个domain上使用.我们可以考虑利用这种特征进行可视化或者对抗攻击等.</p><p>比如利用预训练模型作为分类器,尝试从下从正态分布采样得到噪声图,然后作为输入,优化这个输入使其被分类为想要的分类.这样的图像虽然被正确分类了但人眼还是能明显看出差别.</p><p><img data-src="https://s2.loli.net/2023/10/06/X1qoLVJPAZbYIHr.png" alt="image-20231006173320659"></p><blockquote><p>这种噪音对我们来说没有多大意义，但很可能它包含了很多需要的类别(比如猫)特有的低级别过滤器。然而，由于有很多方法可以优化输入以获得理想的结果，因此优化算法没有动机找到视觉上可理解的模式.</p><p>为了让它看起来不那么像噪音，我们可以在损失函数中引入一个附加项——变化损失。它测量图像的相邻像素的相似程度。如果我们将这个项添加到损失函数中，它将迫使优化器找到噪声较小的解决方案，从而具有更多可识别的细节</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_loss</span>(<span class="params">target,res</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span>*tf.reduce_mean(keras.metrics.sparse_categorical_crossentropy(target,res)) + \</span><br><span class="line">           <span class="number">0.005</span>*tf.image.total_variation(x,res)</span><br><span class="line"></span><br><span class="line">optimize(x,target,loss_fn=total_loss)</span><br></pre></td></tr></table></figure><p>也就是分类的损失加上全变分损失.全变分损失目的是减小噪声,得到图像图下</p><p><img data-src="https://s2.loli.net/2023/10/06/ivem7EW1CjXrZN8.png" alt="image-20231006173331956"></p><p>对抗攻击就利用一张本身是狗分类也确实是狗的图片,对这张图片进行优化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.Variable(np.expand_dims(img,axis=<span class="number">0</span>).astype(np.float32)/<span class="number">255.0</span>)</span><br><span class="line">optimize(x,target,epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2023/10/06/HvpYWiA2uUdz9xe.png" alt="image-20231006173338372"></p><p>在pytorch中使用<code>autograd</code>计算梯度.<a href="https://www.w3cschool.cn/article/4182917.html">pytorch 中autograd.grad()函数的用法说明 | w3cschool笔记</a></p><p>最后推荐一下微软的Ai for beginners的课程,质量比较高,此外还有李沐的d2l,台湾李宏毅老师的深度学习课程以及fast.ai课程,都是比较好的.</p><blockquote><p>我们能够在预先训练的CNN中可视化猫（以及任何其他物体）的理想图像，<strong>使用梯度下降优化来调整输入图像而不是权重</strong>。获得有意义的图像的主要技巧是使用<strong>变化损失作为额外的损失函数</strong>，这会<strong>使图像看起来更平滑</strong>。</p></blockquote><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://zh.d2l.ai/chapter_computer-vision/neural-style.html">13.12. 风格迁移 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></li><li><a href="https://github.com/microsoft/AI-For-Beginners/tree/main/lessons/4-ComputerVision/10-GANs">AI-For-Beginners/lessons/4-ComputerVision/10-GANs at main · microsoft/AI-For-Beginners (github.com)</a></li><li><a href="https://arxiv.org/abs/1508.06576">[1508.06576] A Neural Algorithm of Artistic Style (arxiv.org)</a></li><li><a href="https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/4-ComputerVision/08-TransferLearning/README.md">AI-For-Beginners/lessons/4-ComputerVision/08-TransferLearning/README.md at main · microsoft/AI-For-Beginners (github.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;将一个图像中的风格应用在另一图像之上，即&lt;em&gt;风格迁移&lt;/em&gt;（style transfer）这里我们需要两张输入图像：一张是&lt;em&gt;内容图像&lt;/em&gt;，另一张是&lt;em&gt;风格图像&lt;/em&gt;。 我们将使用神经网络修改内容图像，使其在风格上接近风格图像。 &lt;/p&gt;</summary>
    
    
    
    
    <category term="-style transfer" scheme="https://www.sekyoro.top/tags/style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读_自动驾驶(一)</title>
    <link href="https://www.sekyoro.top/2023/09/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
    <id>https://www.sekyoro.top/2023/09/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/</id>
    <published>2023-09-25T07:39:52.000Z</published>
    <updated>2023-10-09T11:05:37.786Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>cvpr 2023 best paper <strong>Planning-oriented Autonomous Driving</strong><a href="https://arxiv.org/abs/2212.10156">[2212.10156] Planning-oriented Autonomous Driving (arxiv.org)</a></p><span id="more"></span><h2 id="Planning-oriented-Autonomous-Driving"><a href="#Planning-oriented-Autonomous-Driving" class="headerlink" title="Planning-oriented Autonomous Driving"></a>Planning-oriented Autonomous Driving</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>为了执行广泛多样的任务，现代性方法要么为单个任务部署独立模型，要么设计具有独立头部的多任务范式。然而，他们可能会出现累积错误或任务协调不足</p><h4 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h4><p>将全栈驾驶任务集成在一个网络中。它经过精心设计，可以利用每个模块的优势，并从全局角度为代理交互提供互补的功能抽象。任务通过统一的查询接口进行通信，以便于彼此进行规划。我们在具有挑战性的nuScenes基准上实例化UniAD。通过广泛的消融，使用这种哲学的有效性被证明在所有方面都大大优于以前的技术状态。代码和模型是公开的。</p><p>（a） 我们遵循以规划为导向的哲学，对自动驾驶框架进行了新的展望，并证明了有效的任务协调的必要性，而不是独立设计或简单的多任务学习。</p><p>（b）介绍了UniAD，一个全面的端到端系统，可利用广泛的任务。启动的关键组件是将查询设计为连接所有节点的接口。因此，UniAD享有灵活的中间表示和交换多任务知识规划。</p><p>（c） 我们在现实场景的具有挑战性的基准上实例化UniAD。通过大面积消融，我们验证了我们的方法在各个方面都优于以前的技术</p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p><strong>背景介绍</strong></p><p>现代自动驾驶系统的特点是<strong>按顺序执行模块化任务，即感知、预测和规划</strong>.</p><p>为了执行多种多样的任务并实现高级智能，<strong>当代的方法要么是为单个任务部署独立的模型</strong>，要么<strong>是设计一个具有独立头部的多任务范例</strong>。</p><p>但是，他们可能会出现<strong>累积性错误</strong>或<strong>任务协调能力不足</strong>的问题。</p><p><strong>本文工作</strong></p><p>我们将重新审视感知和预测的关键组成部分，并对任务进行优先排序，使所有这些任务都有助于规划。</p><p>我们提出了统一自动驾驶（UniAD）,这是一个将全栈驾驶任务整合到一个网络中的最新综合框架。它设计精巧，充分利用了每个模块的优势，并从全局角度为代理交互提供了互补的功能抽象。任务之间通过统一的查询界面进行交流，以促进彼此的规划工作</p><p><strong>模型有效性(SOTA)</strong></p><p> 我们在具有挑战性的 nuScenes 基准上对 UniAD 进行了实例化。通过广泛的消融，我们证明了使用这种理念的有效性，在所有方面都大大优于以往的先进水平。</p><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><img data-src="https://s2.loli.net/2023/10/06/CRJKVSWItryGxLd.png" alt="image-20231006172334738"></p><p>大多数行业解决方案为每项任务独立部署独立模型,只要板载芯片的资源带宽允许.这样的设计虽然<strong>简化了各团队的研发难度</strong>，但由于优化目标的孤立性，它也承担着<strong>跨模块信息丢失、错误积累和功能错位</strong>的风险。</p><p><img data-src="https://s2.loli.net/2023/10/06/EpzuXA8cUZY9IbH.png" alt="image-20231006172340449"></p><p>一种更优雅的设计是将多种任务纳入多任务学习multi-task learning（MTL）范式，方法是将多个任务特定的头(head)插入一个共享的特征提取器中.</p><blockquote><p>相当于保留网络的底部,更换网络的head用于特定任务</p></blockquote><p>MTL在general vision,自动驾驶以及工业产品中使用很多.在MTL中，跨任务的共同训练策略可以<strong>利用特征抽象</strong>,它可以毫不费力地<strong>扩展到其他任务</strong>，并节省板载芯片的计算成本。这样的方案可能会导致不希望的<strong>“负转移”</strong>（迁移学习,微调模型）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">finetune_net = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">finetune_net.fc = nn.Linear(finetune_net.fc.in_features, <span class="number">2</span>) <span class="comment">#更换输出层</span></span><br><span class="line">nn.init.xavier_uniform_(finetune_net.fc.weight); <span class="comment"># 初始化权重</span></span><br><span class="line"><span class="comment"># 如果param_group=True，输出层中的模型参数将使用十倍的学习率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fine_tuning</span>(<span class="params">net, learning_rate, batch_size=<span class="number">128</span>, num_epochs=<span class="number">5</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                      param_group=<span class="literal">True</span></span>):</span></span><br><span class="line">    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(</span><br><span class="line">        os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>), transform=train_augs),</span><br><span class="line">        batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(</span><br><span class="line">        os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>), transform=test_augs),</span><br><span class="line">        batch_size=batch_size)</span><br><span class="line">    devices = d2l.try_all_gpus()</span><br><span class="line">    loss = nn.CrossEntropyLoss(reduction=<span class="string">&quot;none&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> param_group:</span><br><span class="line">        params_1x = [param <span class="keyword">for</span> name, param <span class="keyword">in</span> net.named_parameters()</span><br><span class="line">             <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;fc.weight&quot;</span>, <span class="string">&quot;fc.bias&quot;</span>]]</span><br><span class="line">        trainer = torch.optim.SGD([&#123;<span class="string">&#x27;params&#x27;</span>: params_1x&#125;,</span><br><span class="line">                                   &#123;<span class="string">&#x27;params&#x27;</span>: net.fc.parameters(),</span><br><span class="line">                                    <span class="string">&#x27;lr&#x27;</span>: learning_rate * <span class="number">10</span>&#125;],</span><br><span class="line">                                lr=learning_rate, weight_decay=<span class="number">0.001</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,</span><br><span class="line">                                  weight_decay=<span class="number">0.001</span>)</span><br><span class="line">    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,</span><br><span class="line">                   devices)</span><br><span class="line">train_fine_tuning(finetune_net, <span class="number">5e-5</span>)</span><br></pre></td></tr></table></figure><p><a href="https://colab.research.google.com/github/d2l-ai/d2l-zh-pytorch-colab/blob/master/chapter_computer-vision/fine-tuning.ipynb#scrollTo=955d840b">fine-tuning.ipynb - Colaboratory (google.com)</a></p><blockquote><p>迁移学习</p><p>Transfer Learning的初衷是节省人工标注样本的时间，让模型可以通过已有的标记数据（source domain data）向未标记数据（target domain data）迁移。</p><p>负迁移指的是，在源域上学习到的知识，对于目标域上的学习产生<strong>负面作用</strong>。</p></blockquote><p><img data-src="https://s2.loli.net/2023/10/06/cmrbgYVXPHJoj6a.png" alt="image-20231006172347353"></p><p>相比之下，端到端自动驾驶的出现将感知、预测和规划的所有节点统一为一个整体。</p><p><img data-src="https://s2.loli.net/2023/10/06/9hi24Ic8HjwdtWO.png" alt="image-20231006172352802"></p><p>应确定先前任务的选择和优先级，以便于规划,该系统应以规划为导向，精心设计，涉及某些组件，以便很少有<strong>独立模型中的累积误差</strong>或<strong>MTL方案中的负迁移</strong>。</p><p>端到端的做法中,一种“白板(tabula-rasa)”做法是直接预测计划的轨迹，没有任何明确的感知和预测监督。虽然这样的方向值得进一步探索，但在安全保障和可解释性方面是不够的，特别是对于高度动态的城市场景。在本文中，我们倾向于另一个角度，并提出以下问题：<strong>对于可靠且以规划为导向的自动驾驶系统，如何设计有利于规划的管道？前面哪些任务是必需的？</strong></p><p>一个直观的解决方案是感知周围的物体，预测未来的行为并明确计划一个安全的操作。当代方法提供了良好的见解并实现了令人印象深刻的性能。<strong>但是</strong>,以前的工作或多或少没有考虑某些组成部分让人想起以规划为导向的精神</p><p>为此，我们推出了UniAD，这是一个统一的自动驾驶算法框架，利用五个基本任务来实现安全可靠的系统。UniAD的设计理念是面向规划的。我们认为，这不是一堆简单的任务，需要简单的工程工作。一个关键组件是基于查询的设计来连接所有节点。与传统的边界框表示形式相比，查询受益于更大的感受域，以减轻上游预测的复合误差。此外，查询可以灵活地对各种交互进行建模和编码</p><h3 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h3><p>UniAD由<strong>四个基于transformer decoder-based的感知和预测模块</strong>组成，<strong>最后由一个规划器组成</strong>。查询 Q 扮演连接pipeline的角色，以对驱动方案中实体的不同交互进行建模。</p><p><img data-src="https://s2.loli.net/2023/10/06/FfyiX9CdYEekwoG.png" alt="image-20231006172400282"></p><p>具体来说，将一系列多相机图像输入特征提取器，并通过BEVFormer中的现成BEV编码器将生成的透视图特征转换为统一的鸟瞰图（BEV）特征B.</p><blockquote><p>也就是说,多机位图片通过特征提取器得到透视图特征,再利用BEVFormer中现成的BEV编码器编码得到统一的鸟瞰图特征.</p></blockquote><p>在 TrackFormer 中，我们称为跟踪查询(track queries)的可学习嵌入从 B 查询agents的信息，以检测和跟踪agents。learnable embeddings从B查询信息</p><p>MapFormer 将地图查询作为道路元素（例如车道和分隔线）的语义抽象，并对地图进行全景分割.</p><p>通过上述表示代理和映射的查询，MotionFormer 捕获agents之间的交互，并映射和预测每个agents的未来轨迹。</p><p>由于每个代理的操作可以显著影响场景中的其他代理，因此此模块对所有考虑的代理进行联合预测。同时，我们设计了一个自我车辆查询来显式地建模自我车辆，并使其能够在这种以场景为中心的范式中与其他代理进行交互</p><p><strong>OccFormer</strong> 使用 BEV 特征 B 作为查询，配备agent-wise知识作为键和值，并在保留agents实体的情况下预测多步骤的未来占用(occupancy)。</p><p><strong>Planner</strong>利用来自MotionFormer 的自我车辆查询来预测规划结果,使自己远离OccForer预测的占领区域以避免碰撞</p><p><img data-src="https://s2.loli.net/2023/10/06/ipwL97YE2kQHPR3.png" alt="image-20231006172407503"></p><h4 id="Perception-Tracking-and-Mapping"><a href="#Perception-Tracking-and-Mapping" class="headerlink" title="Perception: Tracking and Mapping"></a>Perception: Tracking and Mapping</h4><p>感知：跟踪和映射</p><p><img data-src="https://proanimer.com/alimg" alt=""></p><p><img data-src="https://s2.loli.net/2023/10/06/B3WSiX6vjFgoZLz.png" alt="image-20231006172412512"></p><p><strong>TrackFormer</strong>:它可以联合执行检测和多目标跟踪 (MOT)，而无需进行无差别的后处理。除了对象检测中使用的传统检测查询  之外，还引入了其他跟踪查询来跨帧跟踪代理.</p><p>具体来说，在每个时间步长内，<strong>初始化的检测查询负责检测首次感知到的新生agents</strong>，而<strong>跟踪查询则对前几帧中检测到的agents进行建模</strong>。</p><p>检测查询和跟踪查询都通过关注 BEV 特征 B 来捕捉agents抽象。TrackFormer 包含 N 层，最终输出状态 Q~A~ 为下游预测任务提供 N~a~ 有效代理的知识。</p><p>除了对自我车辆(ego-vehicle)周围的其他agents进行编码查询外，我们还在查询集中引入了一个特定的自我车辆查询，以明确模拟自动驾驶车辆本身，并进一步用于规划.</p><p><img data-src="https://s2.loli.net/2023/10/06/ERe2l7duOKzAtI1.png" alt="image-20231006172418732"></p><p><strong>MapFormer</strong>:我们根据二维全景分割方法<code>Panoptic SegFormer</code>设计.我们将道路要素稀疏地表示为地图查询，以帮助下游运动预测，并对位置和结构知识进行编码。</p><p>我们将道路要素稀疏地表示为map queries，以帮助下游运动预测，并对位置和结构知识进行编码。在驾驶场景中，我们将车道、分隔线和交叉路口设置为 “物”，将可驾驶区域设置为 “物”。</p><p>MapFormer 也有 N 个堆叠层，每一层的输出结果都受到监督，只有最后一层的更新查询 Q~M~才会转发给 MotionFormer，以实现agents与地图之间的交互。</p><h4 id="Prediction-Motion-Forecasting"><a href="#Prediction-Motion-Forecasting" class="headerlink" title="Prediction: Motion Forecasting"></a>Prediction: Motion Forecasting</h4><p>预测运动预测</p><p>这种模式只需一次前向传递就能在帧中生成多代理轨迹，从而大大节省了将整个场景与每个代理的坐标对齐的计算成本。通过分别从 TrackFormer 和 MapFormer 获取的动态代理 QA 和静态地图 QM 的高度抽象查询，MotionFormer 可以以场景为中心预测所有代理的多模态未来运动，即前 k 个可能的轨迹。</p><p>这种范式通过单次前向传递在帧中生成多智能体轨迹，这大大节省了将整个场景与每个智能体的坐标对齐的计算成本.通过分别从 TrackFormer 和 MapFormer 获取的动态agents Q~A~ 和静态map Q~M~ 的高度抽象查询，MotionFormer 可以以场景为中心预测所有agents 的多模态未来运动，即前 k 个可能的轨迹。</p><p>同时，我们将来自TrackPreer的自我车辆查询传递到MotionFormer 以吸引自我车辆与其他代理进行交互，同时考虑未来的动态。形式上，输出运动公式化为</p><script type="math/tex; mode=display">{\{\hat{\mathrm{x}}_{i,k}~\in~\mathbb{R}^{T\times2}|i~=~1,\ldots,{N}_{a};k~=1,...,K}\}</script><p>其中 i 索引agents，k 索引轨迹模态，T 是预测范围的长度。</p><h4 id="MotionFormer"><a href="#MotionFormer" class="headerlink" title="MotionFormer"></a>MotionFormer</h4><p>它由 N 层组成，每层捕获三种类型的交互：agents-agents、agents-map和agents-goal point.</p><p><img data-src="https://s2.loli.net/2023/10/06/J4AkdG1SruwH92Y.png" alt="image-20231006172423971"></p><script type="math/tex; mode=display">Q_{a/m}=\text{MHCA}(\text{MHSA}(Q),Q_{A}/Q_{M}),</script><p>利用多头交叉注意力和多头自注意力计算车与地图元素的交互</p><p>通过deformed注意力计算agent-goal的点注意力</p><script type="math/tex; mode=display">Q_{g}=\text{DeformAttn}(Q,\hat{\mathbf{x}}_{T}^{l-1},B),</script><p>x^l−1^ ~T~ 是前一层预测轨迹的最终值。</p><h5 id="Motion-queries"><a href="#Motion-queries" class="headerlink" title="Motion queries"></a>Motion queries</h5><p>MotionFormer的每一层的输入q为motion query.</p><p>包括两个Q：由前一层生成的查询上下文 Qctx 和查询位置 Qpos。具体来说，Qpos整合了位置知识</p><script type="math/tex; mode=display">\begin{aligned}Q_{\mathrm{pos}}& =\mathbf{MLP}(\mathbf{PE}(I^s))+\mathbf{MLP}(\mathbf{PE}(I^a))  \\&+\mathbf{MLP}(\mathbf{PE}(\hat{\mathbf{x}}_0))+\mathbf{MLP}(\mathbf{PE}(\hat{\mathbf{x}}_T^{l-1})).\end{aligned}</script><h4 id="Occupancy-Prediction"><a href="#Occupancy-Prediction" class="headerlink" title="Occupancy Prediction"></a>Occupancy Prediction</h4><p>由于agents知识的使用不足，他们很难预测所有agents的行为，这对于了解场景如何演变至关重要</p><p>为了解决这个问题，提出了OccFormer，在两个方面结合了<strong>场景级和agents级</strong>语义：（1）密集的场景特征通过精心设计的注意力模块获取agent级别的特征</p><p>（2） 通过代理级特征和密集场景特征之间的矩阵乘法轻松生成实例occ，而无需进行繁重的后期处理。</p><h4 id="Planning"><a href="#Planning" class="headerlink" title="Planning"></a>Planning</h4><p>没有高清地图或者可以预测的路径需要高级命令引导路径.</p><p>将原始导航信号转为可学习的嵌入.</p><p>对BEV特征B进行plan query，使其感知周围环境，然后将其解码为未来的航路点 </p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>首先，自动驾驶端到端的训练是很难且不稳定的，因为任务太多，各个任务之间又有依赖关系，因此不能直接训练，得益于UniAD的模块化设计，使得感知，预测等的模块化设计，使得UniAD可以解耦不同的模块，从而分阶段训练。</p><p>UniAD分两个阶段训练，首先联合训练感知部分(包括tracking和mapping模块)6个epochs，然后端到端地训练整个模型(包括感知，预测和规划模块)20个epochs。经验表明，两阶段训练更稳定。</p><p><strong>Shared matching.</strong> 由于UniAD涉及instance-wise的建模，因此在感知和预测任务中需要将预测和gt配对。与DETR类似，在追踪和在线建图阶段引入二分匹配算法。对于tracking，来自检测queries的候选者与新生的gt对象匹配，来自track queries的预测继承了先前帧的分配。tracking模块中的匹配结果在motion会让occupancy节点中被重用，以在端到端的框架中对历史轨迹到未来运动的agent进行一致地建模。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;cvpr 2023 best paper &lt;strong&gt;Planning-oriented Autonomous Driving&lt;/strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2212.10156&quot;&gt;[2212.10156] Planning-oriented Autonomous Driving (arxiv.org)&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>玩转huggingface</title>
    <link href="https://www.sekyoro.top/2023/09/23/%E7%8E%A9%E8%BD%AChuggingface/"/>
    <id>https://www.sekyoro.top/2023/09/23/%E7%8E%A9%E8%BD%AChuggingface/</id>
    <published>2023-09-23T03:29:45.000Z</published>
    <updated>2023-10-06T09:22:15.170Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Hugging Face这一段时间来特别火,融资拿到了一大笔钱,还跟Cousera这些社区常常联系,推出了<code>diffusers</code>,<code>Gradio</code>,<code>Transformers</code>等等好用的库和框架.也可以作为上传数据集和模型的地方,这里尝试玩玩其常用的一些功能.<br><span id="more"></span></p><h2 id="上传模型或数据集"><a href="#上传模型或数据集" class="headerlink" title="上传模型或数据集"></a>上传模型或数据集</h2><p>使用git上传文件<a href="https://huggingface.co/docs/hub/repositories-getting-started">Getting Started with Repositories (huggingface.co)</a></p><p>数据集项目结构<a href="https://huggingface.co/docs/datasets/repository_structure#define-your-splits-in-yaml">Structure your repository (huggingface.co)</a></p><p>一般来说应该使用<code>git</code>相关功能直接上传下载,但是一旦文件特别多或者大,上传数据集时就比较麻烦.我就遇到了这些问题,而且不止我遇到了.<a href="https://discuss.huggingface.co/t/batch-response-too-many-password-attempts-while-uploading-the-dataset-files-with-lfs/38458">Batch response: Too many password attempts while uploading the dataset files with lfs - 🤗Datasets - Hugging Face Forums</a> 解决办法就是使用官方提供的api写python代码上传,或者通过git尝试分批次上传你的数据集.</p><p><img data-src="https://s2.loli.net/2023/10/06/mF1gJYVGtiqZw4c.png" alt="image-20231006172039626" style="zoom:67%;" /></p><p>这个问题截至我写时依旧是个Bug</p><p><img data-src="https://s2.loli.net/2023/10/06/H3dfB9G2sKC8gWc.png" alt="image-20231006172024686"></p><p>看看这位兄弟的解决方案<img data-src="https://s2.loli.net/2023/10/06/rRo9sd8HIC1Tl4w.png" alt=""></p><p>也就是使用<code>upload_folder</code>,知道这点后就方便多了,但是我也建议把git的ssh密钥也加到hugging face里.接下来按照官方教程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli login</span><br><span class="line"><span class="comment"># or using an environment variable</span></span><br><span class="line">huggingface-cli login --token <span class="variable">$HUGGINGFACE_TOKEN</span></span><br></pre></td></tr></table></figure><p>注意,登录需要token,而创建token时,因为要上传数据,所以需要write权限.</p><p><img data-src="https://s2.loli.net/2023/10/06/h3aq7HMGd1AVWez.png" alt="image-20231006172104775"></p><p>登陆之后,如果要上传一个文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> HfApi</span><br><span class="line">api = HfApi()</span><br><span class="line">api.upload_file(</span><br><span class="line">    path_or_fileobj=<span class="string">&quot;D:/anime_face/misaka_mikoto.zip&quot;</span>,</span><br><span class="line">    path_in_repo=<span class="string">&quot;misaka_mikoto.zip&quot;</span>,</span><br><span class="line">    repo_id=<span class="string">&quot;proanimer/anime_face&quot;</span>,</span><br><span class="line">    repo_type=<span class="string">&quot;dataset&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>文件夹也是同理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> HfApi</span><br><span class="line">api = HfApi()</span><br><span class="line">api.upload_folder(</span><br><span class="line">    folder_path=<span class="string">&quot;/path/to/local/space&quot;</span>,</span><br><span class="line">    repo_id=<span class="string">&quot;username/my-cool-space&quot;</span>,</span><br><span class="line">    repo_type=<span class="string">&quot;space&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>当然也可以使用hugging face的cli</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Upload file at root</span></span><br><span class="line">huggingface-cli upload my-cool-model model.safetensors</span><br><span class="line"></span><br><span class="line"><span class="comment"># Upload directory at root</span></span><br><span class="line">huggingface-cli upload my-cool-model ./models</span><br><span class="line"></span><br><span class="line"><span class="comment"># Upload `my-cool-model/` directory if it exist, raise otherwise</span></span><br><span class="line">huggingface-cli upload my-cool-model</span><br></pre></td></tr></table></figure><p>然后可以修改<code>DatasetCard</code>让其他人知道这是个什么,还有自动生成的<code>Dataset Viewer</code>.</p><p><img data-src="https://s2.loli.net/2023/10/06/hEHdwsnB9QFNe6R.png" alt="image-20231006172212449"></p><p>此外,官方建议除了CSV, JSON, JSON lines, text 以及Parquet这些格式数据之外,最好添加一个loading脚本用于加载数据集.</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_dataset/</span><br><span class="line">├── <span class="module-access"><span class="module"><span class="identifier">README</span>.</span></span>md</span><br><span class="line">└── my_dataset.py</span><br></pre></td></tr></table></figure><p>目的是</p><ul><li>Add dataset metadata.</li><li>Download data files.</li><li>Generate samples.</li><li>Generate dataset metadata.</li><li>Upload a dataset to the Hub.</li></ul><p>但是这里我就没有使用了,因为你可以直接<code>git clone</code>这个仓库然后解压即可.</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Hugging Face这一段时间来特别火,融资拿到了一大笔钱,还跟Cousera这些社区常常联系,推出了&lt;code&gt;diffusers&lt;/code&gt;,&lt;code&gt;Gradio&lt;/code&gt;,&lt;code&gt;Transformers&lt;/code&gt;等等好用的库和框架.也可以作为上传数据集和模型的地方,这里尝试玩玩其常用的一些功能.&lt;br&gt;</summary>
    
    
    
    
    <category term="huggingface" scheme="https://www.sekyoro.top/tags/huggingface/"/>
    
  </entry>
  
  <entry>
    <title>大模型减枝和蒸馏</title>
    <link href="https://www.sekyoro.top/2023/09/21/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%87%8F%E6%9E%9D%E5%92%8C%E8%92%B8%E9%A6%8F/"/>
    <id>https://www.sekyoro.top/2023/09/21/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%87%8F%E6%9E%9D%E5%92%8C%E8%92%B8%E9%A6%8F/</id>
    <published>2023-09-21T14:21:00.000Z</published>
    <updated>2023-09-21T14:21:00.885Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>ZTM-pytorchForDL</title>
    <link href="https://www.sekyoro.top/2023/09/16/ZTM-pytorchForDL/"/>
    <id>https://www.sekyoro.top/2023/09/16/ZTM-pytorchForDL/</id>
    <published>2023-09-16T08:35:22.000Z</published>
    <updated>2023-09-26T01:19:14.421Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>ZeroToMastery<a href="https://www.learnpytorch.io/">Zero to Mastery Learn PyTorch for Deep Learning</a>上的课程学习<br><span id="more"></span></p><h2 id="chapter-1"><a href="#chapter-1" class="headerlink" title="chapter 1"></a>chapter 1</h2><p>设置seed,计算tensor的点乘以及tensor数据类型等基础操作,搭配官方文档即可.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set seed</span></span><br><span class="line">torch.manual_seed(<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random tensor</span></span><br><span class="line">x = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove single dimensions</span></span><br><span class="line">y = torch.squeeze(x)</span><br><span class="line"><span class="comment"># Print out tensors and their shapes</span></span><br><span class="line"><span class="built_in">print</span>(x,x.shape)</span><br><span class="line"><span class="built_in">print</span>(y,y.shape)</span><br></pre></td></tr></table></figure><p>此外还有一些常用方法,比如<code>torch.squeeze</code>,<code>torch.cat</code>,<code>torch.stack</code>,<code>torch.unsqueeze</code>,<code>torch.Tensor.view</code>,<code>torch.Tensor.reshape</code>,<code>torch.Tensor.transpose</code>,<code>torch.Tensor.permute</code>等等</p><h2 id="chapter-2"><a href="#chapter-2" class="headerlink" title="chapter 2"></a>chapter 2</h2><h3 id="pytorch-workflow"><a href="#pytorch-workflow" class="headerlink" title="pytorch workflow"></a>pytorch workflow</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create PyTorch linear regression model by subclassing nn.Module</span></span><br><span class="line"><span class="comment">## Option 1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegressionModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.weight = nn.Parameter(data=torch.randn(<span class="number">1</span>, </span><br><span class="line">                                              requires_grad=<span class="literal">True</span>,</span><br><span class="line">                                              dtype=torch.<span class="built_in">float</span></span><br><span class="line">                                              ))</span><br><span class="line">    </span><br><span class="line">    self.bias = nn.Parameter(data=torch.randn(<span class="number">1</span>, </span><br><span class="line">                                              requires_grad=<span class="literal">True</span>,</span><br><span class="line">                                              dtype=torch.<span class="built_in">float</span></span><br><span class="line">                                              ))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> self.weight * x + self.bias</span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Option 2</span></span><br><span class="line"><span class="comment"># class LinearRegressionModel(nn.Module):</span></span><br><span class="line"><span class="comment">#   def __init__(self):</span></span><br><span class="line"><span class="comment">#     super().__init__()</span></span><br><span class="line"><span class="comment">#     self.linear_layer = nn.Linear(in_features = 1,</span></span><br><span class="line"><span class="comment">#                                   out_features = 1)</span></span><br><span class="line"><span class="comment">#   def forward(self,x : torch.Tensor) -&gt; torch.Tensor:</span></span><br><span class="line"><span class="comment">#     return self.linear_layer(x)</span></span><br><span class="line">  </span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">model_1 = LinearRegressionModel()</span><br><span class="line">model_1,model_1.state_dict()</span><br><span class="line">     </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Create the loss function and optimizer</span></span><br><span class="line">loss_fn = nn.L1Loss()</span><br><span class="line">optimizer = torch.optim.SGD(params = model_1.parameters(),</span><br><span class="line">                            lr = <span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training loop</span></span><br><span class="line"><span class="comment"># Train model for 300 epochs</span></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">300</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Send data to target device</span></span><br><span class="line">X_train = X_train.to(device)</span><br><span class="line">X_test = X_test.to(device)</span><br><span class="line">y_train = y_train.to(device)</span><br><span class="line">y_test = y_test.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">  <span class="comment">### Training</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Put model in train mode</span></span><br><span class="line">  model_1.train()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 1. Forward pass</span></span><br><span class="line">  y_pred = model_1(X_train)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 2. Calculate loss</span></span><br><span class="line">  loss = loss_fn(y_pred,y_train)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 3. Zero gradients</span></span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 4. Backpropagation</span></span><br><span class="line">  loss.backward()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 5. Step the optimizer</span></span><br><span class="line">  optimizer.step()</span><br><span class="line"></span><br><span class="line">  <span class="comment">### Perform testing every 20 epochs</span></span><br><span class="line">  <span class="keyword">if</span> epoch % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># Put model in evaluation mode and setup inference context </span></span><br><span class="line">    model_1.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">      <span class="comment"># 1. Forward pass</span></span><br><span class="line">      y_preds = model_1(X_test)</span><br><span class="line">      <span class="comment"># 2. Calculate test loss</span></span><br><span class="line">      test_loss = loss_fn(y_preds,y_test)</span><br><span class="line">      <span class="comment"># Print out what&#x27;s happening</span></span><br><span class="line">      <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | Train loss: <span class="subst">&#123;loss:<span class="number">.3</span>f&#125;</span> | Test loss: <span class="subst">&#123;test_loss:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">     </span><br></pre></td></tr></table></figure><h3 id="save-trained-model"><a href="#save-trained-model" class="headerlink" title="save trained model"></a>save trained model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Create models directory </span></span><br><span class="line">MODEL_PATH = Path(<span class="string">&quot;models&quot;</span>)</span><br><span class="line">MODEL_PATH.mkdir(parents = <span class="literal">True</span>,exist_ok = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 2. Create model save path </span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;01_pytorch_model&quot;</span></span><br><span class="line">MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME </span><br><span class="line"><span class="comment"># 3. Save the model state dict</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Saving model to <span class="subst">&#123;MODEL_SAVE_PATH&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(obj = model_1.state_dict(),f = MODEL_SAVE_PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new instance of model and load saved state dict (make sure to put it on the target device)</span></span><br><span class="line">loaded_model = LinearRegressionModel()</span><br><span class="line">loaded_model.load_state_dict(torch.load(f = MODEL_SAVE_PATH))</span><br><span class="line">loaded_model.to(device)</span><br></pre></td></tr></table></figure><h2 id="chapter-3"><a href="#chapter-3" class="headerlink" title="chapter 3"></a>chapter 3</h2><p>使用<code>torch.inference_mode</code>替代<code>torch.no_grad</code></p><p><a href="https://stackoverflow.com/questions/69543907/pytorch-torch-no-grad-vs-torch-inference-mode">machine learning - PyTorch <code>torch.no_grad</code> vs <code>torch.inference_mode</code> - Stack Overflow</a></p><p>使用<code>torchmetrics</code>作为衡量标准的库方便.使用tensorboard<a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/tensorboard_with_pytorch.ipynb#scrollTo=fUt3jwrIHCks">tensorboard_with_pytorch.ipynb - Colaboratory (google.com)</a>查看loss,acc等.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">!pip install -q tensorboard </span><br><span class="line"><span class="comment">#  load tensorboard</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;./logs&quot;</span>)</span><br><span class="line"><span class="comment"># do train and evalute</span></span><br><span class="line"></span><br><span class="line">writer.add_scalar() <span class="comment"># 添加变量</span></span><br><span class="line">writer.add_image()  <span class="comment">#添加图像</span></span><br><span class="line">writer.add_graph()</span><br><span class="line"></span><br><span class="line">writer.flush()</span><br><span class="line">writer.close()</span><br><span class="line">!tensorboard --logdir=runs</span><br></pre></td></tr></table></figure><p>使用tensorboard.dev分享到公网.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!tensorboard dev upload --logdir runs \</span><br><span class="line">--name <span class="string">&quot;My latest experiment&quot;</span> \</span><br><span class="line">--description <span class="string">&quot;Simple comparison of several hyperparameters&quot;</span></span><br></pre></td></tr></table></figure><p>在colab上使用魔法命令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%tensorboard --logdir logs </span><br></pre></td></tr></table></figure><p><a href="https://medium.com/looka-engineering/how-to-use-tensorboard-with-pytorch-in-google-colab-1f76a938bc34">How to use Tensorboard with PyTorch in Google Colab | by Andrew B. Martin | Looka Engineering | Medium</a></p><p>端口冲突解决</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lsof -i:&lt;port&gt;</span><br><span class="line">kill -<span class="number">9</span> PID</span><br></pre></td></tr></table></figure><p>多GPU训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_parallel</span>(<span class="params">module, <span class="built_in">input</span>, device_ids, output_device=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> device_ids:</span><br><span class="line">        <span class="keyword">return</span> module(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> output_device <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        output_device = device_ids[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    replicas = nn.parallel.replicate(module, device_ids)</span><br><span class="line">    inputs = nn.parallel.scatter(<span class="built_in">input</span>, device_ids)</span><br><span class="line">    replicas = replicas[:<span class="built_in">len</span>(inputs)]</span><br><span class="line">    outputs = nn.parallel.parallel_apply(replicas, inputs)</span><br><span class="line">    <span class="keyword">return</span> nn.parallel.gather(outputs, output_device)</span><br></pre></td></tr></table></figure><p>In general, pytorch’s nn.parallel primitives can be used independently. We have implemented simple MPI-like primitives:</p><ul><li>replicate: replicate a Module on multiple devices</li><li>scatter: distribute the input in the first-dimension</li><li>gather: gather and concatenate the input in the first-dimension</li><li>parallel_apply: apply a set of already-distributed inputs to a set of already-distributed models.</li></ul><h2 id="chapter-4"><a href="#chapter-4" class="headerlink" title="chapter 4"></a>chapter 4</h2><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;ZeroToMastery&lt;a href=&quot;https://www.learnpytorch.io/&quot;&gt;Zero to Mastery Learn PyTorch for Deep Learning&lt;/a&gt;上的课程学习&lt;br&gt;</summary>
    
    
    
    
    <category term="pytorch" scheme="https://www.sekyoro.top/tags/pytorch/"/>
    
    <category term="DeepLearning" scheme="https://www.sekyoro.top/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>pytorch学习——初探</title>
    <link href="https://www.sekyoro.top/2023/09/12/pytorch%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%88%9D%E6%8E%A2/"/>
    <id>https://www.sekyoro.top/2023/09/12/pytorch%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%88%9D%E6%8E%A2/</id>
    <published>2023-09-12T01:04:36.000Z</published>
    <updated>2023-10-06T09:36:16.379Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>我并没有系统地翻阅Pytorch文档,一般都是看别人pytorch实现的网络代码,哪里有不懂的再去看.现在找到一些tutorial并做一些简单的尝试.</p><span id="more"></span><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p><img data-src="https://img.proanimer.com/imgs/image-20230914101921453.png" alt="image-20230914101921453"></p><p><img data-src="https://img.proanimer.com/imgs/image-20230912094601559.png" alt="image-20230912094601559" style="zoom:67%;" /></p><p>首先定义网络架构,注意这里也有很多要点,比如像写代码一样,使用模块嵌套,最终形成一个个小模块组成的大模块,模块的超参设置也很重要.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">model = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">criterion = torch.nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = <span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>损失函数需要根据任务去确定,常用交叉熵.优化器基本没有太多改进空间了,常用的Adam或者RMSprop.在训练时,通过梯度更新参数,再进行验证,通过这样来判断是否过拟合等等.</p><p><img data-src="https://img.proanimer.com/imgs/image-20230912095110476.png" alt="image-20230912095110476" style="zoom:67%;" /></p><p>以上是关于网络的训练,对于一般的任务,对于数据集的处理也是非常重要的,导入之前需要做一些transforms,不同任务做的变化不一样,比如图像的话,一般数据集是PIL数据,需要将其转为Tensor类型数据,还可能需要normalize等等.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"></span><br><span class="line">dataset = MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>上面用的Dataset都是自带的,很多时候需要用我们自己的数据集,那么需要重写Dataset</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data, file</span>):</span></span><br><span class="line">      <span class="comment"># read data and preprocess</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self,index</span>):</span></span><br><span class="line">      <span class="comment"># return one sample at a time</span></span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="comment"># return the size of the dataset</span></span><br><span class="line">      <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>然后使用dataloader方便读入batch以及shuffle打乱</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = MyDataset(data, <span class="string">&#x27;./data/train.csv&#x27;</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>Pytorch中的dim与numpy中的axis一样的,有的时候类似这种术语经常出现混乱.</p><p>常用操作</p><p>transpose 互换维度</p><p>squeezz 去掉指定的长度为1的维度</p><p>unsqueezz 增加一个长度唯一的维度</p><p>cat   将给定维度中的seq张量的给定序列连接起来。所有张量必须具有相同的形状（连接维度除外）或为空</p><p>stack  沿着一个新的维度连接一系列张量。 所有张量的大小都必须相同。</p><h4 id="tensor数据类型"><a href="#tensor数据类型" class="headerlink" title="tensor数据类型"></a>tensor数据类型</h4><div class="table-container"><table><thead><tr><th>Data type</th><th>dtype</th><th>CPU tensor</th><th>GPU tensor</th></tr></thead><tbody><tr><td>32-bit floating point</td><td><code>torch.float32</code> or <code>torch.float</code></td><td><code>torch.FloatTensor</code></td><td><code>torch.cuda.FloatTensor</code></td></tr><tr><td>64-bit floating point</td><td><code>torch.float64</code> or <code>torch.double</code></td><td><code>torch.DoubleTensor</code></td><td><code>torch.cuda.DoubleTensor</code></td></tr><tr><td>32-bit integer (signed)</td><td><code>torch.int32</code> or <code>torch.int</code></td><td><code>torch.IntTensor</code></td><td><code>torch.cuda.IntTensor</code></td></tr></tbody></table></div><p>pytorch中的tensor与numpy都有shape和dtype属性</p><p>在方法上,pytorch用于变更维度的有reshape和view(很多时候看别人代码里用view不要忘了其作用).此外numpy也有squeezz,但是没有unsqueezz,而是使用expand_dims</p><p>而torch.Tensor与np.ndarray比较大的差别是tensor可以在GPU上跑,同时也可以设置梯度.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.is_available() <span class="comment"># 查看GPU是否可用</span></span><br></pre></td></tr></table></figure><p>通过torch.tensor创造tensor时,会根据输入设置dtype,如果输入是int,那就是int32或者int64,跟os有关,如果是浮点数就是float32.如果使用torch.ones这种来创建tensor,dtype默认是float32.</p><h3 id="torch-nn定义模型"><a href="#torch-nn定义模型" class="headerlink" title="torch.nn定义模型"></a>torch.nn定义模型</h3><h4 id="nn-Linear"><a href="#nn-Linear" class="headerlink" title="nn.Linear"></a>nn.Linear</h4><p><img data-src="https://img.proanimer.com/imgs/image-20230914094934618.png" alt="image-20230914094934618"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(). __init__()</span><br><span class="line">    self.net = nn.Sequential(</span><br><span class="line">        nn.Linear(<span class="number">10</span>,<span class="number">32</span>),</span><br><span class="line">        nn.Sigmoid(),</span><br><span class="line">        nn.Linear(<span class="number">32</span>,<span class="number">1</span>)</span><br><span class="line">    )    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    x = self.net(x)</span><br></pre></td></tr></table></figure><p>对于每一个batch,首先需要使用optimizer.zero_grad()去除gradient,然后使用loss.backward()通过损失函数计算梯度,最后使用optimizer.step更新梯度.</p><p>标准<strong>训练</strong>流程如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(). __init__()</span><br><span class="line">    self.net = nn.Sequential( <span class="comment"># 也可以使用nn.Linear  nn.Sigmoid连续写</span></span><br><span class="line">        nn.Linear(<span class="number">10</span>,<span class="number">32</span>),</span><br><span class="line">        nn.Sigmoid(),</span><br><span class="line">        nn.Linear(<span class="number">32</span>,<span class="number">1</span>)</span><br><span class="line">    )    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    x = self.net(x)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">DEVICE = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model = MyModel().to(DEVICE)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">  model.train()</span><br><span class="line">  <span class="keyword">for</span> x,y <span class="keyword">in</span> tr_set:</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    x,y = x.to(DEVICE),y.to(DEVICE)</span><br><span class="line">    pred = model(x)</span><br><span class="line">    loss = criterion(pred,y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">  model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><p>验证时,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">total_loss = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> te_set:</span><br><span class="line">    x,y = x.to(DEVICE),y.to(DEVICE)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">      pred = model(x)</span><br><span class="line">      loss = criterion(pred,y)</span><br><span class="line">      total_loss += loss.cpu().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>: loss = <span class="subst">&#123;total_loss&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>注意</strong> 计算出的loss除了在计算backward时,其他地方需要放在cpu上并移除梯度,应该注意这些细节,也就是将原本在cuda上的数据放在cpu上,并且将tensor数据转为python的数据类型.</p><p><a href="https://zhuanlan.zhihu.com/p/497192910">Pytorch训练过程中，显存（内存）爆炸解决方法 - 知乎 (zhihu.com)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">preds = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> tt_test:</span><br><span class="line">    x = x.to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        pred = model(x)</span><br><span class="line">        preds.append(pred.cpu())</span><br></pre></td></tr></table></figure><p><img data-src="https://img.proanimer.com/imgs/image-20230914224438072.png" alt="image-20230914224438072"></p><p>在训练验证时需要使用model.eval与model.train切换模型中每层的行为,在测试时防止将测试数据放入模型中计算.</p><p>此外要多翻阅Pytorch文档.</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.youtube.com/watch?v=6dEp6oRN2NE&amp;ab_channel=Hung-yiLee">【機器學習 2023】 PyTorch Tutorial (introduction + documentation) - YouTube</a></li><li><a href="https://pytorch.org/docs/stable/tensors">torch.Tensor — PyTorch 2.0 documentation</a></li><li><a href="https://github.com/wkentaro/pytorch-for-numpy-users">wkentaro/pytorch-for-numpy-users: PyTorch for Numpy users. https://pytorch-for-numpy-users.wkentaro.com (github.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;我并没有系统地翻阅Pytorch文档,一般都是看别人pytorch实现的网络代码,哪里有不懂的再去看.现在找到一些tutorial并做一些简单的尝试.&lt;/p&gt;</summary>
    
    
    
    
    <category term="pytorch" scheme="https://www.sekyoro.top/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Autoencoder学习</title>
    <link href="https://www.sekyoro.top/2023/09/01/Autoencoder%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/09/01/Autoencoder%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-09-01T12:28:30.000Z</published>
    <updated>2023-09-07T07:22:29.266Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这种encoder-decoder结构很重要,同时也可以作为学习GAN的前置<br><span id="more"></span></p><h2 id="Autoencoders"><a href="#Autoencoders" class="headerlink" title="Autoencoders"></a>Autoencoders</h2><p>autoencoders是在深度学习经常听到的词,简单来说是基于latent vector,manifold这种概念上的模型,</p><blockquote><p>利用输入数据  本身作为监督，来指导神经网络尝试学习一个映射关系，从而得到一个重构输出 。在时间序列异常检测场景下，异常对于正常来说是少数，所以我们认为，如果使用自编码器重构出来的输出跟原始输入的差异超出一定阈值（threshold）的话，原始时间序列即存在了异常。</p><p>An autoencoder is a type of algorithm with the primary purpose of learning an “informative” representation of the data that can be used for different applicationsa by learning to reconstruct a set of input observations well enough.</p></blockquote><p>latent feature又可以叫做潜在向量,潜在特征,bottleneck等等,叫法很多,不要听见新的说法发怵.简单来说就是encoder-decoder架构,不过进行自监督,使用损失函数比较输入和输出. 使用,重建误差(Reconsrtuction Error)体现,重建误差（RE）是一个指标，它可以指示自动编码器能够重建输入观测x的好坏。相比于全连接网络和卷积网络,AE并不需要labeled data, 我们可以使用图像同时作为输入和输出.</p><p><strong>The main idea of autoencoder is that we will have an encoder network that converts input image into some latent space (normally it is just a vector of some smaller size), then the decoder network, whose goal would be to reconstruct the original image</strong></p><p><img data-src="https://s2.loli.net/2023/08/31/ABn4DgqX7xWGI6y.png" alt=""></p><p>常用于如下用途</p><ul><li>降低图像的维度以进行可视化或训练图像嵌入。通常，自动编码器比PCA给出更好的结果，因为它考虑了图像的空间性质和层次特征。</li><li>去噪，即从图像中去除噪声。由于噪声携带了大量无用的信息，自动编码器无法将其全部放入相对较小的潜在空间，因此只能捕获图像的重要部分。在训练去噪器时，我们从原始图像开始，并使用带有人工添加噪声的图像作为自动编码器的输入。</li><li>超分辨率，提高图像分辨率。我们从高分辨率图像开始，使用分辨率较低的图像作为自动编码器输入。</li><li>生成模型。一旦我们训练了自动编码器，解码器部分就可以用来从随机潜在向量开始创建新的对象。</li></ul><p>缺点是 传统的AE(autoencoders)潜在向量往往没有太多的语义含义,换句话说，以MNIST数据集为例，弄清楚哪些数字对应于不同的潜在向量并不是一项容易的任务，因为接近的潜在向量不一定对应于同一个数字</p><p>尝试改变潜变量大小,看看效果.</p><p>尝试看看不同图像的潜变量,增加噪声后再查看效果.</p><h3 id="AE常用去噪和超分"><a href="#AE常用去噪和超分" class="headerlink" title="AE常用去噪和超分."></a>AE常用去噪和超分.</h3><p>对于去噪来说,将没有噪声的图片人工加噪,训练时使用噪声图片作为输入,正常无噪图片作为输出.</p><blockquote><p>To train super-resolution network, we will start with high-resolution images, and automatically downscale them to produce network inputs. We will then feed autoencoder with small images as inputs and high-resolution images as outputs.</p></blockquote><p>对于超分将宽高缩小的图片作为输入,将正常图作为输出.</p><p>训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = AutoEncoder().to(device)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=lr, eps=eps)</span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line">noisy_tensor = torch.FloatTensor(noisify([<span class="number">256</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])).to(device)</span><br><span class="line">test_noisy_tensor = torch.FloatTensor(noisify([<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])).to(device)</span><br><span class="line">noisy_tensors = (noisy_tensor, test_noisy_tensor)</span><br><span class="line">train(dataloaders, model, loss_fn, optimizer, <span class="number">100</span>, device, noisy=noisy_tensors)</span><br></pre></td></tr></table></figure><p>预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">predictions = []</span><br><span class="line">noise = []</span><br><span class="line">plots = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataset):</span><br><span class="line">    <span class="keyword">if</span> i == plots:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    shapes = data[<span class="number">0</span>].shape</span><br><span class="line">    noisy_data = data[<span class="number">0</span>] + test_noisy_tensor[<span class="number">0</span>].detach().cpu()</span><br><span class="line">    noise.append(noisy_data)</span><br><span class="line">    predictions.append(model(noisy_data.to(device).unsqueeze(<span class="number">0</span>)).detach().cpu())</span><br><span class="line">plotn(plots, noise)</span><br><span class="line">plotn(plots, predictions)</span><br></pre></td></tr></table></figure><p>对于超分,因为输入变化了,考虑潜变量不变,所以encoder需要做一些变化.</p><h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h2><p>对于图像降维来说影响不大,但要训练生成模型，最好对潜在空间有一些了解。这个想法使我们想到了变分自动编码器(VAE)</p><p>VAE是一种自动编码器，它学习预测潜在参数的统计分布，即所谓的潜在分布。</p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/09-Autoencoders/images/vae.png" alt="img" style="zoom: 50%;" /></p><p>VAE是一种自动编码器，它学习预测潜在参数的统计分布，即所谓的潜在分布。例如，我们可能希望潜在向量正态分布，具有一些均值z~mean~和标准差z~sigma~（均值和标准差都是一些维度d的向量）。VAE中的编码器学习预测这些参数，然后解码器从这个分布中提取一个随机向量来重建对象。 </p><p>相比于AE简单的损失函数,变分自动编码器使用由两部分组成的复杂损失函数：</p><ul><li>重建损失是显示重建图像离目标有多近的损失函数（它可以是均方误差或MSE）。它与普通自动编码器中的损失函数相同。</li><li>KL损失，确保潜在变量分布保持接近正态分布。它基于Kullback-Leibler散度的概念，这是一个估计两个统计分布相似程度的指标。</li></ul><p>VAE的一个重要优势是，它们使我们能够相对容易地生成新图像，<strong>因为我们知道从哪个分布对潜在向量进行采样</strong>。例如，如果我们在MNIST上用2D潜在向量训练VAE，那么我们可以改变潜在向量的分量以获得不同的数字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vae_loss</span>(<span class="params">preds, targets, z_vals</span>):</span></span><br><span class="line">    mse = nn.MSELoss()</span><br><span class="line">    reconstruction_loss = mse(preds, targets.view(targets.shape[<span class="number">0</span>], -<span class="number">1</span>)) * <span class="number">784.0</span></span><br><span class="line">    temp = <span class="number">1.0</span> + z_vals[<span class="number">1</span>] - torch.square(z_vals[<span class="number">0</span>]) - torch.exp(z_vals[<span class="number">1</span>]) <span class="comment"># ?尽可能使得潜变量与期望的分布kl相近</span></span><br><span class="line">    <span class="comment"># 期望正态分布 均值0 方差1</span></span><br><span class="line">    kl_loss = -<span class="number">0.5</span> * torch.<span class="built_in">sum</span>(temp, axis=-<span class="number">1</span>)  <span class="comment">#  </span></span><br><span class="line">    <span class="keyword">return</span> torch.mean(reconstruction_loss + kl_loss)</span><br></pre></td></tr></table></figure><p>关键是这里的KL loss,需要使得潜变量与正态分布kl更小,分布更相似. 当我们通过encoder计算出均值和方差的log之后,需要计算其与正态分布的KL,</p><p><img data-src="https://s2.loli.net/2023/09/03/HURDP5TfoBuVjyC.png" alt="image-20230903182226844" style="zoom: 80%;" /></p><p>计算正态分布之间的KL散度公式如上.关于VAE这里的KL 散度比较好的回答<a href="https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes/370048#370048">kullback leibler - Deriving the KL divergence loss for VAEs - Cross Validated (stackexchange.com)</a></p><blockquote><p><strong>KL散度</strong>，是指当某分布q (x)被用于近似p (x)时的信息损失。 KL Divergence 也就是说，q (x)能在多大程度上表达p (x)所包含的信息，KL散度越大，表达效果越差。</p></blockquote><p>所以计算KL时应该是KL(z|n)其中z表示潜变量,n表示正态分布. 目的是利用正态分布描述潜变量的损失.</p><h3 id="Training-a-VAE-with-The-Reparametrization-Trick"><a href="#Training-a-VAE-with-The-Reparametrization-Trick" class="headerlink" title="Training a VAE with The Reparametrization Trick"></a>Training a VAE with The Reparametrization Trick</h3><p>VAE在反向传播时存在一些计算问题.使用了Reparametrization Trick</p><p><a href="https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important">mathematical statistics - How does the reparameterization trick for VAEs work and why is it important? - Cross Validated (stackexchange.com)</a></p><h2 id="AAE"><a href="#AAE" class="headerlink" title="AAE"></a>AAE</h2><p>结合GAN和VAE的结构</p><p>对抗性自动编码器是生成对抗性网络和变分自动编码器的组合。编码器将是生成器，鉴别器将学习区分编码器输出的真实图像和生成的图像。编码器的输出是一个分布，从这个输出解码器将尝试解码图像。</p><p><img data-src="https://s2.loli.net/2023/09/03/mbhaVXe7jrO63D8.png" alt="image-20230903230742551" style="zoom: 67%;" /></p><p>众所周知,GAN的生成器在训练时使用噪声作为输入,</p><p><img data-src="https://s2.loli.net/2023/09/04/dcLtUFBSzg41rVl.png" alt="image-20230904105728118" style="zoom:67%;" /></p><p><strong>纠正</strong>:是Adversarial. 注意,上面一层的autoencoder的encoder也是一个generator,相当于共用了GAN的generator和autoencoder的encoder.首先encoder使用一张图像作为输入,生成的潜变量在VAE中需要减小其与正态分布之间的相似度,也就是优化KL散度,但由于<strong>KL散度项的积分除了少数分布之外没有闭合形式的解析解</strong>,所以利用GAN的鉴别器,从正态分布中采样的数据与生成的潜变量作为鉴别器的输入进行鉴别,利用这个鉴别器的损失更新鉴别器</p><script type="math/tex; mode=display">L_D=-\frac1m\sum_{k=1}^mlog(D(z'))+log(1-D(z))</script><p>更新后,再使用encoder(同时也是generator)以原始图像作为输入,生成潜变量,输入给更新后的鉴别器,鉴别器将其判断为真的概率.</p><script type="math/tex; mode=display">L_G=-\frac1m\sum_{k=1}^mlog(D(z))</script><p>以这种方式定义的损失将迫使鉴别器能够识别假样本，同时推动生成器欺骗鉴别器.</p><p>首先，由于编码器的输出必须遵循高斯分布，我们在其最后一层不使用任何非线性。解码器的输出具有S形非线性，这是因为我们使用的输入以其值在0和1之间的方式归一化。鉴别器网络的输出只是0和1之间的一个数字，表示输入来自真实先验分布的概率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Encoder</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Q_net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Q_net, self).__init__()</span><br><span class="line">        self.lin1 = nn.Linear(X_dim, N)</span><br><span class="line">        self.lin2 = nn.Linear(N, N)</span><br><span class="line">        self.lin3gauss = nn.Linear(N, z_dim)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.droppout(self.lin1(x), p=<span class="number">0.25</span>, training=self.training)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.droppout(self.lin2(x), p=<span class="number">0.25</span>, training=self.training)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        xgauss = self.lin3gauss(x)</span><br><span class="line">        <span class="keyword">return</span> xgauss</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Decoder</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">P_net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(P_net, self).__init__()</span><br><span class="line">        self.lin1 = nn.Linear(z_dim, N)</span><br><span class="line">        self.lin2 = nn.Linear(N, N)</span><br><span class="line">        self.lin3 = nn.Linear(N, X_dim)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.lin1(x)</span><br><span class="line">        x = F.dropout(x, p=<span class="number">0.25</span>, training=self.training)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.lin2(x)</span><br><span class="line">        x = F.dropout(x, p=<span class="number">0.25</span>, training=self.training)</span><br><span class="line">        x = self.lin3(x)</span><br><span class="line">        <span class="keyword">return</span> F.sigmoid(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Discriminator</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">D_net_gauss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(D_net_gauss, self).__init__()</span><br><span class="line">        self.lin1 = nn.Linear(z_dim, N)</span><br><span class="line">        self.lin2 = nn.Linear(N, N)</span><br><span class="line">        self.lin3 = nn.Linear(N, <span class="number">1</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.dropout(self.lin1(x), p=<span class="number">0.2</span>, training=self.training)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.dropout(self.lin2(x), p=<span class="number">0.2</span>, training=self.training)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        <span class="keyword">return</span> F.sigmoid(self.lin3(x))</span><br></pre></td></tr></table></figure><p>所以这里的损失函数定义为重建损失(一般为BCEloss或者cross-entropy loss)和GAN的损失,而GAN的训练一般都是G和D一个训练一下,而之前autoencoder训练时也是把encoder-decoder作为整个模型训练的loss.而这里为了在编码器（也是对抗性网络的生成器）的优化过程中具有独立性，我们为网络的这一部分定义了两个优化器,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">10</span>)</span><br><span class="line">Q, P = Q_net() = Q_net(), P_net(<span class="number">0</span>)     <span class="comment"># Encoder/Decoder</span></span><br><span class="line">D_gauss = D_net_gauss()                <span class="comment"># Discriminator adversarial</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    Q = Q.cuda()</span><br><span class="line">    P = P.cuda()</span><br><span class="line">    D_cat = D_gauss.cuda()</span><br><span class="line">    D_gauss = D_net_gauss().cuda()</span><br><span class="line"><span class="comment"># Set learning rates</span></span><br><span class="line">gen_lr, reg_lr = <span class="number">0.0006</span>, <span class="number">0.0008</span></span><br><span class="line"><span class="comment"># Set optimizators</span></span><br><span class="line">P_decoder = optim.Adam(P.parameters(), lr=gen_lr)</span><br><span class="line">Q_encoder = optim.Adam(Q.parameters(), lr=gen_lr)</span><br><span class="line">Q_generator = optim.Adam(Q.parameters(), lr=reg_lr)</span><br><span class="line">D_gauss_solver = optim.Adam(D_gauss.parameters(), lr=reg_lr)</span><br></pre></td></tr></table></figure><p>通过编码器/解码器部分进行正向计算，计算重建损失并更新编码器Q和解码器P网络的参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">z_sample = Q(X)</span><br><span class="line">X_sample = P(z_sample)</span><br><span class="line">recon_loss = F.binary_cross_entropy(X_sample + TINY, </span><br><span class="line">                                    X.resize(train_batch_size, X_dim) + TINY)</span><br><span class="line">recon_loss.backward()</span><br><span class="line">P_decoder.step()</span><br><span class="line">Q_encoder.step()</span><br></pre></td></tr></table></figure><p>创建一个潜在表示z=Q（x），并从先前的p（z）中提取样本z’，通过鉴别器运行每个样本，并计算分配给每个样本的分数（D（z）和D（z’））</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="module-access"><span class="module"><span class="identifier">Q</span>.</span></span>eval<span class="literal">()</span>    </span><br><span class="line">z_real_gauss = <span class="constructor">Variable(<span class="params">torch</span>.<span class="params">randn</span>(<span class="params">train_batch_size</span>, <span class="params">z_dim</span>)</span><span class="operator"> * </span><span class="number">5</span>)   # Sample from <span class="constructor">N(0,5)</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is<span class="constructor">_available()</span>:</span><br><span class="line">    z_real_gauss = z_real_gauss.cuda<span class="literal">()</span></span><br><span class="line">z_fake_gauss = <span class="constructor">Q(X)</span></span><br></pre></td></tr></table></figure><p>训练过程,首先利用encoder-decoder,得到重建后的输出,这里使用二分类交叉熵,计算梯度后更新encoder和decoder的值.然后使用generator(同时也是encoder)使用从高斯分布采样得到的变量作为输入,注意此时需要设置dropout和normalization模式为测试,因为正则目的是为了防止过拟合、加快拟合过程,所以测试、验证时并不需要正则了. 这里Q.eval目的是只需要得到一个生成的潜变量,而不是进行训练.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compute discriminator outputs and loss</span></span><br><span class="line">D_real_gauss, D_fake_gauss = D_gauss(z_real_gauss), D_gauss(z_fake_gauss)</span><br><span class="line">D_loss_gauss = -torch.mean(torch.log(D_real_gauss + TINY) + torch.log(<span class="number">1</span> - D_fake_gauss + TINY))</span><br><span class="line">D_loss_gauss.backward()       <span class="comment"># Backpropagate loss</span></span><br><span class="line">D_gauss_solver.step()   <span class="comment"># Apply optimization step</span></span><br></pre></td></tr></table></figure><p>计算Generator的loss，并相应地更新Q网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generator</span></span><br><span class="line">Q.train()   <span class="comment"># Back to use dropout</span></span><br><span class="line">z_fake_gauss = Q(X)</span><br><span class="line">D_fake_gauss = D_gauss(z_fake_gauss)</span><br><span class="line"></span><br><span class="line">G_loss = -torch.mean(torch.log(D_fake_gauss + TINY))</span><br><span class="line">G_loss.backward()</span><br><span class="line">Q_generator.step()</span><br></pre></td></tr></table></figure><p>由于需要更新Generator,恢复训练模式,</p><h3 id="Supervised-approach"><a href="#Supervised-approach" class="headerlink" title="Supervised approach"></a>Supervised approach</h3><blockquote><p>特征学习最稳健的方法是尽可能多地分解因素，尽可能少地丢弃有关数据的信息</p></blockquote><p>通常来说,如果我们能提供更多信息,将其作为一个全监督的模型.</p><p><code>disentangled representations</code>类似于风格迁移中概念,可以将一张图像中的东西分为<strong>内容</strong>和<strong>风格</strong>,进行解耦表示。</p><p>我们可以加上类标签的独热码,这其实就是所谓的Conditional GAN</p><blockquote></blockquote><p><img data-src="https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/aae_super.png" alt="aae_semi" style="zoom:33%;" /></p><p>这样在代码上就会增加两个损失函数和一个鉴别器用于分辨产生的label的独热码和真实的label的独热码.</p><p><img data-src="https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/dis_2.png" alt="disentanglement1" style="zoom: 33%;" /></p><p>这是教程<a href="https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/">Adversarial Autoencoders (with Pytorch) (paperspace.com)</a>的图片,使得每一列潜变量第一部分也就是正态分布一样,但类标签不一样,</p><h3 id="Semi-supervised-approach"><a href="#Semi-supervised-approach" class="headerlink" title="Semi-supervised approach"></a>Semi-supervised approach</h3><p>下面这种半监督的方式,我们需要将label加入,而这种加入并不是直接把label作为输入给decoder的,而是类似刚才AAE的方式通过GAN使得潜变量分为两个部分,分别是想要的某种分布和label,将class label的one-hot编码,比如说MNIST数据集中,3这个图像的label就是数字三,one-hot编码是0011(因为一共十个数字,需要4位.</p><p>我们可以修改以前的体系结构，使AAE产生一个由矢量级联组成的潜变量y指示类或标签（使用Softmax）和连续潜在变量z(使用线性层). 使用softmax作为最后一层的激活函数,这样最后一层输出shape就是(Batch_size,4) 每个值在0-1之间,</p><p>通过这种方法还能通过encoder产生的潜变量中的类标签的独热码进行对图像分类,</p><p><img data-src="https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/aae_semi.png" alt="aae002" style="zoom: 33%;" /></p><p>希望向量y表现为一个独热码，我们通过使用鉴别器Dcat的对抗性网络来强制它遵循类别分布。</p><p>编码器现在是q（z，y|x）。解码器使用类标签和连续潜变量来重建图像</p><h2 id="Conditional-Variational-Autoencoders"><a href="#Conditional-Variational-Autoencoders" class="headerlink" title="Conditional Variational Autoencoders"></a>Conditional Variational Autoencoders</h2><p>条件变分自动编码器对编码器和解码器都有一个额外的输入。</p><p><img data-src="https://cdn.sekyoro.top/imgs/image-20230907105548807.png" alt="image-20230907105548807" style="zoom: 67%;" /></p><p>在训练时，将其图像被馈送的数字提供给编码器和解码器。在这种情况下，它将被表示为一个热向量。</p><p>要生成特定数字的图像，只需将该数字与从标准正态分布采样的潜在空间中的随机点一起输入解码器即可。即使输入同一点来产生两个不同的数字，这个过程也会正确工作，因为系统不再依赖潜在空间来编码你正在处理的数字。相反，潜在空间对其他信息进行编码，如笔划宽度或数字写入的角度。</p><p><img data-src="https://s2.loli.net/2023/09/04/HCPMwute1Z2LBV7.png" alt="image-20230904223354814" style="zoom:50%;" /></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/4-ComputerVision/09-Autoencoders/README.md">AI-For-Beginners/lessons/4-ComputerVision/09-Autoencoders/README.md at main · microsoft/AI-For-Beginners (github.com)</a></li><li><a href="https://arxiv.org/pdf/2201.03898.pdf">*2201.03898.pdf (arxiv.org)</a></li><li><a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained">Kullback-Leibler Divergence Explained — Count Bayesie</a></li><li><a href="https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians">normal distribution - KL divergence between two univariate Gaussians - Cross Validated (stackexchange.com)</a></li><li><a href="https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/">Adversarial Autoencoders (with Pytorch) (paperspace.com)</a></li><li><a href="https://ijdykeman.github.io/ml/2016/12/21/cvae.html">Conditional Variational Autoencoders (ijdykeman.github.io)</a></li><li><a href="https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important">mathematical statistics - How does the reparameterization trick for VAEs work and why is it important? - Cross Validated (stackexchange.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;这种encoder-decoder结构很重要,同时也可以作为学习GAN的前置&lt;br&gt;</summary>
    
    
    
    
    <category term="VAE" scheme="https://www.sekyoro.top/tags/VAE/"/>
    
    <category term="autoencoder" scheme="https://www.sekyoro.top/tags/autoencoder/"/>
    
  </entry>
  
  <entry>
    <title>深度学习基础知识(二)</title>
    <link href="https://www.sekyoro.top/2023/08/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86(%E4%BA%8C)/"/>
    <id>https://www.sekyoro.top/2023/08/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86(%E4%BA%8C)/</id>
    <published>2023-08-12T10:16:29.000Z</published>
    <updated>2023-08-18T02:49:56.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>深度学习知识第二部分</p><span id="more"></span><h3 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><p>解决序列数据</p><p>输入数据的数量这个数字将会随着我们遇到的数据量的增加而增加， 因此需要一个近似方法来使这个计算变得容易处理。 本章后面的大部分内容将围绕着如何有效估计<img data-src="https://s2.loli.net/2023/08/11/c82anIiD6Cmr9OE.png" alt="image-20230811182733764">展开。 简单地说，它归结为以下两种策略。</p><p>第一种策略，假设在现实情况下相当长的序列可能是不必要的， 因此我们只需要满足某个长度为l的时间跨度。 当下获得的最直接的好处就是参数的数量总是不变的， 至少在t&gt;l时如此，这就使我们能够训练一个上面提及的深度网络。 这种模型被称为<em>自回归模型</em>（autoregressive models）， 因为它们是对自己执行回归。</p><p>第二种策略， 是保留一些对过去观测的总结ℎ， 并且同时更新预测和总结ℎ。 这就产生了基于<img data-src="https://s2.loli.net/2023/08/11/RZ8LQh2qyYW4Su6.png" alt="image-20230811182855054">计x， 以及公式<img data-src="https://s2.loli.net/2023/08/11/2mkvsVQXMIpajlY.png" alt="image-20230811182927632">更新的模型。 由于ℎ从未被观测到，这类模型也被称为 <em>隐变量自回归模型</em>（latent autoregressive models</p><p><img data-src="https://zh-v2.d2l.ai/_images/sequence-model.svg" alt="../_images/sequence-model.svg"></p><h4 id="文本预处理方式"><a href="#文本预处理方式" class="headerlink" title="文本预处理方式"></a>文本预处理方式</h4><p>步骤通常包括：</p><ol><li>将文本作为字符串加载到内存中。</li><li>将字符串拆分为词元（如单词和字符）。</li><li>建立一个词表，将拆分的词元映射到数字索引。</li><li>将文本转换为数字索引序列，方便模型操作。</li></ol><p><em>词元</em>（token）是文本的基本单位，词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，通常也叫做<em>词表</em>（vocabulary）， 用来将字符串类型的词元映射到从0开始的数字索引中。</p><p>将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为<em>语料</em>（corpus）。 然后根据每个唯一词元的出现频率，为其分配一个数字索引。 很少出现的词元通常被移除，这可以降低复杂性。 另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元“<unk>”。 我们可以选择增加一个列表，用于保存那些被保留的词元， 例如：填充词元（“<pad>”）； 序列开始词元（“<bos>”）； 序列结束词元（“<eos>”）。</p><p>自然语言特征:</p><ol><li><p>词频以一种明确的方式迅速衰减。 将前几个单词作为例外消除后，剩余的所有单词大致遵循双对数坐标图上的一条直线。 这意味着单词的频率满足<em>齐普夫定律</em>（Zipf’s law），</p><p><img data-src="https://s2.loli.net/2023/08/12/5CnHizhOuTlW1wc.png" alt="image-20230812181916062"></p></li><li><p>除了一元语法词，单词序列似乎也遵循齐普夫定律， 尽管公式中的指数α更小 （指数的大小受序列长度的影响）；</p></li><li>词表中n元组的数量并没有那么大，这说明语言中存在相当多的结构， 这些结构给了我们应用模型的希望；</li><li>很多n元组很少出现，这使得拉普拉斯平滑非常不适合语言建模。 作为代替，我们将使用基于深度学习的模型。</li></ol><h3 id="循环神经网络-1"><a href="#循环神经网络-1" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><p><img data-src="https://zh.d2l.ai/_images/rnn.svg" alt="../_images/rnn.svg" style="zoom: 67%;" /></p><h4 id="隐状态"><a href="#隐状态" class="headerlink" title="隐状态"></a>隐状态</h4><p><img data-src="https://s2.loli.net/2023/08/16/zpKICRmb4FvML2g.png" alt="image-20230815235353077"></p><p>隐状态H,有上一个隐状态与本次输入控制.</p><p><img data-src="https://s2.loli.net/2023/08/16/kWAnvRDGEHc2Bxi.png" alt="image-20230816000019295"></p><p>输出O</p><h4 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h4><p><img data-src="https://s2.loli.net/2023/08/16/EPUuOp3Gf1Szlxq.png" alt="image-20230816130933516"></p><h4 id="简单的RNN缺点"><a href="#简单的RNN缺点" class="headerlink" title="简单的RNN缺点"></a>简单的RNN缺点</h4><ul><li>我们可能会遇到这样的情况：早期观测值对预测所有未来观测值具有非常重要的意义。 考虑一个极端情况，其中第一个观测值包含一个校验和， 目标是在序列的末尾辨别校验和是否正确。 在这种情况下，第一个词元的影响至关重要。 我们希望有某些机制能够在一个记忆元里存储重要的早期信息。 如果没有这样的机制，我们将不得不给这个观测值指定一个非常大的梯度， 因为它会影响所有后续的观测值。</li><li>我们可能会遇到这样的情况：一些词元没有相关的观测值。 例如，在对网页内容进行情感分析时， 可能有一些辅助HTML代码与网页传达的情绪无关。 我们希望有一些机制来<em>跳过</em>隐状态表示中的此类词元。</li><li>我们可能会遇到这样的情况：序列的各个部分之间存在逻辑中断。 例如，书的章节之间可能会有过渡存在， 或者证券的熊市和牛市之间可能会有过渡存在。 在这种情况下，最好有一种方法来<em>重置</em>我们的内部状态表示</li></ul><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><blockquote><p>门控循环单元与普通的循环神经网络之间的关键区别在于： 前者支持隐状态的门控。 这意味着模型有专门的机制来确定应该何时更新隐状态， 以及应该何时重置隐状态。 这些机制是可学习的，并且能够解决了上面列出的问题。 例如，如果第一个词元非常重要， 模型将学会在第一次观测之后不更新隐状态。 同样，模型也可以学会跳过不相关的临时观测。 最后，模型还将学会在需要的时候重置隐状态。 下面我们将详细讨论各类门控</p></blockquote><p>引入重置门和更新门. 输入是由当前时间步的输入和前一时间步的隐状态给出。 两个门的输出是由使用sigmoid激活函数的两个全连接层给</p><p><img data-src="https://zh-v2.d2l.ai/_images/gru-1.svg" alt="../_images/gru-1.svg" style="zoom: 67%;" /></p><p>利用重置门的输出与常规隐状态集成,得到一个候选隐状态.如如果重置门输出为1,则是普通的隐状态,由本次输入与上次隐状态作为输入,如果重置门输出为0,则候选隐状态只受输入影响,也就是进行了重置.</p><script type="math/tex; mode=display">\tilde{\mathbf{H}}_t=\tanh \left(\mathbf{X}_t \mathbf{W}_{x h}+\left(\mathbf{R}_t \odot \mathbf{H}_{t-1}\right) \mathbf{W}_{h h}+\mathbf{b}_h\right),</script><p><img data-src="https://zh-v2.d2l.ai/_images/gru-2.svg" alt="../_images/gru-2.svg"></p><p>结合更新门确定最终隐状态,如果输出为1,不进行更新,保持之前的隐状态,如果是0则将候选隐状态作为新的隐状态.</p><script type="math/tex; mode=display">\mathbf{H}_t=\mathbf{Z}_t \odot \mathbf{H}_{t-1}+\left(1-\mathbf{Z}_t\right) \odot \tilde{\mathbf{H}}_t .</script><p><img data-src="https://zh-v2.d2l.ai/_images/gru-3.svg" alt="../_images/gru-3.svg"></p><blockquote><ul><li>门控循环神经网络可以更好地捕获时间步距离很长的序列上的依赖关系。</li><li>重置门有助于捕获序列中的短期依赖关系。</li><li>更新门有助于捕获序列中的长期依赖关系。</li><li>重置门打开时，门控循环单元包含基本循环神经网络；更新门打开时，门控循环单元可以跳过子序列。</li></ul></blockquote><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>从时间上来说,LSTM比GRU结构要早,结构也更复杂.</p><blockquote><ul><li>可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。 长短期记忆网络引入了<em>记忆元</em>（memory cell），或简称为<em>单元</em>（cell）。 有些文献认为记忆元是隐状态的一种特殊类型， 它们与隐状态具有相同的形状，其设计目的是用于记录附加的信息。 为了控制记忆元，我们需要许多门。 其中一个门用来从单元中输出条目，我们将其称为<em>输出门</em>（output gate）。 另外一个门用来决定何时将数据读入单元，我们将其称为<em>输入门</em>（input gate）。 我们还需要一种机制来重置单元的内容，由<em>遗忘门</em>（forget gate）来管理， 这种设计的动机与门控循环单元相同， 能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。</li></ul></blockquote><p>引入输入门,忘记门,输出门用于控制隐状态.</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{I}_t & =\sigma\left(\mathbf{X}_t \mathbf{W}_{x i}+\mathbf{H}_{t-1} \mathbf{W}_{h i}+\mathbf{b}_i\right), \\\mathbf{F}_t & =\sigma\left(\mathbf{X}_t \mathbf{W}_{x f}+\mathbf{H}_{t-1} \mathbf{W}_{h f}+\mathbf{b}_f\right), \\\mathbf{O}_t & =\sigma\left(\mathbf{X}_t \mathbf{W}_{x o}+\mathbf{H}_{t-1} \mathbf{W}_{h o}+\mathbf{b}_o\right),\end{aligned}</script><p>同时还有候选记忆元,</p><script type="math/tex; mode=display">\tilde{\mathbf{C}}_t=\tanh \left(\mathbf{X}_t \mathbf{W}_{x c}+\mathbf{H}_{t-1} \mathbf{W}_{h c}+\mathbf{b}_c\right)</script><p><img data-src="https://zh-v2.d2l.ai/_images/lstm-1.svg" alt="../_images/lstm-1.svg"></p><p>利用忘记门和输入门控制上一次的记忆元和候选记忆元,隐状态的计算就是根据输出门和记忆元.</p><script type="math/tex; mode=display">\mathbf{H}_t=\mathbf{O}_t \odot \tanh \left(\mathbf{C}_t\right)</script><p>只要输出门接近1，就能够有效地将所有记忆信息传递给预测部分，而对于输出门接近0，我们只保留记忆元内的所有信息，而不需要更新隐状态。</p><p><img data-src="https://zh-v2.d2l.ai/_images/lstm-3.svg" alt="../_images/lstm-3.svg"></p><h3 id="深度循环神经网络"><a href="#深度循环神经网络" class="headerlink" title="深度循环神经网络"></a>深度循环神经网络</h3><p><img data-src="https://zh-v2.d2l.ai/_images/deep-rnn.svg" alt="../_images/deep-rnn.svg" style="zoom: 80%;" /></p><script type="math/tex; mode=display">\mathbf{H}_t^{(l)}=\phi_l\left(\mathbf{H}_t^{(l-1)} \mathbf{W}_{x h}^{(l)}+\mathbf{H}_{t-1}^{(l)} \mathbf{W}_{h h}^{(l)}+\mathbf{b}_h^{(l)}\right)</script><script type="math/tex; mode=display">\mathbf{H}_t^{(l)}=\phi_l\left(\mathbf{H}_t^{(l-1)} \mathbf{W}_{x h}^{(l)}+\mathbf{H}_{t-1}^{(l)} \mathbf{W}_{h h}^{(l)}+\mathbf{b}_h^{(l)}\right)</script><script type="math/tex; mode=display">\mathbf{O}_t=\mathbf{H}_t^{(L)} \mathbf{W}_{h q}+\mathbf{b}_q</script><p>与多层感知机一样，隐藏层数目L和隐藏单元数目ℎ都是超参数。 也就是说，它们可以由我们调整的。 另外，用门控循环单元或长短期记忆网络的隐状态 来代替隐状态进行计算， 可以很容易地得到深度门控循环神经网络或深度长短期记忆神经网络。</p><ul><li>在深度循环神经网络中，隐状态的信息被传递到当前层的下一时间步和下一层的当前时间步。</li><li>有许多不同风格的深度循环神经网络， 如长短期记忆网络、门控循环单元、或经典循环神经网络。 这些模型在深度学习框架的高级API中都有涵盖。</li><li>总体而言，深度循环神经网络需要大量的调参（如学习率和修剪） 来确保合适的收敛，模型的初始化也需要谨慎。</li></ul><h3 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h3><p>处在序列中间的文字明显可以收到两边的影响.</p><p><img data-src="https://zh-v2.d2l.ai/_images/birnn.svg" alt="../_images/birnn.svg"></p><p>其中ℎ是隐藏单元的数目。 前向和反向隐状态的更新如下</p><script type="math/tex; mode=display">\begin{aligned}& \overrightarrow{\mathbf{H}}_t=\phi\left(\mathbf{X}_t \mathbf{W}_{x h}^{(f)}+\overrightarrow{\mathbf{H}}_{t-1} \mathbf{W}_{h h}^{(f)}+\mathbf{b}_h^{(f)}\right) \\& \overleftarrow{\mathbf{H}}_t=\phi\left(\mathbf{X}_t \mathbf{W}_{x h}^{(b)}+\overleftarrow{\mathbf{H}}_{t+1} \mathbf{W}_{h h}^{(b)}+\mathbf{b}_h^{(b)}\right)\end{aligned}</script><script type="math/tex; mode=display">\mathbf{O}_t=\mathbf{H}_t \mathbf{W}_{h q}+\mathbf{b}_q .</script><blockquote><p>双向循环神经网络的一个关键特性是：使用来自序列两端的信息来估计输出。 也就是说，我们使用来自过去和未来的观测信息来预测当前的观测。 但是在对下一个词元进行预测的情况中，这样的模型并不是我们所需的。 因为在预测下一个词元时，我们终究无法知道下一个词元的下文是什么， 所以将不会得到很好的精度。 具体地说，在训练期间，我们能够利用过去和未来的数据来估计现在空缺的词； 而在测试期间，我们只有过去的数据，因此精度将会很差。</p><p>另一个严重问题是，双向循环神经网络的计算速度非常慢。 其主要原因是网络的前向传播需要在双向层中进行前向和后向递归， 并且网络的反向传播还依赖于前向传播的结果。 因此，梯度求解将有一个非常长的链</p></blockquote><p>双向层的使用在实践中非常少，并且仅仅应用于部分场合。 例如，<strong>填充缺失的单词</strong>、<strong>词元注释</strong>（例如，用于命名实体识别） 以及作为序列处理流水线中的一个步骤<strong>对序列进行编码</strong></p><h4 id="数据集一般处理流程"><a href="#数据集一般处理流程" class="headerlink" title="数据集一般处理流程"></a>数据集一般处理流程</h4><p>将数据进行预处理(比如替换不间断空格,小写,单词和标点之间插入空格)、词元化后得到词元之后,建立词表.</p><p>由于机器翻译数据集由语言对组成， 因此我们可以分别为源语言和目标语言构建两个词表。 使用单词级词元化时，词表大小将明显大于使用字符级词元化时的词表大小。 为了缓解这一问题，这里我们将<strong>出现次数少于2次的低频率词元 视为相同的未知（“<unk>”）词元</strong>。 除此之外，我们还指定了额外的特定词元， 例如在<strong>小批量时用于将序列填充到相同长度的填充词元（“<pad>”）</strong>， 以及<strong>序列的开始词元（“<bos>”）和结束词元（“<eos>”）</strong>。 这些特殊词元在自然语言处理任务中比较常见.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">truncate_pad</span>(<span class="params">line, num_steps, padding_token</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;截断或填充文本序列&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(line) &gt; num_steps:</span><br><span class="line">        <span class="keyword">return</span> line[:num_steps]  <span class="comment"># 截断</span></span><br><span class="line">    <span class="keyword">return</span> line + [padding_token] * (num_steps - <span class="built_in">len</span>(line))  <span class="comment"># 填充</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_array_nmt</span>(<span class="params">lines, vocab, num_steps</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;将机器翻译的文本序列转换成小批量&quot;&quot;&quot;</span></span><br><span class="line">    lines = [vocab[l] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    lines = [l + [vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    array = np.array([truncate_pad(</span><br><span class="line">        l, num_steps, vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]) <span class="keyword">for</span> l <span class="keyword">in</span> lines])</span><br><span class="line">    valid_len = (array != vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]).astype(np.int32).<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> array, valid_len</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>机器翻译指的是将文本序列从一种语言自动翻译成另一种语言。</li><li>使用单词级词元化时的词表大小，将明显大于使用字符级词元化时的词表大小。为了缓解这一问题，我们可以将低频词元视为相同的未知词元。</li><li>通过截断和填充文本序列，可以保证所有的文本序列都具有相同的长度，以便以小批量的方式加载。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_nmt</span>(<span class="params">batch_size, num_steps, num_examples=<span class="number">600</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回翻译数据集的迭代器和词表&quot;&quot;&quot;</span></span><br><span class="line">    text = preprocess_nmt(read_data_nmt())</span><br><span class="line">    source, target = tokenize_nmt(text, num_examples)</span><br><span class="line">    src_vocab = d2l.Vocab(source, min_freq=<span class="number">2</span>,</span><br><span class="line">                          reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line">    tgt_vocab = d2l.Vocab(target, min_freq=<span class="number">2</span>,</span><br><span class="line">                          reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line">    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)</span><br><span class="line">    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)</span><br><span class="line">    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)</span><br><span class="line">    data_iter = d2l.load_array(data_arrays, batch_size)</span><br><span class="line">    <span class="keyword">return</span> data_iter, src_vocab, tgt_vocab</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_nmt</span>(<span class="params">batch_size, num_steps, num_examples=<span class="number">600</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回翻译数据集的迭代器和词表&quot;&quot;&quot;</span></span><br><span class="line">    text = preprocess_nmt(read_data_nmt())</span><br><span class="line">    source, target = tokenize_nmt(text, num_examples)</span><br><span class="line">    src_vocab = d2l.Vocab(source, min_freq=<span class="number">2</span>,</span><br><span class="line">                          reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line">    tgt_vocab = d2l.Vocab(target, min_freq=<span class="number">2</span>,</span><br><span class="line">                          reserved_tokens=[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line">    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)</span><br><span class="line">    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)</span><br><span class="line">    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)</span><br><span class="line">    data_iter = d2l.load_array(data_arrays, batch_size)</span><br><span class="line">    <span class="keyword">return</span> data_iter, src_vocab, tgt_vocab</span><br></pre></td></tr></table></figure><h3 id="编码器-解码器架构"><a href="#编码器-解码器架构" class="headerlink" title="编码器-解码器架构"></a>编码器-解码器架构</h3><p><img data-src="https://zh-v2.d2l.ai/_images/encoder-decoder.svg" alt="../_images/encoder-decoder.svg"></p><p>前面处理机器翻译时输入和输出长度都是固定的.</p><p>机器翻译是序列转换模型的一个核心问题， 其输入和输出都是长度可变的序列。 为了处理这种类型的输入和输出， 我们可以设计一个包含两个主要组件的架构： 第一个组件是一个<em>编码器</em>（encoder）： 它接受一个长度可变的序列作为输入， 并将其转换为具有固定形状的编码状态。 第二个组件是<em>解码器</em>（decoder）： 它将固定形状的编码状态映射到长度可变的序列。 这被称为<em>编码器-解码器</em>（encoder-decoder）架构.</p><ul><li>“编码器－解码器”架构可以将长度可变的序列作为输入和输出，因此适用于机器翻译等序列转换问题。</li><li>编码器将长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。</li><li>解码器将具有固定形状的编码状态映射为长度可变的序列。</li></ul><h3 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h3><blockquote><p>遵循编码器－解码器架构的设计原则， 循环神经网络编码器使用长度可变的序列作为输入， 将其转换为固定形状的隐状态。 换言之，输入序列的信息被<em>编码</em>到循环神经网络编码器的隐状态中。 为了连续生成输出序列的词元， 独立的循环神经网络解码器是基于输入序列的编码信息 和输出序列已经看见的或者生成的词元来预测下一个词元</p></blockquote><p><img data-src="https://zh-v2.d2l.ai/_images/seq2seq.svg" alt="../_images/seq2seq.svg"></p><h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><script type="math/tex; mode=display">\mathbf{h}_{t}=f(\mathbf{x}_{t},\mathbf{h}_{t-1}).</script><p>隐状态根据本次输入和上次的隐状态输出.</p><script type="math/tex; mode=display">\mathbf{c}=q(\mathbf{h}_1,\ldots,\mathbf{h}_T).</script><p>常常会使用一个嵌入层,获得输入序列中每个词元的特征向量。 嵌入层的权重是一个矩阵， 其行数等于输入词表的大小（<code>vocab_size</code>）， 其列数等于特征向量的维度（<code>embed_size</code>）。 对于任意输入词元的索引i， 嵌入层获取权重矩阵的第i行（从0开始）以返回其特征向量</p><h4 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h4><script type="math/tex; mode=display">\mathbf{s}_{t^{\prime}}=g(y_{t^{\prime}-1},\mathbf{c},\mathbf{s}_{t^{\prime}-1}).</script><p>在获得解码器的隐状态之后， 我们可以使用输出层和softmax操作 来计算在时间步t′时输出y~t~′的条件概率分布</p><p>损失函数使用交叉熵,在每个时间步，解码器预测了输出词元的概率分布。 类似于语言模型，可以使用softmax来获得分布， 并通过计算交叉熵损失函数来进行优化,此外应该将填充词元的预测排除在损失函数的计算之外屏蔽不相关项.</p><h4 id="训练与预测"><a href="#训练与预测" class="headerlink" title="训练与预测"></a>训练与预测</h4><p>训练时,特定的序列开始词元（“<bos>”）和 原始的输出序列（不包括序列结束词元“<eos>”） 拼接在一起作为解码器的输入。 这被称为<em>强制教学</em>（teacher forcing）， 因为原始的输出序列（词元的标签）被送入解码器。 或者，将来自上一个时间步的<em>预测</em>得到的词元作为解码器的当前输入.</p><p>预测时,为了采用一个接着一个词元的方式预测输出序列， 每个解码器当前时间步的输入都将来自于前一时间步的预测词元。 与训练类似，序列开始词元（“<bos>”） 在初始时间步被输入到解码器中.</p><p><img data-src="https://zh-v2.d2l.ai/_images/seq2seq-predict.svg" alt="../_images/seq2seq-predict.svg"></p><h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p><img data-src="https://zh-v2.d2l.ai/_images/qkv.svg" alt="../_images/qkv.svg"></p><p>将注意力简单地分为自主性和非自主性,利用这两种注意力提示,用神经网络来设计注意力机制的框架.</p><p>“是否包含自主性提示”将注意力机制与全连接层或汇聚层区别开来。 在注意力机制的背景下，自主性提示被称为<em>查询</em>（query）。 给定任何查询，注意力机制通过<em>注意力汇聚</em>（attention pooling） 将选择引导至<em>感官输入</em>（sensory inputs，例如中间特征表示）。 在注意力机制中，这些感官输入被称为<em>值</em>（value）。 更通俗的解释，每个值都与一个<em>键</em>（key）配对， 这可以想象为感官输入的非自主提示。 </p><ul><li>人类的注意力是有限的、有价值和稀缺的资源。</li><li>受试者使用非自主性和自主性提示有选择性地引导注意力。前者基于突出性，后者则依赖于意识。</li><li>注意力机制与全连接层或者汇聚层的区别源于增加的自主提示。</li><li>由于包含了自主性提示，注意力机制与全连接的层或汇聚层不同。</li><li>注意力机制通过注意力汇聚使选择偏向于值（感官输入），其中包含查询（自主性提示）和键（非自主性提示）。键和值是成对的。</li><li>可视化查询和键之间的注意力权重是可行的。</li></ul><p><img data-src="https://zh-v2.d2l.ai/_images/attention-output.svg" alt="../_images/attention-output.svg"></p><p>高斯核指数部分可以视为<em>注意力评分函数</em>（attention scoring function）， 简称<em>评分函数</em>（scoring function）， 然后把这个函数的输出结果输入到softmax函数中进行运算。 通过上述步骤，将得到与键对应的值的概率分布（即注意力权重）。 最后，注意力汇聚的输出就是基于这些注意力权重的值的加权和</p><script type="math/tex; mode=display">f(\mathbf{q},(\mathbf{k}_1,\mathbf{v}_1),\ldots,(\mathbf{k}_m,\mathbf{v}_m))=\sum_{i=1}^m\alpha(\mathbf{q},\mathbf{k}_i)\mathbf{v}_i\in\mathbb{R}^v,</script><script type="math/tex; mode=display">\alpha(\mathbf{q},\mathbf{k}_i)=\mathrm{softmax}(a(\mathbf{q},\mathbf{k}_i))=\frac{\exp(a(\mathbf{q},\mathbf{k}_i))}{\sum_{j=1}^m\exp(a(\mathbf{q},\mathbf{k}_j))}\in\mathbb{R}.</script><p>注意力机制涉及到q,k,v分别代表查询,键,值. 计算注意力评分有多种方法,常用的有加性注意力和缩放点积注意力.</p><script type="math/tex; mode=display">a(\mathbf{q}, \mathbf{k})=\mathbf{w}_v^{\top} \tanh \left(\mathbf{W}_q \mathbf{q}+\mathbf{W}_k \mathbf{k}\right) \in \mathbb{R}</script><script type="math/tex; mode=display">\operatorname{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt d}\right)\mathbf{V}\in\mathbb{R}^{n\times v}.</script><p>有了评分函数后,继续考虑注意力模型问题.循环神经网络编码器将长度可变的序列转换为固定形状的上下文变量， 然后循环神经网络解码器<strong>根据生成的词元和上下文变量</strong> 按词元生成输出（目标）序列词元。</p><blockquote><p>即使并非所有输入（源）词元都对解码某个词元都有用， 在每个解码步骤中仍使用编码<em>相同</em>的上下文变量。 有什么方法能改变上下文变量呢</p></blockquote><h4 id="Bahdanau注意力"><a href="#Bahdanau注意力" class="headerlink" title="Bahdanau注意力"></a>Bahdanau注意力</h4><p>在预测词元时，如果不是所有输入词元都相关，模型将仅对齐（或参与）输入序列中与当前预测相关的部分。这是通过<strong>将上下文变量视为注意力集中的输出</strong>来实现的.</p><p>其中解码时间步t~’~都会被c~t’~替换,是作为查询(query)的上一步解码器隐状态和与编码器隐状态</p><script type="math/tex; mode=display">\mathbf{c}_{t^{\prime}}=\sum_{t=1}^T\alpha(\mathbf{s}_{t^{\prime}-1},\mathbf{h}_t)\mathbf{h}_t,</script><p>时间步t′−1时的解码器隐状态s~t~′−1是查询， 编码器隐状态ℎ~t~既是键，也是值. 注意力权重可以使用加性注意力打分.</p><p><img data-src="https://zh-v2.d2l.ai/_images/seq2seq-attention-details.svg" alt="../_images/seq2seq-attention-details.svg"></p><p>定义Bahdanau注意力,只需要改变解码器就行了.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seq2SeqAttentionDecoder</span>(<span class="params">AttentionDecoder</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embed_size, num_hiddens, num_layers,</span></span></span><br><span class="line"><span class="params"><span class="function">                 dropout=<span class="number">0</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Seq2SeqAttentionDecoder, self).__init__(**kwargs)</span><br><span class="line">        self.attention = d2l.AdditiveAttention(</span><br><span class="line">            num_hiddens, num_hiddens, num_hiddens, dropout)</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_size)</span><br><span class="line">        self.rnn = nn.GRU(</span><br><span class="line">            embed_size + num_hiddens, num_hiddens, num_layers,</span><br><span class="line">            dropout=dropout)</span><br><span class="line">        self.dense = nn.Linear(num_hiddens, vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_state</span>(<span class="params">self, enc_outputs, enc_valid_lens, *args</span>):</span></span><br><span class="line">        <span class="comment"># outputs的形状为(batch_size，num_steps，num_hiddens).</span></span><br><span class="line">        <span class="comment"># hidden_state的形状为(num_layers，batch_size，num_hiddens)</span></span><br><span class="line">        outputs, hidden_state = enc_outputs</span><br><span class="line">        <span class="keyword">return</span> (outputs.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>), hidden_state, enc_valid_lens)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X, state</span>):</span></span><br><span class="line">        <span class="comment"># enc_outputs的形状为(batch_size,num_steps,num_hiddens).</span></span><br><span class="line">        <span class="comment"># hidden_state的形状为(num_layers,batch_size,</span></span><br><span class="line">        <span class="comment"># num_hiddens)</span></span><br><span class="line">        enc_outputs, hidden_state, enc_valid_lens = state</span><br><span class="line">        <span class="comment"># 输出X的形状为(num_steps,batch_size,embed_size)</span></span><br><span class="line">        X = self.embedding(X).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">        outputs, self._attention_weights = [], []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> X:</span><br><span class="line">            <span class="comment"># query的形状为(batch_size,1,num_hiddens)</span></span><br><span class="line">            query = torch.unsqueeze(hidden_state[-<span class="number">1</span>], dim=<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># context的形状为(batch_size,1,num_hiddens)</span></span><br><span class="line">            context = self.attention(</span><br><span class="line">                query, enc_outputs, enc_outputs, enc_valid_lens)</span><br><span class="line">            <span class="comment"># 在特征维度上连结</span></span><br><span class="line">            x = torch.cat((context, torch.unsqueeze(x, dim=<span class="number">1</span>)), dim=-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 将x变形为(1,batch_size,embed_size+num_hiddens)</span></span><br><span class="line">            out, hidden_state = self.rnn(x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>), hidden_state)</span><br><span class="line">            outputs.append(out)</span><br><span class="line">            self._attention_weights.append(self.attention.attention_weights)</span><br><span class="line">        <span class="comment"># 全连接层变换后，outputs的形状为</span></span><br><span class="line">        <span class="comment"># (num_steps,batch_size,vocab_size)</span></span><br><span class="line">        outputs = self.dense(torch.cat(outputs, dim=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> outputs.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>), [enc_outputs, hidden_state,</span><br><span class="line">                                          enc_valid_lens]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">attention_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._attention_weights</span><br></pre></td></tr></table></figure><p>首先，初始化解码器的状态，需要下面的输入：</p><p><strong>编码器</strong>在所有时间步的<strong>最终层隐状态，将作为注意力的键和值</strong>；</p><p><strong>上一时间步的编码器全层隐状态，将作为初始化解码器的隐状态</strong>；</p><p><strong>编码器有效长度</strong>（排除在注意力池中填充词元）。</p><p>结合了注意力机制与编码器-解码器,使得解码器中每个解码时间步是注意力模型的输出,查询q是上一步的隐状态,键和值都是编码器的最终隐状态.</p><h3 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h3><blockquote><p>在实践中，当给定相同的查询、键和值的集合时， 我们希望模型可以基于相同的注意力机制学习到不同的行为， 然后将不同的行为作为知识组合起来， 捕获序列内各种范围的依赖关系 （例如，短距离依赖和长距离依赖关系）。 因此，允许注意力机制组合使用查询、键和值的不同 <em>子空间表示</em>（representation subspaces）可能是有益的</p></blockquote><p><img data-src="https://zh-v2.d2l.ai/_images/multi-head-attention.svg" alt="../_images/multi-head-attention.svg"></p><p>可以用独立学习得到的ℎ组不同的<em>线性投影</em>（linear projections）来变换查询、键和值。 然后，这ℎ组变换后的查询、键和值将并行地送到注意力汇聚中。 最后，将这ℎ个注意力汇聚的输出拼接在一起， 并且通过另一个可以学习的线性投影进行变换， 以产生最终输出。</p><p>多头注意力机制,对于h个注意力汇聚输出,每一个注意力汇聚都被称作一个”头”.</p><script type="math/tex; mode=display">\mathbf{h}_i=f(\mathbf{W}_i^{(q)}\mathbf{q},\mathbf{W}_i^{(k)}\mathbf{k},\mathbf{W}_i^{(v)}\mathbf{v})\in\mathbb{R}^{p_v},</script><script type="math/tex; mode=display">\mathbf{W}_o\begin{bmatrix}\mathbf{h}_1\\\vdots\\\mathbf{h}_h\end{bmatrix}\in\mathbb{R}^{p_o}.</script><p>其中的W均是可学习的参数,f是注意力汇聚的函数.</p><ul><li>多头注意力融合了来自于多个注意力汇聚的不同知识，这些知识的不同来源于相同的查询、键和值的不同的子空间表示。</li><li>基于适当的张量操作，可以实现多头注意力的并行计算。</li></ul><h3 id="自注意力和位置编码"><a href="#自注意力和位置编码" class="headerlink" title="自注意力和位置编码"></a>自注意力和位置编码</h3><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;深度学习知识第二部分&lt;/p&gt;</summary>
    
    
    
    
    <category term="deepLearning" scheme="https://www.sekyoro.top/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>GAN深入学习</title>
    <link href="https://www.sekyoro.top/2023/08/11/GAN%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/08/11/GAN%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-08-11T10:08:06.000Z</published>
    <updated>2023-10-23T02:19:10.849Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>深入GAN学习<br><span id="more"></span></p><p><img data-src="https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/10-GANs/images/gan_architecture.png" alt="img"></p><p>注意,实验复现时最好设置随机种子固定<a href="https://pytorch.org/docs/stable/notes/randomness.html">Reproducibility — PyTorch 2.0 documentation</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># seed setting</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">same_seeds</span>(<span class="params">seed</span>):</span></span><br><span class="line">    <span class="comment"># Python built-in random module</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    <span class="comment"># Numpy</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    <span class="comment"># Torch</span></span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed(seed)</span><br><span class="line">        torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">same_seeds(<span class="number">2023</span>)</span><br></pre></td></tr></table></figure><h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><p>标题<strong>Generative Adversarial Nets</strong> 2014年</p><p><strong>摘要</strong></p><p>We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1 2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples</p><p><img data-src="https://pic4.zhimg.com/80/v2-044f8d58f378b088c9a85a8f19dae363_720w.webp" alt="img" style="zoom:67%;" /></p><p>主要贡献:提出GAN  定义G和D以及损失函数.由于GAN中使用的极小极大（minmax）优化，训练可能非常不稳定。</p><script type="math/tex; mode=display">\min_G\max_DV=E_{x\sim\text{p}_r}[\log D(x)]+E_{x\sim\text{p}_g}[\log(1-D(x))]</script><p>存在问题：梯度不稳定,梯度消失,<strong>模式崩溃</strong>(特别是NS-GAN,使用了the - log D trick),也就是生成器的损失改为-logD(x)<a href="https://zhuanlan.zhihu.com/p/25071913">令人拍案叫绝的Wasserstein GAN - 知乎 (zhihu.com)</a></p><p>首先求得生成器固定,最大化V的D</p><script type="math/tex; mode=display">\mathrm{P}_r(x)\log D(x)+P_g(x)\log[1-D(x)]</script><p>对D(x)求导,让导数为0</p><script type="math/tex; mode=display">\begin{aligned}&\frac{\mathrm{P}_r(x)}{D(x)}-\frac{\mathrm{P}_g(x)}{1-D(x)}=0\\\\&\text{化简上式,得最优的D表达式为}.\\\\&D^*(x)=\frac{\mathrm{P}_r(x)}{\mathrm{P}_r(x)+\mathrm{P}_g(x)}\end{aligned}</script><p>将这个最优的D带入一开始的式子</p><script type="math/tex; mode=display">\begin{aligned}&\operatorname*{min}_{G}V=E_{x\sim\mathrm{p}_{r}}[\operatorname{log}D(x)]+E_{x\sim\mathrm{p}_{g}}[\operatorname{log}(1-D(x))] \\&\text{将最大化的D即式}1\text{的}D^*(x)\text{代入式得}: \\&\operatorname*{min}_{G}V=E_{x\sim\mathrm{p}_{r}}[\operatorname{log}(\frac{\mathrm{p}_{r}(x)}{\mathrm{p}_{r}(x)+\mathrm{p}_{g}(x)})]+E_{x\sim\mathrm{p}_{g}}[\operatorname{log}(\frac{\mathrm{p}_{g}(x)}{\mathrm{p}_{r}(x)+\mathrm{p}_{g}(x)})] \\&\text{再化简一步得式:} \\&\min_GV=E_{x\sim\mathrm{p}_r}[\log(\frac{\mathrm{p}_r(x)}{\frac12(\mathrm{p}_r(x)+\mathrm{p}_g(x))})]+E_{x\sim\mathrm{p}_g}[\log(\frac{\mathrm{p}_g(x)}{\frac12(\mathrm{p}_r(x)+\mathrm{p}_g(x))}]-2\log2\end{aligned}</script><p>将JS散度带入,有</p><script type="math/tex; mode=display">\min_GV=2JS(P_r||P_g)-2\log2</script><p>所以当判别器达到固定G情况下最优时,如果两个分布重叠则为JS则为0,否则JS为log2.梯度一直为0,G得不到更新,所以这种原始GAN会面临<strong>梯度消失问题</strong>,导致训练困难.</p><blockquote><p>上述的推导都是建立在最优判别器的基础上的，但是在我们实操过程中往往一开始判别器性能是不理想的，所以生成器还是有梯度更新的</p></blockquote><p>如果使用logD-trick,</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}_{x\sim P_{g}}\left[-\log D^{*}(x)\right]& =KL(P_{g}||P_{r})-\mathbb{E}_{x\sim P_{g}}\log[1-D^{*}(x)]  \\&=KL(P_g||P_r)-2JS(P_r||P_g)+2\log2+\mathbb{E}_{x\sim P_r}[\log D^*(x)]\end{aligned}</script><p>所以最后需要最小化前面两项,因为后面两项与G无关. 这个最小化目标需要同时最小化KL散度又要最大化JS散度,直观上荒谬,数值结果上<strong>导致梯度不稳定</strong>,此外第一项的KL散度表示</p><script type="math/tex; mode=display">P_{g}(x)\log\frac{P_{g}(x)}{P_{r}(x)}</script><p>当P~g~(x)趋近于1,P~r~(x)趋近于0这种情况与当P~g~(x)趋近于0,P~r~(x)趋近于1这种情况对于KL散度情况不一致,由于要最小化KL散度,会导致后者这种情况,也就是</p><p>这种情况下,梯度可能不会消失,但会存在梯度不稳定,模式崩溃的问题.</p><p>以上内容部分是WGAN中的,从理论上解释了GAN训练的一些问题.</p><h4 id="使用tensorboard记录损失"><a href="#使用tensorboard记录损失" class="headerlink" title="使用tensorboard记录损失"></a>使用tensorboard记录损失</h4><p>大致流程是首先将损失计入到一个文件,然后使用tensorboard读取,便能使用tensorboard打开一个端口,在网页上查看。<a href="https://pytorch.org/docs/stable/tensorboard.html">torch.utils.tensorboard — PyTorch 2.0 documentation</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">!pip install tensorboard</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter </span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./logs&#x27;</span>)  </span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,))])</span><br><span class="line">trainset = datasets.MNIST(<span class="string">&#x27;mnist_train&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">model = torchvision.models.resnet50(<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Have ResNet model take in grayscale rather than RGB</span></span><br><span class="line">model.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(trainloader))</span><br><span class="line"></span><br><span class="line">grid = torchvision.utils.make_grid(images)</span><br><span class="line">writer.add_image(<span class="string">&#x27;images&#x27;</span>, grid, <span class="number">0</span>)</span><br><span class="line">writer.add_graph(model, images)</span><br><span class="line"><span class="comment"># 关闭writer</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    x = np.random.random(<span class="number">1000</span>)</span><br><span class="line">    writer.add_histogram(<span class="string">&#x27;distribution centers&#x27;</span>, x + i, i)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><p><img data-src="https://pytorch.org/docs/stable/_images/add_histogram.png" alt="_images/add_histogram.png" style="zoom: 67%;" /></p><p>在google colab使用需要搭配一些magic func</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%load_ext tensorboard  <span class="comment">#使用tensorboard 扩展</span></span><br><span class="line">%tensorboard --logdir logs  <span class="comment">#定位tensorboard读取的文件目录</span></span><br></pre></td></tr></table></figure><h4 id="使用visdom可视化"><a href="#使用visdom可视化" class="headerlink" title="使用visdom可视化"></a>使用visdom可视化</h4><p>visdom一般搭配pytorch,毕竟都是meta的.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pip install visdom</span><br><span class="line">python -m visdom.server</span><br><span class="line">iz = Visdom()</span><br><span class="line">  </span><br><span class="line">viz.line([<span class="number">0.</span>],    <span class="comment">#Y的第一个点</span></span><br><span class="line">         [<span class="number">0.</span>],    <span class="comment">#X的第一个点</span></span><br><span class="line">         win=<span class="string">&quot;train loss&quot;</span>,   <span class="comment">#右上角窗口的名称 </span></span><br><span class="line">         opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;train_loss&#x27;</span>) <span class="comment">#opt的参数都可以用python字典的格式传入，还有很多其他的类似matplotlib美化图形的参数参考官网</span></span><br><span class="line">        )  </span><br><span class="line">        </span><br><span class="line">viz.line([<span class="number">1</span>,],<span class="comment">#Y的下一个点</span></span><br><span class="line">         [<span class="number">1.</span>],<span class="comment">#X的下一个点</span></span><br><span class="line">         win=<span class="string">&quot;train loss&quot;</span>,</span><br><span class="line">         update=<span class="string">&#x27;append&#x27;</span><span class="comment">#添加到下一个点后面</span></span><br><span class="line">         )</span><br></pre></td></tr></table></figure><p>这里还是推荐选择两者之一即可.</p><h3 id="DCGAN"><a href="#DCGAN" class="headerlink" title="*DCGAN"></a>*DCGAN</h3><p>标题<strong>WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS</strong></p><p><strong>intro</strong></p><p>Learning reusable feature representations from large unlabeled datasets has been an area of active research. In the context of computer vision, one can leverage the practically unlimited amount of unlabeled images and videos to learn good intermediate representations, which can then be used on a variety of supervised learning tasks such as image classification. We propose that one way to build good image representations is by training Generative Adversarial Networks (GANs) (Goodfellow et al., 2014), and later reusing parts of the generator and discriminator networks as feature extractors for supervised tasks. GANs provide an attractive alternative to maximum likelihood techniques. One can additionally argue that their learning process and the lack of a heuristic cost function (such as pixel-wise independent mean-square error) are attractive to representation learning. GANs have been known to be unstable to train, often resulting in generators that produce nonsensical outputs. There has been very limited published research in trying to understand and visualize what GANs learn, and the intermediate representations of multi-layer GANs. In this paper, we make the following contributions </p><p>• We propose and evaluate a set of constraints on the architectural topology of Convolutional GANs that make them stable to train in most settings. We name this class of architectures Deep Convolutional GANs (DCGAN) </p><p>• We use the trained discriminators for image classification tasks, showing competitive performance with other unsupervised algorithms. </p><p>• We visualize the filters learnt by GANs and empirically show that specific filters have learned to draw specific objects.</p><p>We show that the generators have interesting vector arithmetic properties allowing for easy manipulation of many semantic qualities of generated sample</p><p>贡献:提出卷积GAN,卷积层替代全连接,使用训练过的判别器用于分类任务,可视化了生成器中的某层,显示出良好的绘制特定对象的能力.生成器的向量显示出能控制样本的语义质量行为.介绍了一些超参的初始化.</p><p>• Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator). </p><p>• Use batchnorm in both the generator and the discriminator. • Remove fully connected hidden layers for deeper architectures. </p><p>• Use ReLU activation in generator for all layers except for the output, which uses Tanh. • Use LeakyReLU activation in the discriminator for all layers</p><p>使用了三个数据集</p><ul><li>批量标准化是两个网络中必须的。</li><li>卷积层替代全连接层。</li><li>使用strided卷积(步幅大于1)可以代替池化</li><li>ReLU激活（<em>几乎</em>总是）会有帮助。</li></ul><p><img data-src="https://s2.loli.net/2023/08/29/L1aVuqWoiDHfS2z.png" alt="image-20230829192803486"></p><p>原论文中D判别函数使用的是ReLU,但现在代码中很多其实还是用的LeakyReLU.此外不使用池化,而是使用deconvolution或者叫分数步长卷积(fractionally-strided convolutions).</p><p><img data-src="https://s2.loli.net/2023/08/29/cktnUB7Lj5g6mlI.png" alt="image-20230829214218494"></p><p>pytorch实现中,D判别器使用nn.AvgPool2d平均池化操作.</p><p><img data-src="https://s2.loli.net/2023/08/30/eIhKBaf3t85gVqx.png" alt="image-20230830120457639"></p><p>layer normalization RNN,nlp任务中,每个token的特征数不同,针对每个token</p><p>instance normalization GAN中,针对单个图像不同的通道</p><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d"><code>InstanceNorm2d</code></a> and <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm"><code>LayerNorm</code></a> are very similar, but have some subtle differences. <a href="https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d"><code>InstanceNorm2d</code></a> is applied on each channel of channeled data like RGB images, but <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm"><code>LayerNorm</code></a> is usually applied on entire sample and often in NLP tasks. Additionally, <a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm"><code>LayerNorm</code></a> applies elementwise affine transform, while <a href="https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d"><code>InstanceNorm2d</code></a> usually don’t apply affine transform</p><p>ConvTranspose2d</p><p>逆卷积fractionally-strided convolutions,可以利用<code>torchsummary</code>这个库查看模型相关信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">myModel = Discriminator().to(DEVICE)</span><br><span class="line">summary(myModel,(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br></pre></td></tr></table></figure><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param #</span><br><span class="line">================================================================</span><br><span class="line">            Conv2d<span class="string">-1</span>          [<span class="string">-1</span>, 512, 14, 14]           4,608</span><br><span class="line">       BatchNorm2d<span class="string">-2</span>          [<span class="string">-1</span>, 512, 14, 14]           1,024</span><br><span class="line">         LeakyReLU<span class="string">-3</span>          [<span class="string">-1</span>, 512, 14, 14]               0</span><br><span class="line">            Conv2d<span class="string">-4</span>            [<span class="string">-1</span>, 256, 7, 7]       1,179,648</span><br><span class="line">       BatchNorm2d<span class="string">-5</span>            [<span class="string">-1</span>, 256, 7, 7]             512</span><br><span class="line">         LeakyReLU<span class="string">-6</span>            [<span class="string">-1</span>, 256, 7, 7]               0</span><br><span class="line">            Conv2d<span class="string">-7</span>            [<span class="string">-1</span>, 128, 4, 4]         294,912</span><br><span class="line">       BatchNorm2d<span class="string">-8</span>            [<span class="string">-1</span>, 128, 4, 4]             256</span><br><span class="line">         LeakyReLU<span class="string">-9</span>            [<span class="string">-1</span>, 128, 4, 4]               0</span><br><span class="line">        AvgPool2d<span class="string">-10</span>            [<span class="string">-1</span>, 128, 1, 1]               0</span><br><span class="line">           Linear<span class="string">-11</span>                    [<span class="string">-1</span>, 1]             129</span><br><span class="line">          Sigmoid<span class="string">-12</span>                    [<span class="string">-1</span>, 1]               0</span><br><span class="line">================================================================</span><br><span class="line">Total params: 1,481,089</span><br><span class="line">Trainable params: 1,481,089</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.00</span><br><span class="line">Forward/backward pass size (MB): 2.63</span><br><span class="line">Params size (MB): 5.65</span><br><span class="line">Estimated Total Size (MB): 8.28</span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>我在测试github上一个DCGAN的代码时,发现其在生成器上除了最后一层使用tanh激活函数,其他层都使用leak激活函数,但是这样生成器会逐渐变大.</p><p><img data-src="https://s2.loli.net/2023/08/31/6QlMEzeH8vsLy7S.png" alt="image-20230831165159320" style="zoom:67%;" /></p><p>因为LeakyReLU照顾到了负数,使得每一线性层输出为负值时也有梯度,这样也许能使得生成器跳出</p><h3 id="WGAN"><a href="#WGAN" class="headerlink" title="*WGAN"></a>*WGAN</h3><p>使用EM距离<a href="https://jonathan-hui.medium.com/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490">GAN — Wasserstein GAN &amp; WGAN-GP. Training GAN is hard. Models may never… | by Jonathan Hui | Medium</a></p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><p><img data-src="https://pic1.zhimg.com/80/v2-b783ce95d8bdf1499fc88994e170a02c_720w.webp" alt="img"></p><p>上面这个公式是基于推图距离的计算</p><p><img data-src="https://img1.imgtp.com/2023/09/15/B6W4SQCF.png" alt="image-20230915205616738" style="zoom: 67%;" /></p><p><img data-src="https://pic2.zhimg.com/80/v2-fe9ef30af6166a5eea47c9006bfc27cd_720w.webp" alt=""></p><p>下面是WGAN论文的intro</p><p><img data-src="https://s2.loli.net/2023/09/05/u4hjRmwN5i3E9oG.png" alt="image-20230905224350055" style="zoom: 80%;" /></p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*5jF5gbIDwU6k9m1ILl0Utg.jpeg" alt="img"></p><p>一开始的GAN的损失函数设计被认为有问题,与KL,JS散度有关.</p><script type="math/tex; mode=display">KL(P_1||P_2)=E_{x\sim P_1}log\frac{P_1}{P_2}</script><script type="math/tex; mode=display">KL(P_1||P_2)=\int\limits_xP_1\log\frac{P_1}{P_2}dx\text{或}KL(P_1||P_2)=\sum p_1\log\frac{P_1}{P_2}</script><p>KL散度是熵与交叉熵的差,它不是对称的.</p><p>而JS散度和KL散度是有关联的,可以看出JS散度是对称的,</p><script type="math/tex; mode=display">JS(P_1||P_2)=\frac12KL(P_1||\frac{P_1+P_2}2)+\frac12KL(P_2||\frac{P_1+P_2}2)</script><p>经证明,当两个分布不重叠时,JS散度为log2<a href="https://blog.csdn.net/Invokar/article/details/88917214">GAN：两者分布不重合JS散度为log2的数学证明_为什么深度学习wganjs散度等于log2</a></p><blockquote><p>从理论和经验上来说，真实的数据分布通常是一个<strong>低维流形</strong>，简单地说就是数据不具备高维特性，而是存在一个嵌入在高维度的低维空间内,在实际操作中，我们的维度空间远远不止3维，有可能是上百维，在这样的情况下，数据就更加难于重合.</p></blockquote><p>WGAN打算训练网络得到一个函数,这个函数满足1-Lipschitz,同时也是D辨别器,这样能使得损失函数更有意义,也能解决梯度与模式崩溃问题. </p><p>WGAN贡献:解决GAN训练不稳定与模式崩溃问题,有一个指标(EM距离),这个值越小训练得越好.</p><h4 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN-GP"></a>WGAN-GP</h4><p>这里的GP就是gradient penalty的意思.在发了第一篇GAN的文章之后,作者又发了这篇.</p><blockquote><p>The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often <strong>due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior</strong></p></blockquote><p>WGAN以及其衍生主要都是为了满足Lipschitz constraint,包括后面的Spectral Normalizaton<a href="https://arxiv.org/pdf/1802.05957.pdf">1802.05957.pdf (arxiv.org)</a>.</p><p>意思是强制使用梯度裁剪(clamp)到一个范围会导致不想要的行为,因为本身想要的是让critic满足Lipschitz,所以粗暴地使用了梯度裁剪.</p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*NVBkG5vDwwz-1ad-zwxddA.jpeg" alt="img"></p><p>需要使得判别器f的梯度范数处处小于1,WGAN-GP证明了需要使得在真实数据和生成的数据之间插值的点对于f应该具有1的梯度范数。</p><p>范数有多种.<img data-src="https://img1.imgtp.com/2023/09/17/ZwMIQPEx.png" alt="image-20230917103610368"></p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*TErKpfBkilA-G24FNFg0FA.png" alt="img"></p><p>所以需要使用到梯度,而且是对于输入的梯度,通过限制输入的梯度,而不是WGAN中限制每次模型的weight和bias的值.<a href="https://pytorch.org/docs/stable/generated/torch.autograd.grad.html">torch.autograd.grad — PyTorch 2.0 documentation</a>在pytorch中使用autograd.grad计算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> autograd</span><br><span class="line"><span class="comment"># demo</span></span><br><span class="line">x = torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">x.requires_grad_()</span><br><span class="line">y = torch.<span class="built_in">sum</span>(x**<span class="number">2</span>)</span><br><span class="line">grads = autograd.grad(outputs=y, inputs=x,create_graph=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(grads)</span><br></pre></td></tr></table></figure><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*r8472Sg5fDJ1XKQPUbRC4Q.png" alt=""></p><p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*gi2isFNxtXE-pNiQ_CrZ8w.jpeg" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gradient Penalty (e.g. gradients w.r.t x_penalty)</span></span><br><span class="line">eps = torch.rand(batch_size, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).to(DEVICE) <span class="comment"># x shape: (64, 1, 28, 28)</span></span><br><span class="line">x_penalty = eps*x + (<span class="number">1</span>-eps)*x_fake</span><br><span class="line">x_penalty = x_penalty.view(x_penalty.size(<span class="number">0</span>), -<span class="number">1</span>)  <span class="comment"># n 1 28*28</span></span><br><span class="line">p_outputs = D(x_penalty, y)  <span class="comment"># N,1</span></span><br><span class="line">xp_grad = autograd.grad(outputs=p_outputs, inputs=x_penalty, grad_outputs=D_labels, <span class="comment"># N 1</span></span><br><span class="line">                        create_graph=<span class="literal">True</span>, retain_graph=<span class="literal">True</span>, only_inputs=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(xp_grad)</span><br><span class="line">grad_penalty = p_coeff * torch.mean(torch.<span class="built_in">pow</span>(torch.norm(xp_grad[<span class="number">0</span>], <span class="number">2</span>, <span class="number">1</span>) - <span class="number">1</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure><p>对于辨别器,WGAN一般叫做critic,损失函数,而生成器依旧是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Wasserstein loss</span></span><br><span class="line">x_outputs = D(x, y)</span><br><span class="line">z_outputs = D(x_fake, y)</span><br><span class="line">D_x_loss = torch.mean(x_outputs)</span><br><span class="line">D_z_loss = torch.mean(z_outputs)</span><br><span class="line">D_loss = D_z_loss - D_x_loss + grad_penalty</span><br></pre></td></tr></table></figure><p>此外不使用BN,批次标准化会在同一批次中的样本之间创建相关性。它<strong>影响了梯度惩罚的有效性</strong>，实验证实了这一点。</p><p>一般可以使用Layer Normalization也就是对单个样本进行归一化.</p><h3 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="*Conditional GAN"></a>*Conditional GAN</h3><p>某种程度上里程碑作品,能够控制GAN生成的东西了,通过添加label,也就是condition.</p><p>例如在MNIST数据上,增加数字对应的label的one-hot变量,cat到图像数据上.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">    <span class="keyword">for</span> idx, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        <span class="comment"># Training Discriminator</span></span><br><span class="line">        x = images.to(DEVICE)</span><br><span class="line">        y = labels.view(batch_size, <span class="number">1</span>)</span><br><span class="line">        y = to_onehot(y).to(DEVICE) <span class="comment"># condition</span></span><br><span class="line">        x_outputs = D(x, y)</span><br><span class="line">        D_x_loss = criterion(x_outputs, D_labels)</span><br><span class="line"></span><br><span class="line">        z = torch.randn(batch_size, n_noise).to(DEVICE)</span><br><span class="line">        z_outputs = D(G(z, y), y)</span><br><span class="line">        D_z_loss = criterion(z_outputs, D_fakes)</span><br><span class="line">        D_loss = D_x_loss + D_z_loss</span><br><span class="line">        </span><br><span class="line">        D.zero_grad()</span><br><span class="line">        D_loss.backward()</span><br><span class="line">        D_opt.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> step % n_critic == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># Training Generator</span></span><br><span class="line">            z = torch.randn(batch_size, n_noise).to(DEVICE)</span><br><span class="line">            z_outputs = D(G(z, y), y)</span><br><span class="line">            G_loss = criterion(z_outputs, D_labels)</span><br><span class="line"></span><br><span class="line">            G.zero_grad()</span><br><span class="line">            G_loss.backward()</span><br><span class="line">            G_opt.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125;/&#123;&#125;, Step: &#123;&#125;, D Loss: &#123;&#125;, G Loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, max_epoch, step, D_loss.item(), G_loss.item()))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            G.<span class="built_in">eval</span>()</span><br><span class="line">            img = get_sample_image(G, n_noise)</span><br><span class="line">            imsave(<span class="string">&#x27;samples/&#123;&#125;_step&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(MODEL_NAME, <span class="built_in">str</span>(step).zfill(<span class="number">3</span>)), img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">            G.train()</span><br><span class="line">        step += <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Simple Generator w/ MLP</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size=<span class="number">100</span>, condition_size=<span class="number">10</span>, num_classes=<span class="number">784</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Linear(input_size+condition_size, <span class="number">128</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, num_classes),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, c</span>):</span></span><br><span class="line">        x, c = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>), c.view(c.size(<span class="number">0</span>), -<span class="number">1</span>).<span class="built_in">float</span>()</span><br><span class="line">        v = torch.cat((x, c), <span class="number">1</span>) <span class="comment"># v: [input, label] concatenated vector</span></span><br><span class="line">        y_ = self.layer(v)</span><br><span class="line">        y_ = y_.view(x.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        <span class="keyword">return</span> y_</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Simple Discriminator w/ MLP</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size=<span class="number">784</span>, condition_size=<span class="number">10</span>, num_classes=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Linear(input_size+condition_size, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, num_classes),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, c</span>):</span>        </span><br><span class="line">        x, c = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>), c.view(c.size(<span class="number">0</span>), -<span class="number">1</span>).<span class="built_in">float</span>()</span><br><span class="line">        v = torch.cat((x, c), <span class="number">1</span>) <span class="comment"># v: [input, label] concatenated vector</span></span><br><span class="line">        y_ = self.layer(v)</span><br><span class="line">        <span class="keyword">return</span> y_</span><br></pre></td></tr></table></figure><h3 id="InfoGAN"><a href="#InfoGAN" class="headerlink" title="InfoGAN"></a>InfoGAN</h3><p>提出利用互信息诱导潜变量.该方法将信息最大化引入到标准GAN网络中。</p><p><a href="https://medium.com/mlearning-ai/infogan-interpretable-representation-learning-to-distangle-data-unsupervised-33a4089d7c09">InfoGAN: Interpretable Representation Learning to Distangle Data Unsupervised | by Renee LIN | MLearning.ai | Medium</a></p><p>期望有良好的特征解耦关系.</p><blockquote><p>GAN公式使用简单的连续输入噪声矢量z，同时对G使用噪声的方式没有限制。因此，噪声可能会被生成器以高度纠缠(entangled)的方式使用，导致 z 的各个维度与数据的语义特征不对应。</p><p>在本文中，将输入噪声向量分解为两部分，而不是使用单个非结构化噪声向量：（i）z，它被视为不可压缩噪声源;（ii） c，我们称之为潜在代码，将针对数据分布的显著结构化语义特征。</p></blockquote><script type="math/tex; mode=display">I(X;Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)</script><p>引入互信息,在G输入时加入一个潜变量c,潜在代码 C 和生成器分布 G(z,c) 之间应该有高度的互信息。因此I(c;G(z,c)) 应该很高。给定任何 x ∼ P~G~(x),希望 P~G~（c|x） 有一个较小的熵。换句话说，潜在代码c中的信息不应该在生成过程中丢失。</p><script type="math/tex; mode=display">\operatorname*{min}_{G}\operatorname*{max}_{D}V_{I}(D,G)=V(D,G)-\lambda I(c;G(z,c))</script><p>然而上面互信息的计算涉及后验概率分布P(c|x)，而后者在实际中是很难获取的，所以需要定义一个辅助性的概率分布Q(c|x)，采用Variational Information Maximization对互信息进行下界拟合.</p><script type="math/tex; mode=display">\begin{aligned}I(c;G(z,c))& =H(c)-H(c|G(z,c))  \\&=\mathbb{E}_{x\sim G(z,c)}[\mathbb{E}_{c^{\prime}\sim P(c|x)}[\log P(c^{\prime}|x)]]+H(c) \\&=\mathbb{E}_{x\sim G(z,c)}[\underbrace{D_{\mathrm{KL}}(P(\cdot|x)\parallel Q(\cdot|x))}_{\geq0}+\mathbb{E}_{c^{\prime}\sim P(c|x)}[\log Q(c^{\prime}|x)]]+H(c) \\&\geq\mathbb{E}_{x\sim G(z,c)}[\mathbb{E}_{c^{\prime}\sim P(c|x)}[\log Q(c^{\prime}|x)]]+H(c)\end{aligned}</script><p>这样互信息计算就能确定最小值,继续推导有</p><script type="math/tex; mode=display">\begin{aligned}L_{I}(G,Q)& =E_{c\sim P(c),x\sim G(z,c)}[\log Q(c|x)]+H(c)  \\&=E_{x\sim G(z,c)}[\mathbb{E}_{c^{\prime}\sim P(c|x)}[\log Q(c^{\prime}|x)]]+H(c) \\&\leq I(c;G(z,c))\end{aligned}</script><p>最后目标函数为</p><p><img data-src="https://pic4.zhimg.com/80/v2-ede0624e4acb54575483852435d0ec2b_720w.webp" alt="img"></p><p><img data-src="https://miro.medium.com/v2/resize:fit:543/1*c0wSI0WJR9-yagc0ruFGGg.png" alt="img" style="zoom: 67%;" /></p><p>z,c均为采样得到,z依旧是正态分布采样,c由两部分组成,一部分是离散分布另一部分是连续分布.论文中使用Categorical与Unif分布,是离散均匀分布与连续均匀分布.</p><p><img data-src="https://img1.imgtp.com/2023/09/18/TvDtnXUu.png" alt="image-20230918102341583" style="zoom:67%;" /></p><p>在MNIST数据集上,比如使用c~1~作为离散变量控制生成的数字的类型,其他的c~2~和c~3~作为连续变量控制其他.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_noise</span>(<span class="params">batch_size, n_noise, n_c_discrete, n_c_continuous, label=<span class="literal">None</span>, supervised=<span class="literal">False</span></span>):</span></span><br><span class="line">    z = torch.randn(batch_size, n_noise).to(DEVICE) <span class="comment">#正态分布 潜变量 与VAE的中间变量类似. bottleneck</span></span><br><span class="line">    <span class="comment"># 离散分布 控制数字类型也就是类别 如果supervised 会根据label的值</span></span><br><span class="line">    <span class="keyword">if</span> supervised:</span><br><span class="line">        c_discrete = to_onehot(label).to(DEVICE) <span class="comment"># (B,10)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 否则随机离散均匀生成</span></span><br><span class="line">        c_discrete = to_onehot(torch.LongTensor(batch_size, <span class="number">1</span>).random_(<span class="number">0</span>, n_c_discrete)).to(DEVICE) <span class="comment"># (B,10)</span></span><br><span class="line">    <span class="comment"># 连续分布 控制其他属性 </span></span><br><span class="line">    c_continuous = torch.zeros(batch_size, n_c_continuous).uniform_(-<span class="number">1</span>, <span class="number">1</span>).to(DEVICE) <span class="comment"># (B,2)</span></span><br><span class="line">    c = torch.cat((c_discrete.<span class="built_in">float</span>(), c_continuous), <span class="number">1</span>) <span class="comment">#c (B,12)</span></span><br><span class="line">    <span class="keyword">return</span> z, c</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># Training Discriminator</span></span><br><span class="line">x = images.to(DEVICE)</span><br><span class="line">x_outputs, _, = D(x)</span><br><span class="line">D_x_loss = bce_loss(x_outputs, D_labels)</span><br><span class="line"></span><br><span class="line">z, c = sample_noise(batch_size, n_noise, n_c_discrete, n_c_continuous, label=labels, supervised=<span class="literal">True</span>)</span><br><span class="line">z_outputs, _, = D(G(z, c))</span><br><span class="line">D_z_loss = bce_loss(z_outputs, D_fakes)</span><br><span class="line">D_loss = D_x_loss + D_z_loss</span><br><span class="line"></span><br><span class="line">D_opt.zero_grad()</span><br><span class="line">D_loss.backward()</span><br><span class="line">D_opt.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_gaussian</span>(<span class="params">c, mu, var</span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    criterion for Q(condition classifier)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">return</span> -((c - mu)**<span class="number">2</span>)/(<span class="number">2</span>*var+<span class="number">1e-8</span>) - <span class="number">0.5</span>*torch.log(<span class="number">2</span>*np.pi*var+<span class="number">1e-8</span>)</span><br><span class="line">    </span><br><span class="line"> <span class="comment"># Training Generator</span></span><br><span class="line">z, c = sample_noise(batch_size, n_noise, n_c_discrete, n_c_continuous, label=labels, supervised=<span class="literal">True</span>)</span><br><span class="line">c_discrete_label = torch.<span class="built_in">max</span>(c[:, :-<span class="number">2</span>], <span class="number">1</span>)[<span class="number">1</span>].view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">z_outputs, features = D(G(z, c)) <span class="comment"># (B,1), (B,10), (B,4)</span></span><br><span class="line">c_discrete_out, cc_mu, cc_var = Q(features)</span><br><span class="line"></span><br><span class="line">G_loss = bce_loss(z_outputs, D_labels)</span><br><span class="line">Q_loss_discrete = ce_loss(c_discrete_out, c_discrete_label.view(-<span class="number">1</span>))</span><br><span class="line">Q_loss_continuous = -torch.mean(torch.<span class="built_in">sum</span>(log_gaussian(c[:, -<span class="number">2</span>:], cc_mu, cc_var), <span class="number">1</span>)) <span class="comment"># N(x | mu,var) -&gt; (B, 2) -&gt; (,1)</span></span><br><span class="line">mutual_info_loss = Q_loss_discrete + Q_loss_continuous*<span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">GnQ_loss = G_loss + mutual_info_loss</span><br><span class="line"></span><br><span class="line">G_opt.zero_grad()</span><br><span class="line">GnQ_loss.backward()</span><br><span class="line">G_opt.step()</span><br></pre></td></tr></table></figure><p>离散分布的c求损失使用交叉熵,利用一个Q网络,输入是D的倒数第二层输出,得到离散输出与连续输出的均值和logV. 相当于利用Q的输出与D的倒数第二层输出计算损失,判断在生成过程中是否有损失.</p><p>其中log_gaussian是在计算log(q(x)),看来还是要学好数理统计和矩阵论才行.</p><h3 id="BIGGAN"><a href="#BIGGAN" class="headerlink" title="BIGGAN"></a>BIGGAN</h3><h3 id="proGAN"><a href="#proGAN" class="headerlink" title="proGAN"></a>proGAN</h3><h3 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h3><p>与cycleGAN都是比较重要的jia</p><h3 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h3><h3 id="SAGAN"><a href="#SAGAN" class="headerlink" title="SAGAN"></a>SAGAN</h3><h3 id="TelDiGAN"><a href="#TelDiGAN" class="headerlink" title="TelDiGAN"></a>TelDiGAN</h3><h3 id="SRGAN"><a href="#SRGAN" class="headerlink" title="SRGAN"></a>SRGAN</h3><h2 id="evaluate-GAN"><a href="#evaluate-GAN" class="headerlink" title="evaluate GAN"></a>evaluate GAN</h2><p>通过FID等方法(使用预训练模型看分类)(quality)</p><p>但无法解决model collapse问题</p><p>model drop问题(diversity),平均每张图像的分布,要求均匀.</p><p>Inception Score(IS),quality高,diversity大</p><p>FID(Frechet Inception)</p><p>不使用分类器后得到的结果,使用feature层提取的结果,计算生成与实际feature层shu’chu’d</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><p><a href="https://zhuanlan.zhihu.com/p/44926155">盘点各种GAN及资源整理（1） - 知乎 (zhihu.com)</a></p></li><li><p><a href="https://github.com/soumith/ganhacks">soumith/ganhacks: starter from “How to Train a GAN?” at NIPS2016 (github.com)</a></p></li><li><p><a href="https://github.com/Yangyangii/GAN-Tutorial/tree/master">Yangyangii/GAN-Tutorial: Simple Implementation of many GAN models with PyTorch. (github.com)</a> 在一些数据集上的GAN</p></li><li><p><a href="https://github.com/eriklindernoren/PyTorch-GAN">eriklindernoren/PyTorch-GAN: PyTorch implementations of Generative Adversarial Networks. (github.com)</a>pytorch实现的GAN</p></li><li><p><a href="https://github.com/ccc013/GAN_Study">ccc013/GAN_Study: 学习GAN的笔记和代码 (github.com)</a></p></li><li><p><a href="https://github.com/torchgan/torchgan">torchgan/torchgan: Research Framework for easy and efficient training of GANs based on Pytorch (github.com)</a> pytorch实现的库</p></li><li><p><a href="https://github.com/tensorflow/models/tree/master/research/gan">File not found (github.com)</a>tensorflow实现的GAN</p></li><li><p><a href="https://github.com/eriklindernoren/Keras-GAN">eriklindernoren/Keras-GAN: Keras implementations of Generative Adversarial Networks. (github.com)</a>keras实现的GAN</p></li><li><p><a href="https://github.com/zhangqianhui/AdversarialNetsPapers">zhangqianhui/AdversarialNetsPapers: Awesome paper list with code about generative adversarial nets (github.com)</a>GAN论文与代码</p></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;深入GAN学习&lt;br&gt;</summary>
    
    
    
    
    <category term="GAN" scheme="https://www.sekyoro.top/tags/GAN/"/>
    
  </entry>
  
</feed>
