<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sekyoro的博客小屋</title>
  
  
  <link href="https://www.sekyoro.top/atom.xml" rel="self"/>
  
  <link href="https://www.sekyoro.top/"/>
  <updated>2024-03-25T06:53:44.850Z</updated>
  <id>https://www.sekyoro.top/</id>
  
  <author>
    <name>Sekyoro</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Qt变天了?了解Qt6相关技术</title>
    <link href="https://www.sekyoro.top/2024/03/24/Qt%E5%8F%98%E5%A4%A9%E4%BA%86-%E4%BA%86%E8%A7%A3Qt6%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/"/>
    <id>https://www.sekyoro.top/2024/03/24/Qt%E5%8F%98%E5%A4%A9%E4%BA%86-%E4%BA%86%E8%A7%A3Qt6%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/</id>
    <published>2024-03-24T10:37:06.000Z</published>
    <updated>2024-03-25T06:53:44.850Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>目前c/s架构的应用开发已经有了足够多的选择,其中跨平台的开发也非常多.比如Dart的Flutter,C++的Qt,.Net的MAUI等等,不过其中坑不是外行能一眼看透的,尤其是微软相关的UI技术栈分支实在多,跨平台相关能力不明(微软这方面的文档感觉还是有点乱),学习资料不够充足,而Qt并不开源,但是最近我看到其官网又更新了一波技术,感觉很亮眼,咱们来看看.<br><span id="more"></span></p><p>目前跨平台的解决方案还是琳琅满目,但其中比较成熟的开发效率不低的,网上教程多的又成了凤毛麟角.让我说的话,有Flutter,.Net MAUI以及Qt等等</p><p>Flutter就不多提了,我是最推荐这个的.</p><p>.Net相关项目在微软操持下,生不如死.最成熟的是WPF本身不支持跨平台,此外的Avalonia,Uno等跨平台并不是微软首推. 微软目前首推MAUI与Blazor,后者是Web框架,此外还有UWP的继任者WinUI3目前也不成熟(其目的应该是占据WPF的部分市场).<a href="https://www.cnblogs.com/duwenlong/p/17462010.html">聊聊MAUI、WinUI3和WPF的优势及劣势 - 杜文龙 - 博客园 (cnblogs.com)</a></p><p><img data-src="https://s2.loli.net/2024/03/25/6WmE12y9JhZRXaO.png" alt="image-20240325123001580"></p><p><img data-src="https://github.com/robloo/PublicDocs/raw/master/XAMLFrameworkEvolution.png?raw=true" alt="img"></p><p>此外还有移动端跨平台的React Native,Jetpack Compose(Compose Multiplatform)等等,桌面应用还有Electron,Tauri(目前也能在移动端使用)等,国内生态下还有微信小程序,Uniapp,Taro等.</p><p><img data-src="https://s2.loli.net/2024/03/25/V3DjN1wpYhmUSZF.png" alt="image-20240325123020037"></p><blockquote><p><a href="https://developer.android.google.cn/jetpack/compose?hl=zh-cn">Jetpack Compose</a> 是一款新型工具包，旨在帮助简化界面开发。该工具包将响应式编程模型与简洁易用的 Kotlin 编程语言相结合，并采用完全声明式的代码编写方式，让您可以通过调用一系列函数来描述界面，这些函数会将数据转换为界面层次结构。当底层数据发生变化时，框架会自动重新执行这些函数，为您更新界面层次结构。简单来说,包括Flutter,这些都是使用代码声明UI的,而.Net下许多UI框架使用xaml,这与之前的安卓开发类似.</p></blockquote><p>上面说了这么多,做技术选型来个总结的话,当然首先需要顾及团队人员,最好结合工期和团队技术栈选择.如果是个人开发者,由于目前Flutter对web和桌面支持还是不太成熟,我个人其实想推荐.Net的技术,或者你也可以考虑Electron做桌面(强调软件性能或者容错性考虑WPF,Qt等),移动端用Flutter或React Native(Compose目前跨平台也不太成熟,如果只考虑安卓可以试试)</p><p>而今天要谈到的Qt,在工业领域用得多,感觉还是因为历史沉淀.这几天看了Qt官网,其推出了Design Studio软件,Qt Creator貌似也支持了AI辅助编码,说明还是跟上了潮流,而Qt6的优势就是跟Qt quick更好结合了.目前下载Qt也不像之前那么麻烦,现在用一个unified-downloader联网下载以及后续更新就行了.</p><h2 id="新的Qt"><a href="#新的Qt" class="headerlink" title="新的Qt"></a>新的Qt</h2><p>Qt主要还是在桌面、嵌入式多,但其实移动端也可以,相信其跨平台能力.Qt6与Qt5基本可以无缝转换.</p><blockquote><p>Qt 6 is highly compatible with <a href="https://doc.qt.io/qt-5.15/">Qt 5</a>. Developers of Qt 5 applications can move seamlessly to Qt 6 while retaining the applications’ functionality.</p></blockquote><p><img data-src="https://s2.loli.net/2024/03/25/b8UsBofHexM9gZ6.png" alt="image-20240325132130083"></p><p>Qt目前提供了设计,开发,测试和优化的工具,主要使用前两者即可.</p><h3 id="对于UI设计"><a href="#对于UI设计" class="headerlink" title="对于UI设计"></a>对于UI设计</h3><p><img data-src="https://doc.qt.io/qtcreator/images/qtcreator-project-qt-quick.webp" alt="{New Project dialog}"></p><p>如果想要在移动端或者需要丝滑的动画,那就用Qt Quick.可以使用Qt Design Studio辅助设计.</p><p><img data-src="https://s2.loli.net/2024/03/25/9nFhjdfoMGsXUyV.png" alt="image-20240325143557948"></p><figure class="highlight qml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> QtQuick</span><br><span class="line"><span class="title">Rectangle</span> &#123;</span><br><span class="line">    <span class="attribute">id:</span><span class="string"> page</span></span><br><span class="line">    <span class="attribute">anchors.fill</span>: <span class="built_in">parent</span></span><br><span class="line">    <span class="attribute">color</span>: <span class="string">&quot;#ffffff&quot;</span>&#125;</span><br></pre></td></tr></table></figure><p>使用qml描述界面</p><figure class="highlight qml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">ListModel</span> &#123;</span><br><span class="line">        <span class="attribute">id:</span><span class="string"> todayTasksListModel</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="title">ListModel</span> &#123;</span><br><span class="line">        <span class="attribute">id:</span><span class="string"> thisWeekTasksListModel</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="title">ListModel</span> &#123;</span><br><span class="line">        <span class="attribute">id:</span><span class="string"> laterTasksListModel</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="title">Column</span> &#123;</span><br><span class="line">        <span class="attribute">id:</span><span class="string"> column</span></span><br><span class="line"></span><br><span class="line">        <span class="attribute">anchors.fill</span>: <span class="built_in">parent</span></span><br><span class="line">        <span class="attribute">spacing</span>: <span class="number">14</span></span><br><span class="line"></span><br><span class="line">        <span class="title">TasksList</span> &#123;</span><br><span class="line">            <span class="attribute">id:</span><span class="string"> todayTasks</span></span><br><span class="line"></span><br><span class="line">            <span class="attribute">width</span>: column.width</span><br><span class="line">            <span class="attribute">maxHeight</span>: <span class="number">180</span></span><br><span class="line">            <span class="attribute">listModel</span>: todayTasksListModel</span><br><span class="line">            <span class="attribute">headerText</span>: qsTr(<span class="string">&quot;Today&quot;</span>)</span><br><span class="line">            <span class="attribute">tasksCount</span>: todayTasksListModel.count</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="title">TasksList</span> &#123;</span><br><span class="line">            <span class="attribute">id:</span><span class="string"> thisWeekTasks</span></span><br><span class="line"></span><br><span class="line">            <span class="attribute">width</span>: column.width</span><br><span class="line">            <span class="attribute">maxHeight</span>: column.height - y - <span class="number">60</span></span><br><span class="line">            <span class="attribute">listModel</span>: thisWeekTasksListModel</span><br><span class="line">            <span class="attribute">headerText</span>: qsTr(<span class="string">&quot;This week&quot;</span>)</span><br><span class="line">            <span class="attribute">tasksCount</span>: thisWeekTasksListModel.count</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="title">TasksList</span> &#123;</span><br><span class="line">            <span class="attribute">id:</span><span class="string"> laterTasks</span></span><br><span class="line"></span><br><span class="line">            <span class="attribute">width</span>: column.width</span><br><span class="line">            <span class="attribute">maxHeight</span>: column.height - y</span><br><span class="line">            <span class="attribute">listModel</span>: laterTasksListModel</span><br><span class="line">            <span class="attribute">headerText</span>: qsTr(<span class="string">&quot;Later&quot;</span>)</span><br><span class="line">            <span class="attribute">tasksCount</span>: laterTasksListModel.count</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>我在使用的时候感觉很像安卓的compose或者WPF的xaml开发,也是声明式,Flutter也是声明式,这可能就是趋势吧.类似js通过findelementById再到React,Vue的声明式UI.</p><h3 id="使用QtWidget"><a href="#使用QtWidget" class="headerlink" title="使用QtWidget"></a>使用QtWidget</h3><p><img data-src="https://doc.qt.io/qt-6/images/notepad2.png" alt="&quot;Qt Creator New Project dialog&quot;"></p><p><img data-src="https://doc.qt.io/qt-6/images/qtdesigner.png" alt="&quot;Qt Designer opened from Qt Creator&quot;"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;notepad.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;QApplication&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">QApplication <span class="title">a</span><span class="params">(argc, argv)</span></span>;</span><br><span class="line">    Notepad w;</span><br><span class="line">    w.<span class="built_in">show</span>();</span><br><span class="line">    <span class="keyword">return</span> a.<span class="built_in">exec</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用QtWidget是传统开发方式,这里就不赘述了.</p><p>目前我在Qt官网以及开发工具上找到了一堆tutorial,可惜目前没多少时间学习,可以预见的是,虽然Qt在互联网以及开源软件领域基本没什么市场占有率(目前被Web技术占着,要么就是Flutter或者.Net),但是在使用c++比较多的工业领域或是使用Python进行Qt开发应该是一个技术上不错的选择了.比如下面代码就是用python执行qml.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PySide6.QtGui <span class="keyword">import</span> QGuiApplication</span><br><span class="line"><span class="keyword">from</span> PySide6.QtQml <span class="keyword">import</span> QQmlApplicationEngine</span><br><span class="line">QML = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">import QtQuick</span></span><br><span class="line"><span class="string">import QtQuick.Controls</span></span><br><span class="line"><span class="string">import QtQuick.Layouts</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Window &#123;</span></span><br><span class="line"><span class="string">    width: 300</span></span><br><span class="line"><span class="string">    height: 200</span></span><br><span class="line"><span class="string">    visible: true</span></span><br><span class="line"><span class="string">    title: &quot;Hello World&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    readonly property list&lt;string&gt; texts: [&quot;Hallo Welt&quot;, &quot;Hei maailma&quot;,</span></span><br><span class="line"><span class="string">                                           &quot;Hola Mundo&quot;, &quot;Привет мир&quot;]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    function setText() &#123;</span></span><br><span class="line"><span class="string">        var i = Math.round(Math.random() * 3)</span></span><br><span class="line"><span class="string">        text.text = texts[i]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ColumnLayout &#123;</span></span><br><span class="line"><span class="string">        anchors.fill:  parent</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Text &#123;</span></span><br><span class="line"><span class="string">            id: text</span></span><br><span class="line"><span class="string">            text: &quot;Hello World&quot;</span></span><br><span class="line"><span class="string">            Layout.alignment: Qt.AlignHCenter</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        Button &#123;</span></span><br><span class="line"><span class="string">            text: &quot;Click me&quot;</span></span><br><span class="line"><span class="string">            Layout.alignment: Qt.AlignHCenter</span></span><br><span class="line"><span class="string">            onClicked:  setText()</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QGuiApplication(sys.argv)</span><br><span class="line">    engine = QQmlApplicationEngine()</span><br><span class="line">    engine.loadData(QML.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> engine.rootObjects():</span><br><span class="line">        sys.exit(-<span class="number">1</span>)</span><br><span class="line">    exit_code = app.<span class="built_in">exec</span>()</span><br><span class="line">    <span class="keyword">del</span> engine</span><br><span class="line">    sys.exit(exit_code)</span><br></pre></td></tr></table></figure><p>下面是常见的用python写qtwidget</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PySide6 <span class="keyword">import</span> QtCore, QtWidgets, QtGui</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyWidget</span>(<span class="params">QtWidgets.QWidget</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.hello = [<span class="string">&quot;Hallo Welt&quot;</span>, <span class="string">&quot;Hei maailma&quot;</span>, <span class="string">&quot;Hola Mundo&quot;</span>, <span class="string">&quot;Привет мир&quot;</span>]</span><br><span class="line"></span><br><span class="line">        self.button = QtWidgets.QPushButton(<span class="string">&quot;Click me!&quot;</span>)</span><br><span class="line">        self.text = QtWidgets.QLabel(<span class="string">&quot;Hello World&quot;</span>,</span><br><span class="line">                                     alignment=QtCore.Qt.AlignCenter)</span><br><span class="line"></span><br><span class="line">        self.layout = QtWidgets.QVBoxLayout(self)</span><br><span class="line">        self.layout.addWidget(self.text)</span><br><span class="line">        self.layout.addWidget(self.button)</span><br><span class="line"></span><br><span class="line">        self.button.clicked.connect(self.magic)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @QtCore.Slot()</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">magic</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.text.setText(random.choice(self.hello))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QtWidgets.QApplication([])</span><br><span class="line"></span><br><span class="line">    widget = MyWidget()</span><br><span class="line">    widget.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line">    widget.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.<span class="built_in">exec</span>())</span><br></pre></td></tr></table></figure><p>目前QtWidget与Qt quick没有绝对优劣,官网也是推荐在使用动画和移动端触摸时使用qml,事实上这两者也可以结合使用. 而安卓方面Compose已经成了趋势,但传统xml开发也需要掌握用来维护旧项目以及新项目缺少的组件.</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;目前c/s架构的应用开发已经有了足够多的选择,其中跨平台的开发也非常多.比如Dart的Flutter,C++的Qt,.Net的MAUI等等,不过其中坑不是外行能一眼看透的,尤其是微软相关的UI技术栈分支实在多,跨平台相关能力不明(微软这方面的文档感觉还是有点乱),学习资料不够充足,而Qt并不开源,但是最近我看到其官网又更新了一波技术,感觉很亮眼,咱们来看看.&lt;br&gt;</summary>
    
    
    
    
    <category term="技术栈" scheme="https://www.sekyoro.top/tags/%E6%8A%80%E6%9C%AF%E6%A0%88/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅生成式AI课程学习</title>
    <link href="https://www.sekyoro.top/2024/03/17/%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%94%9F%E6%88%90%E5%BC%8FAI%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/03/17/%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%94%9F%E6%88%90%E5%BC%8FAI%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-03-17T14:13:03.000Z</published>
    <updated>2024-03-22T01:12:25.230Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>lec3 神奇的咒语</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>如何开始写一篇现代八股论文</title>
    <link href="https://www.sekyoro.top/2024/03/16/%E5%A6%82%E4%BD%95%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E7%AF%87%E7%8E%B0%E4%BB%A3%E5%85%AB%E8%82%A1%E8%AE%BA%E6%96%87/"/>
    <id>https://www.sekyoro.top/2024/03/16/%E5%A6%82%E4%BD%95%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E7%AF%87%E7%8E%B0%E4%BB%A3%E5%85%AB%E8%82%A1%E8%AE%BA%E6%96%87/</id>
    <published>2024-03-16T02:28:08.000Z</published>
    <updated>2024-03-26T03:21:41.427Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>通过阅读一系列文章,分析摘要、介绍每个section的组织形式,方便写出一些列现代八股文.<br><span id="more"></span></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><blockquote><p>实验部分介绍使用的数据集,评价指标,实现细节,定量分析,定性分析以及消融实验.</p></blockquote><p>首先介绍论文进行了comprehensive的实验,然后分别介绍数据集,随后介绍评价指标.</p><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>介绍使用的框架、工具以及训练的GPU设备.然后介绍训练时的细节,比如使用的optimizer和lr_scheduler,batch_size,epochs等.然后介绍自己的算法中的参数设置,最后介绍一些细节等</p><h3 id="定量分析"><a href="#定量分析" class="headerlink" title="定量分析"></a>定量分析</h3><p>使用不同指标进行对比</p><h2 id="Latex常用"><a href="#Latex常用" class="headerlink" title="Latex常用"></a>Latex常用</h2><blockquote><p>众所周知,不用latex写出来的只能是文章,不能是论文(暴言).</p></blockquote><h3 id="对文字操作"><a href="#对文字操作" class="headerlink" title="对文字操作"></a>对文字操作</h3><p>比如<code>\textbf</code>等等能使文字改变(包括公式),这些还是非常有用的.</p><p>引入宏包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;amsmath&#125;</span><br><span class="line">\usepackage&#123;amssymb&#125;</span><br><span class="line">\usepackage&#123;bm&#125;</span><br></pre></td></tr></table></figure><p>对于排版数学公式,主要使用amsmath宏,而amssymb提供许多数学符号</p><h4 id="行内和行间公式"><a href="#行内和行间公式" class="headerlink" title="行内和行间公式"></a>行内和行间公式</h4><blockquote><p>数学公式有两种排版方式：其一是与文字混排，称为行内公式；其二是单独列为一行排版， 称为行间公式。</p></blockquote><p>简单来说行内公式使用$$$$,行间公式使用<code>\equation</code>.</p><p>equation 环境为公式自动生成一 个编号，<strong>这个编号可以用 \label 和 \ref 生成交叉引用，amsmath 的 \eqref 命令甚至为引用 自动加上圆括号</strong>；还可以用 \tag 命令手动修改公式的编号，或者用 \notag 命令取消为公式编 号</p><p>如果需要<strong>直接使用不带编号的行间公式</strong>，则将公式用命令 [ 和 ] 包裹，与之等效的是 displaymath 环境。有的人更喜欢 equation* 环境，体现了带星号和不带星号的环境之间的区 别。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;equation*&#125;</span><br><span class="line">a^2 + b^2 = c^2</span><br><span class="line">\end&#123;equation*&#125;</span><br><span class="line">For short:</span><br><span class="line">\[ a^2 + b^2 = c^2 \]</span><br><span class="line">Or if you like the long one:</span><br><span class="line">\begin&#123;displaymath&#125;</span><br><span class="line">a^2 + b^2 = c^2</span><br><span class="line">\end&#123;displaymath&#125;</span><br></pre></td></tr></table></figure><blockquote><p>当用户使用 $ 开启行内公式输入，或是使用 [ 命令、equation 环境时，LATEX 就进入了 数学模式。</p></blockquote><ul><li>数学模式中输入的空格被忽略。数学符号的间距默认由符号的性质（关系符号、运算符等） 决定。需要人为引入间距时，使用 \quad 和 \qquad 等命令</li><li><p>不允许有空行（分段）。行间公式中也无法用 \ 命令手动换行，排版多行公式需要使用其他环境</p></li><li><p>所有的字母被当作数学公式中的变量处理，字母间距与文本模式不一致，也无法生成单词 之间的空格。想在数学公式中输入正体的文本，简单情况下可用  \mathrm 命令。或者用 amsmath 提供的 \text 命令</p></li></ul><h5 id="一般符号"><a href="#一般符号" class="headerlink" title="一般符号"></a>一般符号</h5><p>希腊字母符号的名称就是其英文名称，如 α (\alpha)、β (\beta) 等等。大写的希腊字母为 首字母大写的命令，如 Γ (\Gamma)、∆ (\Delta) 等等。无穷大符号为 ∞ (\infty)。</p><h5 id="hyperref"><a href="#hyperref" class="headerlink" title="hyperref"></a>hyperref</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;hyperref&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">    Please visit my \href&#123;https://www.example.com&#125;&#123;website&#125;.</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;hyperref&#125;</span><br><span class="line">\hypersetup&#123;</span><br><span class="line">colorlinks=true,</span><br><span class="line">linkcolor=cyan,</span><br><span class="line">filecolor=blue,      </span><br><span class="line">urlcolor=red,</span><br><span class="line">citecolor=green,</span><br><span class="line">pagebackref=true,</span><br><span class="line">    breaklinks=true,</span><br><span class="line">    letterpaper=true,</span><br><span class="line">    </span><br><span class="line">    bookmarks=false,</span><br><span class="line">   </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>colorlinks就是说超链接是否带颜色；<br>linkcolor就是目录，公式，图表等内部链接的颜色；<br>filecolor就是文件型链接的颜色；<br>urlcolor就是网页链接的颜色；<br>citecolor就是参考文献连接的颜色</p><p>pagebackref=true<code>：在参考文献中添加返回页码的链接。</code>breaklinks=true`：允许链接跨行断开。</p><p>letterpaper=true：将页面大小设置为Letter纸张尺寸。</p><p>bookmarks=false：禁用书签生成。</p></blockquote><p>amssymb 宏包提供了一些次常用的符号。</p><h5 id="xcolor"><a href="#xcolor" class="headerlink" title="xcolor"></a>xcolor</h5><p>文本设置颜色</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;xcolor&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">    \textcolor&#123;red&#125;&#123;这是红色的文本。&#125;</span><br><span class="line"></span><br><span class="line">    \colorbox&#123;blue!30&#125;&#123;这是一个蓝色背景的盒子。&#125;</span><br><span class="line"></span><br><span class="line">    \definecolor&#123;mygreen&#125;&#123;rgb&#125;&#123;0,0.5,0&#125;</span><br><span class="line">    \textcolor&#123;mygreen&#125;&#123;这是自定义的绿色文本。&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h5 id="soul"><a href="#soul" class="headerlink" title="soul"></a>soul</h5><p>下划线和删除线等</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\st&#123;This text has a strikethrough.&#125;</span><br><span class="line">\hl&#123;\ul&#123;Highlighted and underlined text.&#125;&#125;</span><br><span class="line">\st&#123;\ul&#123;Strikethrough and underlined text.&#125;&#125;</span><br></pre></td></tr></table></figure><h5 id="times"><a href="#times" class="headerlink" title="times"></a>times</h5><p>times宏包用于将文档的字体设置为Times字体。使用\usepackage{times}命令导入该宏包即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;times&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">This is some text in Times font.</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h5 id="epsfig宏包"><a href="#epsfig宏包" class="headerlink" title="epsfig宏包"></a>epsfig宏包</h5><p><code>epsfig</code>宏包用于在LaTeX文档中插入EPS格式的图像文件。使用<code>\usepackage&#123;epsfig&#125;</code>命令导入该宏包即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;epsfig&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;figure&#125;</span><br><span class="line">    \centering</span><br><span class="line">    \epsfig&#123;file=example.eps, width=0.5\textwidth&#125;</span><br><span class="line">    \caption&#123;An example EPS figure.&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h5 id="graphicx"><a href="#graphicx" class="headerlink" title="graphicx"></a>graphicx</h5><p><code>graphicx</code>宏包是LaTeX中最常用的图形处理宏包之一，用于插入和操作各种图像文件格式。使用<code>\usepackage&#123;graphicx&#125;</code>命令导入该宏包即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;figure&#125;</span><br><span class="line">    \centering</span><br><span class="line">    \includegraphics[width=0.5\textwidth]&#123;example.png&#125;</span><br><span class="line">    \caption&#123;An example PNG image.&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">\graphicspath&#123;&#123;resource/&#125;&#125;     % organize your images and other figures under resource/ folder</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="bbding"><a href="#bbding" class="headerlink" title="bbding"></a>bbding</h5><p><code>bbding</code>宏包提供了一系列特殊符号和图标，如手势、箭头、勾号、叉号等。使用<code>\usepackage&#123;bbding&#125;</code>命令导入该宏包即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;bbding&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\Checkmark \quad \XSolidBrush \quad \HandRight</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h5 id="subcaption"><a href="#subcaption" class="headerlink" title="subcaption"></a>subcaption</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\usepackage&#123;subcaption&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;figure&#125;</span><br><span class="line">    \centering</span><br><span class="line">    \begin&#123;subfigure&#125;&#123;0.3\textwidth&#125;</span><br><span class="line">        \includegraphics[width=\linewidth]&#123;image1.png&#125;</span><br><span class="line">        \caption&#123;Subfigure 1&#125;</span><br><span class="line">    \end&#123;subfigure&#125;</span><br><span class="line">    \quad</span><br><span class="line">    \begin&#123;subfigure&#125;&#123;0.3\textwidth&#125;</span><br><span class="line">        \includegraphics[width=\linewidth]&#123;image2.png&#125;</span><br><span class="line">        \caption&#123;Subfigure 2&#125;</span><br><span class="line">    \end&#123;subfigure&#125;</span><br><span class="line">    \caption&#123;Example with subfigures.&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">As shown in Figure \ref&#123;fig:example&#125;, subfigure \subref&#123;subfig:1&#125; is interesting.</span><br></pre></td></tr></table></figure><p>使用<code>\subref</code>引用子图</p><h5 id="nicefrac"><a href="#nicefrac" class="headerlink" title="\nicefrac"></a>\nicefrac</h5><p><code>\nicefrac</code>命令是由<code>nicefrac</code>宏包提供的。它用于生成更紧凑的分数符号，比如1/2、3/4等。通常在文本模式下使用，可以将其用于正文、标注或其他地方需要使用分数的场景。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;nicefrac&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">    The result is \nicefrac&#123;1&#125;&#123;2&#125;.</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h5 id="microtype"><a href="#microtype" class="headerlink" title="microtype"></a>microtype</h5><p><code>microtype</code>宏包提供了微调字距和字形的功能，以改善文本的排版效果。它可以自动调整字符之间的间距、字号和字形，以提高视觉效果和可读性。要使用<code>microtype</code>宏包，只需在导言区使用<code>\usepackage&#123;microtype&#125;</code>命令导入即可。</p><h5 id="fancyhdr"><a href="#fancyhdr" class="headerlink" title="fancyhdr"></a>fancyhdr</h5><p><code>fancyhdr</code>宏包用于自定义页眉和页脚的样式。它允许在页面的顶部和底部添加自定义内容，如文档标题、章节标题、页码等。通过使用<code>fancyhdr</code>宏包，您可以灵活地控制和设计页面的页眉和页脚。要使用<code>fancyhdr</code>宏包，只需在导言区使用<code>\usepackage&#123;fancyhdr&#125;</code>命令导入即可。</p><h3 id="画表格"><a href="#画表格" class="headerlink" title="画表格"></a>画表格</h3><p>三线表</p><h3 id="引入图片"><a href="#引入图片" class="headerlink" title="引入图片"></a>引入图片</h3><p>我看通常使用的是pdf引入.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> \begin&#123;figure&#125;[t]</span><br><span class="line">  \centering</span><br><span class="line">  \includegraphics[width=\linewidth]&#123;imgs/temporal.pdf&#125;</span><br><span class="line">  \caption&#123;(a) The architecture of the proposed CIA component, including selective information filtering (\textit&#123;left&#125;) and spatio-temporal feature integration (\textit&#123;middle&#125;). (b) The multi-scale convolutional structure in the pyramid LSTM.</span><br><span class="line">  &#125;</span><br><span class="line">  \label&#123;temporal&#125;</span><br><span class="line">  \vspace&#123;-9pt&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br></pre></td></tr></table></figure><p>需要[t]表示在当页的顶部.</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>lshort<a href="https://github.com/CTeX-org/lshort-zh-cn/releases">Releases · CTeX-org/lshort-zh-cn (github.com)</a></li><li><a href="https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes">Learn LaTeX in 30 minutes - Overleaf, Online LaTeX Editor</a></li><li><a href="https://dmackinnon1.github.io/LaTeX101/">LaTeX101 (dmackinnon1.github.io)</a></li><li><a href="https://www.ctan.org/topic/class">CTAN: Class</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;通过阅读一系列文章,分析摘要、介绍每个section的组织形式,方便写出一些列现代八股文.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>CMA热力图学习</title>
    <link href="https://www.sekyoro.top/2024/03/03/CMA%E7%83%AD%E5%8A%9B%E5%9B%BE%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/03/03/CMA%E7%83%AD%E5%8A%9B%E5%9B%BE%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-03-03T11:32:36.000Z</published>
    <updated>2024-03-03T11:32:37.016Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>attention mechanisms in CV</title>
    <link href="https://www.sekyoro.top/2024/03/03/attention-mechanisms-in-CV/"/>
    <id>https://www.sekyoro.top/2024/03/03/attention-mechanisms-in-CV/</id>
    <published>2024-03-03T07:19:50.000Z</published>
    <updated>2024-03-12T09:30:39.551Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>主要是在视觉领域以及二维的feature map上的注意力机制,不同于1D数据,一般不会用q,k,v来算.总结一下cv中attention的发展.</p><span id="more"></span><h2 id="Coordinate-Attention"><a href="#Coordinate-Attention" class="headerlink" title="Coordinate Attention"></a>Coordinate Attention</h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://arxiv.org/pdf/2111.07624.pdf">2111.07624.pdf (arxiv.org)</a> 综述</li><li><a href="https://arxiv.org/pdf/2112.05561.pdf">2112.05561.pdf (arxiv.org)</a></li><li><a href="https://arxiv.org/pdf/1807.06521.pdf">1807.06521.pdf (arxiv.org)</a></li><li><a href="https://arxiv.org/pdf/2103.02907.pdf">2103.02907.pdf (arxiv.org)</a></li><li><a href="https://arxiv.org/pdf/1811.11721.pdf">1811.11721.pdf (arxiv.org)</a></li><li><a href="https://arxiv.org/pdf/1711.07971.pdf">arxiv.org/pdf/1711.07971.pdf</a></li><li><a href="https://arxiv.org/pdf/1709.01507.pdf">1709.01507.pdf (arxiv.org)</a></li><li><a href="https://arxiv.org/pdf/1903.06586.pdf">1903.06586.pdf (arxiv.org)</a></li><li><a href="https://mlrad.io/combining-convolution-and-attention-mechanisms">Convolution-Attention Mechanism Fusion (mlrad.io)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要是在视觉领域以及二维的feature map上的注意力机制,不同于1D数据,一般不会用q,k,v来算.总结一下cv中attention的发展.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>再回看扩散模型</title>
    <link href="https://www.sekyoro.top/2024/02/23/%E5%86%8D%E5%9B%9E%E7%9C%8B%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"/>
    <id>https://www.sekyoro.top/2024/02/23/%E5%86%8D%E5%9B%9E%E7%9C%8B%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/</id>
    <published>2024-02-23T08:53:30.000Z</published>
    <updated>2024-02-24T03:55:44.472Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>最近OpenAI的Sora模型又大火了一把,据说背后的技术是transformer+diffusion.之前我也大致介绍过stable diffusion的过程,这里我再稍微详细介绍一下经典的扩散模型以及改进之后的DDIM.其中我也有很多不太明白的,只有结合代码理解了.<br><span id="more"></span></p><p>相关论文<a href="https://arxiv.org/abs/2006.11239">[2006.11239] Denoising Diffusion Probabilistic Models (arxiv.org)</a>与<a href="https://arxiv.org/abs/2010.02502">[2010.02502] Denoising Diffusion Implicit Models (arxiv.org)</a>,<a href="https://arxiv.org/pdf/2112.10752.pdf">2112.10752.pdf (arxiv.org)</a></p><blockquote><p>Stable Diffusion is a latent text-to-image diffusion model.</p></blockquote><p>已经提出了几种基于扩散的生成模型，其下有类似的想法，包括扩散概率模型、噪声条件评分网络和去噪扩散概率模型。现在常说的基于扩散的生成模型通常指的后者DDPM或者改进的DDIM.</p><h2 id="前向扩散过程"><a href="#前向扩散过程" class="headerlink" title="前向扩散过程"></a>前向扩散过程</h2><p><img data-src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png" alt="img"></p><script type="math/tex; mode=display">q(\mathbf{x}_t|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_t;\sqrt{1-\beta_t}\mathbf{x}_{t-1},\beta_t\mathbf{I})\quad q(\mathbf{x}_{1:T}|\mathbf{x}_0)=\prod_{t=1}^Tq(\mathbf{x}_t|\mathbf{x}_{t-1})</script><p>所谓的扩散就是给图片(或者是特征,比如stable diffusion就是在所谓latent空间上进行扩散的)加噪声,所加的噪声按照一定分布.</p><p>前向过程为一个马尔科夫链,使用重参数化(在VAE中也有),可以表示为</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{x}_t&=\sqrt{\alpha_t}\mathbf{x}_{t-1}+\sqrt{1-\alpha_t}\boldsymbol{\epsilon}_{t-1}&&\text{;where }\boldsymbol{\epsilon}_{t-1},\boldsymbol{\epsilon}_{t-2},\cdots\sim\mathcal{N}(\boldsymbol{0},\mathbf{I})\\&=\sqrt{\alpha_t\alpha_{t-1}}\mathbf{x}_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1}}\boldsymbol{\bar{\epsilon}}_{t-2}&&\text{;where }\boldsymbol{\bar{\boldsymbol{\epsilon}}}_{t-2}\text{ merges two Gaussians }(*).\\&=\ldots\\&=\sqrt{\alpha}_t\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}&&\text{j}\\q(\mathbf{x}_t|\mathbf{x}_0)&=\mathcal{N}(\mathbf{x}_t;\sqrt{\alpha}_t\mathbf{x}_0,(1-\bar{\alpha}_t)\mathbf{I})\end{aligned}</script><p>其中α=1-β.$\bar{\alpha}<em>{t}=\prod</em>{i=1}^{t}\alpha_{i}$,β是从0到1中间的采样值,比如0.01,0.02..</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_beta_schedule</span>(<span class="params">timesteps, start=<span class="number">0.0001</span>, end=<span class="number">0.02</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.linspace(start, end, timesteps)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_index_from_list</span>(<span class="params">vals, t, x_shape</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">    Returns a specific index t of a passed list of values vals</span></span><br><span class="line"><span class="string">    while considering the batch dimension.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batch_size = t.shape[<span class="number">0</span>]</span><br><span class="line">    out = vals.gather(-<span class="number">1</span>, t.cpu())</span><br><span class="line">    <span class="keyword">return</span> out.reshape(batch_size, *((<span class="number">1</span>,) * (<span class="built_in">len</span>(x_shape) - <span class="number">1</span>))).to(t.device)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_diffusion_sample</span>(<span class="params">x_0, t, device=<span class="string">&quot;cpu&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">    Takes an image and a timestep as input and </span></span><br><span class="line"><span class="string">    returns the noisy version of it</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    noise = torch.randn_like(x_0)</span><br><span class="line">    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)</span><br><span class="line">    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(</span><br><span class="line">        sqrt_one_minus_alphas_cumprod, t, x_0.shape</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># mean + variance</span></span><br><span class="line">    <span class="keyword">return</span> sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \</span><br><span class="line">    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define beta schedule</span></span><br><span class="line">T = <span class="number">300</span></span><br><span class="line">betas = linear_beta_schedule(timesteps=T)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pre-calculate different terms for closed form</span></span><br><span class="line">alphas = <span class="number">1.</span> - betas</span><br><span class="line">alphas_cumprod = torch.cumprod(alphas, axis=<span class="number">0</span>)</span><br><span class="line">alphas_cumprod_prev = F.pad(alphas_cumprod[:-<span class="number">1</span>], (<span class="number">1</span>, <span class="number">0</span>), value=<span class="number">1.0</span>)</span><br><span class="line">sqrt_recip_alphas = torch.sqrt(<span class="number">1.0</span> / alphas)</span><br><span class="line">sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)</span><br><span class="line">sqrt_one_minus_alphas_cumprod = torch.sqrt(<span class="number">1.</span> - alphas_cumprod)</span><br><span class="line">posterior_variance = betas * (<span class="number">1.</span> - alphas_cumprod_prev) / (<span class="number">1.</span> - alphas_cumprod)</span><br></pre></td></tr></table></figure><p>加噪声的schedule有多种</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosine_beta_schedule</span>(<span class="params">timesteps, s=<span class="number">0.008</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    cosine schedule as proposed in https://arxiv.org/abs/2102.09672</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    steps = timesteps + <span class="number">1</span></span><br><span class="line">    x = torch.linspace(<span class="number">0</span>, timesteps, steps)</span><br><span class="line">    alphas_cumprod = torch.cos(((x / timesteps) + s) / (<span class="number">1</span> + s) * torch.pi * <span class="number">0.5</span>) ** <span class="number">2</span></span><br><span class="line">    alphas_cumprod = alphas_cumprod / alphas_cumprod[<span class="number">0</span>]</span><br><span class="line">    betas = <span class="number">1</span> - (alphas_cumprod[<span class="number">1</span>:] / alphas_cumprod[:-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> torch.clip(betas, <span class="number">0.0001</span>, <span class="number">0.9999</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_beta_schedule</span>(<span class="params">timesteps</span>):</span></span><br><span class="line">    beta_start = <span class="number">0.0001</span></span><br><span class="line">    beta_end = <span class="number">0.02</span></span><br><span class="line">    <span class="keyword">return</span> torch.linspace(beta_start, beta_end, timesteps)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quadratic_beta_schedule</span>(<span class="params">timesteps</span>):</span></span><br><span class="line">    beta_start = <span class="number">0.0001</span></span><br><span class="line">    beta_end = <span class="number">0.02</span></span><br><span class="line">    <span class="keyword">return</span> torch.linspace(beta_start**<span class="number">0.5</span>, beta_end**<span class="number">0.5</span>, timesteps) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_beta_schedule</span>(<span class="params">timesteps</span>):</span></span><br><span class="line">    beta_start = <span class="number">0.0001</span></span><br><span class="line">    beta_end = <span class="number">0.02</span></span><br><span class="line">    betas = torch.linspace(-<span class="number">6</span>, <span class="number">6</span>, timesteps)</span><br><span class="line">    <span class="keyword">return</span> torch.sigmoid(betas) * (beta_end - beta_start) + beta_start</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="反向扩散过程"><a href="#反向扩散过程" class="headerlink" title="反向扩散过程"></a>反向扩散过程</h2><p>如果能将上述过程反向,就能从高斯噪声图像得到一整图像了.也就是需要知道$q(\mathbf{x}<em>{t-1}|\mathbf{x}</em>{t})$,这跟贝叶斯有点关系,可以使用神经网络近似这个条件概率,以便运行反向扩散过程.</p><script type="math/tex; mode=display">p_\theta(\mathbf{x}_{0:T})=p(\mathbf{x}_T)\prod_{t=1}^Tp_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)\quad p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)=\mathcal{N}(\mathbf{x}_{t-1};\boldsymbol{\mu}_\theta(\mathbf{x}_t,t),\boldsymbol{\Sigma}_\theta(\mathbf{x}_t,t))</script><p>假设反向也是高斯,可以有条件概率</p><script type="math/tex; mode=display">q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t-1};\tilde{\boldsymbol{\mu}}(\mathbf{x}_t,\mathbf{x}_0),\color{red}{\tilde{\boldsymbol{\beta}}_t}\mathbf{I})</script><p>使用贝叶斯</p><script type="math/tex; mode=display">\begin{aligned}q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)& =q(\mathbf{x}_t|\mathbf{x}_{t-1},\mathbf{x}_0)\frac{q(\mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_t|\mathbf{x}_0)}  \\&\propto\exp\left(-\frac12(\frac{(\mathbf{x}_t-\sqrt{\alpha_t}\mathbf{x}_{t-1})^2}{\beta_t}+\frac{(\mathbf{x}_{t-1}-\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0)^2}{1-\bar{\alpha}_{t-1}}-\frac{(\mathbf{x}_t-\sqrt{\bar{\alpha}_t}\mathbf{x}_0)^2}{1-\bar{\alpha}_t})\right) \\&=\exp\left(-\frac12(\frac{\mathbf{x}_t^2-2\sqrt{\alpha_t}\mathbf{x}_t\mathbf{x}_{t-1}+\alpha_t\mathbf{x}_{t-1}^2}{\beta_t}+\frac{\mathbf{x}_{t-1}^2-2\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0\mathbf{x}_{t-1}+\bar{\alpha}_{t-1}\mathbf{x}_0^2}{1-\bar{\alpha}_{t-1}}-\frac{(\mathbf{x}_t-\sqrt{\bar{\alpha}_t}\mathbf{x}_0)^2}{1-\bar{\alpha}_t})\right) \\&\left.=\exp\left(-\frac12(\color{red}{(\frac{\alpha_t}{\beta_t}+\frac1{1-\bar{\alpha}_{t-1}})x_{t-1}^2-(\frac{2\sqrt{\alpha_t}}{\beta_t}x_t+\frac{2\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}x_0)x_{t-1}+C(\mathbf{x}_t,\mathbf{x}_0)}\right)\right)\end{aligned}</script><p>根据一堆公式计算(这不是我擅长的),得到均值和方差.</p><script type="math/tex; mode=display">\begin{aligned}\tilde{\beta}_{t}& =1/(\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar{\alpha}_{t-1}})=1/(\frac{\alpha_t-\bar{\alpha}_t+\beta_t}{\beta_t(1-\bar{\alpha}_{t-1})})=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t  \\\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t,\mathbf{x}_0)& =(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t+\frac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}\mathbf{x}_0)/(\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar{\alpha}_{t-1}})  \\&=(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t+\frac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}\mathbf{x}_0)\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t \\&=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t+\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0\end{aligned}</script><p>由于$\mathbf{x}_0=\frac1{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}_t)$,有均值如下:</p><script type="math/tex; mode=display">\begin{aligned}\tilde{\boldsymbol{\mu}}_{t}& =\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t+\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}_t)  \\&=\color{red}{\frac1{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_t\right)}\end{aligned}</script><p>所以需要训练一个神经网络拟合这个概率分布,使用重参数化技巧,前向加噪声后,利用得到的图像数据得到高斯分布的参数μ</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{\mu}_{\theta}(\mathbf{x}_{t},t)& =\color{red}{\frac1{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)\right)}  \\\Gamma\mathrm{hus~}\mathbf{x}_{t-1}& =\mathcal{N}(\mathbf{x}_{t-1};\frac{1}{\sqrt{\alpha_{t}}}\left(\mathbf{x}_{t}-\frac{1-\alpha_{t}}{\sqrt{1-\bar{\alpha}_{t}}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t},t)\right),\boldsymbol{\Sigma}_{\theta}(\mathbf{x}_{t},t)) \end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}L_{t}& =\mathbb{E}_{\mathbf{x}_0,\epsilon}\Big[\frac{1}{2\|\boldsymbol{\Sigma}_\theta(\mathbf{x}_t,t)\|_2^2}\|\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t,\mathbf{x}_0)-\boldsymbol{\mu}_\theta(\mathbf{x}_t,t)\|^2\Big]  \\&=\mathbb{E}_{\mathbf{x}_0,\epsilon}\Big[\frac1{2\|\boldsymbol{\Sigma}_\theta\|_2^2}\|\color{red}{\frac1{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_t\right)}-\frac1{\sqrt{\alpha_t}}\Big(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \\&=\mathbb{E}_{\mathbf{x}_0,\boldsymbol{\epsilon}}\Big[\frac{(1-\alpha_t)^2}{2\alpha_t(1-\bar{\alpha}_t)\|\boldsymbol{\Sigma}_\theta\|_2^2}\|\boldsymbol{\epsilon}_t-\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)\|^2\Big] \\&=\mathbb{E}_{\mathbf{x}_0,\epsilon}\Big[\frac{(1-\alpha_t)^2}{2\alpha_t(1-\bar{\alpha}_t)\|\boldsymbol{\Sigma}_\theta\|_2^2}\|\boldsymbol{\epsilon}_t-\boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}_t,t)\|^2\Big]\end{aligned}</script><h3 id="简化"><a href="#简化" class="headerlink" title="简化"></a>简化</h3><script type="math/tex; mode=display">\begin{aligned}L_{t}^{\operatorname{simple}}& =\mathbb{E}_{t\sim[1,T],\mathbf{x}_0,\boldsymbol{\epsilon}_t}\left[\|\boldsymbol{\epsilon}_t-\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)\|^2\right]  \\&=\mathbb{E}_{t\sim[1,T],\mathbf{x}_0,\boldsymbol{\epsilon}_t}\left[\|\boldsymbol{\epsilon}_t-\boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}_t,t)\|^2\right]\end{aligned}</script><p>最终目标优化函数</p><script type="math/tex; mode=display">L_\text{simple} = L_t^\text{simple} + C</script><p><img data-src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM-algo.png" alt="img"></p><h2 id="加速扩散模型采样"><a href="#加速扩散模型采样" class="headerlink" title="加速扩散模型采样"></a>加速扩散模型采样</h2><p>DDPM生成样本很慢,可以通过经过多步后进行采样(也就是增加采样间隔),或者根据DDIM论文,跳过p(x~t~|x~t-1~)直接从p(x~t~|x~0~)出发.</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{X}_{t-1}& =\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_{t-1}}\boldsymbol{\epsilon}_{t-1}  \\&=\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2}\boldsymbol{\epsilon}_t+\sigma_t\boldsymbol{\epsilon} \\&=\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2}\frac{\mathbf{x}_t-\sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1-\bar{\alpha}_t}}+\sigma_t\boldsymbol{\epsilon} \\q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)& =\mathcal{N}(\mathbf{x}_{t-1};\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t-1}-\sigma_{t}^{2}}\frac{\mathbf{x}_{t}-\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0}}{\sqrt{1-\bar{\alpha}_{t}}},\sigma_{t}^{2}\mathbf{I}) \end{aligned}</script><script type="math/tex; mode=display">\tilde{\beta}_t=\sigma_t^2=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\cdot\beta_t</script><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://huggingface.co/blog/annotated-diffusion">The Annotated Diffusion Model (huggingface.co)</a></li><li><a href="https://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing#scrollTo=qWw50ui9IZ5q">diffusion_model.ipynb - Colaboratory (google.com)</a></li><li><a href="https://github.com/cloneofsimo/minDiffusion/tree/master">cloneofsimo/minDiffusion: Self-contained, minimalistic implementation of diffusion models with Pytorch. (github.com)</a></li><li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models? | Lil’Log (lilianweng.github.io)</a></li><li><a href="https://spaces.ac.cn/archives/9119">生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼 - 科学空间|Scientific Spaces</a></li><li><a href="https://sungsoo.github.io/2022/07/20/diffusion-model.html">Diffusion Models from Scratch in PyTorch (sungsoo.github.io)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近OpenAI的Sora模型又大火了一把,据说背后的技术是transformer+diffusion.之前我也大致介绍过stable diffusion的过程,这里我再稍微详细介绍一下经典的扩散模型以及改进之后的DDIM.其中我也有很多不太明白的,只有结合代码理解了.&lt;br&gt;</summary>
    
    
    
    
    <category term="diffusion model" scheme="https://www.sekyoro.top/tags/diffusion-model/"/>
    
  </entry>
  
  <entry>
    <title>机器学习回顾:集成学习</title>
    <link href="https://www.sekyoro.top/2024/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E9%A1%BE-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E9%A1%BE-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-02-22T15:49:54.000Z</published>
    <updated>2024-02-23T04:55:42.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>传统的机器学习方法,现在用得不多了(自我感觉).但是有必要稍微了解一下原理。<br><span id="more"></span></p><p>集成学习方法可以分为Bagging,Boosting以及Stacking.</p><p>Bagging也称为bootstrap聚合，是预测模型的多个版本的聚合。每个模型都是单独训练的，并使用平均过程进行组合。装袋的主要重点是实现比任何模型单独具有的方差更小的方差。</p><p>Bootstrapping 是从给定的数据集中生成自举样本的过程。样本是通过随机抽取数据点并进行替换而形成的。</p><p>重新采样的数据包含原始数据中作为一个整体的不同特征。它绘制了数据点中存在的分布，并且往往保持彼此不同，即数据分布必须保持完整，同时保持Bootstrapping 样本之间的不相似性.其实这跟目前深度学习中的样本增强等概念又何尝不同呢.</p><p>在Bagging中,首先创建自举样本.然后,对每个样本应用回归算法或分类算法.最后在回归的情况下,对个体学习者预测的所有输出取平均值.对于分类,要么接受投票最多的类别（硬投票）,要么将所有类别概率的最高平均值作为输出（软投票）</p><script type="math/tex; mode=display">\widehat{f_{bag}}=\widehat{f_1}\left(X\right)+\widehat{f_2}\left(X\right)+\cdots+\widehat{f_b}\left(X\right)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">seed = <span class="number">7</span></span><br><span class="line">kfold = model_selection.KFold(n_splits=<span class="number">10</span>, random_state=seed)</span><br><span class="line">cart = DecisionTreeClassifier()</span><br><span class="line">num_trees = <span class="number">100</span></span><br><span class="line">model = BaggingClassifier(base_estimator=cart,n_estimators=num_trees, random_state=seed)</span><br><span class="line"></span><br><span class="line">results = model_selection.cross_val_score(model, X, Y, cv=kfold)</span><br><span class="line"><span class="built_in">print</span>(results.mean())</span><br></pre></td></tr></table></figure><p>Stacking是通过一个元分类器或者元回归器来整合多个分类模型或回归模型的集成学习技术。基础模型利用整个训练集做训练，元模型将基础模型的特征作为特征进行训练.感觉有点类似于元学习(meta learning)的概念.</p><p><img data-src="https://pic1.zhimg.com/80/v2-6a1eb954185433e79498dea9bf87e0e0_720w.webp" alt="img"></p><p>或者又可以分为顺序的和并行的训练器.不同的模型按顺序生成,之前模型的错误由后面的分类器学习.这旨在通过赋予错误标记的示例更高的权重（例如AdaBoost）来利用模型之间的相关性。</p><p> 并行训练器,其中基础模型是并行生成的.这通过平均错误来利用模型之间的独立性（例如随机森林）</p><p>这里主要介绍其中的Boosting,Boosting算法试图从几个较弱模型的错误中建立一个强大的学习者（预测模型）。首先从训练数据创建模型.然后通过尝试减少上一个模型中的错误,从上一个创建第二个模型.依次添加模型,每个模型都对其前身进行校正,直到训练数据得到完美预测或添加了最大数量的模型。</p><p>Boosting包括AdaBoost,Gradient Tree Boosting等等.</p><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>AdaBoost是一种非常流行的Boosting技术,旨在将多个弱分类器组合起来构建一个强分类器.弱分类器比随机猜测性能更好，但在为对象指定类方面仍然表现不佳。单个分类器可能无法准确预测对象的类别，但当我们将多个弱分类器分组，每个弱分类器从其他错误分类的对象中逐步学习时，我们可以建立一个这样的强模型。这里提到的分类器可以是任何基本分类器，从决策树（通常是默认的）到逻辑回归等。</p><p>步骤1：基于加权样本在训练数据之上进行弱分类器（例如decision stump）.每个样本的权重表明正确分类的重要性。最初，对于第一个stump,我们给予所有样本相等的权重。</p><p>第2步：我们为每个变量创建一个决策树桩,看看每个树桩将样本分类到目标类的效果如何.</p><p>步骤3：将更多的权重分配给分类错误的样本,以便在下一个决策阶段对其进行正确分类.权重也根据分类器的精度分配给每个分类器,这意味着高精度=高权重</p><p>第4步：从第2步开始重复,直到所有数据点都被正确分类,或者达到最大迭代级别.</p><p>首先给每个样本相同权重,计算得到的预测结果错误率,根据错误率得到α</p><script type="math/tex; mode=display">error = sum(w(i) * terror(i)) / sum(w) \\terror = 0 if(y == p), otherwise 1</script><script type="math/tex; mode=display">\alpha_t=\frac12ln\frac{(1-TotalError)}{TotalError}</script><p>然后对权重进行更新</p><script type="math/tex; mode=display">w_i=w_{i-1}*e^{\pm\alpha}</script><p>当预测输出和实际输出一致时（样本分类正确），Alpha为正。在这种情况下，我们减少了样权重，因为已经表现得很好了。</p><p>当预测输出与实际类别不一致时（即样本分类错误），Alpha为负值。在这种情况下需要增加样本权重，以便在下一个树桩中不会重复相同的错误分类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Created on Nov 28, 2010</span></span><br><span class="line"><span class="string">Adaboost is short for Adaptive Boosting</span></span><br><span class="line"><span class="string">@author: Peter</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadSimpData</span>():</span></span><br><span class="line">    datMat = matrix([[ <span class="number">1.</span> ,  <span class="number">2.1</span>],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.1</span>],</span><br><span class="line">        [ <span class="number">1.3</span>,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">1.</span> ,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.</span> ]])</span><br><span class="line">    classLabels = [<span class="number">1.0</span>, <span class="number">1.0</span>, -<span class="number">1.0</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>]</span><br><span class="line">    <span class="keyword">return</span> datMat,classLabels</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>(<span class="params">fileName</span>):</span>      <span class="comment">#general function to parse tab -delimited floats</span></span><br><span class="line">    numFeat = <span class="built_in">len</span>(<span class="built_in">open</span>(fileName).readline().split(<span class="string">&#x27;\t&#x27;</span>)) <span class="comment">#get number of fields </span></span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    fr = <span class="built_in">open</span>(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr =[]</span><br><span class="line">        curLine = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeat-<span class="number">1</span>):</span><br><span class="line">            lineArr.append(<span class="built_in">float</span>(curLine[i]))</span><br><span class="line">        dataMat.append(lineArr)</span><br><span class="line">        labelMat.append(<span class="built_in">float</span>(curLine[-<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span>(<span class="params">dataMatrix,dimen,threshVal,threshIneq</span>):</span><span class="comment">#just classify the data</span></span><br><span class="line">    retArray = ones((shape(dataMatrix)[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> threshIneq == <span class="string">&#x27;lt&#x27;</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &lt;= threshVal] = -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &gt; threshVal] = -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">return</span> retArray</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span>(<span class="params">dataArr,classLabels,D</span>):</span></span><br><span class="line">    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T</span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    numSteps = <span class="number">10.0</span>; bestStump = &#123;&#125;; bestClasEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    minError = inf <span class="comment">#init error sum, to +infinity</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):<span class="comment">#loop over all dimensions</span></span><br><span class="line">        rangeMin = dataMatrix[:,i].<span class="built_in">min</span>(); rangeMax = dataMatrix[:,i].<span class="built_in">max</span>();</span><br><span class="line">        stepSize = (rangeMax-rangeMin)/numSteps</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">1</span>,<span class="built_in">int</span>(numSteps)+<span class="number">1</span>):<span class="comment">#loop over all range in current dimension</span></span><br><span class="line">            <span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">&#x27;lt&#x27;</span>, <span class="string">&#x27;gt&#x27;</span>]: <span class="comment">#go over less than and greater than</span></span><br><span class="line">                threshVal = (rangeMin + <span class="built_in">float</span>(j) * stepSize)</span><br><span class="line">                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)<span class="comment">#call stump classify with i, j, lessThan</span></span><br><span class="line">                errArr = mat(ones((m,<span class="number">1</span>)))</span><br><span class="line">                errArr[predictedVals == labelMat] = <span class="number">0</span></span><br><span class="line">                weightedError = D.T*errArr  <span class="comment">#calc total error multiplied by D</span></span><br><span class="line">                <span class="comment">#print &quot;split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f&quot; % (i, threshVal, inequal, weightedError)</span></span><br><span class="line">                <span class="keyword">if</span> weightedError &lt; minError:</span><br><span class="line">                    minError = weightedError</span><br><span class="line">                    bestClasEst = predictedVals.copy()</span><br><span class="line">                    bestStump[<span class="string">&#x27;dim&#x27;</span>] = i</span><br><span class="line">                    bestStump[<span class="string">&#x27;thresh&#x27;</span>] = threshVal</span><br><span class="line">                    bestStump[<span class="string">&#x27;ineq&#x27;</span>] = inequal</span><br><span class="line">    <span class="keyword">return</span> bestStump,minError,bestClasEst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span>(<span class="params">dataArr,classLabels,numIt=<span class="number">40</span></span>):</span></span><br><span class="line">    weakClassArr = []</span><br><span class="line">    m = shape(dataArr)[<span class="number">0</span>]</span><br><span class="line">    D = mat(ones((m,<span class="number">1</span>))/m)   <span class="comment">#init D to all equal</span></span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numIt):</span><br><span class="line">        bestStump,error,classEst = buildStump(dataArr,classLabels,D)<span class="comment">#build Stump</span></span><br><span class="line">        <span class="comment">#print &quot;D:&quot;,D.T</span></span><br><span class="line">        alpha = <span class="built_in">float</span>(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/<span class="built_in">max</span>(error,<span class="number">1e-16</span>)))<span class="comment">#calc alpha, throw in max(error,eps) to account for error=0</span></span><br><span class="line">        bestStump[<span class="string">&#x27;alpha&#x27;</span>] = alpha  </span><br><span class="line">        weakClassArr.append(bestStump)                  <span class="comment">#store Stump Params in Array</span></span><br><span class="line">        <span class="comment">#print &quot;classEst: &quot;,classEst.T</span></span><br><span class="line">        expon = multiply(-<span class="number">1</span>*alpha*mat(classLabels).T,classEst) <span class="comment">#exponent for D calc, getting messy</span></span><br><span class="line">        D = multiply(D,exp(expon))                              <span class="comment">#Calc New D for next iteration</span></span><br><span class="line">        D = D/D.<span class="built_in">sum</span>()</span><br><span class="line">        <span class="comment">#calc training error of all classifiers, if this is 0 quit for loop early (use break)</span></span><br><span class="line">        aggClassEst += alpha*classEst</span><br><span class="line">        <span class="comment">#print &quot;aggClassEst: &quot;,aggClassEst.T</span></span><br><span class="line">        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,<span class="number">1</span>)))</span><br><span class="line">        errorRate = aggErrors.<span class="built_in">sum</span>()/m</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;total error: &quot;</span>,errorRate</span><br><span class="line">        <span class="keyword">if</span> errorRate == <span class="number">0.0</span>: <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> weakClassArr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span>(<span class="params">datToClass,classifierArr</span>):</span></span><br><span class="line">    dataMatrix = mat(datToClass)<span class="comment">#do stuff similar to last aggClassEst in adaBoostTrainDS</span></span><br><span class="line">    m = shape(dataMatrix)[<span class="number">0</span>]</span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classifierArr)):</span><br><span class="line">        classEst = stumpClassify(dataMatrix, classifierArr[i][<span class="string">&#x27;dim&#x27;</span>],\</span><br><span class="line">                                 classifierArr[i][<span class="string">&#x27;thresh&#x27;</span>],\</span><br><span class="line">                                 classifierArr[i][<span class="string">&#x27;ineq&#x27;</span>])<span class="comment">#call stump classify</span></span><br><span class="line">        aggClassEst += classifierArr[i][<span class="string">&#x27;alpha&#x27;</span>]*classEst</span><br><span class="line">        <span class="built_in">print</span> aggClassEst</span><br><span class="line">    <span class="keyword">return</span> sign(aggClassEst)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotROC</span>(<span class="params">predStrengths, classLabels</span>):</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    cur = (<span class="number">1.0</span>,<span class="number">1.0</span>) <span class="comment">#cursor</span></span><br><span class="line">    ySum = <span class="number">0.0</span> <span class="comment">#variable to calculate AUC</span></span><br><span class="line">    numPosClas = <span class="built_in">sum</span>(array(classLabels)==<span class="number">1.0</span>)</span><br><span class="line">    yStep = <span class="number">1</span>/<span class="built_in">float</span>(numPosClas); xStep = <span class="number">1</span>/<span class="built_in">float</span>(<span class="built_in">len</span>(classLabels)-numPosClas)</span><br><span class="line">    sortedIndicies = predStrengths.argsort()<span class="comment">#get sorted index, it&#x27;s reverse</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    fig.clf()</span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment">#loop through all the values, drawing a line segment at each point</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> sortedIndicies.tolist()[<span class="number">0</span>]:</span><br><span class="line">        <span class="keyword">if</span> classLabels[index] == <span class="number">1.0</span>:</span><br><span class="line">            delX = <span class="number">0</span>; delY = yStep;</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            delX = xStep; delY = <span class="number">0</span>;</span><br><span class="line">            ySum += cur[<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#draw line from cur to (cur[0]-delX,cur[1]-delY)</span></span><br><span class="line">        ax.plot([cur[<span class="number">0</span>],cur[<span class="number">0</span>]-delX],[cur[<span class="number">1</span>],cur[<span class="number">1</span>]-delY], c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">        cur = (cur[<span class="number">0</span>]-delX,cur[<span class="number">1</span>]-delY)</span><br><span class="line">    ax.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">&#x27;b--&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;False positive rate&#x27;</span>); plt.ylabel(<span class="string">&#x27;True positive rate&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;ROC curve for AdaBoost horse colic detection system&#x27;</span>)</span><br><span class="line">    ax.axis([<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;the Area Under the Curve is: &quot;</span>,ySum*xStep</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/">Boosting and AdaBoost for Machine Learning - MachineLearningMastery.com</a></li><li><a href="https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/">A Gentle Introduction to XGBoost for Applied Machine Learning - MachineLearningMastery.com</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;传统的机器学习方法,现在用得不多了(自我感觉).但是有必要稍微了解一下原理。&lt;br&gt;</summary>
    
    
    
    
    <category term="Ensemble Learning" scheme="https://www.sekyoro.top/tags/Ensemble-Learning/"/>
    
  </entry>
  
  <entry>
    <title>深度学习有用的库以及介绍</title>
    <link href="https://www.sekyoro.top/2024/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%89%E7%94%A8%E7%9A%84%E5%BA%93%E4%BB%A5%E5%8F%8A%E4%BB%8B%E7%BB%8D/"/>
    <id>https://www.sekyoro.top/2024/02/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%89%E7%94%A8%E7%9A%84%E5%BA%93%E4%BB%A5%E5%8F%8A%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-02-19T07:49:03.000Z</published>
    <updated>2024-02-23T07:07:03.166Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在看其他源代码时以及自己写代码时可能用到的有用的库以及一些常用写法.<br><span id="more"></span></p><h2 id="python自带的库"><a href="#python自带的库" class="headerlink" title="python自带的库"></a>python自带的库</h2><h3 id="itertools"><a href="#itertools" class="headerlink" title="itertools"></a>itertools</h3><p>用于迭代器的工具<a href="https://docs.python.org/zh-cn/3/library/itertools.html">itertools —- 为高效循环而创建迭代器的函数 — Python 3.12.2 文档</a></p><h3 id="functools"><a href="#functools" class="headerlink" title="functools"></a>functools</h3><p>用于处理函数的工具</p><h3 id="collections"><a href="#collections" class="headerlink" title="collections"></a>collections</h3><p>集合工具</p><h2 id="深度学习库"><a href="#深度学习库" class="headerlink" title="深度学习库"></a>深度学习库</h2><h3 id="timm"><a href="#timm" class="headerlink" title="timm"></a>timm</h3><h3 id="einops"><a href="#einops" class="headerlink" title="einops"></a>einops</h3><h3 id="from-torch-import-einsum"><a href="#from-torch-import-einsum" class="headerlink" title="from torch import einsum"></a>from torch import einsum</h3><h2 id="transformers"><a href="#transformers" class="headerlink" title="transformers"></a>transformers</h2><h2 id="accelerate"><a href="#accelerate" class="headerlink" title="accelerate"></a>accelerate</h2><h2 id="一些常用代码"><a href="#一些常用代码" class="headerlink" title="一些常用代码"></a>一些常用代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">seed = <span class="number">2024</span></span><br><span class="line">random.seed(seed)</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Optimizer</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> LambdaLR</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cosine_schedule_with_warmup</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">optimizer: Optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">num_warmup_steps: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">num_training_steps: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">num_cycles: <span class="built_in">float</span> = <span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">last_epoch: <span class="built_in">int</span> = -<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Create a schedule with a learning rate that decreases following the values of the cosine function between the</span></span><br><span class="line"><span class="string">initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the</span></span><br><span class="line"><span class="string">initial lr set in the optimizer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">optimizer (:class:`~torch.optim.Optimizer`):</span></span><br><span class="line"><span class="string">The optimizer for which to schedule the learning rate.</span></span><br><span class="line"><span class="string">num_warmup_steps (:obj:`int`):</span></span><br><span class="line"><span class="string">The number of steps for the warmup phase.</span></span><br><span class="line"><span class="string">num_training_steps (:obj:`int`):</span></span><br><span class="line"><span class="string">The total number of training steps.</span></span><br><span class="line"><span class="string">num_cycles (:obj:`float`, `optional`, defaults to 0.5):</span></span><br><span class="line"><span class="string">The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0</span></span><br><span class="line"><span class="string">following a half-cosine).</span></span><br><span class="line"><span class="string">last_epoch (:obj:`int`, `optional`, defaults to -1):</span></span><br><span class="line"><span class="string">The index of the last epoch when resuming training.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Return:</span></span><br><span class="line"><span class="string">:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_lambda</span>(<span class="params">current_step</span>):</span></span><br><span class="line"><span class="comment"># Warmup</span></span><br><span class="line"><span class="keyword">if</span> current_step &lt; num_warmup_steps:</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">float</span>(current_step) / <span class="built_in">float</span>(<span class="built_in">max</span>(<span class="number">1</span>, num_warmup_steps))</span><br><span class="line"><span class="comment"># decadence</span></span><br><span class="line">progress = <span class="built_in">float</span>(current_step - num_warmup_steps) / <span class="built_in">float</span>(</span><br><span class="line"><span class="built_in">max</span>(<span class="number">1</span>, num_training_steps - num_warmup_steps)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">max</span>(</span><br><span class="line"><span class="number">0.0</span>, <span class="number">0.5</span> * (<span class="number">1.0</span> + math.cos(math.pi * <span class="built_in">float</span>(num_cycles) * <span class="number">2.0</span> * progress))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> LambdaLR(optimizer, lr_lambda, last_epoch)</span><br></pre></td></tr></table></figure><h2 id="一些有用的资料"><a href="#一些有用的资料" class="headerlink" title="一些有用的资料"></a>一些有用的资料</h2><ol><li><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks">CS 230 - Deep Learning Tips and Tricks Cheatsheet (stanford.edu)</a></li><li><a href="https://github.com/Conchylicultor/Deep-Learning-Tricks">Conchylicultor/Deep-Learning-Tricks: Enumerate diverse machine learning training tricks. (github.com)</a></li><li><a href="https://github.com/ayyucedemirbas/Deep-Learning-Tips-and-Tricks">ayyucedemirbas/Deep-Learning-Tips-and-Tricks (github.com)</a></li><li>找一些模型代码<a href="https://github.com/huggingface/pytorch-image-models">huggingface/pytorch-image-models: PyTorch image models, scripts, pretrained weights — ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNet-V3/V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more (github.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在看其他源代码时以及自己写代码时可能用到的有用的库以及一些常用写法.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>transformer and attention(三)</title>
    <link href="https://www.sekyoro.top/2024/02/16/transformer-and-attention-%E4%B8%89/"/>
    <id>https://www.sekyoro.top/2024/02/16/transformer-and-attention-%E4%B8%89/</id>
    <published>2024-02-16T14:44:00.000Z</published>
    <updated>2024-02-21T15:14:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>这里介绍一些细节信息.有关位置编码信息和用于图像的transformer.<br><span id="more"></span></p><h2 id="线性注意力"><a href="#线性注意力" class="headerlink" title="线性注意力"></a>线性注意力</h2><script type="math/tex; mode=display">Attention(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V})=softmax\left(\boldsymbol{Q}\boldsymbol{K}^\top\right)\boldsymbol{V}</script><p>其中$Q\in\mathbb{R}^{n\times d_k},\boldsymbol{K}\in\mathbb{R}^{m\times d_k},\boldsymbol{V}\in\mathbb{R}^{m\times d_v}$​,一般情况下n&gt;d甚至n&gt;&gt;d.所以如果对QK^T^进行softmax操作,复杂度为O(mn),所以去掉Softmax的Attention的复杂度可以降到最理想的线性级别Linear Attention.</p><script type="math/tex; mode=display">Attention(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V})_i=\frac{\sum_{j=1}^nsim(\boldsymbol{q}_i,\boldsymbol{k}_j)\boldsymbol{v}_j}{\sum_{j=1}^nsim(\boldsymbol{q}_i,\boldsymbol{k}_j)}</script><p>只要保证Attention相似的分布特性,要求sim(q~i~,k~j~)≥0恒成立.比如可以把核函数改为激活函数使得输出大于0.</p><p>还可以改成softmax.</p><p><img data-src="https://s2.loli.net/2024/02/17/wE3HgYJ7KnxZ5pe.png" alt="image-20240217224419083"></p><p>其中softmax1、softmax2分别指在第一个（n）、第二个维度（d）进行Softmax运算.</p><p><a href="https://spaces.ac.cn/archives/7546">线性Attention的探索：Attention必须有个Softmax吗？ - 科学空间|Scientific Spaces</a>提出将指数</p><p>e^qK^泰勒展开,$e^{\boldsymbol{q}_i^\top\boldsymbol{k}_j}\approx1+\boldsymbol{q}_i^\top\boldsymbol{k}_j$</p><p><img data-src="https://s2.loli.net/2024/02/17/fhBMIgcsqzZQt3k.png" alt="image-20240217224836831"></p><p>此外还有稀疏注意力,这里就不多介绍了.</p><h2 id="图像中的transformer与attention"><a href="#图像中的transformer与attention" class="headerlink" title="图像中的transformer与attention"></a>图像中的transformer与attention</h2><p>注意力机制以及transformer都是先在NLP领域发展,所以一般attention可能会处理一些1维数据,有CNN与transformer结合的Conformer<a href="https://arxiv.org/abs/2005.08100">[2005.08100] Conformer: Convolution-augmented Transformer for Speech Recognition (arxiv.org)</a>,conformer中的编码采用相对位置编码.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, einsum</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exists</span>(<span class="params">val</span>):</span></span><br><span class="line">    <span class="keyword">return</span> val <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">default</span>(<span class="params">val, d</span>):</span></span><br><span class="line">    <span class="keyword">return</span> val <span class="keyword">if</span> exists(val) <span class="keyword">else</span> d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Swish</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * x.sigmoid()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, mult=<span class="number">4</span>, dropout=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(dim, dim * mult),</span><br><span class="line">            Swish(),  <span class="comment"># or can be replace by nn.silu()</span></span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">            nn.Linear(dim * mult, dim),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, heads=<span class="number">8</span>, dim_head=<span class="number">64</span>, dropout=<span class="number">0.0</span>, max_pos_emb=<span class="number">512</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dim_head * heads</span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dim_head**-<span class="number">0.5</span></span><br><span class="line">        self.to_q = nn.Linear(dim, inner_dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_kv = nn.Linear(dim, inner_dim * <span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_out = nn.Linear(inner_dim, dim)</span><br><span class="line"></span><br><span class="line">        self.max_pos_emb = max_pos_emb</span><br><span class="line">        self.rel_pos_emb = nn.Embedding(<span class="number">2</span> * max_pos_emb + <span class="number">1</span>, dim_head)</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, context=<span class="literal">None</span>, mask=<span class="literal">None</span>, context_mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        n, device, h, max_pos_emb, has_context = (</span><br><span class="line">            x.shape[-<span class="number">2</span>],</span><br><span class="line">            x.device,</span><br><span class="line">            self.heads,</span><br><span class="line">            self.max_pos_emb,</span><br><span class="line">            exists(context),</span><br><span class="line">        )</span><br><span class="line">        context = default(context, x)</span><br><span class="line"></span><br><span class="line">        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(<span class="number">2</span>, dim=-<span class="number">1</span>))</span><br><span class="line">        q, k, v = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: rearrange(t, <span class="string">&quot;b n (h d) -&gt; b h n d&quot;</span>, h=h), (q, k, v))</span><br><span class="line"></span><br><span class="line">        dots = einsum(<span class="string">&quot;b h i d, b h j d -&gt; b h i j&quot;</span>, q, k) * self.scale</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shaw&#x27;s relative positional embedding</span></span><br><span class="line">        seq = torch.arange(n, device=device)</span><br><span class="line">        dist = rearrange(seq, <span class="string">&quot;i -&gt; i ()&quot;</span>) - rearrange(seq, <span class="string">&quot;j -&gt; () j&quot;</span>)</span><br><span class="line">        dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb</span><br><span class="line">        rel_pos_emb = self.rel_pos_emb(dist).to(q)</span><br><span class="line">        pos_attn = einsum(<span class="string">&quot;b h n d, n r d -&gt; b h n r&quot;</span>, q, rel_pos_emb) * self.scale</span><br><span class="line">        dots = dots + pos_attn</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> exists(mask) <span class="keyword">or</span> exists(context_mask):</span><br><span class="line">            mask = default(mask, <span class="keyword">lambda</span>: torch.ones(*x.shape[:<span class="number">2</span>], device=device))</span><br><span class="line">            context_mask = (</span><br><span class="line">                default(context_mask, mask)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> has_context</span><br><span class="line">                <span class="keyword">else</span> default(</span><br><span class="line">                    context_mask, <span class="keyword">lambda</span>: torch.ones(*context.shape[:<span class="number">2</span>], device=device)</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">            mask_value = -torch.finfo(dots.dtype).<span class="built_in">max</span></span><br><span class="line">            mask = rearrange(mask, <span class="string">&quot;b i -&gt; b () i ()&quot;</span>) * rearrange(</span><br><span class="line">                context_mask, <span class="string">&quot;b j -&gt; b () () j&quot;</span></span><br><span class="line">            )</span><br><span class="line">            dots.masked_fill_(~mask, mask_value)</span><br><span class="line"></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = einsum(<span class="string">&quot;b h i j, b h j d -&gt; b h i d&quot;</span>, attn, v)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        out = self.to_out(out)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_same_padding</span>(<span class="params">kernel_size</span>):</span></span><br><span class="line">    pad = kernel_size // <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> pad, pad - (kernel_size + <span class="number">1</span>) % <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DepthWiseConv1d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, chan_in, chan_out, kernel_size, padding</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.padding = padding</span><br><span class="line">        self.conv = nn.Conv1d(chan_in, chan_out, kernel_size, groups=chan_in)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.pad(x, self.padding)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GLU</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out, gate = x.chunk(<span class="number">2</span>, dim=self.dim)</span><br><span class="line">        <span class="keyword">return</span> out * gate.sigmoid()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConformerConvModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, dim, causal=<span class="literal">False</span>, expansion_factor=<span class="number">2</span>, kernel_size=<span class="number">31</span>, dropout=<span class="number">0.0</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dim * expansion_factor</span><br><span class="line">        padding = calc_same_padding(kernel_size) <span class="keyword">if</span> <span class="keyword">not</span> causal <span class="keyword">else</span> (kernel_size - <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            Rearrange(<span class="string">&quot;b n d -&gt; b d n&quot;</span>),</span><br><span class="line">            nn.Conv1d(dim, inner_dim * <span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">            GLU(dim=<span class="number">1</span>),</span><br><span class="line">            DepthWiseConv1d(</span><br><span class="line">                inner_dim, inner_dim, kernel_size=kernel_size, padding=padding</span><br><span class="line">            ),</span><br><span class="line">            nn.BatchNorm1d(inner_dim) <span class="keyword">if</span> <span class="keyword">not</span> causal <span class="keyword">else</span> nn.Identity(),</span><br><span class="line">            Swish(),</span><br><span class="line">            nn.Conv1d(inner_dim, dim, <span class="number">1</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b d n -&gt; b n d&quot;</span>),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scale</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, scale, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.scale = scale</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fn(x, **kwargs) * self.scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PreNorm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fn = fn</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> self.fn(x, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConformerBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        *,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_mult=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_expansion_factor=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_kernel_size=<span class="number">31</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_causal=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.ff1 = FeedForward(dim=dim, mult=ff_mult, dropout=ff_dropout)</span><br><span class="line">        self.attn = Attention(</span><br><span class="line">            dim=dim, dim_head=dim_head, heads=heads, dropout=attn_dropout</span><br><span class="line">        )</span><br><span class="line">        self.conv = ConformerConvModule(</span><br><span class="line">            dim=dim,</span><br><span class="line">            causal=conv_causal,</span><br><span class="line">            expansion_factor=conv_expansion_factor,</span><br><span class="line">            kernel_size=conv_kernel_size,</span><br><span class="line">            dropout=conv_dropout,</span><br><span class="line">        )</span><br><span class="line">        self.ff2 = FeedForward(dim=dim, mult=ff_mult, dropout=ff_dropout)</span><br><span class="line"></span><br><span class="line">        self.attn = PreNorm(dim, self.attn)</span><br><span class="line">        self.ff1 = Scale(<span class="number">0.5</span>, PreNorm(dim, self.ff1))</span><br><span class="line">        self.ff2 = Scale(<span class="number">0.5</span>, PreNorm(dim, self.ff2))</span><br><span class="line"></span><br><span class="line">        self.post_norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        x = self.ff1(x) + x</span><br><span class="line">        x = self.attn(x, mask=mask) + x</span><br><span class="line">        x = self.conv(x) + x</span><br><span class="line">        x = self.ff2(x) + x</span><br><span class="line">        x = self.post_norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        *,</span></span></span><br><span class="line"><span class="params"><span class="function">        depth,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_mult=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_expansion_factor=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_kernel_size=<span class="number">31</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        ff_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        conv_causal=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(</span><br><span class="line">                ConformerBlock(</span><br><span class="line">                    dim=dim,</span><br><span class="line">                    dim_head=dim_head,</span><br><span class="line">                    heads=heads,</span><br><span class="line">                    ff_mult=ff_mult,</span><br><span class="line">                    conv_expansion_factor=conv_expansion_factor,</span><br><span class="line">                    conv_kernel_size=conv_kernel_size,</span><br><span class="line">                    conv_causal=conv_causal,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = block(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上一节中其实已经充分使用了feature map也就是二维数据上的注意力机制,现在介绍一下在视觉领域表现出色的transformer及其变体.</p><h2 id="Vision-Transformer"><a href="#Vision-Transformer" class="headerlink" title="Vision Transformer"></a>Vision Transformer</h2><p><img data-src="https://s2.loli.net/2024/02/17/mdybruOEWxgSDVt.png" alt="image-20240217121859843"></p><p>将transformer拿到CV领域的出名作品,通过patch embedding得到序列,再加上位置编码就能像在nlp一样处理问题.</p><p><img data-src="https://pic1.zhimg.com/80/v2-1c6aa554d8fc53daa7bf79c755b1f86c_720w.webp" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="comment"># helpers</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pair</span>(<span class="params">t</span>):</span></span><br><span class="line">    <span class="keyword">return</span> t <span class="keyword">if</span> <span class="built_in">isinstance</span>(t, <span class="built_in">tuple</span>) <span class="keyword">else</span> (t, t)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">posemb_sincos_2d</span>(<span class="params">h, w, dim, temperature: <span class="built_in">int</span> = <span class="number">10000</span>, dtype=torch.float32</span>):</span></span><br><span class="line">    y, x = torch.meshgrid(torch.arange(h), torch.arange(w), indexing=<span class="string">&quot;ij&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> (dim % <span class="number">4</span>) == <span class="number">0</span>, <span class="string">&quot;feature dimension must be multiple of 4 for sincos emb&quot;</span></span><br><span class="line">    omega = torch.arange(dim // <span class="number">4</span>) / (dim // <span class="number">4</span> - <span class="number">1</span>)</span><br><span class="line">    omega = <span class="number">1.0</span> / (temperature**omega)</span><br><span class="line"></span><br><span class="line">    y = y.flatten()[:, <span class="literal">None</span>] * omega[<span class="literal">None</span>, :]</span><br><span class="line">    x = x.flatten()[:, <span class="literal">None</span>] * omega[<span class="literal">None</span>, :]</span><br><span class="line">    pe = torch.cat((x.sin(), x.cos(), y.sin(), y.cos()), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pe.<span class="built_in">type</span>(dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># classes</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, hidden_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">            nn.Linear(dim, hidden_dim),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Linear(hidden_dim, dim),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, heads=<span class="number">8</span>, dim_head=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        inner_dim = dim_head * heads</span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dim_head**-<span class="number">0.5</span></span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">        self.attend = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.to_qkv = nn.Linear(dim, inner_dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_out = nn.Linear(inner_dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line"></span><br><span class="line">        qkv = self.to_qkv(x).chunk(<span class="number">3</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        q, k, v = <span class="built_in">map</span>(<span class="keyword">lambda</span> t: rearrange(t, <span class="string">&quot;b n (h d) -&gt; b h n d&quot;</span>, h=self.heads), qkv)</span><br><span class="line"></span><br><span class="line">        dots = torch.matmul(q, k.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) * self.scale</span><br><span class="line"></span><br><span class="line">        attn = self.attend(dots)</span><br><span class="line"></span><br><span class="line">        out = torch.matmul(attn, v)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> self.to_out(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, depth, heads, dim_head, mlp_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(</span><br><span class="line">                nn.ModuleList(</span><br><span class="line">                    [</span><br><span class="line">                        Attention(dim, heads=heads, dim_head=dim_head),</span><br><span class="line">                        FeedForward(dim, mlp_dim),</span><br><span class="line">                    ]</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> attn, ff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x) + x</span><br><span class="line">            x = ff(x) + x</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleViT</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        *,</span></span></span><br><span class="line"><span class="params"><span class="function">        image_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        patch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_classes,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        depth,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        channels=<span class="number">3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        image_height, image_width = pair(image_size)</span><br><span class="line">        patch_height, patch_width = pair(patch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            image_height % patch_height == <span class="number">0</span> <span class="keyword">and</span> image_width % patch_width == <span class="number">0</span></span><br><span class="line">        ), <span class="string">&quot;Image dimensions must be divisible by the patch size.&quot;</span></span><br><span class="line"></span><br><span class="line">        patch_dim = channels * patch_height * patch_width</span><br><span class="line"></span><br><span class="line">        self.to_patch_embedding = nn.Sequential(</span><br><span class="line">            Rearrange(</span><br><span class="line">                <span class="string">&quot;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&quot;</span>,</span><br><span class="line">                p1=patch_height,</span><br><span class="line">                p2=patch_width,</span><br><span class="line">            ),</span><br><span class="line">            nn.LayerNorm(patch_dim),</span><br><span class="line">            nn.Linear(patch_dim, dim),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pos_embedding = posemb_sincos_2d(</span><br><span class="line">            h=image_height // patch_height,</span><br><span class="line">            w=image_width // patch_width,</span><br><span class="line">            dim=dim,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)</span><br><span class="line"></span><br><span class="line">        self.pool = <span class="string">&quot;mean&quot;</span></span><br><span class="line">        self.to_latent = nn.Identity()</span><br><span class="line"></span><br><span class="line">        self.linear_head = nn.Linear(dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        device = img.device</span><br><span class="line"></span><br><span class="line">        x = self.to_patch_embedding(img)</span><br><span class="line">        x += self.pos_embedding.to(device, dtype=x.dtype)</span><br><span class="line"></span><br><span class="line">        x = self.transformer(x)</span><br><span class="line">        x = x.mean(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.to_latent(x)</span><br><span class="line">        <span class="keyword">return</span> self.linear_head(x)</span><br></pre></td></tr></table></figure><p>上面做了patch之后的位置编码使用三角函数绝对编码,attention和feednetwork与transformer没有什么差别.</p><h2 id="卷积注意力"><a href="#卷积注意力" class="headerlink" title="卷积注意力"></a>卷积注意力</h2><p>使用vision transformer中使用的绝对位置注意力,但是也可以使用相对位置注意力或者卷积注意力.</p><blockquote><p>卷积位置嵌入( CPE )方法考虑了输入序列的2D性质。采用补零的方式进行2D卷积采集位置信息。卷积位置嵌入( Convolutional Position嵌入，CPE )可用于合并ViT不同阶段的位置数据。CPE可以具体引入到自注意力模块，前馈网络，或者在两个编码器层之间的。</p></blockquote><p>卷积注意力通常方法是利用2D卷积或者depth-wise的卷积将已经做了patch的图像数据进行处理.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvolutionalPositionEmbedding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(d_model, d_model, kernel_size, padding=padding)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 将通道维度和序列长度维度交换</span></span><br><span class="line">        x = x.unsqueeze(<span class="number">2</span>)  <span class="comment"># 在通道维度和序列长度维度之间添加一个维度</span></span><br><span class="line">        x = self.conv(x)  <span class="comment"># 对输入进行卷积操作</span></span><br><span class="line">        x = x.squeeze(<span class="number">2</span>)  <span class="comment"># 移除添加的维度</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 将通道维度和序列长度维度交换回来</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="CVT"><a href="#CVT" class="headerlink" title="CVT"></a>CVT</h3><p><img data-src="https://github.com/rishikksh20/convolution-vision-transformers/raw/master/assets/model.PNG" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#   #!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#   #-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#  Copyleft (C) 2024 proanimer, Inc. All Rights Reserved</span></span><br><span class="line"><span class="comment">#   author:proanimer</span></span><br><span class="line"><span class="comment">#   createTime:2024/2/18 上午10:38</span></span><br><span class="line"><span class="comment">#   lastModifiedTime:2024/2/18 上午10:38</span></span><br><span class="line"><span class="comment">#   file:cvt.py</span></span><br><span class="line"><span class="comment">#   software: classicNets</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange, repeat</span><br><span class="line"><span class="keyword">from</span> einops.layers.torch <span class="keyword">import</span> Rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> einsum</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SepConv2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">        out_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">        kernel_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        padding=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dilation=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SepConv2d, self).__init__()</span><br><span class="line">        self.depthwise = torch.nn.Conv2d(</span><br><span class="line">            in_channels,</span><br><span class="line">            in_channels,</span><br><span class="line">            kernel_size=kernel_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            padding=padding,</span><br><span class="line">            dilation=dilation,</span><br><span class="line">            groups=in_channels,</span><br><span class="line">        )</span><br><span class="line">        self.bn = torch.nn.BatchNorm2d(in_channels)</span><br><span class="line">        self.pointwise = torch.nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.depthwise(x)</span><br><span class="line">        x = self.bn(x)</span><br><span class="line">        x = self.pointwise(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fn(x, **kwargs) + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PreNorm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, fn</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.LayerNorm(dim)</span><br><span class="line">        self.fn = fn</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fn(self.norm(x), **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, hidden_dim, dropout=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(dim, hidden_dim),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">            nn.Linear(hidden_dim, dim),</span><br><span class="line">            nn.Dropout(dropout),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        img_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        kernel_size=<span class="number">3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        q_stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        k_stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        v_stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        last_stage=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.last_stage = last_stage</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        inner_dim = dim_head * heads</span><br><span class="line">        project_out = <span class="keyword">not</span> (heads == <span class="number">1</span> <span class="keyword">and</span> dim_head == dim)</span><br><span class="line"></span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.scale = dim_head**-<span class="number">0.5</span></span><br><span class="line">        pad = (kernel_size - q_stride) // <span class="number">2</span></span><br><span class="line">        self.to_q = SepConv2d(dim, inner_dim, kernel_size, q_stride, pad)</span><br><span class="line">        self.to_k = SepConv2d(dim, inner_dim, kernel_size, k_stride, pad)</span><br><span class="line">        self.to_v = SepConv2d(dim, inner_dim, kernel_size, v_stride, pad)</span><br><span class="line"></span><br><span class="line">        self.to_out = (</span><br><span class="line">            nn.Sequential(nn.Linear(inner_dim, dim), nn.Dropout(dropout))</span><br><span class="line">            <span class="keyword">if</span> project_out</span><br><span class="line">            <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        b, n, _, h = *x.shape, self.heads</span><br><span class="line">        <span class="keyword">if</span> self.last_stage:</span><br><span class="line">            cls_token = x[:, <span class="number">0</span>]</span><br><span class="line">            x = x[:, <span class="number">1</span>:]</span><br><span class="line">            cls_token = rearrange(cls_token.unsqueeze(<span class="number">1</span>), <span class="string">&quot;b n (h d) -&gt; b h n d&quot;</span>, h=h)</span><br><span class="line">        x = rearrange(x, <span class="string">&quot;b (l w) n -&gt; b n l w&quot;</span>, l=self.img_size, w=self.img_size)</span><br><span class="line">        q = self.to_q(x)</span><br><span class="line">        q = rearrange(q, <span class="string">&quot;b (h d) l w -&gt; b h (l w) d&quot;</span>, h=h)</span><br><span class="line"></span><br><span class="line">        v = self.to_v(x)</span><br><span class="line">        v = rearrange(v, <span class="string">&quot;b (h d) l w -&gt; b h (l w) d&quot;</span>, h=h)</span><br><span class="line"></span><br><span class="line">        k = self.to_k(x)</span><br><span class="line">        k = rearrange(k, <span class="string">&quot;b (h d) l w -&gt; b h (l w) d&quot;</span>, h=h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.last_stage:</span><br><span class="line">            q = torch.cat((cls_token, q), dim=<span class="number">2</span>)</span><br><span class="line">            v = torch.cat((cls_token, v), dim=<span class="number">2</span>)</span><br><span class="line">            k = torch.cat((cls_token, k), dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        dots = einsum(<span class="string">&quot;b h i d, b h j d -&gt; b h i j&quot;</span>, q, k) * self.scale</span><br><span class="line"></span><br><span class="line">        attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = einsum(<span class="string">&quot;b h i j, b h j d -&gt; b h i d&quot;</span>, attn, v)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        out = self.to_out(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        img_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        depth,</span></span></span><br><span class="line"><span class="params"><span class="function">        heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim_head,</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        last_stage=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(</span><br><span class="line">                nn.ModuleList(</span><br><span class="line">                    [</span><br><span class="line">                        PreNorm(</span><br><span class="line">                            dim,</span><br><span class="line">                            ConvAttention(</span><br><span class="line">                                dim,</span><br><span class="line">                                img_size,</span><br><span class="line">                                heads=heads,</span><br><span class="line">                                dim_head=dim_head,</span><br><span class="line">                                dropout=dropout,</span><br><span class="line">                                last_stage=last_stage,</span><br><span class="line">                            ),</span><br><span class="line">                        ),</span><br><span class="line">                        PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout)),</span><br><span class="line">                    ]</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> attn, ff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x) + x</span><br><span class="line">            x = ff(x) + x</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cvt</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        image_size,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_classes,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        kernels=[<span class="number">7</span>, <span class="number">3</span>, <span class="number">3</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        strides=[<span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        heads=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        depth=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">10</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        pool=<span class="string">&quot;cls&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        emb_dropout=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        scale_dim=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>(cvt, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> pool <span class="keyword">in</span> &#123;</span><br><span class="line">            <span class="string">&quot;cls&quot;</span>,</span><br><span class="line">            <span class="string">&quot;mean&quot;</span>,</span><br><span class="line">        &#125;, <span class="string">&quot;pool type must be either cls (cls token) or mean (mean pooling)&quot;</span></span><br><span class="line">        self.pool = pool</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.stage1_conv_embed = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, dim, kernels[<span class="number">0</span>], strides[<span class="number">0</span>], <span class="number">2</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b c h w -&gt; b (h w) c&quot;</span>, h=image_size // <span class="number">4</span>, w=image_size // <span class="number">4</span>),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line">        self.stage_1_transformer = nn.Sequential(</span><br><span class="line">            Transformer(</span><br><span class="line">                dim,</span><br><span class="line">                img_size=image_size // <span class="number">4</span>,</span><br><span class="line">                depth=depth[<span class="number">0</span>],</span><br><span class="line">                heads=heads[<span class="number">0</span>],</span><br><span class="line">                dim_head=dim // heads[<span class="number">0</span>],</span><br><span class="line">                mlp_dim=dim * scale_dim,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                last_stage=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">            Rearrange(<span class="string">&quot;b (h w) c -&gt; b c h w&quot;</span>, h=image_size // <span class="number">4</span>, w=image_size // <span class="number">4</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#     stage 2</span></span><br><span class="line">        in_channels = dim</span><br><span class="line">        scale = heads[<span class="number">1</span>] // heads[<span class="number">0</span>]</span><br><span class="line">        dim = scale * dim</span><br><span class="line">        self.stage2_conv_embed = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, dim, kernels[<span class="number">1</span>], strides[<span class="number">1</span>], <span class="number">1</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b c h w -&gt; b (h w) c&quot;</span>, h=image_size // <span class="number">8</span>, w=image_size // <span class="number">8</span>),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line">        self.stage_2_transformer = nn.Sequential(</span><br><span class="line">            Transformer(</span><br><span class="line">                dim,</span><br><span class="line">                img_size=image_size // <span class="number">8</span>,</span><br><span class="line">                depth=depth[<span class="number">1</span>],</span><br><span class="line">                heads=heads[<span class="number">1</span>],</span><br><span class="line">                dim_head=dim // heads[<span class="number">1</span>],</span><br><span class="line">                mlp_dim=dim * scale_dim,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                last_stage=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">            Rearrange(<span class="string">&quot;b (h w) c -&gt; b c h w&quot;</span>, h=image_size // <span class="number">8</span>, w=image_size // <span class="number">8</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#     stage 3</span></span><br><span class="line">        in_channels = dim</span><br><span class="line">        scale = heads[<span class="number">2</span>] // heads[<span class="number">1</span>]</span><br><span class="line">        dim = scale * dim</span><br><span class="line">        self.stage3_conv_embed = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, dim, kernels[<span class="number">2</span>], strides[<span class="number">2</span>], <span class="number">1</span>),</span><br><span class="line">            Rearrange(<span class="string">&quot;b c h w -&gt; b (h w) c&quot;</span>, h=image_size // <span class="number">16</span>, w=image_size // <span class="number">16</span>),</span><br><span class="line">            nn.LayerNorm(dim),</span><br><span class="line">        )</span><br><span class="line">        self.stage_3_transformer = nn.Sequential(</span><br><span class="line">            Transformer(</span><br><span class="line">                dim=dim,</span><br><span class="line">                img_size=image_size // <span class="number">16</span>,</span><br><span class="line">                depth=depth[<span class="number">2</span>],</span><br><span class="line">                heads=heads[<span class="number">2</span>],</span><br><span class="line">                dim_head=self.dim,</span><br><span class="line">                mlp_dim=dim * scale_dim,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                last_stage=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">        self.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))</span><br><span class="line">        self.drop_large = nn.Dropout(emb_dropout)</span><br><span class="line"></span><br><span class="line">        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,img</span>):</span></span><br><span class="line">        xs = self.stage1_conv_embed(img)</span><br><span class="line">        xs = self.stage1_transformer(xs)</span><br><span class="line"></span><br><span class="line">        xs = self.stage2_conv_embed(xs)</span><br><span class="line">        xs = self.stage2_transformer(xs)</span><br><span class="line"></span><br><span class="line">        xs = self.stage3_conv_embed(xs)</span><br><span class="line">        b, n, _ = xs.shape</span><br><span class="line">        cls_tokens = repeat(self.cls_token, <span class="string">&#x27;() n d -&gt; b n d&#x27;</span>, b=b)</span><br><span class="line">        xs = torch.cat((cls_tokens, xs), dim=<span class="number">1</span>)</span><br><span class="line">        xs = self.stage3_transformer(xs)</span><br><span class="line">        xs = xs.mean(dim=<span class="number">1</span>) <span class="keyword">if</span> self.pool == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> xs[:, <span class="number">0</span>]</span><br><span class="line">        xs = self.mlp_head(xs)</span><br><span class="line">        <span class="keyword">return</span> xs</span><br></pre></td></tr></table></figure><h3 id="PVT"><a href="#PVT" class="headerlink" title="PVT"></a>PVT</h3><p><img data-src="https://s2.loli.net/2024/02/18/w8EUDyAJ4sIv51n.png" alt="image-20240218105527163"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#   #!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#   #-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#  Copyleft (C) 2024 proanimer, Inc. All Rights Reserved</span></span><br><span class="line"><span class="comment">#   author:proanimer</span></span><br><span class="line"><span class="comment">#   createTime:2024/2/18 下午2:22</span></span><br><span class="line"><span class="comment">#   lastModifiedTime:2024/2/18 下午2:22</span></span><br><span class="line"><span class="comment">#   file:pvt.py</span></span><br><span class="line"><span class="comment">#   software: classicNets</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> timm.models.layers <span class="keyword">import</span> DropPath, to_2tuple, trunc_normal_</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mlp</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_features,</span></span></span><br><span class="line"><span class="params"><span class="function">        hidden_features=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        out_features=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        act_layer=nn.GELU,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qkv_bias=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qk_scale=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        proj_drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        sr_ratio=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            dim % num_heads == <span class="number">0</span></span><br><span class="line">        ), <span class="string">f&quot;dim <span class="subst">&#123;dim&#125;</span> should be divided by num_heads <span class="subst">&#123;num_heads&#125;</span>.&quot;</span></span><br><span class="line"></span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        self.scale = qk_scale <span class="keyword">or</span> head_dim**-<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.q = nn.Linear(dim, dim, bias=qkv_bias)</span><br><span class="line">        self.kv = nn.Linear(dim, dim * <span class="number">2</span>, bias=qkv_bias)</span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop)</span><br><span class="line"></span><br><span class="line">        self.sr_ratio = sr_ratio</span><br><span class="line">        <span class="keyword">if</span> sr_ratio &gt; <span class="number">1</span>:</span><br><span class="line">            self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)</span><br><span class="line">            self.norm = nn.LayerNorm(dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, H, W</span>):</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        q = (</span><br><span class="line">            self.q(x)</span><br><span class="line">            .reshape(B, N, self.num_heads, C // self.num_heads)</span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.sr_ratio &gt; <span class="number">1</span>:</span><br><span class="line">            x_ = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(B, C, H, W)</span><br><span class="line">            x_ = self.sr(x_).reshape(B, C, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">            x_ = self.norm(x_)</span><br><span class="line">            kv = (</span><br><span class="line">                self.kv(x_)</span><br><span class="line">                .reshape(B, -<span class="number">1</span>, <span class="number">2</span>, self.num_heads, C // self.num_heads)</span><br><span class="line">                .permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            kv = (</span><br><span class="line">                self.kv(x)</span><br><span class="line">                .reshape(B, -<span class="number">1</span>, <span class="number">2</span>, self.num_heads, C // self.num_heads)</span><br><span class="line">                .permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">            )</span><br><span class="line">        k, v = kv[<span class="number">0</span>], kv[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale  <span class="comment"># q (B,H,N,C)  K(B,H,C,N)</span></span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = self.attn_drop(attn)</span><br><span class="line"></span><br><span class="line">        x = (</span><br><span class="line">            (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)</span><br><span class="line">        )  <span class="comment"># (B,H,N,N) @ (B,H,N,C) -&gt; (B,H,N,C)</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        x = self.proj_drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        dim,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_ratio=<span class="number">4.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qkv_bias=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qk_scale=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_drop=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop_path=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        act_layer=nn.GELU,</span></span></span><br><span class="line"><span class="params"><span class="function">        norm_layer=nn.LayerNorm,</span></span></span><br><span class="line"><span class="params"><span class="function">        sr_ratio=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm1 = norm_layer(dim)</span><br><span class="line">        self.attn = Attention(</span><br><span class="line">            dim,</span><br><span class="line">            num_heads=num_heads,</span><br><span class="line">            qkv_bias=qkv_bias,</span><br><span class="line">            qk_scale=qk_scale,</span><br><span class="line">            attn_drop=attn_drop,</span><br><span class="line">            proj_drop=drop,</span><br><span class="line">            sr_ratio=sr_ratio,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> drop path for stochastic depth, we shall see if this is better than dropout here</span></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.norm2 = norm_layer(dim)</span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        self.mlp = Mlp(</span><br><span class="line">            in_features=dim,</span><br><span class="line">            hidden_features=mlp_hidden_dim,</span><br><span class="line">            act_layer=act_layer,</span><br><span class="line">            drop=drop,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, H, W</span>):</span></span><br><span class="line">        x = x + self.drop_path(self.attn(self.norm1(x), H, W))</span><br><span class="line">        x = x + self.drop_path(self.mlp(self.norm2(x)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PatchEmbed</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Image to Patch Embedding&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        patch_size = to_2tuple(patch_size)</span><br><span class="line"></span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            img_size[<span class="number">0</span>] % patch_size[<span class="number">0</span>] == <span class="number">0</span> <span class="keyword">and</span> img_size[<span class="number">1</span>] % patch_size[<span class="number">1</span>] == <span class="number">0</span></span><br><span class="line">        ), <span class="string">f&quot;img_size <span class="subst">&#123;img_size&#125;</span> should be divided by patch_size <span class="subst">&#123;patch_size&#125;</span>.&quot;</span></span><br><span class="line">        self.H, self.W = img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>]</span><br><span class="line">        self.num_patches = self.H * self.W</span><br><span class="line">        self.proj = nn.Conv2d(</span><br><span class="line">            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size</span><br><span class="line">        )</span><br><span class="line">        self.norm = nn.LayerNorm(embed_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line"></span><br><span class="line">        x = (</span><br><span class="line">            self.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        )  <span class="comment"># B,C,H,W-&gt;B,embed_dim,seq*seq-&gt;B,seq*seq,embed_dim</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        H, W = H // self.patch_size[<span class="number">0</span>], W // self.patch_size[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, (H, W)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyramidVisionTransformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        img_size=<span class="number">224</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        patch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        in_chans=<span class="number">3</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_classes=<span class="number">1000</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        embed_dims=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        num_heads=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        mlp_ratios=[<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        qkv_bias=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        qk_scale=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        attn_drop_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        drop_path_rate=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        norm_layer=nn.LayerNorm,</span></span></span><br><span class="line"><span class="params"><span class="function">        depths=[<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        sr_ratios=[<span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">        F4=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        num_stages=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.depths = depths</span><br><span class="line">        self.F4 = F4</span><br><span class="line">        self.num_stages = num_stages</span><br><span class="line"></span><br><span class="line">        dpr = [</span><br><span class="line">            x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))</span><br><span class="line">        ]  <span class="comment"># stochastic depth decay rule</span></span><br><span class="line">        cur = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_stages):</span><br><span class="line">            patch_embed = PatchEmbed(</span><br><span class="line">                img_size=img_size <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> img_size // (<span class="number">2</span> ** (i + <span class="number">1</span>)),</span><br><span class="line">                patch_size=patch_size <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="number">2</span>,</span><br><span class="line">                in_chans=in_chans <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> embed_dims[i - <span class="number">1</span>],</span><br><span class="line">                embed_dim=embed_dims[i],</span><br><span class="line">            )  <span class="comment"># [B,seq=num_patches,dim=patch_size**2*embed_dim]</span></span><br><span class="line">            num_patches = (</span><br><span class="line">                patch_embed.num_patches</span><br><span class="line">                <span class="keyword">if</span> i != num_stages - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span> patch_embed.num_patches + <span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches, embed_dims[i]))</span><br><span class="line">            pos_drop = nn.Dropout(p=drop_rate)</span><br><span class="line"></span><br><span class="line">            block = nn.ModuleList(</span><br><span class="line">                [</span><br><span class="line">                    Block(</span><br><span class="line">                        dim=embed_dims[i],</span><br><span class="line">                        num_heads=num_heads[i],</span><br><span class="line">                        mlp_ratio=mlp_ratios[i],</span><br><span class="line">                        qkv_bias=qkv_bias,</span><br><span class="line">                        qk_scale=qk_scale,</span><br><span class="line">                        drop=drop_rate,</span><br><span class="line">                        attn_drop=attn_drop_rate,</span><br><span class="line">                        drop_path=dpr[cur + j],</span><br><span class="line">                        norm_layer=norm_layer,</span><br><span class="line">                        sr_ratio=sr_ratios[i],</span><br><span class="line">                    )</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(depths[i])</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line">            cur += depths[i]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;patch_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, patch_embed)</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;pos_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, pos_embed)</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;pos_drop<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, pos_drop)</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">f&quot;block<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>, block)</span><br><span class="line"></span><br><span class="line">            trunc_normal_(pos_embed, std=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># init weights</span></span><br><span class="line">        self.apply(self._init_weights)</span><br><span class="line">        <span class="comment"># self.init_weights(pretrained)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_weights</span>(<span class="params">self, m</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">            trunc_normal_(m.weight, std=<span class="number">0.02</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_pos_embed</span>(<span class="params">self, pos_embed, patch_embed, H, W</span>):</span></span><br><span class="line">        <span class="keyword">if</span> H * W == self.patch_embed1.num_patches:</span><br><span class="line">            <span class="keyword">return</span> pos_embed</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (</span><br><span class="line">                F.interpolate(</span><br><span class="line">                    pos_embed.reshape(<span class="number">1</span>, patch_embed.H, patch_embed.W, -<span class="number">1</span>).permute(</span><br><span class="line">                        <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">                    ),</span><br><span class="line">                    size=(H, W),</span><br><span class="line">                    mode=<span class="string">&quot;bilinear&quot;</span>,</span><br><span class="line">                )</span><br><span class="line">                .reshape(<span class="number">1</span>, -<span class="number">1</span>, H * W)</span><br><span class="line">                .permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        outs = []</span><br><span class="line">        B = x.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_stages):</span><br><span class="line">            patch_embed = <span class="built_in">getattr</span>(self, <span class="string">f&quot;patch_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            pos_embed = <span class="built_in">getattr</span>(self, <span class="string">f&quot;pos_embed<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            pos_drop = <span class="built_in">getattr</span>(self, <span class="string">f&quot;pos_drop<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            block = <span class="built_in">getattr</span>(self, <span class="string">f&quot;block<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">            x, (H, W) = patch_embed(x)</span><br><span class="line">            <span class="keyword">if</span> i == self.num_stages - <span class="number">1</span>:</span><br><span class="line">                pos_embed = self._get_pos_embed(pos_embed[:, <span class="number">1</span>:], patch_embed, H, W)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pos_embed = self._get_pos_embed(pos_embed, patch_embed, H, W)</span><br><span class="line"></span><br><span class="line">            x = pos_drop(x + pos_embed)</span><br><span class="line">            <span class="keyword">for</span> blk <span class="keyword">in</span> block:</span><br><span class="line">                x = blk(x, H, W)</span><br><span class="line">            x = x.reshape(B, H, W, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>).contiguous()</span><br><span class="line">            outs.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outs</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.forward_features(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.F4:</span><br><span class="line">            x = x[<span class="number">3</span>:<span class="number">4</span>]</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="PVT-v2"><a href="#PVT-v2" class="headerlink" title="PVT v2"></a>PVT v2</h3><p><a href="https://arxiv.org/pdf/2106.13797.pdf">2106.13797.pdf (arxiv.org)</a>对之前的pvt进行了改进,包括空间大小降低放的方法,patch embdedding改为了有重叠区域的patch embedding.FeedNetwork中加了depth-wise卷积.</p><p><img data-src="https://s2.loli.net/2024/02/21/buMGx8v6TfNOQht.png" alt="image-20240221212026465"></p><p><img data-src="https://s2.loli.net/2024/02/21/OhtbAGq8NgvKnEX.png" alt="image-20240221212055900"></p><h3 id="CPVT中的PEG"><a href="#CPVT中的PEG" class="headerlink" title="CPVT中的PEG"></a>CPVT中的PEG</h3><p><img data-src="https://s2.loli.net/2024/02/19/LHY9bVrE8w2DlZs.png" alt="image-20240219150034479"></p><p>conditional position encoding</p><p><img data-src="https://s2.loli.net/2024/02/18/cfmP5yO41sN6h8o.png" alt="image-20240218103528794"></p><p>出自论文<a href="https://arxiv.org/pdf/2102.10882.pdf">2102.10882.pdf (arxiv.org)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PEG</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim=<span class="number">256</span>, k=<span class="number">3</span></span>):</span></span><br><span class="line">        self.proj = nn.Conv2d(dim, dim, k, <span class="number">1</span>, k//<span class="number">2</span>, groups=dim)</span><br><span class="line">        <span class="comment"># Only for demo use, more complicated functions are effective too.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, H, W</span>):</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        cls_token, feat_token = x[:, <span class="number">0</span>], x[:, <span class="number">1</span>:] <span class="comment"># cls token不参与PEG</span></span><br><span class="line">        cnn_feat = feat_token.transpose(<span class="number">1</span>, <span class="number">2</span>).view(B, C, H, W)</span><br><span class="line">        x = self.proj(cnn_feat) + cnn_feat <span class="comment"># 产生PE加上自身</span></span><br><span class="line">        x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = torch.cat((cls_token.unsqueeze(<span class="number">1</span>), x), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VisionTransformer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">layers=<span class="number">12</span>, dim=<span class="number">192</span>, nhead=<span class="number">3</span>, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span></span>):</span></span><br><span class="line">        self.pos_block = PEG(dim)</span><br><span class="line">        self.blocks = nn.ModuleList([TransformerEncoderLayer(dim</span><br><span class="line">, nhead, dim*<span class="number">4</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(layers)])</span><br><span class="line">        self.patch_embed = PatchEmbed(img_size, patch_size, dim</span><br><span class="line">*<span class="number">4</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        x, patch_size = self.patch_embed(x)</span><br><span class="line">        _H, _W = H // patch_size, W // patch_size</span><br><span class="line">        x = torch.cat((self.cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i, blk <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.blocks):</span><br><span class="line">            x = blk(x)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>: <span class="comment"># 第一个encoder之后施加PEG</span></span><br><span class="line">                x = self.pos_block(x, _H, _W)</span><br><span class="line">        <span class="keyword">return</span> x[:, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><h3 id="LocalVit"><a href="#LocalVit" class="headerlink" title="LocalVit"></a>LocalVit</h3><p><img data-src="https://s2.loli.net/2024/02/18/ncu63LwS7bKhl8j.png" alt="image-20240218105718876"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, depth, heads, dim_head, patch_height, patch_width, scale = <span class="number">4</span>, depth_kernel = <span class="number">3</span>, dropout = <span class="number">0.</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(nn.ModuleList([</span><br><span class="line">                Residual(PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout))),</span><br><span class="line">                Residual(PreNorm(dim, ConvFF(dim, scale, depth_kernel, patch_height, patch_width)))</span><br><span class="line">            ]))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> attn, convff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x)</span><br><span class="line">            cls_tokens = x[:, <span class="number">0</span>]</span><br><span class="line">            x = convff(x[:, <span class="number">1</span>:])</span><br><span class="line">            x = torch.cat((cls_tokens.unsqueeze(<span class="number">1</span>), x), dim=<span class="number">1</span>) </span><br><span class="line">        <span class="keyword">return</span> xclass ConvFF(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim = <span class="number">192</span>, scale = <span class="number">4</span>, depth_kernel = <span class="number">3</span>, patch_height = <span class="number">14</span>, patch_width = <span class="number">14</span>, dropout=<span class="number">0.</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        scale_dim = dim*scale</span><br><span class="line">        self.up_proj = nn.Sequential(</span><br><span class="line">                                    Rearrange(<span class="string">&#x27;b (h w) c -&gt; b c h w&#x27;</span>, h=patch_height, w=patch_width),</span><br><span class="line">                                    nn.Conv2d(dim, scale_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                                    nn.Hardswish()</span><br><span class="line">                                    )</span><br><span class="line">        </span><br><span class="line">        self.depth_conv = nn.Sequential(</span><br><span class="line">                        nn.Conv2d(scale_dim, scale_dim, kernel_size=depth_kernel, padding=<span class="number">1</span>, groups=scale_dim, bias=<span class="literal">True</span>),</span><br><span class="line">                        nn.Conv2d(scale_dim, scale_dim, kernel_size=<span class="number">1</span>, bias=<span class="literal">True</span>),</span><br><span class="line">                        nn.Hardswish()</span><br><span class="line">                        )</span><br><span class="line">        </span><br><span class="line">        self.down_proj = nn.Sequential(</span><br><span class="line">                                    nn.Conv2d(scale_dim, dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                                    nn.Dropout(dropout),</span><br><span class="line">                                    Rearrange(<span class="string">&#x27;b c h w -&gt;b (h w) c&#x27;</span>)</span><br><span class="line">                                    )</span><br></pre></td></tr></table></figure><p>在feed-forward中使用2d的卷积.</p><h2 id="transformer中的绝对和相对位置编码"><a href="#transformer中的绝对和相对位置编码" class="headerlink" title="transformer中的绝对和相对位置编码"></a>transformer中的绝对和相对位置编码</h2><p>位置编码可以分为使用<code>nn.Embedding</code>或者<code>nn.Parameter</code>的可学习参数,也可以直接使用固定的值,比如三角函数编码.此外可以分为相对位置和绝对位置编码</p><h3 id="绝对位置编码"><a href="#绝对位置编码" class="headerlink" title="绝对位置编码"></a>绝对位置编码</h3><p>transformer中使用了位置编码信息,被认为是绝对位置编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;Implement the PE function.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, dropout, max_len=<span class="number">5000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)],</span><br><span class="line">                         requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure><blockquote><p>我们可能希望使用相对位置编码而不是绝对位置编码，原因有很多。首先，使用绝对位置信息必然意味着模型可以处理的token数量有限制。假设一个语言模型最多只能编码1024个位置。这必然意味着任何长于1024个token的序列都不能被模型处理;相对位置编码可以推广到看不见长度的序列，因为理论上它编码的唯一信息是两个标记之间的相对成对距离。</p></blockquote><h3 id="相对位置编码的历史"><a href="#相对位置编码的历史" class="headerlink" title="相对位置编码的历史"></a>相对位置编码的历史</h3><blockquote><p>相对位置嵌入( Relative Position Embedding，RPE )技术主要用于将与相对位置相关的信息纳入到注意力模块中。该技术基于这样的思想：块之间的空间关系比它们的绝对位置承载更多的权重。为了计算RPE值，使用了基于可学习参数的查找表。查找过程由图像patch间的相对距离决定。虽然RPE技术可以扩展到不同长度的序列，但它可能会增加训练和测试时间。</p></blockquote><p>在<code>attention is all you need</code>中的attention中,自我注意力可以表述为如下,并使用三角函数索引进行位置编码.</p><script type="math/tex; mode=display">z_i=\sum_{j=1}^n\alpha_{ij}(x_jW^V) \\\alpha_{ij}=\frac{\exp e_{ij}}{\sum_{k=1}^n\exp e_{ik}} \\e_{ij}=\frac{(x_iW^Q)(x_jW^K)^T}{\sqrt{d_z}}</script><h3 id="1D数据"><a href="#1D数据" class="headerlink" title="1D数据"></a>1D数据</h3><h4 id="Shaw"><a href="#Shaw" class="headerlink" title="Shaw"></a>Shaw</h4><p>相对位置编码在swin-transformer以及Self-Attention with Relative Position Representations中都有体现.较早的论文<a href="https://arxiv.org/pdf/1803.02155.pdf">1803.02155.pdf (arxiv.org)</a></p><script type="math/tex; mode=display">z_i=\sum_{j=1}^n\alpha_{ij}(x_jW^V+a_{ij}^V) \\e_{ij}=\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\sqrt{d_z}} \\\begin{aligned}a_{ij}^{K}& =w_{\mathrm{clip}(j-i,k)}^{K}  \\a_{ij}^{V}& =w_{\mathrm{clip}(j-i,k)}^{V}  \\\operatorname{clip}(x,k)& =\max(-k,\min(k,x)) \end{aligned}</script><p>其中的w^k^和w^v^是需要训练的参数.</p><script type="math/tex; mode=display">w^{K}=(w_{-k}^{K},\ldots,w_{k}^{K}) \\w^{V}=(\dot{w_{-k}^{V}},\ldots,w_{k}^{V})</script><p>以下是<a href="https://arxiv.org/pdf/1803.02155.pdf">1803.02155.pdf (arxiv.org)</a>中的相对位置注意力</p><p><img data-src="https://s2.loli.net/2024/02/16/4esqYAdLkgNuybn.png" alt="image-20240216225108501" style="zoom: 67%;" /></p><p><img data-src="https://pic4.zhimg.com/80/v2-f6d057978590bd14fd876856500b69df_720w.webp" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaw&#x27;s relative positional embedding</span></span><br><span class="line">seq = torch.arange(n, device=device)</span><br><span class="line">dist = rearrange(seq, <span class="string">&quot;i -&gt; i ()&quot;</span>) - rearrange(seq, <span class="string">&quot;j -&gt; () j&quot;</span>)</span><br><span class="line">dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb</span><br><span class="line">rel_pos_emb = self.rel_pos_emb(dist).to(q)</span><br><span class="line">pos_attn = einsum(<span class="string">&quot;b h n d, n r d -&gt; b h n r&quot;</span>, q, rel_pos_emb) * self.scale</span><br><span class="line">dots = dots + pos_attn</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> exists(mask) <span class="keyword">or</span> exists(context_mask):</span><br><span class="line">    mask = default(mask, <span class="keyword">lambda</span>: torch.ones(*x.shape[:<span class="number">2</span>], device=device))</span><br><span class="line">    context_mask = (</span><br><span class="line">        default(context_mask, mask)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> has_context</span><br><span class="line">        <span class="keyword">else</span> default(</span><br><span class="line">            context_mask, <span class="keyword">lambda</span>: torch.ones(*context.shape[:<span class="number">2</span>], device=device)</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    mask_value = -torch.finfo(dots.dtype).<span class="built_in">max</span></span><br><span class="line">    mask = rearrange(mask, <span class="string">&quot;b i -&gt; b () i ()&quot;</span>) * rearrange(</span><br><span class="line">        context_mask, <span class="string">&quot;b j -&gt; b () () j&quot;</span></span><br><span class="line">    )</span><br><span class="line">    dots.masked_fill_(~mask, mask_value)</span><br><span class="line"></span><br><span class="line">attn = dots.softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">out = einsum(<span class="string">&quot;b h i j, b h j d -&gt; b h i d&quot;</span>, attn, v)</span><br><span class="line">out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">out = self.to_out(out)</span><br></pre></td></tr></table></figure><h4 id="transformer-xl"><a href="#transformer-xl" class="headerlink" title="transformer-xl"></a>transformer-xl</h4><p>众所周知,q=xW~Q~,k=xW~K~,加入相对位置编码后,展开一般注意力公式有</p><p><img data-src="https://pic4.zhimg.com/80/v2-5ee0eed4bc859e400591d7c83047bffb_720w.webp" alt="img"></p><p><img data-src="https://pic1.zhimg.com/80/v2-733f110568f1c83519ada84af1e32014_720w.webp" alt="img"></p><p>Transformer-XL的做法很简单，直接将 $p<em>j$ 替换为相对位置向量 $R</em>{i-j}$, 至于两个 $p_i$ , 则干脆替换为两个可训练的问量 $u,v$</p><p>之后的改进也是基于此,并且不再改动计算V了.</p><p>在transformer-xl(或者也是XLNET中使用的编码)中</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q+\mathbf{u})(\mathbf{x}_j\mathbf{W}^K)^T+(\mathbf{x}_i\mathbf{W}^Q+\mathbf{v})(\mathbf{s}_{i-j}\mathbf{W}^R)^T}{\sqrt{d_z}},</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEmbedding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, demb</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEmbedding, self).__init__()</span><br><span class="line">        self.demb = demb</span><br><span class="line">        inv_freq = <span class="number">1</span> / (<span class="number">10000</span> ** (torch.arange(<span class="number">0.0</span>, demb, <span class="number">2.0</span>) / demb))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, pos_seq</span>):</span></span><br><span class="line">        sinusoid_inp = torch.outer(pos_seq, self.inv_freq) <span class="comment"># 向量之间相乘</span></span><br><span class="line">        pos_emb = torch.cat([sinusoid_inp.sin(), sinusoid_inp.cos()], dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> pos_emb[:,<span class="literal">None</span>,:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">w_head_q = w_head_q.view(qlen, bsz, self.n_head, self.d_head)           <span class="comment"># qlen x bsz x n_head x d_head</span></span><br><span class="line">w_head_k = w_head_k.view(klen, bsz, self.n_head, self.d_head)           <span class="comment"># qlen x bsz x n_head x d_head</span></span><br><span class="line">w_head_v = w_head_v.view(klen, bsz, self.n_head, self.d_head)           <span class="comment"># qlen x bsz x n_head x d_head</span></span><br><span class="line"></span><br><span class="line">r_head_k = r_head_k.view(rlen, self.n_head, self.d_head)                <span class="comment"># qlen x n_head x d_head</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### compute attention score</span></span><br><span class="line">rw_head_q = w_head_q + r_w_bias   <span class="comment">#加上biase                                       # qlen x bsz x n_head x d_head</span></span><br><span class="line">AC = torch.einsum(<span class="string">&#x27;ibnd,jbnd-&gt;ijbn&#x27;</span>, (rw_head_q, w_head_k))             <span class="comment"># qlen x klen x bsz x n_head</span></span><br><span class="line"></span><br><span class="line">rr_head_q = w_head_q + r_r_bias  <span class="comment">#加上biase  </span></span><br><span class="line">BD = torch.einsum(<span class="string">&#x27;ibnd,jnd-&gt;ijbn&#x27;</span>, (rr_head_q, r_head_k))              <span class="comment"># qlen x klen x bsz x n_head</span></span><br><span class="line">BD = self._rel_shift(BD)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [qlen x klen x bsz x n_head]</span></span><br><span class="line">attn_score = AC + BD</span><br><span class="line">attn_score.mul_(self.scale)</span><br></pre></td></tr></table></figure><p>其中u,v是两个可学习参数,W^R^是一个矩阵将s~i-j~投影到一个与位置相关的key向量.</p><h4 id="Music-transformer"><a href="#Music-transformer" class="headerlink" title="Music transformer"></a>Music transformer</h4><p>后来Huang对shaw的相对位置编码进行改进</p><p><img data-src="https://s2.loli.net/2024/02/16/PX9Ev1HjwKDB5xt.png" alt="image-20240216225143335" style="zoom: 67%;" /></p><h4 id="Huang"><a href="#Huang" class="headerlink" title="Huang"></a>Huang</h4><p>此外还有<a href="https://arxiv.org/pdf/2009.13658.pdf">2009.13658.pdf (arxiv.org)</a>提出的</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q+\mathbf{p}_{ij})(\mathbf{x}_j\mathbf{W}^K+\mathbf{p}_{ij})^T-\mathbf{p}_{ij}\mathbf{p}_{ij}^T}{\sqrt{d_z}},</script><h4 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h4><p><img data-src="https://pic1.zhimg.com/80/v2-16c2aa40bbf7a888a62d9dc1373d6c94_720w.webp" alt="img" style="zoom:50%;" /></p><h4 id="DeBERTa"><a href="#DeBERTa" class="headerlink" title="DeBERTa"></a>DeBERTa</h4><p><img data-src="https://pic3.zhimg.com/80/v2-b5436edfcde32b292cdf24c7f39d9c0e_720w.webp" alt="img"></p><p>总结下来就是在计算attention权重时或者在计算最后的注意力时加上一个与相对位置信息相关的值.这个值的计算通常类似如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shaw&#x27;s relative positional embedding</span></span><br><span class="line">seq = torch.arange(n, device=device)</span><br><span class="line">dist = rearrange(seq, <span class="string">&quot;i -&gt; i ()&quot;</span>) - rearrange(seq, <span class="string">&quot;j -&gt; () j&quot;</span>)</span><br><span class="line">dist = dist.clamp(-max_pos_emb, max_pos_emb) + max_pos_emb</span><br><span class="line">rel_pos_emb = self.rel_pos_emb(dist).to(q)</span><br></pre></td></tr></table></figure><p>以上大多用于1D数据比如音频和文字.</p><h3 id="2D数据"><a href="#2D数据" class="headerlink" title="2D数据"></a>2D数据</h3><h4 id="Stand-Alone-Self-Attention-in-Vision-Models"><a href="#Stand-Alone-Self-Attention-in-Vision-Models" class="headerlink" title="Stand-Alone Self-Attention in Vision Models"></a>Stand-Alone Self-Attention in Vision Models</h4><p><img data-src="https://user-images.githubusercontent.com/19909320/137499552-3bdf3189-7f57-4f95-a85e-8d5dd2ef6fd0.png" alt="SASA" style="zoom:50%;" /></p><p>公式如下</p><script type="math/tex; mode=display">y_{ij}=\sum_{a,b\in\mathcal{N}_{k}(i,j)}\text{softmax}_{ab}\left(q_{ij}^{\top}k_{ab}+q_{ij}^{\top}r_{a-i,b-j}\right)v_{ab}</script><p>对相对距离进行维度分解，每个元素ab∈N~k(i,j)~得到两个距离：行偏移量a-i和列偏移量b-j .</p><p>行偏移和列偏移分别与一个嵌入r~a-i~和r~b-j~相关联，每个嵌入维度为1/2d~out~,行偏移嵌入和列偏移嵌入被串联起来形成r~a-i,b-j~。</p><p>或者表示如下</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q)(\mathbf{x}_j\mathbf{W}^K+concat(\mathbf{p}_{\delta\bar{x}}^K,\mathbf{p}_{\delta\bar{y}}^K))^T}{\sqrt{d_z}},</script><p>其中p是可训练参数,长度是1/2d~z~</p><p><img data-src="https://s2.loli.net/2024/02/17/2S9UbyF7DYfujVw.png" alt="image-20240217180330619"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">use_cuda = torch.cuda.is_available()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SASA_Layer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, kernel_size=<span class="number">7</span>, num_heads=<span class="number">8</span>, image_size=<span class="number">224</span>, inference=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SASA_Layer, self).__init__()</span><br><span class="line">        self.kernel_size = <span class="built_in">min</span>(kernel_size, image_size) <span class="comment"># receptive field shouldn&#x27;t be larger than input H/W         </span></span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.dk = self.dv = in_channels</span><br><span class="line">        self.dkh = self.dk // self.num_heads</span><br><span class="line">        self.dvh = self.dv // self.num_heads</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> self.dk % self.num_heads == <span class="number">0</span>, <span class="string">&quot;dk should be divided by num_heads. (example: dk: 32, num_heads: 8)&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> self.dk % self.num_heads == <span class="number">0</span>, <span class="string">&quot;dv should be divided by num_heads. (example: dv: 32, num_heads: 8)&quot;</span>  </span><br><span class="line">        </span><br><span class="line">        self.k_conv = nn.Conv2d(self.dk, self.dk, kernel_size=<span class="number">1</span>).to(device)</span><br><span class="line">        self.q_conv = nn.Conv2d(self.dk, self.dk, kernel_size=<span class="number">1</span>).to(device)</span><br><span class="line">        self.v_conv = nn.Conv2d(self.dv, self.dv, kernel_size=<span class="number">1</span>).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Positional encodings</span></span><br><span class="line">        self.rel_encoding_h = nn.Parameter(torch.randn(self.dk // <span class="number">2</span>, self.kernel_size, <span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        self.rel_encoding_w = nn.Parameter(torch.randn(self.dk // <span class="number">2</span>, <span class="number">1</span>, self.kernel_size), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># later access attention weights</span></span><br><span class="line">        self.inference = inference</span><br><span class="line">        <span class="keyword">if</span> self.inference:</span><br><span class="line">            self.register_parameter(<span class="string">&#x27;weights&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        batch_size, _, height, width = x.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute k, q, v</span></span><br><span class="line">        padded_x = F.pad(x, [(self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>, (self.kernel_size-<span class="number">1</span>)-((self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>), (self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>, (self.kernel_size-<span class="number">1</span>)-((self.kernel_size-<span class="number">1</span>)//<span class="number">2</span>)])</span><br><span class="line">        k = self.k_conv(padded_x)</span><br><span class="line">        q = self.q_conv(x)</span><br><span class="line">        v = self.v_conv(padded_x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Unfold patches into [BS, num_heads*depth, horizontal_patches, vertical_patches, kernel_size, kernel_size]</span></span><br><span class="line">        k = k.unfold(<span class="number">2</span>, self.kernel_size, <span class="number">1</span>).unfold(<span class="number">3</span>, self.kernel_size, <span class="number">1</span>)</span><br><span class="line">        v = v.unfold(<span class="number">2</span>, self.kernel_size, <span class="number">1</span>).unfold(<span class="number">3</span>, self.kernel_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Reshape into [BS, num_heads, horizontal_patches, vertical_patches, depth_per_head, kernel_size*kernel_size]</span></span><br><span class="line">        k = k.reshape(batch_size, self.num_heads, height, width, self.dkh, -<span class="number">1</span>)</span><br><span class="line">        v = v.reshape(batch_size, self.num_heads, height, width, self.dvh, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Reshape into [BS, num_heads, height, width, depth_per_head, 1]</span></span><br><span class="line">        q = q.reshape(batch_size, self.num_heads, height, width, self.dkh, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        qk = torch.matmul(q.transpose(<span class="number">4</span>, <span class="number">5</span>), k)    </span><br><span class="line">        qk = qk.reshape(batch_size, self.num_heads, height, width, self.kernel_size, self.kernel_size)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Add positional encoding</span></span><br><span class="line">        qr_h = torch.einsum(<span class="string">&#x27;bhxydz,cij-&gt;bhxyij&#x27;</span>, q, self.rel_encoding_h)</span><br><span class="line">        qr_w = torch.einsum(<span class="string">&#x27;bhxydz,cij-&gt;bhxyij&#x27;</span>, q, self.rel_encoding_w)</span><br><span class="line">        qk += qr_h</span><br><span class="line">        qk += qr_w</span><br><span class="line">        </span><br><span class="line">        qk = qk.reshape(batch_size, self.num_heads, height, width, <span class="number">1</span>, self.kernel_size*self.kernel_size)</span><br><span class="line">        weights = F.softmax(qk, dim=-<span class="number">1</span>)    </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.inference:</span><br><span class="line">            self.weights = nn.Parameter(weights)</span><br><span class="line">        </span><br><span class="line">        attn_out = torch.matmul(weights, v.transpose(<span class="number">4</span>, <span class="number">5</span>)) </span><br><span class="line">        attn_out = attn_out.reshape(batch_size, -<span class="number">1</span>, height, width)</span><br><span class="line">        <span class="keyword">return</span> attn_out</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>上面的代码可能有些问题,应该是将i,j的距离差嵌入到一个<code>embedding</code>中更合适</p><h4 id="Rethinking-and-Improving-Relative-Position-Encoding-for-Vision-Transformer"><a href="#Rethinking-and-Improving-Relative-Position-Encoding-for-Vision-Transformer" class="headerlink" title="Rethinking and Improving Relative Position Encoding for Vision Transformer"></a>Rethinking and Improving Relative Position Encoding for Vision Transformer</h4><p>这是篇好文章,关于注意力中相对位置用于2d图像数据的方法.也是在上面SASA的一种改进.</p><p><img data-src="https://s2.loli.net/2024/02/17/CHqOLZKXNxhIdzj.png" alt="image-20240217181329312"></p><p>以往的相对位置编码方法都依赖于输入嵌入。这就带来了一个问题，即编码能否独立于输入?</p><p>论文引入相对位置编码的偏向模式和语境模式来研究该问题。前者独立于输入嵌入，而后者考虑了与查询、键或值的交互。也就上图的两种模式.</p><script type="math/tex; mode=display">e_{ij}=\frac{(\mathbf{x}_i\mathbf{W}^Q)(\mathbf{x}_j\mathbf{W}^K)^T\color{blue}{+}b_{ij}}{\sqrt{d_z}} \\b_{ij}=\bold{r}_{ij} \space for \space  bias \space mode\\b_{ij}=(x_{i}W^Q)r_{ij}\space for\space  context  \space mode\\</script><p>计算attention weight加上一个偏置,在bias模式下,这个偏置是一个可学习的参数,表示相对位置的权重.</p><p>在context模式下,有多种可行的方式.其中r是一个可训练的向量,也表示相对位置,但它会与Q或K交互.</p><script type="math/tex; mode=display">b_{ij}=(\mathbf{x}_i\mathbf{W}^Q)(\mathbf{r}_{ij}^K)^T+(\mathbf{x}_j\mathbf{W}^K)(\mathbf{r}_{ij}^Q)^T</script><p>此外context模式也可以应用于value嵌入</p><script type="math/tex; mode=display">\mathbf{z}_i=\sum_{j=1}^n\alpha_{ij}(\mathbf{x}_j\mathbf{W}^V\color{red}{+}\mathbf{r}_{ij}^V),</script><p>为了计算二维图像平面上的相对位置并定义相对权重r~ij~,提出了两种无向映射方法Euclidean和Quantization，以及两种有向映射方法Cross和Product。</p><script type="math/tex; mode=display">\mathbf{r}_{ij}=\mathbf{p}_{I(i,j)},</script><script type="math/tex; mode=display">I(i,j)=g(\sqrt{(\tilde{x}_i-\tilde{x}_j)^2+(\tilde{y}_i-\tilde{y}_j)^2}),</script><p>在上述欧几里得方法中，距离较近的两个具有不同相对距离的邻居可能被映射到同一个索引中，例如二维相对位置( 1、0 )和( 1 , 1)都被映射到索引1中。假设近邻应该是分离的。因此对欧氏距离进行量化，即将不同的实数映射成不同的整数。</p><script type="math/tex; mode=display">I(i,j)=g(quant(\sqrt{(\tilde{x}_i-\tilde{x}_j)^2+(\tilde{y}_i-\tilde{y}_j)^2}).</script><p>运算quant ( · )将一组实数{ 0，1，1.41，2，2.24，.. }映射为一组整数{ 0，1，2，3，4，.. } .这种方法也是无向的.</p><p>像素的位置方向对图像也很重要，因此提出了有向映射方法。这种方法被称为Cross方法，它分别在水平和垂直方向上计算编码，然后进行汇总。方法如下</p><script type="math/tex; mode=display">\begin{gathered}\mathbf{r}_{ij}=\mathbf{p}_{I^{\tilde{x}}(i,j)}^{\tilde{x}}+\mathbf{p}_{I^{\tilde{y}}(i,j)}^{\tilde{y}}, \\I^{\tilde{x}}(i,j)=g(\tilde{x_{i}}-\tilde{x_{j}}), \\I^{\tilde{y}}(i,j)=g(\tilde{y}_i-\tilde{y}_j), \end{gathered}</script><p>如果某个方向上的距离是相同的，那么Cross方法将不同的相对位置编码到同一个嵌入中，此外带来了额外的计算开销。为了提高效率并包含更多的方向性信息，设计了Product方法，公式如下：</p><p><img data-src="https://s2.loli.net/2024/02/17/2rIStXgva96PhTZ.png" alt="image-20240217223648427"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h3 id="Swin-transformer"><a href="#Swin-transformer" class="headerlink" title="Swin transformer"></a>Swin transformer</h3><p><a href="https://arxiv.org/abs/2103.14030">[2103.14030] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (arxiv.org)</a></p><p><a href="https://arxiv.org/abs/2111.09883">[2111.09883] Swin Transformer V2: Scaling Up Capacity and Resolution (arxiv.org)</a></p><p><img data-src="https://s2.loli.net/2024/02/18/NMFCXv8EKabh6cp.png" alt="image-20240218140849412"></p><script type="math/tex; mode=display">\begin{aligned}\Omega(\mathbf{MSA})&=4hwC^2+2(hw)^2C,\\\Omega(\mathbf{W-MSA})&=4hwC^2+2M^2hwC,\end{aligned}</script><p><img data-src="https://s2.loli.net/2024/02/18/WBD3do8KnrHqlLU.png" alt="image-20240218141119075"></p><blockquote><p>将Transformer从语言转换到视觉的挑战来自于两个领域之间的差异，例如视觉实体的尺度变化较大，图像中的像素相对于文本中的文字分辨率较高。</p><p>为了解决这些差异，提出了一个分层Transformer，其表示由Shifted窗口计算。移位窗口方案通过将自注意力计算限制在不重叠的局部窗口，同时允许跨窗口连接，从而带来更高的效率。这种分层架构具有在各种尺度下建模的灵活性，并且具有与图像大小相关的线性计算复杂度。</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/21/If19Km8TFPneM6x.png" alt="image-20240221231106703"></p><h3 id="Swin-transformerV2"><a href="#Swin-transformerV2" class="headerlink" title="Swin-transformerV2"></a>Swin-transformerV2</h3><p><a href="https://arxiv.org/abs/2111.09883">[2111.09883] Swin Transformer V2: Scaling Up Capacity and Resolution (arxiv.org)</a></p><p><img data-src="https://s2.loli.net/2024/02/21/6izranSXgP7CobN.png" alt="image-20240221231423057"></p><h3 id="Twins"><a href="#Twins" class="headerlink" title="Twins"></a>Twins</h3><p><a href="https://arxiv.org/abs/2104.13840">[2104.13840] Twins: Revisiting the Design of Spatial Attention in Vision Transformers (arxiv.org)</a></p><p><img data-src="https://github.com/lucidrains/vit-pytorch/raw/main/images/twins_svt.png" alt="img" style="zoom:67%;" /></p><p><img data-src="https://s2.loli.net/2024/02/18/1Zf5pWymzPTaHoB.png" alt="image-20240218141741213"></p><blockquote><p>在这项工作中，重新审视了空间注意力的设计，并证明了一个精心设计但简单的空间注意力机制与最先进的方案相比具有良好的性能。因此，我们提出了两种视觉转换器结构，即Twins - PCPVT和TwinsSVT。我们提出的架构高效且易于实现，只涉及在现代深度学习框架中高度优化的矩阵乘法。更重要的是，所提出的架构在包括图像级cla在内的广泛的视觉任务上取得了优异的性能</p></blockquote><p>此外随着时间发展,目前已经有了空间注意力,通道注意力等等可以用于2D数据的注意力模型.但是基本思想是类似的.</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/364828960">Relative position embedding - 知乎 (zhihu.com)</a></li><li><a href="https://arxiv.org/abs/1803.02155">[1803.02155] Self-Attention with Relative Position Representations (arxiv.org)</a></li><li><a href="https://placebokkk.github.io/asr/2021/01/14/asr-rpe.html">Relative Positional Embedding | Chao Yang (placebokkk.github.io)</a></li><li><a href="https://aclanthology.org/2020.findings-emnlp.298.pdf">Improve Transformer Models with Better Relative Position Embeddings (aclanthology.org)</a></li><li><a href="https://zhuanlan.zhihu.com/p/352898810">让研究人员绞尽脑汁的Transformer位置编码 - 知乎 (zhihu.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/669523714">《A survey of the Vision Transformers and its CNN-Transformer based Variants》第一期 - 知乎 (zhihu.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;这里介绍一些细节信息.有关位置编码信息和用于图像的transformer.&lt;br&gt;</summary>
    
    
    
    
    <category term="transformers" scheme="https://www.sekyoro.top/tags/transformers/"/>
    
    <category term="attention" scheme="https://www.sekyoro.top/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>TypeScript on the way:学习TypeScript</title>
    <link href="https://www.sekyoro.top/2024/02/11/TypeScript-on-the-way-%E5%AD%A6%E4%B9%A0TypeScript/"/>
    <id>https://www.sekyoro.top/2024/02/11/TypeScript-on-the-way-%E5%AD%A6%E4%B9%A0TypeScript/</id>
    <published>2024-02-11T08:01:13.000Z</published>
    <updated>2024-02-13T12:02:04.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>早该学学了.<br><span id="more"></span></p><p>之前写过Python的类型系统,如果对于写C++,Java,C#等这类语言来说,typing根本不成问题,所以理解TypeScript也不是问题.</p><h2 id="特殊的类型"><a href="#特殊的类型" class="headerlink" title="特殊的类型"></a>特殊的类型</h2><h3 id="any-unknown与never"><a href="#any-unknown与never" class="headerlink" title="any,unknown与never"></a>any,unknown与never</h3><p>any,unknown是”顶层类型”,never是”底层类型”.never类型是所有类型共有的,any类型基本没有限制,unknown类型不能直接调用并且运算是有限的,只能进行比较运算.推荐使用unknown代替any然后使用as转换类型.</p><h2 id="类型系统"><a href="#类型系统" class="headerlink" title="类型系统"></a>类型系统</h2><h3 id="String与string-Number与number"><a href="#String与string-Number与number" class="headerlink" title="String与string,Number与number"></a>String与string,Number与number</h3><p>String与string是不同的,前者是可以包含后者的.但是在ts中,很多方法只能使用后者.</p><p>所以推荐只使用后者.</p><p><img data-src="https://s2.loli.net/2024/02/11/4DiknPFr569Ulgp.png" alt="image-20240211171858237"></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> obj: <span class="built_in">Object</span>;</span><br><span class="line"><span class="keyword">let</span> obj2:&#123;&#125;;</span><br><span class="line">obj = &#123; <span class="attr">name</span>: <span class="string">&quot;John&quot;</span> &#125;;</span><br><span class="line">obj = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure><p>此外Object类型包括除了undefined和null的基本类型.所以这并不符合直觉,推荐使用<code>object</code></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> obj3:<span class="built_in">object</span>;</span><br><span class="line">obj3 = &#123;<span class="attr">name</span>:<span class="string">&quot;John&quot;</span>&#125;;</span><br><span class="line">obj3 = <span class="number">13</span>; <span class="comment">//报错 不能将number分配给类型object</span></span><br></pre></td></tr></table></figure><p>object类型包含对象,数组,函数.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> ccx = &#123; <span class="attr">foo</span>: <span class="number">1</span> &#125;;</span><br><span class="line">ccx.foo = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">let</span> t = &#123; <span class="attr">foo</span>: <span class="number">1</span> &#125;;</span><br><span class="line">t.foo = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">let</span> hh:<span class="built_in">object</span> = &#123;<span class="attr">foo</span>:<span class="number">1</span>&#125;</span><br><span class="line"><span class="comment">// hh.foo 报错 类型不对</span></span><br></pre></td></tr></table></figure><p>此外undefined和null也可以赋值为number,object等等.</p><p>TypeScript中单个值也是类型成为值类型</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> t: <span class="string">&quot;dfasdf&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> xy = <span class="string">&quot;https&quot;</span>;</span><br><span class="line"><span class="built_in">console</span>.log(xy);</span><br></pre></td></tr></table></figure><p>将多个类型组合起来就是联合类型,如果严格检查也就是设置<code>strictNullChecks</code>,使得其他类型变量不能被赋值为undefined或null.这个时候就可以用联合类型</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> setting: <span class="literal">true</span> | <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> gender: <span class="string">&quot;male&quot;</span> | <span class="string">&quot;female&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> rainbowColor: <span class="string">&quot;赤&quot;</span> | <span class="string">&quot;橙&quot;</span> | <span class="string">&quot;黄&quot;</span> | <span class="string">&quot;绿&quot;</span> | <span class="string">&quot;青&quot;</span> | <span class="string">&quot;蓝&quot;</span> | <span class="string">&quot;紫&quot;</span>;</span><br><span class="line"><span class="keyword">let</span> name: <span class="built_in">string</span> | <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">name = <span class="string">&quot;John&quot;</span>;</span><br><span class="line">name = <span class="literal">null</span>;</span><br></pre></td></tr></table></figure><p>对象的合成可以给对象添加新的属性,属于交叉类型.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> obj5: &#123; <span class="attr">foo</span>: <span class="built_in">string</span> &#125; &amp; &#123; <span class="attr">bar</span>: <span class="built_in">number</span> &#125;;</span><br></pre></td></tr></table></figure><h3 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Age = <span class="built_in">number</span>;</span><br><span class="line"><span class="keyword">let</span> age:Age =  <span class="number">55</span>;</span><br></pre></td></tr></table></figure><p>跟Python的typing和Go语言类似.</p><h2 id="数组-元组"><a href="#数组-元组" class="headerlink" title="数组 元组"></a>数组 元组</h2><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> arr: <span class="built_in">number</span>[] = [];</span><br><span class="line"><span class="keyword">let</span> arr2: (<span class="built_in">number</span>|<span class="built_in">string</span>)[] = [];</span><br><span class="line"><span class="keyword">let</span> arr3: <span class="built_in">Array</span>&lt;<span class="built_in">number</span>&gt; = [];</span><br></pre></td></tr></table></figure><p>const数组中的元素是可以改变的,所以在ts中增加了<code>readonly</code>,readonly数组是原本数组的子类型.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> arr5: <span class="built_in">number</span>[] = [<span class="number">0</span>, <span class="number">1</span>];</span><br><span class="line">arr5[<span class="number">0</span>] = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">let</span> arr6: <span class="keyword">readonly</span> <span class="built_in">number</span>[] = arr5;</span><br></pre></td></tr></table></figure><p>声明readonly数组</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> aa: <span class="keyword">readonly</span> <span class="built_in">number</span>[] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="keyword">let</span> a1: ReadonlyArray&lt;<span class="built_in">number</span>&gt; = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line"><span class="keyword">let</span> a2: Readonly&lt;<span class="built_in">number</span>[]&gt; = [];</span><br><span class="line"><span class="keyword">let</span> a3 = [] <span class="keyword">as</span> <span class="keyword">const</span>;</span><br></pre></td></tr></table></figure><blockquote><p>TypeScript 推断类型时，遇到<code>const</code>命令声明的变量，如果代码里面没有注明类型，就会推断该变量是值类型。</p><p><code>const</code>命令声明的变量，如果赋值为对象，并不会推断为值类型,这是因为 JavaScript 里面，<code>const</code>变量赋值为对象时，属性值是可以改变的(数组等同理)</p></blockquote><h3 id="元组tuple"><a href="#元组tuple" class="headerlink" title="元组tuple"></a>元组tuple</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> s: [<span class="built_in">string</span>, <span class="built_in">string</span>, <span class="built_in">boolean</span>] = [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="literal">true</span>];</span><br></pre></td></tr></table></figure><p>使用元组时必须声明类型不然会默认数组.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> ot: [<span class="built_in">number</span>, <span class="built_in">string</span>?] | <span class="literal">undefined</span> = [<span class="number">1</span>];</span><br></pre></td></tr></table></figure><p>使用扩展运算符可以不下成员数量的元组.</p><p>元组也有只读元组</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> readonlyTuple: <span class="keyword">readonly</span> [<span class="built_in">number</span>] = [<span class="number">1</span>];</span><br><span class="line"><span class="keyword">let</span> point = [<span class="number">3</span>, <span class="number">4</span>] <span class="keyword">as</span> <span class="keyword">const</span>;</span><br></pre></td></tr></table></figure><h3 id="symbol类型"><a href="#symbol类型" class="headerlink" title="symbol类型"></a>symbol类型</h3><p>symbol主要用于类的属性.</p><p>ts增加了unique symbol作为symbol的子类型.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">const</span> x: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错</span></span><br><span class="line"><span class="keyword">let</span> y: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="keyword">const</span> x: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="keyword">const</span> x = <span class="built_in">Symbol</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> a: unique symbol = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="keyword">const</span> b: <span class="keyword">typeof</span> a = a; <span class="comment">// 正确</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>感觉平常可能用不上…</p><h3 id="函数-对象-interface"><a href="#函数-对象-interface" class="headerlink" title="函数 对象 interface"></a>函数 对象 interface</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">hello</span>(<span class="params">txt: <span class="built_in">string</span></span>): <span class="title">void</span> </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;hello &quot;</span> + txt);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法一</span></span><br><span class="line"><span class="keyword">const</span> hello = <span class="function"><span class="keyword">function</span> (<span class="params">txt: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;hello &quot;</span> + txt);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法二</span></span><br><span class="line"><span class="keyword">const</span> hello: <span class="function">(<span class="params">txt: <span class="built_in">string</span></span>) =&gt;</span> <span class="built_in">void</span> = <span class="function"><span class="keyword">function</span> (<span class="params">txt</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&quot;hello &quot;</span> + txt);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>函数声明与函数变量声明.前者需要声明参数类型,否则默认为any.后者可以在选择在赋值时写出类型或者在声明变量时添加类型.此外还有这种写法</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> add: &#123;</span><br><span class="line">  (x: <span class="built_in">number</span>, <span class="attr">y</span>: <span class="built_in">number</span>): <span class="built_in">number</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">add = <span class="function"><span class="keyword">function</span> (<span class="params">x, y</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x + y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="箭头函数"><a href="#箭头函数" class="headerlink" title="箭头函数"></a>箭头函数</h4><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> repeat = (str: <span class="built_in">string</span>, <span class="attr">times</span>: <span class="built_in">number</span>): <span class="function"><span class="params">string</span> =&gt;</span> str.repeat(times);</span><br></pre></td></tr></table></figure><p>另外使用?表示可选参数</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x?: <span class="built_in">number</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f(); <span class="comment">// OK</span></span><br><span class="line">f(<span class="number">10</span>); <span class="comment">// OK</span></span><br></pre></td></tr></table></figure><p>默认值也类似.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">createPoint</span>(<span class="params">x: <span class="built_in">number</span> = <span class="number">0</span>, y: <span class="built_in">number</span> = <span class="number">0</span></span>): [<span class="title">number</span>, <span class="title">number</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> [x, y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">createPoint(); <span class="comment">// [0, 0]</span></span><br></pre></td></tr></table></figure><p>rest参数也可以用于将多个值包裹为数组或元组</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">joinNum</span>(<span class="params">...nums: [...<span class="built_in">number</span>[]]</span>): <span class="title">string</span> </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(nums);</span><br><span class="line">  <span class="keyword">return</span> nums.join(<span class="string">&quot; &quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">joinNum(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">joinNumAndString</span>(<span class="params">...args: [<span class="built_in">string</span>, <span class="built_in">number</span>]</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(args);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">joinNumAndString(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>参数也可以使用readonly进行修饰.</p><p>此外函数返回有void和never类型.前者表示没有返回值(或undefined)后者表示不会退出,常用于丢错误或循环.</p><h4 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a>函数重载</h4><p>不同于其他语言重载,</p><blockquote><p>有一些编程语言允许不同的函数参数，对应不同的函数实现。但是，JavaScript 函数只能有一个实现，必须在这个实现当中，处理不同的参数。因此，函数体内部就需要判断参数的类型及个数，并根据判断结果执行不同的操作。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">str: <span class="built_in">string</span></span>): <span class="title">string</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">arr: <span class="built_in">any</span>[]</span>): <span class="title">any</span>[]</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">stringOrArray: <span class="built_in">string</span> | <span class="built_in">any</span>[]</span>): <span class="title">string</span> | <span class="title">any</span>[] </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">typeof</span> stringOrArray === <span class="string">&quot;string&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> stringOrArray.split(<span class="string">&quot;&quot;</span>).reverse().join(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> stringOrArray.slice().reverse();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重载声明的排序很重要，因为 TypeScript 是按照顺序进行检查的，一旦发现符合某个类型声明，就不再往下检查了，所以类型最宽的声明应该放在最后面，防止覆盖其他类型声明</p><p><strong>构造函数</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> AnimalConstructor = <span class="keyword">new</span> () =&gt; Animal;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">create</span>(<span class="params">c: AnimalConstructor</span>): <span class="title">Animal</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> c();</span><br><span class="line">&#125;</span><br><span class="line">create(Animal);</span><br></pre></td></tr></table></figure><p>构造函数的类型写法，就是在参数列表前面加上<code>new</code>命令</p><p>此外也有对象形式写法</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> F = &#123;</span><br><span class="line">  <span class="keyword">new</span> (s: <span class="built_in">string</span>): <span class="built_in">object</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对对象,既可以使用<code>type</code>别名也可以使用<code>interface</code></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> ReadOnlyPerson &#123;</span><br><span class="line">  <span class="keyword">readonly</span> name: <span class="built_in">string</span>;</span><br><span class="line">  <span class="keyword">readonly</span> age: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> w:ReadOnlyPerson = &#123;</span><br><span class="line">  <span class="attr">name</span>:<span class="string">&quot;John&quot;</span>,</span><br><span class="line">  <span class="attr">age</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>空对象是 TypeScript 的一种特殊值，也是一种特殊类型。</p><blockquote><p>TypeScript 不允许动态添加属性，所以对象不能分步生成，必须生成时一次性声明所有属性。</p></blockquote><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;&#125;;</span><br><span class="line">obj.prop = <span class="number">123</span>; <span class="comment">// 报错</span></span><br></pre></td></tr></table></figure><p>因为<code>Object</code>可以接受各种类型的值，而空对象是<code>Object</code>类型的简写，所以它不会有严格字面量检查，赋值时总是允许多余的属性，只是不能读取这些属性。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Empty &#123;&#125;</span><br><span class="line"><span class="keyword">const</span> b: Empty = &#123; <span class="attr">myProp</span>: <span class="number">1</span>, <span class="attr">anotherProp</span>: <span class="number">2</span> &#125;; <span class="comment">// 正确</span></span><br><span class="line">b.myProp; <span class="comment">// 报错</span></span><br><span class="line"><span class="keyword">let</span> d: &#123;&#125;;</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="comment">// let d:Object;</span></span><br><span class="line"></span><br><span class="line">d = &#123;&#125;;</span><br><span class="line">d = &#123; <span class="attr">x</span>: <span class="number">1</span> &#125;;</span><br><span class="line">d = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">d = <span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>interface 是对象的模板，可以看作是一种类型约定，中文译为“接口”。使用了某个模板的对象，就拥有了指定的类型结构。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Person &#123;</span><br><span class="line">  <span class="attr">firstName</span>: <span class="built_in">string</span>;</span><br><span class="line">  lastName: <span class="built_in">string</span>;</span><br><span class="line">  age: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>interface 可以表示对象的各种语法，它的成员有 5 种形式。</p><ul><li>对象属性</li><li>对象的属性索引</li><li>对象方法</li><li>函数</li><li>构造函数</li></ul></blockquote><p>interface 与 type 的区别有下面几点。</p><p>（1）<code>type</code>能够表示非对象类型，而<code>interface</code>只能表示对象类型（包括数组、函数等）。</p><p>（2）<code>interface</code>可以继承其他类型，<code>type</code>不支持继承。</p><p>可以在interface中写方法以及利用interface写函数,构造函数.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写法一</span></span><br><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="built_in">boolean</span>): <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法二</span></span><br><span class="line"><span class="keyword">interface</span> B &#123;</span><br><span class="line">  <span class="attr">f</span>: <span class="function">(<span class="params">x: <span class="built_in">boolean</span></span>) =&gt;</span> <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法三</span></span><br><span class="line"><span class="keyword">interface</span> C &#123;</span><br><span class="line">  <span class="attr">f</span>: &#123; (x: <span class="built_in">boolean</span>): <span class="built_in">string</span> &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Add &#123;</span><br><span class="line">  (x: <span class="built_in">number</span>, <span class="attr">y</span>: <span class="built_in">number</span>): <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> myAdd: Add = <span class="function">(<span class="params">x, y</span>) =&gt;</span> x + y;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> ErrorConstructor &#123;</span><br><span class="line">  <span class="keyword">new</span> (message?: <span class="built_in">string</span>): <span class="built_in">Error</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>interface可以实现继承,而type不行.而且可以多继承.多重继承时,如果多个父接口存在同名属性,那么这些同名属性不能有类型冲突,否则会报错</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Shape &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Circle <span class="keyword">extends</span> Shape &#123;</span><br><span class="line">  <span class="attr">radius</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Style &#123;</span><br><span class="line">  <span class="attr">color</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Shape &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Circle <span class="keyword">extends</span> Style, Shape &#123;</span><br><span class="line">  <span class="attr">radius</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Country = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="built_in">string</span>;</span><br><span class="line">  capital: <span class="built_in">string</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> CountryWithPop <span class="keyword">extends</span> Country &#123;</span><br><span class="line">  <span class="attr">population</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，如果<code>type</code>命令定义的类型不是对象，interface 就无法继承</p><p>多个同名接口会进行合并.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Box &#123;</span><br><span class="line">  <span class="attr">height</span>: <span class="built_in">number</span>;</span><br><span class="line">  width: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Box &#123;</span><br><span class="line">  <span class="attr">length</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>举例来说，Web 网页开发经常会对<code>windows</code>对象和<code>document</code>对象添加自定义属性，但是 TypeScript 会报错，因为原始定义没有这些属性。解决方法就是把自定义属性写成 interface，合并进原始定义。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="string">&quot;foo&quot;</span>): <span class="built_in">boolean</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="built_in">any</span>): <span class="built_in">void</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="keyword">interface</span> A &#123;</span><br><span class="line">  f(x: <span class="string">&quot;foo&quot;</span>): <span class="built_in">boolean</span>;</span><br><span class="line">  f(x: <span class="built_in">any</span>): <span class="built_in">void</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果两个 interface 组成的联合类型存在同名属性，那么该属性的类型也是联合类型</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Circle &#123;</span><br><span class="line">  <span class="attr">area</span>: bigint;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Rectangle &#123;</span><br><span class="line">  <span class="attr">area</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">const</span> s: Circle | Rectangle;</span><br><span class="line"></span><br><span class="line">s.area; <span class="comment">// bigint | number</span></span><br></pre></td></tr></table></figure><h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3><p>对于顶层声明的属性，可以在声明时同时给出类型,如果不给声明默认any.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">  <span class="attr">x</span>: <span class="built_in">number</span>;</span><br><span class="line">  y: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>TypeScript 有一个配置项<code>strictPropertyInitialization</code>，只要打开，就会检查属性是否设置了初值，如果没有就报错。</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/12/4chodubBD5QySIM.png" alt="image-20240212174733858"></p><p>如果打开了这个设置，但是某些情况下，不是在声明时赋值或在构造方法里面赋值，为了防止这个设置报错，可以使用非空断言。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">  x!: <span class="built_in">number</span>;</span><br><span class="line">  y!: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>泛型类</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&lt;<span class="title">Type</span>&gt; </span>&#123;</span><br><span class="line">  <span class="attr">contents</span>: Type;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="title">constructor</span>(<span class="params">value: Type</span>)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.contents = value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> b: Box&lt;<span class="built_in">string</span>&gt; = <span class="keyword">new</span> Box(<span class="string">&quot;hello!&quot;</span>);</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="attr">key</span>: K;</span><br><span class="line">  value: V;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>抽象类</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="attr">foo</span>: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">B</span> <span class="keyword">extends</span> <span class="title">A</span> </span>&#123;</span><br><span class="line">  <span class="attr">bar</span>: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>抽象类的内部可以有已经实现好的属性和方法，也可以有还未实现的属性和方法。后者就叫做“抽象成员”（abstract member），即属性名和方法名有<code>abstract</code>关键字，表示该方法需要子类实现。如果子类没有实现抽象成员，就会报错。</p><h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getFirst</span>&lt;<span class="title">Type</span>&gt;(<span class="params">arr: Type[]</span>): <span class="title">Type</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arr[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不过为了方便，函数调用时，往往省略不写类型参数的值，让 TypeScript 自己推断,有些复杂的使用场景，TypeScript 可能推断不出类型参数的值，这时就必须显式给出.</p><blockquote><p>类型参数的名字，可以随便取，但是必须为合法的标识符。习惯上，类型参数的第一个字符往往采用大写字母。一般会使用<code>T</code>（type 的第一个字母）作为类型参数的名字。如果有多个类型参数，则使用 T 后面的 U、V 等字母命名，各个参数之间使用逗号（“,”）分隔。</p></blockquote><p>泛型主要用在四个场合：函数、接口、类和别名。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">id</span>&lt;<span class="title">T</span>&gt;(<span class="params">arg: T</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arg;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">id</span>&lt;<span class="title">T</span>&gt;(<span class="params">arg: T</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arg;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> myid: &lt;T&gt;<span class="function">(<span class="params">arg: T</span>) =&gt;</span> T = id;</span><br><span class="line"><span class="keyword">interface</span> Box&lt;Type&gt; &#123;</span><br><span class="line">  <span class="attr">contents</span>: Type;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> box: Box&lt;<span class="built_in">string</span>&gt;;</span><br></pre></td></tr></table></figure><p><strong>类型别名</strong></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Nullable&lt;T&gt; = T | <span class="literal">undefined</span> | <span class="literal">null</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Container&lt;T&gt; = &#123; <span class="attr">value</span>: T &#125;;</span><br><span class="line"><span class="keyword">type</span> Tree&lt;T&gt; = &#123;</span><br><span class="line">  <span class="attr">value</span>: T;</span><br><span class="line">  left: Tree&lt;T&gt; | <span class="literal">null</span>;</span><br><span class="line">  right: Tree&lt;T&gt; | <span class="literal">null</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>类型参数默认值</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getFirst_</span>&lt;<span class="title">T</span> = <span class="title">string</span>&gt;(<span class="params">arr: T[]</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> arr[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类型参数的约束条件</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">comp</span>&lt;<span class="title">Type</span> <span class="title">extends</span> </span>&#123; length: <span class="built_in">number</span> &#125;&gt;(a: Type, <span class="attr">b</span>: Type) &#123;</span><br><span class="line">  <span class="keyword">if</span> (a.length &gt; b.length) &#123;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Fn&lt;A <span class="keyword">extends</span> <span class="built_in">string</span>, B <span class="keyword">extends</span> <span class="built_in">string</span> = <span class="string">&quot;world&quot;</span>&gt; = [A, B];</span><br><span class="line"><span class="keyword">type</span> Result = Fn&lt;<span class="string">&quot;hello&quot;</span>&gt;</span><br></pre></td></tr></table></figure><p>类型参数的约束条件如下</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;TypeParameter <span class="keyword">extends</span> ConstraintType&gt;</span><br></pre></td></tr></table></figure><p>泛型使用注意:</p><ol><li><strong>尽量少用泛型</strong></li><li><strong>类型参数越少越好</strong></li><li><strong>类型参数需要出现两次</strong></li><li><strong>泛型可以嵌套</strong></li></ol><h3 id="Enum类型"><a href="#Enum类型" class="headerlink" title="Enum类型"></a>Enum类型</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">enum</span> Color &#123;</span><br><span class="line">  Red, <span class="comment">// 0</span></span><br><span class="line">  Green, <span class="comment">// 1</span></span><br><span class="line">  Blue, <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">enum</span> Direction &#123;</span><br><span class="line">  Up = <span class="string">&quot;UP&quot;</span>,</span><br><span class="line">  Down = <span class="string">&quot;DOWN&quot;</span>,</span><br><span class="line">  Left = <span class="string">&quot;LEFT&quot;</span>,</span><br><span class="line">  Right = <span class="string">&quot;RIGHT&quot;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Enum 结构本身也是一种类型。比如，上例的变量<code>c</code>等于<code>1</code>，它的类型可以是 Color，也可以是<code>number</code></p><p>多个同名的 Enum 结构会自动合并。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="built_in">enum</span> MediaTypes &#123;</span><br><span class="line">  <span class="built_in">JSON</span> = <span class="string">&quot;application/json&quot;</span>,</span><br><span class="line">  XML = <span class="string">&quot;application/xml&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> url = <span class="string">&quot;localhost&quot;</span>;</span><br><span class="line"></span><br><span class="line">fetch(url, &#123;</span><br><span class="line">  <span class="attr">headers</span>: &#123;</span><br><span class="line">    <span class="attr">Accept</span>: MediaTypes.JSON,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;).then(<span class="function">(<span class="params">response</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="类型断言"><a href="#类型断言" class="headerlink" title="类型断言"></a>类型断言</h3><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 语法一</span></span><br><span class="line"><span class="keyword">let</span> bar: T = &lt;T&gt;foo;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 语法二</span></span><br><span class="line"><span class="keyword">let</span> bar: T = foo <span class="keyword">as</span> T;</span><br></pre></td></tr></table></figure><p>类型断言要求实际的类型与断言的类型兼容，实际类型可以断言为一个更加宽泛的类型（父类型），也可以断言为一个更加精确的类型（子类型），但不能断言为一个完全无关的类型</p><p>此外还有as const断言,<code>s const</code>断言只能用于字面量,<code>as const</code>也不能用于表达式</p><p>或者先断言为unknown.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expr <span class="keyword">as</span> unknown <span class="keyword">as</span> T;</span><br></pre></td></tr></table></figure><p>对于那些可能为空的变量（即可能等于<code>undefined</code>或<code>null</code>），TypeScript 提供了非空断言，保证这些变量不会为空，写法是在变量名后面加上感叹号<code>!</code></p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> root = <span class="built_in">document</span>.getElementById(<span class="string">&quot;root&quot;</span>)!;</span><br></pre></td></tr></table></figure><p>断言函数</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">isString</span>(<span class="params">value: unknown</span>): <span class="title">asserts</span> <span class="title">value</span> <span class="title">is</span> <span class="title">string</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">typeof</span> value !== <span class="string">&quot;string&quot;</span>) <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">&quot;Not a string&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="模块和namespace"><a href="#模块和namespace" class="headerlink" title="模块和namespace"></a>模块和namespace</h3><p>TypeScript 模块除了支持所有 ES 模块的语法，特别之处在于允许输出和输入类型。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">type</span> Bool = <span class="literal">true</span> | <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><p>模块加载方式有classic和Node,也就是Command js和ES6.</p><p>namespace 用来建立一个容器，内部的所有变量和函数，都必须在这个容器里面使用。</p><blockquote><p>它出现在 ES 模块诞生之前，作为 TypeScript 自己的模块格式而发明的。但是，自从有了 ES 模块，官方已经不推荐使用 namespace 了。</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> Utils &#123;</span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">isString</span>(<span class="params">value: <span class="built_in">any</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">typeof</span> value === <span class="string">&quot;string&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 正确</span></span><br><span class="line">  isString(<span class="string">&quot;yes&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Utils.isString(<span class="string">&quot;no&quot;</span>); <span class="comment">// 报错</span></span><br></pre></td></tr></table></figure><p>如果要在命名空间以外使用内部成员，就必须为该成员加上<code>export</code>前缀，表示对外输出该成员</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> Utility &#123;</span><br><span class="line">  <span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">log</span>(<span class="params">msg: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(msg);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">error</span>(<span class="params">msg: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.error(msg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Utility.log(<span class="string">&quot;Call me&quot;</span>);</span><br><span class="line">Utility.error(<span class="string">&quot;maybe!&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>装饰器（Decorator）是一种语法结构，用来在定义时修改类（class）的行为。</p><p>在语法上，装饰器有如下几个特征。</p><p>（1）第一个字符（或者说前缀）是<code>@</code>，后面是一个表达式。</p><p>（2）<code>@</code>后面的表达式，必须是一个函数（或者执行后可以得到一个函数）。</p><p>（3）这个函数接受所修饰对象的一些相关值作为参数。</p><p>（4）这个函数要么不返回值，要么返回一个新对象取代所修饰的目标对象。</p><p>装饰器函数和装饰器方法</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Decorator = <span class="function">(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">  value: DecoratedValue,</span></span></span><br><span class="line"><span class="params"><span class="function">  context: &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    kind: <span class="built_in">string</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    name: <span class="built_in">string</span> | symbol;</span></span></span><br><span class="line"><span class="params"><span class="function">    addInitializer?(initializer: () =&gt; <span class="built_in">void</span>): <span class="built_in">void</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">static</span>?: <span class="built_in">boolean</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">private</span>?: <span class="built_in">boolean</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    access: &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">      get?(): unknown;</span></span></span><br><span class="line"><span class="params"><span class="function">      set?(value: unknown): <span class="built_in">void</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    &#125;;</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) =&gt;</span> <span class="built_in">void</span> | ReplacementValue;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ClassDecorator = <span class="function">(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">  value: <span class="built_in">Function</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  context: &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    kind: <span class="string">&quot;class&quot;</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    name: <span class="built_in">string</span> | <span class="literal">undefined</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">    addInitializer(initializer: () =&gt; <span class="built_in">void</span>): <span class="built_in">void</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) =&gt;</span> <span class="built_in">Function</span> | <span class="built_in">void</span>;</span><br></pre></td></tr></table></figure><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">countInstances</span>(<span class="params">value: <span class="built_in">any</span>, context: <span class="built_in">any</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> instanceCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> wrapper = <span class="function"><span class="keyword">function</span> (<span class="params">...args: <span class="built_in">any</span>[]</span>) </span>&#123;</span><br><span class="line">    instanceCount++;</span><br><span class="line">    <span class="keyword">const</span> instance = <span class="keyword">new</span> value(...args);</span><br><span class="line">    instance.count = instanceCount;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125; <span class="keyword">as</span> unknown <span class="keyword">as</span> <span class="keyword">typeof</span> MyClass;</span><br><span class="line"></span><br><span class="line">  wrapper.prototype = value.prototype; <span class="comment">// A</span></span><br><span class="line">  <span class="keyword">return</span> wrapper;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@countInstances</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> inst1 = <span class="keyword">new</span> MyClass();</span><br><span class="line">inst1 <span class="keyword">instanceof</span> MyClass; <span class="comment">// true</span></span><br><span class="line">inst1.count; <span class="comment">// 1</span></span><br></pre></td></tr></table></figure><h3 id="declare关键字"><a href="#declare关键字" class="headerlink" title="declare关键字"></a>declare关键字</h3><p>declare 关键字用来告诉编译器，某个类型是存在的，可以在当前文件中使用。</p><p>它的主要作用，就是让当前文件可以使用其他文件声明的类型。举例来说，自己的脚本使用外部库定义的函数，编译器会因为不知道外部函数的类型定义而报错，这时就可以在自己的脚本里面使用<code>declare</code>关键字，告诉编译器外部函数的类型。这样的话，编译单个脚本就不会因为使用了外部类型而报错。</p><p>declare 关键字可以描述以下类型。</p><ul><li>变量（const、let、var 命令声明）</li><li>type 或者 interface 命令声明的类型</li><li>class</li><li>enum</li><li>函数（function）</li><li>模块（module）</li><li>命名空间（namespace）</li></ul><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">let</span> x: <span class="built_in">number</span>;</span><br><span class="line"><span class="keyword">declare</span> <span class="function"><span class="keyword">function</span> <span class="title">sayHello</span>(<span class="params">name: <span class="built_in">string</span></span>): <span class="title">void</span></span>;</span><br><span class="line"></span><br><span class="line">sayHello(<span class="string">&quot;张三&quot;</span>);</span><br><span class="line"><span class="keyword">declare</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">  <span class="title">constructor</span>(<span class="params">name: <span class="built_in">string</span></span>);</span><br><span class="line">  eat(): <span class="built_in">void</span>;</span><br><span class="line">  sleep(): <span class="built_in">void</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">namespace</span> AnimalLib &#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    <span class="title">constructor</span>(<span class="params">name: <span class="built_in">string</span></span>);</span><br><span class="line">    eat(): <span class="built_in">void</span>;</span><br><span class="line">    sleep(): <span class="built_in">void</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">type</span> Animals = <span class="string">&quot;Fish&quot;</span> | <span class="string">&quot;Dog&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line"><span class="keyword">declare</span> <span class="built_in">module</span> AnimalLib &#123;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Animal</span> </span>&#123;</span><br><span class="line">    <span class="title">constructor</span>(<span class="params">name: <span class="built_in">string</span></span>);</span><br><span class="line">    eat(): <span class="built_in">void</span>;</span><br><span class="line">    sleep(): <span class="built_in">void</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">type</span> Animals = <span class="string">&quot;Fish&quot;</span> | <span class="string">&quot;Dog&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="d-ts类型声明文件"><a href="#d-ts类型声明文件" class="headerlink" title="d.ts类型声明文件"></a>d.ts类型声明文件</h2><p>可以为每个模块脚本，定义一个<code>.d.ts</code>文件，把该脚本用到的类型定义都放在这个文件里面。但是，更方便的做法是为整个项目，定义一个大的<code>.d.ts</code>文件，在这个文件里面使用<code>declare module</code>定义每个模块脚本的类型</p><p>使用时，自己的脚本使用三斜杠命令，加载这个类型声明文件。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// &lt;reference path=&quot;node.d.ts&quot;/&gt;</span></span><br></pre></td></tr></table></figure><p>如果没有上面这一行命令，自己的脚本使用外部模块时，就需要在脚本里面使用 declare 命令单独给出外部模块的类型。</p><blockquote><p>单独使用的模块，一般会同时提供一个单独的类型声明文件（declaration file），把本模块的外部接口的所有类型都写在这个文件里面，便于模块使用者了解接口，也便于编译器检查使用者的用法是否正确。</p><p>类型声明文件里面只有类型代码，没有具体的代码实现。它的文件名一般为<code>[模块名].d.ts</code>的形式，其中的<code>d</code>表示 declaration（声明）</p></blockquote><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// &lt;reference path=&quot;node.d.ts&quot;/&gt;</span></span><br><span class="line"><span class="keyword">import</span> &#123; test &#125; <span class="keyword">from</span> <span class="string">&quot;./test&quot;</span>;</span><br><span class="line"><span class="keyword">declare</span> <span class="keyword">let</span> x: <span class="built_in">number</span>;</span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">console</span>.log(x);</span><br><span class="line"><span class="built_in">console</span>.log(test);</span><br><span class="line"><span class="keyword">let</span> p: Post = &#123; <span class="attr">id</span>: <span class="number">1</span>, <span class="attr">title</span>: <span class="string">&quot;title&quot;</span>, <span class="attr">content</span>: <span class="string">&quot;content&quot;</span> &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// node.d.ts</span></span><br><span class="line"><span class="keyword">interface</span> Post &#123;</span><br><span class="line">  <span class="attr">id</span>: <span class="built_in">number</span>;</span><br><span class="line">  title: <span class="built_in">string</span>;</span><br><span class="line">  content: <span class="built_in">string</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后推荐两个练习网站:</p><ul><li><a href="https://typehero.dev/">TypeHero</a></li><li><a href="https://github.com/type-challenges/type-challenges">type-challenges/type-challenges: Collection of TypeScript type challenges with online judge (github.com)</a></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://typescript.p6p.net">https://typescript.p6p.net</a></li><li><a href="https://www.typescriptlang.org/docs/handbook/intro.html">TypeScript: Handbook - The TypeScript Handbook (typescriptlang.org)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;早该学学了.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>回头再看前端框架</title>
    <link href="https://www.sekyoro.top/2024/02/03/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8B%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6/"/>
    <id>https://www.sekyoro.top/2024/02/03/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8B%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6/</id>
    <published>2024-02-03T06:34:45.000Z</published>
    <updated>2024-02-11T07:28:06.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>马上又要到农历新年了,趁现在回顾一下过去一年的前端发展.当然是站在我的角度,因为有许多新的技术,对于不同领域的人以及不同层面的开发者都有不同的意味.<br>对于我来说,快捷、轻松的开发体验是比较重要的,臃肿的大型框架并不是优秀的代名词,所以我会尽量使用或者倾向喜欢一些生态发展好,开发者使用体验好,社区也比较活跃的框架或者技术.此外,随着事件发展肯定会不断涌现一些新型技术甚至新的思想,对于学习者来说,这些东西还需要一些观望.<br><span id="more"></span></p><p>除开一些基本概念,我来写一些我平常会用的框架和技术.当然我这里并不是想做一个技术栈的介绍,更多的是在做一个web前端项目时可以考虑的提升开发效率的工具.</p><h2 id="Tailwind-css"><a href="#Tailwind-css" class="headerlink" title="Tailwind css"></a>Tailwind css</h2><p>虽然有争议,但这个css工具已经是极为方便的工具了,目前浏览器已经支持许多css新的特性,所以我觉得可以说,类似less和scss的工具是不需要的了.</p><p>Bootstrap或许过于臃肿,使用tailwind css本身并没有组件库,这里我推荐两个组件库，一个是<a href="https://daisyui.com/">daisyUI — Tailwind CSS Components ( version 4 update is here )</a>另一个是<a href="https://ui.shadcn.com/docs">Introduction - shadcn/ui</a></p><p>搭配现代的css特性,这样写css基本就够了.实在觉得不行可以再往Element-Plus也就是更抽象高级的组件库上靠.</p><h2 id="React"><a href="#React" class="headerlink" title="React"></a>React</h2><p>react的生态很好,状态管理工具以及搭配的一些动效库都很多.此外搭配Next.js,Remix.js等等成为一个较为完整的web前端解决方案.React是一个library,关键是使用了JSX,很多其他库也是受此影响,比如Solid,Preact,Millions等等.</p><h2 id="Vue"><a href="#Vue" class="headerlink" title="Vue"></a>Vue</h2><p>Vue在国内用的很多,当然国外也不少.相对来说我认为较大的差别是Vue的官方本身已经提供了整套的解决方案,Vue也有Nuxt解决SSR的问题,它有Pinia解决状态管理的问题,不像React状态管理通常会选用第三方的Zusland或者jotai等等(当然,如果需要管理的不多直接使用context也可以).目前vue2已经不在维护了,我也大力推荐直接上vue3.Vue使用单独的一个.vue文件表示一个或多个组件,svelte框架也类似.</p><p>可以这么说,如果要做一个中大型的前端项目,使用vue或者react的以及它们各自的生态工具是完全没有问题,也没有太大差异的.而且vue对于国内开发者还是比较友好的,各类文档的中文支持还是要比react好.</p><p>React和Vue都有SSR的框架,分别是Next和Nuxt,当然React还有Gatsby,Expo这些</p><h2 id="Svelte-or-Solid"><a href="#Svelte-or-Solid" class="headerlink" title="Svelte or Solid"></a>Svelte or Solid</h2><p>在virtual dom上不再赘述.而svelte和solid都是使用的真实的dom.</p><p>有的时候你并不需要也并不想要写一个较大的应用,并不想引入过多依赖,但是又想使用一些方便的库.</p><p>这时候react,vue就可以稍微退退,使用一些既新颖又成熟的方案,比如Svelte,Solid,Preact或者Million等等.前端框架的发展特别快,在使用过程中掌握一些基本概念会更好.</p><p>在浏览这些框架时,我也体会到一个深刻的事情,作为普通开发者在选择这些框架时,即使文档宣传有多么好多么快,如果背后的社区不坚持做下去不坚持宣传,背后的生态,背后没有一个较为统一的解决方案,还是无法做的长久.</p><p>我说这些话的意思是,在这么多前端框架出现的今天,如果想要有一个顺畅的开发体验,除了框架本身宣传的技术,还有背后的生态工具链也很重要,毕竟,当项目体积变大,事情就更复杂了.</p><p>Svelte官方提供了一个SvelteKit工具,也支持SSR等功能.</p><p>Solid也是类似.可以简单粗暴地说在语法上Svelte更像Vue,Solid更像React.而且后两者都提供了SSR的能力.</p><h2 id="对比一下Next-Nuxt以及SvelteKit和solid-js"><a href="#对比一下Next-Nuxt以及SvelteKit和solid-js" class="headerlink" title="对比一下Next,Nuxt以及SvelteKit和solid.js"></a>对比一下Next,Nuxt以及SvelteKit和solid.js</h2><p>平常我们写前端代码关注哪些点?</p><p>Next官网给了以下几点</p><p><img data-src="https://s2.loli.net/2024/02/03/gZW9YjzshmFBXnx.png" alt="image-20240203185447263" style="zoom:67%;" /></p><h3 id="构建工具"><a href="#构建工具" class="headerlink" title="构建工具"></a>构建工具</h3><p>对于Next,可以使用<code>create-next-app</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx create-next-app@latest</span><br></pre></td></tr></table></figure><p>使用Next或者Nuxt一般主要目的是使用SSR功能.当然除了SSR之外这些框架本身也提供了很多功能,一些开箱即用的库,一些默认的目录结构.不过不是为了强调SSR,SEO,貌似也没有必要使用Next(事实上你也可以使用这些框架但不过多使用它们的一些feature,好处是不用费时费力安装一些常用库)</p><p>如果不使用Next而是用React,可以考虑使用Vite等构建工具.</p><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><p>使用不同的构建工具或者框架会默认一些目录结构.</p><p>Next使用基于文件结构的路由,所录在目录结构上需要注意的.在Next的大更新也就是v13之后,路由默认使用App Router. App Router默认使用app目录进行路由,而Page Router 使用Page目录.</p><p>推荐只是用app router就够了.</p><p>在<code>app/layout.tsx</code>中创建html,在<code>app/page.tsx</code>中创建组件,然后创建public文件夹放图像和字体等静态文件.</p><p>具体Next项目结构参看<a href="https://nextjs.org/docs/getting-started/project-structure">Getting Started: Project Structure | Next.js (nextjs.org)</a>,可以看到还是有很多默认规则的.</p><h3 id="如何写一个组件"><a href="#如何写一个组件" class="headerlink" title="如何写一个组件"></a>如何写一个组件</h3><p>由于有了SSR功能,组件分为了服务端和客户端组件</p><h4 id="服务端组件"><a href="#服务端组件" class="headerlink" title="服务端组件"></a>服务端组件</h4><p>服务器组件相比于原本的CSR应用有很多好处.比如数据获取更快,更安全,有缓存,客户端需要的Bundle更小,更好的SEO.</p><p>渲染过程:在服务器上，Next.js使用React的API来编排渲染。渲染工作分为多个块：按各个route segments和suspense boundaries。</p><p>每个块(chunks)分两个步骤呈现：React将服务器组件呈现为一种特殊的数据格式，称为React服务器组件有效载荷（RSC Payload）。Next.js使用RSC Payload和Client Component JavaScript指令在服务器上呈现HTML。</p><p>然后，在客户端上：HTML用于立即显示对应路由的快速非交互式预览-这仅用于初始页面加载。React服务器组件有效负载用于协调客户端和服务器组件树，并更新DOM。JavaScript指令用于水合客户端组件并使应用程序具有交互性。</p><p><strong>渲染策略</strong></p><p>有静态渲染,动态渲染</p><p>默认是静态渲染,使用静态渲染，路由在构建时渲染，或在数据重新验证后在后台渲染。结果被缓存，并且可以被推送到内容交付网络（CDN）。此优化允许您在用户和服务器请求之间共享渲染工作的结果。当路由包含的数据不是针对用户个性化的，并且可能在构建时已知时（例如静态博客文章或产品页面），静态渲染非常有用。</p><p>使用动态渲染，<strong>可以在请求时为每个用户渲染路由</strong>。当路由具有针对用户个性化的数据或具有只能在请求时才知道的信息（如cookie或URL的搜索参数）时，动态呈现非常有用。</p><blockquote><p>作为开发人员，您不需要在静态和动态渲染之间进行选择，因为Next.js会根据所使用的功能和API自动为每条路由选择最佳渲染策略。相反，您可以选择何时缓存或重新验证特定数据，也可以选择流式处理UI的部分内容。</p></blockquote><p>此外还有streaming,流式处理使您能够从服务器逐步渲染UI。工作被分割成块，并在准备就绪时流式传输到客户端。这允许用户在整个内容完成呈现之前立即查看页面的部分内容。</p><h4 id="客户端组件"><a href="#客户端组件" class="headerlink" title="客户端组件"></a>客户端组件</h4><p>客户端组件<strong>可以使用state,effects以及事件监听.此外还可以使用浏览器的API</strong>.</p><p>“use client”用于声明服务器和客户端组件模块之间的边界。这意味着，通过在文件中定义“use clinet”，导入其中的所有其他模块，包括子组件，都被视为客户端捆绑包的一部分。</p><p>一旦定义了边界，导入其中的所有子组件和模块都将被视为客户端捆绑包的一部分。</p><h3 id="styling"><a href="#styling" class="headerlink" title="styling"></a>styling</h3><p>一般来说可以使用tailwind css,像这种主要关注的是组件化,也就是不同的组件之间的css不要互相污染.全局的css可以方便插入.除了tailwind css外还有css in js,css modules等方法,我建议使用其中两种搭配就行了,不然会让人confused(推荐css modules和tailwind css搭配).</p><h3 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h3><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fterminology-url-anatomy.png&amp;w=3840&amp;q=75&amp;dpl=dpl_8JSreCCcxctwsnJ6FNFujsNZdfsZ" alt="Terminology for URL Anatomy"></p><p>Next的app router支持共享布局,嵌套路由,加载状态,错误处理等等.文件用于定义路由.</p><p>每个目录表示一个路由段,使用<code>page.tsx</code>表示对于那个该路由的组件.</p><p>page默认是服务端组件,可以改为客户端组件</p><p>layouts在不同pages中是共享的,跳转时layouts保留state,不再重新渲染.这个组件应该接受一个<code>children</code>属性作为一个child layout或者一个child page.</p><p>顶层有一个Root Layout,这是必须的.在所有pages中共享.包含html和body.</p><p>每个路由段可以选择性定义自己的layout,路由中的layout默认被包含,每个父layout把子layout通过children包含在一起.layout和page可以在同一个目录下,layoput会包含这个page.</p><p>此外Next还有template,跟layouts类似,但是它并不会保持routes之间的state,这意思是当一个用户在共享一个template的不同路由之间跳转时,不会保持状态.会重新渲染元素.</p><p>在定义metadata信息时可以在page或者layout中导出metadata对象.</p><h3 id="链接与页面导航"><a href="#链接与页面导航" class="headerlink" title="链接与页面导航"></a>链接与页面导航</h3><p>Next有四种跳转路由的方式</p><ol><li>使用Link组件</li><li>使用useRouter hook(客户端组件)</li><li>使用redirect函数(服务端组件)</li><li>浏览器的History API</li></ol><h4 id="Link组件"><a href="#Link组件" class="headerlink" title="Link组件"></a>Link组件</h4><p>继承了\<a\>标签并且使得在客户端跳转提供了prefetching功能,优选方式</p><p>跳转路由时默认行为会到顶端,可以使用属性<code>scroll=&#123;false&#125;</code></p><h4 id="useRouter"><a href="#useRouter" class="headerlink" title="useRouter"></a>useRouter</h4><p>使用useRouter hook</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;use client&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> &#123; useRouter &#125; <span class="keyword">from</span> <span class="string">&#x27;next/navigation&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="function"><span class="keyword">function</span> <span class="title">Page</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> router = useRouter()</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="xml"><span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">onClick</span>=<span class="string">&#123;()</span> =&gt;</span> router.push(&#x27;/dashboard&#x27;)&#125;&gt;</span></span><br><span class="line"><span class="xml">      Dashboard</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于服务端组件,可以使用redirect.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; redirect &#125; <span class="keyword">from</span> <span class="string">&#x27;next/navigation&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">fetchTeam</span>(<span class="params">id: string</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> res = <span class="keyword">await</span> fetch(<span class="string">&#x27;https://...&#x27;</span>)</span><br><span class="line">  <span class="keyword">if</span> (!res.ok) <span class="keyword">return</span> <span class="literal">undefined</span></span><br><span class="line">  <span class="keyword">return</span> res.json()</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">Profile</span>(<span class="params">&#123; params &#125;: &#123; params: &#123; id: string &#125; &#125;</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> team = <span class="keyword">await</span> fetchTeam(params.id)</span><br><span class="line">  <span class="keyword">if</span> (!team) &#123;</span><br><span class="line">    redirect(<span class="string">&#x27;/login&#x27;</span>)</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Next.js路由默认缓存等机制.</p><p>使用<code>loading.js</code>加载一些内容,原本是React中的suspense.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Floading-ui.png&amp;w=3840&amp;q=75&amp;dpl=dpl_7E1cZLB9sZWvkjQY6Ei4tJ18mYN7" alt="Loading UI"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export default function Loading() &#123;</span><br><span class="line">  // You can add any UI inside Loading, including a Skeleton.</span><br><span class="line">  return &lt;LoadingSkeleton /&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用loading.js与suspense可以获得<strong>Streaming Server Rendering</strong> 和<strong>Selective Hydration</strong>的效果.</p><h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>使用error.js进行错误处理.如果要处理根目录下的错误,需要使用<code>global-error.tsx</code>文件,它可以处理包括根下layout.tsx和template.tsx中丢出的错误,此外也推荐再定义error.tsx处理根下page.tsx中的错误.</p><p>error.tsx文件会被嵌入到layout之中,所以不会处理layout.tsx中丢出的错误.</p><h4 id="重定向"><a href="#重定向" class="headerlink" title="重定向"></a>重定向</h4><p><img data-src="https://s2.loli.net/2024/02/06/Zav7h3fXBkOIR8g.png" alt="image-20240206130511356"></p><p>重定向跟路由类似,也分在服务端组件和客户端使用.</p><h4 id="redirect"><a href="#redirect" class="headerlink" title="redirect"></a>redirect</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x27;use server&#x27;</span><br><span class="line"> </span><br><span class="line">import &#123; redirect &#125; from &#x27;next/navigation&#x27;</span><br><span class="line">import &#123; revalidatePath &#125; from &#x27;next/cache&#x27;</span><br><span class="line"> </span><br><span class="line">export async function createPost(id: string) &#123;</span><br><span class="line">  try &#123;</span><br><span class="line">    // Call database</span><br><span class="line">  &#125; catch (error) &#123;</span><br><span class="line">    // Handle errors</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  revalidatePath(&#x27;/posts&#x27;) // Update cached posts</span><br><span class="line">  redirect(`/post/$&#123;id&#125;`) // Navigate to the new post page</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以在<code>next.config.js</code>中设置redirects使得在请求的页面渲染之前进行跳转.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  <span class="keyword">async</span> <span class="function"><span class="title">redirects</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">      <span class="comment">// Basic redirect</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">source</span>: <span class="string">&#x27;/about&#x27;</span>,</span><br><span class="line">        <span class="attr">destination</span>: <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">        <span class="attr">permanent</span>: <span class="literal">true</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="comment">// Wildcard path matching</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">source</span>: <span class="string">&#x27;/blog/:slug&#x27;</span>,</span><br><span class="line">        <span class="attr">destination</span>: <span class="string">&#x27;/news/:slug&#x27;</span>,</span><br><span class="line">        <span class="attr">permanent</span>: <span class="literal">true</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外还有在Middleware中的跳转,方便在进行验证之后进行选择性跳转.</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; NextResponse, NextRequest &#125; <span class="keyword">from</span> <span class="string">&#x27;next/server&#x27;</span></span><br><span class="line"><span class="keyword">import</span> &#123; authenticate &#125; <span class="keyword">from</span> <span class="string">&#x27;auth-provider&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">middleware</span>(<span class="params">request: NextRequest</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> isAuthenticated = authenticate(request)</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// If the user is authenticated, continue as normal</span></span><br><span class="line">  <span class="keyword">if</span> (isAuthenticated) &#123;</span><br><span class="line">    <span class="keyword">return</span> NextResponse.next()</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// Redirect to login page if not authenticated</span></span><br><span class="line">  <span class="keyword">return</span> NextResponse.redirect(<span class="keyword">new</span> URL(<span class="string">&#x27;/login&#x27;</span>, request.url))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> config = &#123;</span><br><span class="line">  <span class="attr">matcher</span>: <span class="string">&#x27;/dashboard/:path*&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="路由组"><a href="#路由组" class="headerlink" title="路由组"></a>路由组</h4><p>路由组可以将路由分成一组,同时使得在一个路由段建立多个嵌套的layout.</p><p>使用<code>()</code>包含一个目录名,这个目录不会被当作一个路由.在这个路由组中的路由可以共享一个layout.这个目录不会被处理成路由段,此外可以利用这个创建多个root layout.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Froute-group-multiple-root-layouts.png&amp;w=3840&amp;q=75&amp;dpl=dpl_Fr1VCq6W9RFeEuXYFe2L4sUmaW7a" alt="Route Groups with Multiple Root Layouts"></p><h4 id="项目结构和文件安排"><a href="#项目结构和文件安排" class="headerlink" title="项目结构和文件安排"></a>项目结构和文件安排</h4><p>在目录前加<code>_</code>使得其不可访问.</p><blockquote><p>：_folderName这表示文件夹是一个专用的实现细节，路由系统不应考虑它，从而选择不路由文件夹及其所有子文件夹。</p></blockquote><p>这样做可以使得UI与路由分开.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fproject-organization-private-folders.png&w=3840&q=75&dpl=dpl_FhZP1LTtukMJX1yNmAQ5DmdgAZ2Q" alt="An example folder structure using private folders" style="zoom:67%;" /></p><p>此外可以配置module aliases方便导入.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;compilerOptions&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;baseUrl&quot;</span>: <span class="string">&quot;.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;paths&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;@/components/*&quot;</span>: [<span class="string">&quot;components/*&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>项目组织策略</strong></p><p>可以将组件和lib库放在根目录,跟app目录同层.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fproject-organization-project-root.png&w=3840&q=75&dpl=dpl_FhZP1LTtukMJX1yNmAQ5DmdgAZ2Q" alt="An example folder structure with project files outside of app" style="zoom:50%;" /></p><p>还可以将这些目录放在app目录下,此外还可以放在路由目录下.</p><p><img data-src="https://nextjs.org/_next/image?url=%2Fdocs%2Flight%2Fproject-organization-app-root-split.png&amp;w=3840&amp;q=75&amp;dpl=dpl_FhZP1LTtukMJX1yNmAQ5DmdgAZ2Q" alt="An example folder structure with project files split by feature or route"></p><h4 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h4><p>给目录命名的时候使用<code>[]</code>,这样在layout,page,route或者generateMetadata函数中可以访问动态路由的参数.</p><p>此外使用<code>[...slug]</code>不仅可以捕获该路由下其下的子路由也能被捕获</p><p>使用<code>dynamicParams</code>控制<code>generateStaticParams</code>得到的结果之外的能否访问.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export const dynamicParams = false</span><br></pre></td></tr></table></figure><p>存在multiple-dynamic route以及catch-all segments</p><p><img data-src="https://s2.loli.net/2024/02/06/rcxIzpTYlAGDZPK.png" alt="image-20240206163014573"></p><p>此外还有Optional Catch-all Segments,<code>[[...]]</code>既可以匹配原本路由也可以匹配子路由</p><h4 id="并行路由"><a href="#并行路由" class="headerlink" title="并行路由"></a>并行路由</h4><p>并行路由允许您同时或有条件地呈现同一布局中的一个或多个页面。它们适用于应用程序的高度动态部分，如社交网站上的仪表板和提要。</p><p>使用<code>@</code>开头的目录,类似slot可以插入到layout中.</p><h4 id="插入路由"><a href="#插入路由" class="headerlink" title="插入路由"></a>插入路由</h4><p>截取路由允许您在当前布局中从应用程序的另一部分加载路由。当您希望在不让用户切换到不同上下文的情况下显示路线的内容时，这种路由范例可能很有用。</p><h4 id="路由处理器"><a href="#路由处理器" class="headerlink" title="路由处理器"></a>路由处理器</h4><p>这也是Next能作为全栈框架的原因,当然在这方面不如Nest.</p><p>路由处理器类似page.js而且不能跟其重合.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export const dynamic = &#x27;force-dynamic&#x27; // defaults to auto</span><br><span class="line">export async function GET(request: Request) &#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用GET方法并用Response返回能自动缓存.并且可以使用revalidate验证缓存数据.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">export async function GET() &#123;</span><br><span class="line">  const res = await fetch(&#x27;https://data.mongodb-api.com/...&#x27;, &#123;</span><br><span class="line">    next: &#123; revalidate: 60 &#125;, // Revalidate every 60 seconds</span><br><span class="line">  &#125;)</span><br><span class="line">  const data = await res.json()</span><br><span class="line"> </span><br><span class="line">  return Response.json(data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>page,layout和route handler有个<code>dynamic</code>属性,控制静态和动态的渲染和缓存.</p><p>默认为<code>auto</code>表示尽可能地缓存,<code>force-dynamic</code>表示强制动态渲染,使得每此渲染在每次请求的时候渲染.<code>error</code>如果每个组件使用了动态函数或者没有缓存的数据基会报错.</p><p><code>force-static</code>强制静态渲染并且缓存数据,cookies和headers等返回空值.</p><p>动态函数包括cookies和headers.</p><p>动态路由也可以处理请求的参数.</p><h4 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h4><blockquote><p>Middleware允许在请求完成之前运行代码。然后，根据传入的请求，您可以通<strong>过重写、重定向、修改请求或响应标头或直接响应</strong>来修改响应。</p></blockquote><p>在根目录使用<code>middleware.ts</code>进行对请求的拦截相应.</p><p><img data-src="https://s2.loli.net/2024/02/07/z9TjK2Om3EcICDY.png" alt="image-20240207234054276"></p><h3 id="Data-Fetching"><a href="#Data-Fetching" class="headerlink" title="Data Fetching"></a>Data Fetching</h3><p>由于引入了SSR等,数据获取也有了变化.分为在server上和在client上.</p><h4 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h4><p>在Next.js服务端中,fetch可以配置缓存和重验证.</p><p>在客户端中可以调用route handler获取数据,也可以使用React Query等第三方库.</p><h4 id="Server-Actions和Mutations"><a href="#Server-Actions和Mutations" class="headerlink" title="Server Actions和Mutations"></a>Server Actions和Mutations</h4><p>Server Actions是在服务上的异步函数,既可以在服务和客户端的组件来处理提交和和数据改变.</p><p>对于服务端组件,将”use server”放在一个异步函数的最顶部.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// Server Component</span><br><span class="line">export default function Page() &#123;</span><br><span class="line">  // Server Action</span><br><span class="line">  async function create() &#123;</span><br><span class="line">    &#x27;use server&#x27;</span><br><span class="line"> </span><br><span class="line">    // ...</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  return (</span><br><span class="line">    // ...</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于客户端组件,将”use server”放在客户端组件最顶部.</p><h3 id="Nuxt"><a href="#Nuxt" class="headerlink" title="Nuxt"></a>Nuxt</h3><p>Vue的SSR框架,Nuxt默认使用Vite构建工具.官方文档将它的和核心概念分为以下几个部分</p><p><img data-src="https://s2.loli.net/2024/02/06/iU72dluEKhtOkI9.png" alt="image-20240206000905397"></p><p>总体看来跟Next差别不大,具体的可以查看<a href="https://nuxt.com/docs/getting-started/introduction">Introduction · Get Started with Nuxt</a>.</p><h3 id="SvelteKit"><a href="#SvelteKit" class="headerlink" title="SvelteKit"></a>SvelteKit</h3><p>SvelteKit默认使用Vite构建,推荐使用SvelteKit创建一个svelte项目</p><blockquote><p>SvelteKit将处理调用Svelte编译器，将.Svelte文件转换为.js文件，这些文件创建DOM和.css文件。它还提供构建web应用程序所需的所有其他部分，如开发服务器、路由、部署以及SSR支持.</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/03/kOdja1mSY925byP.png" alt="image-20240203190856868"></p><p>值得注意的是,Svelte是的更新是基于赋值,使用数组的push等操作不会自动更新.</p><p>sveltekit类似Next也在路由,fetch数据,headers,cookies等有很多opinioned的配置.</p><h3 id="Solid"><a href="#Solid" class="headerlink" title="Solid"></a>Solid</h3><p>Solid也是使用Vite构建,使用<code>createSignal</code>来管理状态实现交互性.目前github上的star没有svelte多,因为发展成熟度还没有svelte高,但是solid目前更像一个方便的动态库,比较轻巧.</p><p>Solid的SSR支持有点特别.</p><blockquote><p>Solid有一个动态服务器端渲染解决方案，可以实现真正同构的开发体验。通过使用我们的Resource原语，可以轻松地进行异步数据请求，更重要的是，可以在客户端和浏览器之间自动序列化和同步。</p></blockquote><p>Solid的响应式基于Signal,Memo以及Effect.</p><p>目前Solid正在开发Solid Start,目的也是提供一个较为整体的Solid生态的解决方案.</p><p><img data-src="https://s2.loli.net/2024/02/08/CwB6zkX5yPvnf4q.png" alt="image-20240208002623304"></p><p>Solid和Svelte都有很好的tutorial而且在掌握vue或者react之后再去看它们的文档也并不困难.</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>对于这一类前端框架,以后可能还会不断涌现,但是其中的生态还是很重要的,如果想要快速没有太多心智负担的开发一个较为成熟生产应用,还是推荐使用React或者Vue等较为成熟的框架或者库.此外这些框架其中的要解决的问题是一致的,解决方法也是趋同的.</p><p>响应性,组件创建,生命周期等等,此外附带路由,状态管理,数据获取操作等等都有解决方法.</p><h2 id="Astro"><a href="#Astro" class="headerlink" title="Astro"></a>Astro</h2><p>我一看到这个框架的官网介绍就觉得这个框架适合写博客.当然它很灵活,功能很强大.</p><p>Astro本身并不与React和Vue冲突,所以一起用并没问题.<a href="https://docs.astro.build/zh-cn/guides/integrations-guide/">使用集成 | Docs (astro.build)</a></p><h2 id="Typescript"><a href="#Typescript" class="headerlink" title="Typescript"></a>Typescript</h2><p>现在流行用ts代替js了,所以还是学习一下.其实并不是很难.</p><h2 id="Bun-Deno"><a href="#Bun-Deno" class="headerlink" title="Bun?Deno?"></a>Bun?Deno?</h2><p>node之后的运行时.Deno现在没声了,可以考虑用用Bun.</p><blockquote><p>开发、测试、运行和捆绑JavaScript&amp;TypeScript项目——所有这些都使用Bun。Bun是一个一体化的JavaScript运行时和工具包，专为速度而设计，配有bundler、测试运行程序和Node.js兼容的包管理器。</p></blockquote><h2 id="htmlx"><a href="#htmlx" class="headerlink" title="htmlx??"></a>htmlx??</h2><p>最近比较火,但其实本身就是使用html的语法增加了一些原本用js才能实现的比如传文件、发送请求的功能.</p><p>但我总感觉定制化能力有点弱,可能本身也是为了快速开发一些web工具用的.</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>有很多技术我并没有提到,比如还有前端框架Angular以及WASM<a href="https://developer.mozilla.org/zh-CN/docs/WebAssembly">WebAssembly | MDN (mozilla.org)</a>,Qwik等等,因为我现实中并没有过多使用它们,还是让子弹飞一会吧.</p><p>一些前端框架的黑盒有点多,对于初学者还是要多多学习基础,学习框架时建议从简单入手,慢慢深入,毕竟很多框架的一些功能其实平常可能用不上.我推荐在掌握React,Next之后可以往Svelte或者Solid框架学习.因为Vue从一些概念上我觉得并没有与React太大的差异,主要是生态上差别,Vue的官方给的工具链已经比较齐全了,而React的生态可以说比较多样化,但也会导致在选择工具上的犹豫和困难.</p><p>Solid目前正在开发Solid Start框架,预计应该是类似于SvelteKit之于Svelte,期待后续发展.</p><p>而Astro这类框架用于个人博客等等还是很不错的.最后推荐几位Youtube上的前端博主,<a href="https://www.youtube.com/@WebDevSimplified">Web Dev Simplified - YouTube</a>,<a href="https://www.youtube.com/@TraversyMedia">Traversy Media - YouTube</a>,<a href="https://www.youtube.com/@Fireship">Fireship - YouTube</a>以及<a href="https://www.youtube.com/@freecodecamp">freeCodeCamp.org - YouTube</a>.当然不只是前端以及一些技术趋势.</p><h2 id="可以观看的一些视频和文章"><a href="#可以观看的一些视频和文章" class="headerlink" title="可以观看的一些视频和文章"></a>可以观看的一些视频和文章</h2><ol><li><a href="https://www.youtube.com/watch?v=Gc4Xh8u19NU">YouTube</a></li><li><a href="https://www.youtube.com/watch?v=9He4UBLyk8Y&amp;list=PLWKjhJtqVAbmMuZ3saqRIBimAKIMYkt0E&amp;ab_channel=freeCodeCamp.org">Front End Developer Roadmap 2024 - YouTube</a></li><li><a href="https://www.youtube.com/watch?v=8sXRyHI3bLw&amp;ab_channel=TraversyMedia">Web Development In 2024 - A Practical Guide (youtube.com)</a></li><li><a href="https://risingstars.js.org/2023/en">2023 JavaScript Rising Stars</a></li><li><a href="https://www.satellytes.com/blog/post/getting-started-gatsby-next-remix/">Getting Started: Gatsby vs. Next.js vs. Remix | Satellytes</a></li><li><a href="https://clonecoding.com/zh-cn/next-js-三种渲染方式-ssr-csr-ssg-优缺点分析/">[Next.js] 三种渲染方式 - SSR、CSR、SSG：优缺点分析 - CloneCoding</a></li><li><a href="https://juejin.cn/post/7145669817428049957">后起之秀svelte和solid是否值得花时间学习？ - 掘金 (juejin.cn)</a></li><li><a href="https://www.jdon.com/59675.html">比较前端框架ReactJs、SolidJS、Svelte和Lit底层逻辑 - Smashing - 极道 (jdon.com)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;马上又要到农历新年了,趁现在回顾一下过去一年的前端发展.当然是站在我的角度,因为有许多新的技术,对于不同领域的人以及不同层面的开发者都有不同的意味.&lt;br&gt;对于我来说,快捷、轻松的开发体验是比较重要的,臃肿的大型框架并不是优秀的代名词,所以我会尽量使用或者倾向喜欢一些生态发展好,开发者使用体验好,社区也比较活跃的框架或者技术.此外,随着事件发展肯定会不断涌现一些新型技术甚至新的思想,对于学习者来说,这些东西还需要一些观望.&lt;br&gt;</summary>
    
    
    
    
    <category term="front end" scheme="https://www.sekyoro.top/tags/front-end/"/>
    
  </entry>
  
  <entry>
    <title>协同融合代码学习</title>
    <link href="https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-01-31T11:15:43.000Z</published>
    <updated>2024-03-05T03:00:19.052Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>代码还是很重要的,虽然发现有些代码库不怎么样.<br><span id="more"></span></p><p>目前协同感知算法主要就是利用注意力机制和图神经网络,利用backbone(包括voxelNet,Point Pillar等网络)处理后的特征进行融合,具体的codebase我找到三个(此外还有很多基于OpenCOOD的多模态、关注其他问题的代码,这里就放一些基础的).</p><ul><li>一个是<a href="https://github.com/coperception/where2comm?tab=readme-ov-file">coperception/where2comm: [NeurIPS 2022] Where2comm (github.com)</a>,</li><li>还有<a href="https://github.com/GT-RIPL/MultiAgentPerception">GT-RIPL/MultiAgentPerception: Official source code to CVPR’20 paper, “When2com: Multi-Agent Perception via Communication Graph Grouping” (github.com)</a>.</li><li>另一个是<a href="https://github.com/DerrickXuNu/OpenCOOD">DerrickXuNu/OpenCOOD: [ICRA 2022] An opensource framework for cooperative detection. Official implementation for OPV2V. (github.com)</a>.可以说包含许多20年到现在的经典车辆协同感知的算法代码了,此外还有一些零散的算法代码,这里咱就细细把玩一下.</li></ul><h2 id="Coperceptions"><a href="#Coperceptions" class="headerlink" title="Coperceptions"></a>Coperceptions</h2><p>包括where2comm,v2vnet,disconet,v2x-vit以及when2comm的代码.</p><p><img data-src="https://github.com/coperception/where2comm/raw/gh-pages/static/images/Intro.png" alt="Where2comm"></p><p>本身有mean,max,cat以及agent的融合方式.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>继承自FusionBase,而<code>FusionBase</code>又继承自<code>SegModelBase</code>,后者实现了一系列模型.在<code>FusionBase</code>中,首先对特征进行下采样,然后转换除了ego agent的特征,然后进行融合,最后再上采样.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> coperception.models.seg.SegModelBase <span class="keyword">import</span> SegModelBase</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FusionBase</span>(<span class="params">SegModelBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, n_channels, n_classes, num_agent=<span class="number">5</span>, kd_flag=<span class="literal">False</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line">        self.neighbor_feat_list = <span class="literal">None</span></span><br><span class="line">        self.tg_agent = <span class="literal">None</span></span><br><span class="line">        self.current_num_agent = <span class="literal">None</span></span><br><span class="line">        self.kd_flag = kd_flag</span><br><span class="line">        self.only_v2i = only_v2i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(</span><br><span class="line">            <span class="string">&quot;Please implement this method for specific fusion strategies&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, trans_matrices, num_agent_tensor</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)  <span class="comment"># b 512 32 32</span></span><br><span class="line">        size = (<span class="number">1</span>, <span class="number">512</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.compress_level &gt; <span class="number">0</span>:</span><br><span class="line">            x4 = F.relu(self.bn_compress(self.com_compresser(x4)))</span><br><span class="line">            x4 = F.relu(self.bn_decompress(self.com_decompresser(x4)))</span><br><span class="line"></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>) // self.num_agent</span><br><span class="line">        feat_list = <span class="built_in">super</span>().build_feat_list(x4, batch_size)</span><br><span class="line"></span><br><span class="line">        local_com_mat = torch.cat(<span class="built_in">tuple</span>(feat_list), <span class="number">1</span>)</span><br><span class="line">        local_com_mat_update = torch.cat(<span class="built_in">tuple</span>(feat_list), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            self.com_num_agent = num_agent_tensor[b, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            agent_feat_list = <span class="built_in">list</span>()</span><br><span class="line">            <span class="keyword">for</span> nb <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">                agent_feat_list.append(local_com_mat[b, nb])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">                self.tg_agent = local_com_mat[b, i]</span><br><span class="line"></span><br><span class="line">                self.neighbor_feat_list = <span class="built_in">list</span>()</span><br><span class="line">                self.neighbor_feat_list.append(self.tg_agent)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">                    <span class="keyword">if</span> j != i:</span><br><span class="line">                        <span class="keyword">if</span> self.only_v2i <span class="keyword">and</span> i != <span class="number">0</span> <span class="keyword">and</span> j != <span class="number">0</span>:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                        self.neighbor_feat_list.append(</span><br><span class="line">                            <span class="built_in">super</span>().feature_transformation(</span><br><span class="line">                                b,</span><br><span class="line">                                j,</span><br><span class="line">                                i,</span><br><span class="line">                                local_com_mat,</span><br><span class="line">                                size,</span><br><span class="line">                                trans_matrices,</span><br><span class="line">                            )</span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">                local_com_mat_update[b, i] = self.fusion()</span><br><span class="line"></span><br><span class="line">        feat_mat = <span class="built_in">super</span>().agents_to_batch(local_com_mat_update)</span><br><span class="line"></span><br><span class="line">        x5 = self.down4(feat_mat)</span><br><span class="line">        x6 = self.up1(x5, feat_mat)</span><br><span class="line">        x7 = self.up2(x6, x3)</span><br><span class="line">        x8 = self.up3(x7, x2)</span><br><span class="line">        x9 = self.up4(x8, x1)</span><br><span class="line">        logits = self.outc(x9)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.kd_flag:</span><br><span class="line">            <span class="keyword">return</span> logits, x9, x8, x7, x6, x5, feat_mat</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure><p>使用了连续的下采样和上采样,先下采样,然后进行融合再进行上采样.这几种融合方式真是一层套一层,这么多参数效果不变强才怪…</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SegModelBase</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, n_channels, n_classes, bilinear=<span class="literal">True</span>, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line">        self.num_agent = num_agent</span><br><span class="line">        self.only_v2i = only_v2i</span><br><span class="line"></span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span> // factor)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">        self.compress_level = compress_level</span><br><span class="line">        <span class="keyword">if</span> compress_level &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">assert</span> compress_level &lt;= <span class="number">9</span></span><br><span class="line">            feat_map_channel_num = <span class="number">512</span></span><br><span class="line">            compress_channel_num = feat_map_channel_num // (<span class="number">2</span>**compress_level)</span><br><span class="line"></span><br><span class="line">            self.com_compresser = nn.Conv2d(</span><br><span class="line">                feat_map_channel_num, compress_channel_num, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            self.bn_compress = nn.BatchNorm2d(compress_channel_num)</span><br><span class="line"></span><br><span class="line">            self.com_decompresser = nn.Conv2d(</span><br><span class="line">                compress_channel_num, feat_map_channel_num, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            self.bn_decompress = nn.BatchNorm2d(feat_map_channel_num)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_feat_list</span>(<span class="params">self, feat_maps, batch_size</span>):</span></span><br><span class="line">        feat_maps = torch.flip(feat_maps, (<span class="number">2</span>,))</span><br><span class="line"></span><br><span class="line">        tmp_feat_map = &#123;&#125;</span><br><span class="line">        feat_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_agent):</span><br><span class="line">            tmp_feat_map[i] = torch.unsqueeze(</span><br><span class="line">                feat_maps[batch_size * i : batch_size * (i + <span class="number">1</span>)], <span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">            feat_list.append(tmp_feat_map[i])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_list</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feature_transformation</span>(<span class="params">b, j, agent_idx, local_com_mat, size, trans_matrices</span>):</span></span><br><span class="line">        device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        nb_agent = torch.unsqueeze(local_com_mat[b, j], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        tfm_ji = trans_matrices[b, j, agent_idx]</span><br><span class="line">        M = (</span><br><span class="line">            torch.hstack((tfm_ji[:<span class="number">2</span>, :<span class="number">2</span>], -tfm_ji[:<span class="number">2</span>, <span class="number">3</span>:<span class="number">4</span>])).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>)</span><br><span class="line">        )  <span class="comment"># [1,2,3]</span></span><br><span class="line">        M = M.to(device)</span><br><span class="line"></span><br><span class="line">        mask = torch.tensor([[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span> / <span class="number">128</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span> / <span class="number">128</span>]]], device=M.device)</span><br><span class="line"></span><br><span class="line">        M *= mask</span><br><span class="line"></span><br><span class="line">        grid = F.affine_grid(M, size=torch.Size(size))</span><br><span class="line">        warp_feat = F.grid_sample(nb_agent, grid).squeeze()</span><br><span class="line">        <span class="keyword">return</span> warp_feat</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">agents_to_batch</span>(<span class="params">self, feats</span>):</span></span><br><span class="line">        feat_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_agent):</span><br><span class="line">            feat_list.append(feats[:, i, :, :, :])</span><br><span class="line">        feat_mat = torch.cat(feat_list, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        feat_mat = torch.flip(feat_mat, (<span class="number">2</span>,))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_mat</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, mid_channels=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mid_channels:</span><br><span class="line">            mid_channels = out_channels</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, mid_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(mid_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(mid_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> bilinear:</span><br><span class="line">            self.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&quot;bilinear&quot;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels, in_channels // <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.up = nn.ConvTranspose2d(</span><br><span class="line">                in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span></span><br><span class="line">            )</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        diff_y = x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]</span><br><span class="line">        diff_x = x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x1 = F.pad(</span><br><span class="line">            x1, [diff_x // <span class="number">2</span>, diff_x - diff_x // <span class="number">2</span>, diff_y // <span class="number">2</span>, diff_y - diff_y // <span class="number">2</span>]</span><br><span class="line">        )</span><br><span class="line">        x = torch.cat([x2, x1], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><p>mean,max和sum不用多说,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> coperception.models.seg.FusionBase <span class="keyword">import</span> FusionBase</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SumFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaxFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">max</span>(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>).values</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>catFusion将其他特征做个mean然后与自己的特征连接起来.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent, compress_level, only_v2i</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line">        self.modulation_layer_3 = ModulationLayer3()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        mean_feat = torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class="number">0</span>)  <span class="comment"># [c, h, w]</span></span><br><span class="line">        cat_feat = torch.cat([self.tg_agent, mean_feat], dim=<span class="number">0</span>)</span><br><span class="line">        cat_feat = cat_feat.unsqueeze(<span class="number">0</span>)  <span class="comment"># [1, 1, c, h, w]</span></span><br><span class="line">        <span class="keyword">return</span> self.modulation_layer_3(cat_feat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">FIXME:</span> Change size</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModulationLayer3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ModulationLayer3, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1_1 = nn.Conv2d(<span class="number">1024</span>, <span class="number">512</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.bn1_1 = nn.BatchNorm2d(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, x.size(-<span class="number">3</span>), x.size(-<span class="number">2</span>), x.size(-<span class="number">1</span>))</span><br><span class="line">        x_1 = F.relu(self.bn1_1(self.conv1_1(x)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x_1</span><br></pre></td></tr></table></figure><p>此外还有个<code>AgentWiseWeightedFusion</code>,每个ego_agent单独和每个其他特征cat在一起再通过,然后计算一个融合特征,再计算一个softmax作为特征的权重.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AgentWiseWeightedFusion</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, num_agent=<span class="number">5</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class="line">        )</span><br><span class="line">        self.agent_weighted_fusion = AgentWeightedFusion()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        agent_weight_list = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">            cat_feat = torch.cat([self.tg_agent, self.neighbor_feat_list[k]], dim=<span class="number">0</span>)</span><br><span class="line">            cat_feat = cat_feat.unsqueeze(<span class="number">0</span>)</span><br><span class="line">            agent_weight = self.agent_weighted_fusion(cat_feat)</span><br><span class="line">            agent_weight_list.append(agent_weight)</span><br><span class="line"></span><br><span class="line">        soft_agent_weight_list = torch.squeeze(</span><br><span class="line">            F.softmax(torch.tensor(agent_weight_list).unsqueeze(<span class="number">0</span>), dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        agent_wise_weight_feat = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(self.com_num_agent):</span><br><span class="line">            agent_wise_weight_feat = (</span><br><span class="line">                agent_wise_weight_feat</span><br><span class="line">                + soft_agent_weight_list[k] * self.neighbor_feat_list[k]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> agent_wise_weight_feat</span><br></pre></td></tr></table></figure><p>discoNet特别之处就在于使用了所谓学生-教师模型进行知识蒸馏,在代码中添加了这个.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--kd_flag&quot;</span>,</span><br><span class="line">    default=<span class="number">0</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;Whether to enable distillation (only DiscNet is 1 )&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 还添加了权重参数,可见权重加得还挺大的.</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--kd_weight&quot;</span>, default=<span class="number">100000</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;KD loss weight&quot;</span>)</span><br></pre></td></tr></table></figure><p>然后类似<code>AgentWiseWeightedFusion</code>,将ego的特征与通信的单独每辆车的特征cat在一起传入一个网络中,计算得到所有值的幂和.然后再用各自的值乘以和(跟softmax差不多).算按出来权重再乘以对应的特征.最后的值是相加起来</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiscoNet</span>(<span class="params">FusionBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, n_channels, n_classes, num_agent, kd_flag=<span class="literal">True</span>, compress_level=<span class="number">0</span>, only_v2i=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            n_channels,</span><br><span class="line">            n_classes,</span><br><span class="line">            num_agent,</span><br><span class="line">            kd_flag=kd_flag,</span><br><span class="line">            compress_level=compress_level,</span><br><span class="line">            only_v2i=only_v2i,</span><br><span class="line">        )</span><br><span class="line">        self.pixel_weighted_fusion = PixelWeightedFusionSoftmax(<span class="number">512</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fusion</span>(<span class="params">self</span>):</span></span><br><span class="line">        tmp_agent_weight_list = <span class="built_in">list</span>()</span><br><span class="line">        sum_weight = <span class="number">0</span></span><br><span class="line">        nb_len = <span class="built_in">len</span>(self.neighbor_feat_list)</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nb_len):</span><br><span class="line">            cat_feat = torch.cat([self.tg_agent, self.neighbor_feat_list[k]], dim=<span class="number">0</span>)</span><br><span class="line">            cat_feat = cat_feat.unsqueeze(<span class="number">0</span>)</span><br><span class="line">            agent_weight = torch.squeeze(self.pixel_weighted_fusion(cat_feat))</span><br><span class="line">            tmp_agent_weight_list.append(torch.exp(agent_weight))</span><br><span class="line">            sum_weight = sum_weight + torch.exp(agent_weight)</span><br><span class="line"></span><br><span class="line">        agent_weight_list = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nb_len):</span><br><span class="line">            agent_weight = torch.div(tmp_agent_weight_list[k], sum_weight)</span><br><span class="line">            agent_weight.expand([<span class="number">256</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">            agent_weight_list.append(agent_weight)</span><br><span class="line"></span><br><span class="line">        agent_wise_weight_feat = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nb_len):</span><br><span class="line">            agent_wise_weight_feat = (</span><br><span class="line">                agent_wise_weight_feat</span><br><span class="line">                + agent_weight_list[k] * self.neighbor_feat_list[k]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> agent_wise_weight_feat</span><br></pre></td></tr></table></figure><h3 id="V2VNet"><a href="#V2VNet" class="headerlink" title="V2VNet"></a>V2VNet</h3><p><img data-src="https://s2.loli.net/2024/02/13/LK8F15wDS6jdkPJ.png" alt="image-20240213170444226"></p><p>说实话,看了代码感觉也就那样…</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author: Hao Xiang &lt;haxiang@g.ucla.edu&gt;</span></span><br><span class="line"><span class="comment"># License: TDG-Attribution-NonCommercial-NoDistrib</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Implementation of V2VNet Fusion</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> opencood.models.sub_modules.torch_transformation_utils <span class="keyword">import</span> \</span><br><span class="line">    get_discretized_transformation_matrix, get_transformation_matrix, \</span><br><span class="line">    warp_affine, get_rotated_roi</span><br><span class="line"><span class="keyword">from</span> opencood.models.sub_modules.convgru <span class="keyword">import</span> ConvGRU</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">V2VNetFusion</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, args</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(V2VNetFusion, self).__init__()</span><br><span class="line">        </span><br><span class="line">        in_channels = args[<span class="string">&#x27;in_channels&#x27;</span>]</span><br><span class="line">        H, W = args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;H&#x27;</span>], args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;W&#x27;</span>]</span><br><span class="line">        kernel_size = args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;kernel_size&#x27;</span>]</span><br><span class="line">        num_gru_layers = args[<span class="string">&#x27;conv_gru&#x27;</span>][<span class="string">&#x27;num_layers&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.discrete_ratio = args[<span class="string">&#x27;voxel_size&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">        self.downsample_rate = args[<span class="string">&#x27;downsample_rate&#x27;</span>]</span><br><span class="line">        self.num_iteration = args[<span class="string">&#x27;num_iteration&#x27;</span>]</span><br><span class="line">        self.gru_flag = args[<span class="string">&#x27;gru_flag&#x27;</span>]</span><br><span class="line">        self.agg_operator = args[<span class="string">&#x27;agg_operator&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.msg_cnn = nn.Conv2d(in_channels * <span class="number">2</span>, in_channels, kernel_size=<span class="number">3</span>,</span><br><span class="line">                                 stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv_gru = ConvGRU(input_size=(H, W),</span><br><span class="line">                                input_dim=in_channels * <span class="number">2</span>,</span><br><span class="line">                                hidden_dim=[in_channels],</span><br><span class="line">                                kernel_size=kernel_size,</span><br><span class="line">                                num_layers=num_gru_layers,</span><br><span class="line">                                batch_first=<span class="literal">True</span>,</span><br><span class="line">                                bias=<span class="literal">True</span>,</span><br><span class="line">                                return_all_layers=<span class="literal">False</span>)</span><br><span class="line">        self.mlp = nn.Linear(in_channels, in_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">regroup</span>(<span class="params">self, x, record_len</span>):</span></span><br><span class="line">        cum_sum_len = torch.cumsum(record_len, dim=<span class="number">0</span>)</span><br><span class="line">        split_x = torch.tensor_split(x, cum_sum_len[:-<span class="number">1</span>].cpu())</span><br><span class="line">        <span class="keyword">return</span> split_x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, record_len, pairwise_t_matrix</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fusion forwarding.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        x : torch.Tensor</span></span><br><span class="line"><span class="string">            input data, (B, C, H, W)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        record_len : list</span></span><br><span class="line"><span class="string">            shape: (B)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        pairwise_t_matrix : torch.Tensor</span></span><br><span class="line"><span class="string">            The transformation matrix from each cav to ego, </span></span><br><span class="line"><span class="string">            shape: (B, L, L, 4, 4) </span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        Fused feature.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        _, C, H, W = x.shape</span><br><span class="line">        B, L = pairwise_t_matrix.shape[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># split x:[(L1, C, H, W), (L2, C, H, W)]</span></span><br><span class="line">        split_x = self.regroup(x, record_len)</span><br><span class="line">        <span class="comment"># (B,L,L,2,3)</span></span><br><span class="line">        pairwise_t_matrix = get_discretized_transformation_matrix(</span><br><span class="line">            pairwise_t_matrix.reshape(-<span class="number">1</span>, L, <span class="number">4</span>, <span class="number">4</span>), self.discrete_ratio,</span><br><span class="line">            self.downsample_rate).reshape(B, L, L, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># (B*L,L,1,H,W)</span></span><br><span class="line">        roi_mask = get_rotated_roi((B * L, L, <span class="number">1</span>, H, W),</span><br><span class="line">                                   pairwise_t_matrix.reshape(B * L * L, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        roi_mask = roi_mask.reshape(B, L, L, <span class="number">1</span>, H, W)</span><br><span class="line">        batch_node_features = split_x</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># iteratively update the features for num_iteration times</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(self.num_iteration):</span><br><span class="line"></span><br><span class="line">            batch_updated_node_features = []</span><br><span class="line">            <span class="comment"># iterate each batch</span></span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(B):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># number of valid agent</span></span><br><span class="line">                N = record_len[b]</span><br><span class="line">                <span class="comment"># (N,N,4,4)</span></span><br><span class="line">                <span class="comment"># t_matrix[i, j]-&gt; from i to j</span></span><br><span class="line">                t_matrix = pairwise_t_matrix[b][:N, :N, :, :]</span><br><span class="line">                updated_node_features = []</span><br><span class="line">                <span class="comment"># update each node i</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">                    <span class="comment"># (N,1,H,W)</span></span><br><span class="line">                    mask = roi_mask[b, :N, i, ...]</span><br><span class="line"></span><br><span class="line">                    current_t_matrix = t_matrix[:, i, :, :]</span><br><span class="line">                    current_t_matrix = get_transformation_matrix(</span><br><span class="line">                        current_t_matrix, (H, W))</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                    neighbor_feature = warp_affine(batch_node_features[b],</span><br><span class="line">                                                   current_t_matrix,</span><br><span class="line">                                                   (H, W))</span><br><span class="line">                    <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                    ego_agent_feature = batch_node_features[b][i].unsqueeze(</span><br><span class="line">                        <span class="number">0</span>).repeat(N, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                    <span class="comment">#(N,2C,H,W)</span></span><br><span class="line">                    neighbor_feature = torch.cat(</span><br><span class="line">                        [neighbor_feature, ego_agent_feature], dim=<span class="number">1</span>)</span><br><span class="line">                    <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                    message = self.msg_cnn(neighbor_feature) * mask</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># (C,H,W)</span></span><br><span class="line">                    <span class="keyword">if</span> self.agg_operator==<span class="string">&quot;avg&quot;</span>:</span><br><span class="line">                        agg_feature = torch.mean(message, dim=<span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">elif</span> self.agg_operator==<span class="string">&quot;max&quot;</span>:</span><br><span class="line">                        agg_feature = torch.<span class="built_in">max</span>(message, dim=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">raise</span> ValueError(<span class="string">&quot;agg_operator has wrong value&quot;</span>)</span><br><span class="line">                    <span class="comment"># (2C, H, W)</span></span><br><span class="line">                    cat_feature = torch.cat(</span><br><span class="line">                        [batch_node_features[b][i, ...], agg_feature], dim=<span class="number">0</span>)</span><br><span class="line">                    <span class="comment"># (C,H,W)</span></span><br><span class="line">                    <span class="keyword">if</span> self.gru_flag:</span><br><span class="line">                        gru_out = \</span><br><span class="line">                            self.conv_gru(cat_feature.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>))[</span><br><span class="line">                                <span class="number">0</span>][</span><br><span class="line">                                <span class="number">0</span>].squeeze(<span class="number">0</span>).squeeze(<span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        gru_out = batch_node_features[b][i, ...] + agg_feature</span><br><span class="line">                    updated_node_features.append(gru_out.unsqueeze(<span class="number">0</span>))</span><br><span class="line">                <span class="comment"># (N,C,H,W)</span></span><br><span class="line">                batch_updated_node_features.append(</span><br><span class="line">                    torch.cat(updated_node_features, dim=<span class="number">0</span>))</span><br><span class="line">            batch_node_features = batch_updated_node_features</span><br><span class="line">        <span class="comment"># (B,C,H,W)</span></span><br><span class="line">        out = torch.cat(</span><br><span class="line">            [itm[<span class="number">0</span>, ...].unsqueeze(<span class="number">0</span>) <span class="keyword">for</span> itm <span class="keyword">in</span> batch_node_features], dim=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># (B,C,H,W)</span></span><br><span class="line">        out = self.mlp(out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>有的实现没有RNN比如上面代码,也有的用了RNN和LSTM.后者代码代码简直就是屎…</p><h3 id="V2xvit"><a href="#V2xvit" class="headerlink" title="V2xvit"></a>V2xvit</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> v2xvit.models.sub_modules.base_transformer <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> v2xvit.models.sub_modules.hmsa <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> v2xvit.models.sub_modules.mswin <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> v2xvit.models.sub_modules.torch_transformation_utils <span class="keyword">import</span> \</span><br><span class="line">    get_transformation_matrix, warp_affine, get_roi_and_cav_mask, \</span><br><span class="line">    get_discretized_transformation_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">STTF</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, args</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(STTF, self).__init__()</span><br><span class="line">        self.discrete_ratio = args[<span class="string">&#x27;voxel_size&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">        self.downsample_rate = args[<span class="string">&#x27;downsample_rate&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask, spatial_correction_matrix</span>):</span></span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">        dist_correction_matrix = get_discretized_transformation_matrix(</span><br><span class="line">            spatial_correction_matrix, self.discrete_ratio,</span><br><span class="line">            self.downsample_rate)</span><br><span class="line">        <span class="comment"># Only compensate non-ego vehicles</span></span><br><span class="line">        B, L, C, H, W = x.shape</span><br><span class="line"></span><br><span class="line">        T = get_transformation_matrix(</span><br><span class="line">            dist_correction_matrix[:, <span class="number">1</span>:, :, :].reshape(-<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (H, W))</span><br><span class="line">        cav_features = warp_affine(x[:, <span class="number">1</span>:, :, :, :].reshape(-<span class="number">1</span>, C, H, W), T,</span><br><span class="line">                                   (H, W))</span><br><span class="line">        cav_features = cav_features.reshape(B, -<span class="number">1</span>, C, H, W)</span><br><span class="line">        x = torch.cat([x[:, <span class="number">0</span>, :, :, :].unsqueeze(<span class="number">1</span>), cav_features], dim=<span class="number">1</span>)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RelTemporalEncoding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implement the Temporal Encoding (Sinusoid) function.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_hid, RTE_ratio, max_len=<span class="number">100</span>, dropout=<span class="number">0.2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RelTemporalEncoding, self).__init__()</span><br><span class="line">        position = torch.arange(<span class="number">0.</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, n_hid, <span class="number">2</span>) *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / n_hid))</span><br><span class="line">        emb = nn.Embedding(max_len, n_hid)</span><br><span class="line">        emb.weight.data[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term) / math.sqrt(</span><br><span class="line">            n_hid)</span><br><span class="line">        emb.weight.data[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term) / math.sqrt(</span><br><span class="line">            n_hid)</span><br><span class="line">        emb.requires_grad = <span class="literal">False</span></span><br><span class="line">        self.RTE_ratio = RTE_ratio</span><br><span class="line">        self.emb = emb</span><br><span class="line">        self.lin = nn.Linear(n_hid, n_hid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        <span class="comment"># When t has unit of 50ms, rte_ratio=1.</span></span><br><span class="line">        <span class="comment"># So we can train on 100ms but test on 50ms</span></span><br><span class="line">        <span class="keyword">return</span> x + self.lin(self.emb(t * self.RTE_ratio)).unsqueeze(</span><br><span class="line">            <span class="number">0</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RTE</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, RTE_ratio=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RTE, self).__init__()</span><br><span class="line">        self.RTE_ratio = RTE_ratio</span><br><span class="line"></span><br><span class="line">        self.emb = RelTemporalEncoding(dim, RTE_ratio=self.RTE_ratio)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, dts</span>):</span></span><br><span class="line">        <span class="comment"># x: (B,L,H,W,C)</span></span><br><span class="line">        <span class="comment"># dts: (B,L)</span></span><br><span class="line">        rte_batch = []</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">0</span>]):</span><br><span class="line">            rte_list = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">                rte_list.append(</span><br><span class="line">                    self.emb(x[b, i, :, :, :], dts[b, i]).unsqueeze(<span class="number">0</span>))</span><br><span class="line">            rte_batch.append(torch.cat(rte_list, dim=<span class="number">0</span>).unsqueeze(<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> torch.cat(rte_batch, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">V2XFusionBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_blocks, cav_att_config, pwindow_config</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># first multi-agent attention and then multi-window attention</span></span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        self.num_blocks = num_blocks</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">            att = HGTCavAttention(cav_att_config[<span class="string">&#x27;dim&#x27;</span>],</span><br><span class="line">                                  heads=cav_att_config[<span class="string">&#x27;heads&#x27;</span>],</span><br><span class="line">                                  dim_head=cav_att_config[<span class="string">&#x27;dim_head&#x27;</span>],</span><br><span class="line">                                  dropout=cav_att_config[<span class="string">&#x27;dropout&#x27;</span>]) <span class="keyword">if</span> \</span><br><span class="line">                cav_att_config[<span class="string">&#x27;use_hetero&#x27;</span>] <span class="keyword">else</span> \</span><br><span class="line">                CavAttention(cav_att_config[<span class="string">&#x27;dim&#x27;</span>],</span><br><span class="line">                             heads=cav_att_config[<span class="string">&#x27;heads&#x27;</span>],</span><br><span class="line">                             dim_head=cav_att_config[<span class="string">&#x27;dim_head&#x27;</span>],</span><br><span class="line">                             dropout=cav_att_config[<span class="string">&#x27;dropout&#x27;</span>])</span><br><span class="line">            self.layers.append(nn.ModuleList([</span><br><span class="line">                PreNorm(cav_att_config[<span class="string">&#x27;dim&#x27;</span>], att),</span><br><span class="line">                PreNorm(cav_att_config[<span class="string">&#x27;dim&#x27;</span>],</span><br><span class="line">                        PyramidWindowAttention(pwindow_config[<span class="string">&#x27;dim&#x27;</span>],</span><br><span class="line">                                               heads=pwindow_config[<span class="string">&#x27;heads&#x27;</span>],</span><br><span class="line">                                               dim_heads=pwindow_config[</span><br><span class="line">                                                   <span class="string">&#x27;dim_head&#x27;</span>],</span><br><span class="line">                                               drop_out=pwindow_config[</span><br><span class="line">                                                   <span class="string">&#x27;dropout&#x27;</span>],</span><br><span class="line">                                               window_size=pwindow_config[</span><br><span class="line">                                                   <span class="string">&#x27;window_size&#x27;</span>],</span><br><span class="line">                                               relative_pos_embedding=</span><br><span class="line">                                               pwindow_config[</span><br><span class="line">                                                   <span class="string">&#x27;relative_pos_embedding&#x27;</span>],</span><br><span class="line">                                               fuse_method=pwindow_config[</span><br><span class="line">                                                   <span class="string">&#x27;fusion_method&#x27;</span>]))]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask, prior_encoding</span>):</span></span><br><span class="line">        <span class="keyword">for</span> cav_attn, pwindow_attn <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = cav_attn(x, mask=mask, prior_encoding=prior_encoding) + x</span><br><span class="line">            x = pwindow_attn(x) + x</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">V2XTEncoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, args</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        cav_att_config = args[<span class="string">&#x27;cav_att_config&#x27;</span>]</span><br><span class="line">        pwindow_att_config = args[<span class="string">&#x27;pwindow_att_config&#x27;</span>]</span><br><span class="line">        feed_config = args[<span class="string">&#x27;feed_forward&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        num_blocks = args[<span class="string">&#x27;num_blocks&#x27;</span>]</span><br><span class="line">        depth = args[<span class="string">&#x27;depth&#x27;</span>]</span><br><span class="line">        mlp_dim = feed_config[<span class="string">&#x27;mlp_dim&#x27;</span>]</span><br><span class="line">        dropout = feed_config[<span class="string">&#x27;dropout&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.downsample_rate = args[<span class="string">&#x27;sttf&#x27;</span>][<span class="string">&#x27;downsample_rate&#x27;</span>]</span><br><span class="line">        self.discrete_ratio = args[<span class="string">&#x27;sttf&#x27;</span>][<span class="string">&#x27;voxel_size&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">        self.use_roi_mask = args[<span class="string">&#x27;use_roi_mask&#x27;</span>]</span><br><span class="line">        self.use_RTE = cav_att_config[<span class="string">&#x27;use_RTE&#x27;</span>]</span><br><span class="line">        self.RTE_ratio = cav_att_config[<span class="string">&#x27;RTE_ratio&#x27;</span>]</span><br><span class="line">        self.sttf = STTF(args[<span class="string">&#x27;sttf&#x27;</span>])</span><br><span class="line">        <span class="comment"># adjust the channel numbers from 256+3 -&gt; 256</span></span><br><span class="line">        self.prior_feed = nn.Linear(cav_att_config[<span class="string">&#x27;dim&#x27;</span>] + <span class="number">3</span>,</span><br><span class="line">                                    cav_att_config[<span class="string">&#x27;dim&#x27;</span>])</span><br><span class="line">        self.layers = nn.ModuleList([])</span><br><span class="line">        <span class="keyword">if</span> self.use_RTE:</span><br><span class="line">            self.rte = RTE(cav_att_config[<span class="string">&#x27;dim&#x27;</span>], self.RTE_ratio)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">            self.layers.append(nn.ModuleList([</span><br><span class="line">                V2XFusionBlock(num_blocks, cav_att_config, pwindow_att_config),</span><br><span class="line">                PreNorm(cav_att_config[<span class="string">&#x27;dim&#x27;</span>],</span><br><span class="line">                        FeedForward(cav_att_config[<span class="string">&#x27;dim&#x27;</span>], mlp_dim,</span><br><span class="line">                                    dropout=dropout))</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask, spatial_correction_matrix</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># transform the features to the current timestamp</span></span><br><span class="line">        <span class="comment"># velocity, time_delay, infra</span></span><br><span class="line">        <span class="comment"># (B,L,H,W,3)</span></span><br><span class="line">        prior_encoding = x[..., -<span class="number">3</span>:]</span><br><span class="line">        <span class="comment"># (B,L,H,W,C)</span></span><br><span class="line">        x = x[..., :-<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">if</span> self.use_RTE:</span><br><span class="line">            <span class="comment"># dt: (B,L)</span></span><br><span class="line">            dt = prior_encoding[:, :, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>].to(torch.<span class="built_in">int</span>)</span><br><span class="line">            x = self.rte(x, dt)</span><br><span class="line">        x = self.sttf(x, mask, spatial_correction_matrix)</span><br><span class="line">        com_mask = mask.unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">2</span>).unsqueeze(</span><br><span class="line">            <span class="number">3</span>) <span class="keyword">if</span> <span class="keyword">not</span> self.use_roi_mask <span class="keyword">else</span> get_roi_and_cav_mask(x.shape,</span><br><span class="line">                                                                  mask,</span><br><span class="line">                                                                  spatial_correction_matrix,</span><br><span class="line">                                                                  self.discrete_ratio,</span><br><span class="line">                                                                  self.downsample_rate)</span><br><span class="line">        <span class="keyword">for</span> attn, ff <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = attn(x, mask=com_mask, prior_encoding=prior_encoding)</span><br><span class="line">            x = ff(x) + x</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">V2XTransformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, args</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(V2XTransformer, self).__init__()</span><br><span class="line"></span><br><span class="line">        encoder_args = args[<span class="string">&#x27;encoder&#x27;</span>]</span><br><span class="line">        self.encoder = V2XTEncoder(encoder_args)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask, spatial_correction_matrix</span>):</span></span><br><span class="line">        output = self.encoder(x, mask, spatial_correction_matrix)</span><br><span class="line">        output = output[:, <span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>关键是脱离了agent2agent,而是vehicle2everything,向异构多模态发展.</p><h3 id="DiscoNet"><a href="#DiscoNet" class="headerlink" title="DiscoNet"></a>DiscoNet</h3><p>主要是利用了蒸馏,教师-学生模型这种理论.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.kd_flag == <span class="number">1</span>:</span><br><span class="line">        teacher = TeacherNet(config)</span><br><span class="line">        teacher = nn.DataParallel(teacher)</span><br><span class="line">        teacher = teacher.to(device)</span><br><span class="line">        faf_module = FaFModule(</span><br><span class="line">            model, teacher, config, optimizer, criterion, args.kd_flag</span><br><span class="line">        )</span><br><span class="line">        checkpoint_teacher = torch.load(args.resume_teacher)</span><br><span class="line">        start_epoch_teacher = checkpoint_teacher[<span class="string">&quot;epoch&quot;</span>]</span><br><span class="line">        faf_module.teacher.load_state_dict(checkpoint_teacher[<span class="string">&quot;model_state_dict&quot;</span>])</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">&quot;Load teacher model from &#123;&#125;, at epoch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                args.resume_teacher, start_epoch_teacher</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        faf_module.teacher.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><p>先使用tearcherNet拿数据进行训练,然后拿训练后的模型加载</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TeacherNet</span>(<span class="params">NonIntermediateModelBase</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The teacher net for knowledged distillation in DiscoNet.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, config</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(TeacherNet, self).__init__(config, compress_level=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, bevs, maps=<span class="literal">None</span>, vis=<span class="literal">None</span></span>):</span></span><br><span class="line">        bevs = bevs.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>)  <span class="comment"># (Batch, seq, z, h, w)</span></span><br><span class="line">        <span class="comment"># vis = vis.permute(0, 3, 1, 2)</span></span><br><span class="line">        <span class="keyword">return</span> self.stpn(bevs)</span><br></pre></td></tr></table></figure><p>使用教师模型得到的结果和原本模型得到的结果(一些中间融合层)计算损失,代码中用的KL交叉熵损失</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kd_loss</span>(<span class="params">self, batch_size, data, fused_layer, num_agent, x_5, x_6, x_7</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.kd_flag:</span><br><span class="line">        bev_seq_teacher = data[<span class="string">&quot;bev_seq_teacher&quot;</span>]</span><br><span class="line">        kd_weight = data[<span class="string">&quot;kd_weight&quot;</span>]</span><br><span class="line">        (</span><br><span class="line">            x_8_teacher,</span><br><span class="line">            x_7_teacher,</span><br><span class="line">            x_6_teacher,</span><br><span class="line">            x_5_teacher,</span><br><span class="line">            x_3_teacher,</span><br><span class="line">            x_2_teacher,</span><br><span class="line">        ) = self.teacher(bev_seq_teacher)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># for k, v in self.teacher.named_parameters():</span></span><br><span class="line">        <span class="comment"># if k != &#x27;xxx.weight&#x27; and k != &#x27;xxx.bias&#x27;:</span></span><br><span class="line">        <span class="comment"># print(v.requires_grad)  # should be False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># for k, v in self.model.named_parameters():</span></span><br><span class="line">        <span class="comment"># if k != &#x27;xxx.weight&#x27; and k != &#x27;xxx.bias&#x27;:</span></span><br><span class="line">        <span class="comment"># print(v.requires_grad)  # should be False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># -------- KD loss---------#</span></span><br><span class="line">        kl_loss_mean = nn.KLDivLoss(size_average=<span class="literal">True</span>, reduce=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># target_x8 = x_8_teacher.permute(0, 2, 3, 1).reshape(5 * batch_size * 256 * 256, -1)</span></span><br><span class="line">        <span class="comment"># student_x8 = x_8.permute(0, 2, 3, 1).reshape(5 * batch_size * 256 * 256, -1)</span></span><br><span class="line">        <span class="comment"># kd_loss_x8 = kl_loss_mean(F.log_softmax(student_x8, dim=1), F.softmax(target_x8, dim=1))</span></span><br><span class="line">        <span class="comment"># #</span></span><br><span class="line">        target_x7 = x_7_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">128</span> * <span class="number">128</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x7 = x_7.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">128</span> * <span class="number">128</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_x7 = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x7, dim=<span class="number">1</span>), F.softmax(target_x7, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        target_x6 = x_6_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">64</span> * <span class="number">64</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x6 = x_6.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">64</span> * <span class="number">64</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_x6 = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x6, dim=<span class="number">1</span>), F.softmax(target_x6, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># #</span></span><br><span class="line">        target_x5 = x_5_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x5 = x_5.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_x5 = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x5, dim=<span class="number">1</span>), F.softmax(target_x5, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        target_x3 = x_3_teacher.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        student_x3 = fused_layer.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</span><br><span class="line">            num_agent * batch_size * <span class="number">32</span> * <span class="number">32</span>, -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        kd_loss_fused_layer = kl_loss_mean(</span><br><span class="line">            F.log_softmax(student_x3, dim=<span class="number">1</span>), F.softmax(target_x3, dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        kd_loss = kd_weight * (</span><br><span class="line">            kd_loss_x7 + kd_loss_x6 + kd_loss_x5 + kd_loss_fused_layer</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># kd_loss = kd_weight * (kd_loss_x6 + kd_loss_x5 + kd_loss_fused_layer)</span></span><br><span class="line">        <span class="comment"># print(kd_loss)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        kd_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> kd_loss</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>KL损失定义如下</p><p><img data-src="https://s2.loli.net/2024/02/27/CQuUxlwvFV7ceB5.png" alt="image-20240227225503889"></p><h2 id="Comunicaton-Mechanism"><a href="#Comunicaton-Mechanism" class="headerlink" title="Comunicaton Mechanism"></a>Comunicaton Mechanism</h2><p>之前的方法基本都是使用通信范围内固定车辆的所有特征,之后有了自定义的通信机制,对通信的车辆,特征等进行选择.</p><h3 id="who2com-2020"><a href="#who2com-2020" class="headerlink" title="who2com 2020"></a>who2com 2020</h3><p><a href="https://arxiv.org/abs/2003.09575">[2003.09575] Who2com: Collaborative Perception via Learnable Handshake Communication (arxiv.org)</a></p><p><img data-src="https://s2.loli.net/2024/02/29/muRMCOTiKLwl6X9.png" alt="image-20240229143700618"></p><p><img data-src="https://s2.loli.net/2024/02/29/ZheUYj6bvl9T7XP.png" alt="image-20240229143720495"></p><p><strong>Who2com 建立了首个带宽限制下的通信机制</strong>，通过三阶段握手实现。具体来说，<strong>Who2com 使用一般注意力函数计算代理之间的匹配分数，并选择最需要的代理，从而有效减少带宽</strong>。</p><p>定义了一个三阶段的handshake通信机制,分为request,match,connect.</p><p>具体来说，代理首先向邻近的代理广播其请求信息 μ~j~∈ R~m~，代理计算其keys κi∈ R~k~ 与请求信息之间的匹配得分 s~ji~。</p><p>一旦理将其匹配分数返回给降级ego代理,ego代理会进一步选择最佳的 n 个代理与之连接</p><p>在每个步骤中，每个代理 i 可以通过key生成器 G~i~^k^、信息生成器 G~i~^m^、图像编码器 E~i~ 和任务解码器 D~i~ 对信息进行压缩。</p><p>简单来说,对于一个ego代理,首先使用一个request生成器(就是一个网络)得到一个信息.此外其他车也会生成一个key发送给ego代理,然后使用注意力机制计算两者值作为相似度.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # Message generator</span></span><br><span class="line">       self.query_key_net = policy_net4(n_classes=n_classes, in_channels=in_channels, enc_backbone=enc_backbone)</span><br><span class="line">       <span class="keyword">if</span> self.has_query:</span><br><span class="line">           self.query_net = linear(out_size=self.query_size, input_feat_sz=image_size / <span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">       self.key_net = linear(out_size=self.key_size, input_feat_sz=image_size / <span class="number">32</span>)</span><br><span class="line">       <span class="keyword">if</span> attention == <span class="string">&#x27;additive&#x27;</span>:</span><br><span class="line">           self.attention_net = AdditiveAttentin()</span><br><span class="line">       <span class="keyword">elif</span> attention == <span class="string">&#x27;general&#x27;</span>:</span><br><span class="line">           self.attention_net = GeneralDotProductAttention(self.query_size, self.key_size)</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           self.attention_net = ScaledDotProductAttention(<span class="number">128</span> ** <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\mu_j=G_m^j(\tilde{x}_j;\theta_m)\in\mathbb{R}^m \\s_{ji}=\Phi(\mu_j,\kappa_i),\quad\kappa_i=G_k^i(x_i;\theta_k)\in\mathbb{R}^k \\\text{General: }\Phi=\mu_j^TW_a\kappa_i \\\tilde{\boldsymbol{y}}_j=D^j([\tilde{\boldsymbol{f}}_j;f_{\hat{\imath}}];\boldsymbol{\theta}_d) \\f_{\hat{\imath}}=E^i(x_{\hat{\imath}};\boldsymbol{\theta}_e)\in\mathbb{R}^{d_f\times d_f\times d_c}   \tilde{\boldsymbol{f}}_j=E^j(\tilde{\boldsymbol{x}}_j;\boldsymbol{\theta}_e) \\\tilde{y}_{j}=D^{j}([\tilde{f}_{j};f_{sum}];\theta_{d}),\quad f_{sum}=\sum_{i=1}^{N}\alpha_{j,i}f_{i} \\\hat{i}=\underset{i}{\operatorname*{argmax}}s_{ji}</script><blockquote><p>α~j,i~ is ith element of α~j~ = ρ([s~j1~; …; s~jN~ ]) ∈ R^N^ and ρ is a softmax operation</p></blockquote><p>attention方法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScaledDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Scaled Dot-Product Attention &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, temperature, attn_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.temperature = temperature</span><br><span class="line">        self.sparsemax = Sparsemax(dim=<span class="number">1</span>)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, sparse=<span class="literal">True</span></span>):</span></span><br><span class="line">        attn_orig = torch.bmm(k, q.transpose(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">        attn_orig = attn_orig / self.temperature</span><br><span class="line">        <span class="keyword">if</span> sparse:</span><br><span class="line">            attn_orig = self.sparsemax(attn_orig)  </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            attn_orig = self.softmax(attn_orig)  </span><br><span class="line">        attn = torch.unsqueeze(torch.unsqueeze(attn_orig, <span class="number">3</span>), <span class="number">4</span>)  </span><br><span class="line">        output = attn * v  <span class="comment"># (batch,4,channel,size,size)</span></span><br><span class="line">        output = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line">        <span class="keyword">return</span> output, attn_orig.transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">AdditiveAttentin</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># self.dropout = nn.Dropout(attn_dropout)</span></span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.sparsemax = Sparsemax(dim=<span class="number">1</span>)</span><br><span class="line">        self.linear_feat = nn.Linear(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.linear_context = nn.Linear(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.linear_out = nn.Linear(<span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, sparse=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="comment"># q (batch,1,128)</span></span><br><span class="line">        <span class="comment"># k (batch,4,128)</span></span><br><span class="line">        <span class="comment"># v (batch,4,channel,size,size)</span></span><br><span class="line">        temp1 = self.linear_feat(k)  <span class="comment"># (batch,4,128)</span></span><br><span class="line">        temp2 = self.linear_context(q)  <span class="comment"># (batch,1,128)</span></span><br><span class="line">        attn_orig = self.linear_out(temp1 + temp2)  <span class="comment"># (batch,4,1)</span></span><br><span class="line">        <span class="keyword">if</span> sparse:</span><br><span class="line">            attn_orig = self.sparsemax(attn_orig)  <span class="comment"># (batch,4,1)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            attn_orig = self.softmax(attn_orig)  <span class="comment"># (batch,4,1)</span></span><br><span class="line">        attn = torch.unsqueeze(torch.unsqueeze(attn_orig, <span class="number">3</span>), <span class="number">4</span>)  <span class="comment"># (batch,4,1,1,1)</span></span><br><span class="line">        output = attn * v</span><br><span class="line">        output = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line">        <span class="keyword">return</span> output, attn_orig.transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneralDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Scaled Dot-Product Attention &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, query_size, key_size, attn_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.sparsemax = Sparsemax(dim=<span class="number">1</span>)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.linear = nn.Linear(query_size, key_size)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Msg size: &#x27;</span>,query_size,<span class="string">&#x27;  Key size: &#x27;</span>, key_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, sparse=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="comment"># q (batch,1,128)</span></span><br><span class="line">        <span class="comment"># k (batch,4,128)</span></span><br><span class="line">        <span class="comment"># v (batch,4,channel*size*size)</span></span><br><span class="line">        query = self.linear(q)  <span class="comment"># (batch,1,key_size)</span></span><br><span class="line">        attn_orig = torch.bmm(k, query.transpose(<span class="number">2</span>, <span class="number">1</span>))  <span class="comment"># (batch,4,1)</span></span><br><span class="line">        <span class="keyword">if</span> sparse:</span><br><span class="line">            attn_orig = self.sparsemax(attn_orig)  <span class="comment"># (batch,4,1)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            attn_orig = self.softmax(attn_orig)  <span class="comment"># (batch,4,1)</span></span><br><span class="line">        attn = torch.unsqueeze(torch.unsqueeze(attn_orig, <span class="number">3</span>), <span class="number">4</span>)  <span class="comment"># (batch,4,1,1,1)</span></span><br><span class="line">        output = attn * v  <span class="comment"># (batch,4,channel,size,size)</span></span><br><span class="line">        output = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line">        <span class="keyword">return</span> output, attn_orig.transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="when2comm-2020"><a href="#when2comm-2020" class="headerlink" title="when2comm 2020"></a>when2comm 2020</h3><p>who2comm的同作者.</p><p>在 Who2com 的基础上，When2com引入了缩放一般注意力来决定何时与他人交流。这样，自我代理只有在信息不足时才会与他人交流，从而有效地节省了协作资源。</p><p><img data-src="https://s2.loli.net/2024/02/29/COiPgxUSrsYvqQL.png" alt="image-20240229162328653"></p><p>when2comm的代码就要复杂的多,它构建了很多块.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KmGenerator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, out_size=<span class="number">128</span>, input_feat_sz=<span class="number">32.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(KmGenerator, self).__init__()</span><br><span class="line">        feat_map_sz = input_feat_sz // <span class="number">4</span></span><br><span class="line">        self.n_feat = <span class="built_in">int</span>(<span class="number">256</span> * feat_map_sz * feat_map_sz)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(self.n_feat, <span class="number">256</span>),  <span class="comment">#</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">128</span>),  <span class="comment">#</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, out_size),</span><br><span class="line">        )  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features_map</span>):</span></span><br><span class="line">        outputs = self.fc(features_map.view(-<span class="number">1</span>, self.n_feat))</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PolicyNet4</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels=<span class="number">13</span>, input_feat_sz=<span class="number">32</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PolicyNet4, self).__init__()</span><br><span class="line">        feat_map_sz = input_feat_sz // <span class="number">4</span></span><br><span class="line">        self.n_feat = <span class="built_in">int</span>(<span class="number">256</span> * feat_map_sz * feat_map_sz)</span><br><span class="line">        self.lidar_encoder = LidarEncoder(height_feat_size=in_channels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Encoder</span></span><br><span class="line">        <span class="comment"># down 1</span></span><br><span class="line">        self.conv1 = Conv2DBatchNormRelu(<span class="number">512</span>, <span class="number">512</span>, k_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = Conv2DBatchNormRelu(<span class="number">512</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv3 = Conv2DBatchNormRelu(<span class="number">256</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># down 2</span></span><br><span class="line">        self.conv4 = Conv2DBatchNormRelu(<span class="number">256</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5 = Conv2DBatchNormRelu(<span class="number">256</span>, <span class="number">256</span>, k_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features_map</span>):</span></span><br><span class="line">        _, _, _, _, outputs1 = self.lidar_encoder(features_map)</span><br><span class="line">        outputs = self.conv1(outputs1)</span><br><span class="line">        outputs = self.conv2(outputs)</span><br><span class="line">        outputs = self.conv3(outputs)</span><br><span class="line">        outputs = self.conv4(outputs)</span><br><span class="line">        outputs = self.conv5(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line">   </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LidarEncoder</span>(<span class="params">Backbone</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The encoder class. Encodes input features in forward pass.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, height_feat_size=<span class="number">13</span>, compress_level=<span class="number">0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(height_feat_size, compress_level)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().encode(x)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LidarDecoder</span>(<span class="params">Backbone</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;The decoder class. Decodes input features in forward pass.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, height_feat_size=<span class="number">13</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(height_feat_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, x_1, x_2, x_3, x_4, batch, kd_flag=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().decode(x, x_1, x_2, x_3, x_4, batch, kd_flag)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>首先使用encode进行降采样,选择某一层采样后的输出,利用采样后的输出计算q,k,v使用注意力机制融合.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">self.key_net = KmGenerator(</span><br><span class="line">    out_size=self.key_size, input_feat_sz=image_size / <span class="number">32</span></span><br><span class="line">)</span><br><span class="line">self.attention_net = MIMOGeneralDotProductAttention(</span><br><span class="line">    self.query_size, self.key_size, self.warp_flag</span><br><span class="line">)</span><br><span class="line"><span class="comment"># # Message generator</span></span><br><span class="line">self.query_key_net = PolicyNet4(in_channels=in_channels)</span><br><span class="line"><span class="keyword">if</span> self.has_query:</span><br><span class="line">    self.query_net = KmGenerator(</span><br><span class="line">        out_size=self.query_size, input_feat_sz=image_size / <span class="number">32</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>利用query_key_net生成特征,再利用key_net生成key,query_net生成query,使用attention_net利用注意力机制进行融合.val_mat就是采样后的输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">key_mat = torch.cat(<span class="built_in">tuple</span>(key_list), <span class="number">1</span>)</span><br><span class="line">query_mat = torch.cat(<span class="built_in">tuple</span>(query_list), <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>用的就是点积注意力,然后使用decoder回去.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment"># hand-shake</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MIMOGeneralDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scaled Dot-Product Attention&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, query_size, key_size, warp_flag, attn_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.sparsemax = Sparsemax(dim=<span class="number">1</span>)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.linear = nn.Linear(query_size, key_size)</span><br><span class="line">        self.warp_flag = warp_flag</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Msg size: &quot;</span>, query_size, <span class="string">&quot;  Key size: &quot;</span>, key_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, qu, k, v, sparse=<span class="literal">True</span></span>):</span></span><br><span class="line">      </span><br><span class="line">        query = self.linear(qu)  <span class="comment"># (batch,5,key_size)</span></span><br><span class="line">        attn_orig = torch.bmm(</span><br><span class="line">            k, query.transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        )  </span><br><span class="line">        attn_orig_softmax = self.softmax(attn_orig)  <span class="comment"># (batch,5,5)</span></span><br><span class="line"></span><br><span class="line">        attn_shape = attn_orig_softmax.shape</span><br><span class="line">        bats, key_num, query_num = attn_shape[<span class="number">0</span>], attn_shape[<span class="number">1</span>], attn_shape[<span class="number">2</span>]</span><br><span class="line">        attn_orig_softmax_exp = attn_orig_softmax.view(</span><br><span class="line">            bats, key_num, query_num, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.warp_flag == <span class="number">1</span>:</span><br><span class="line">            v_exp = v</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            v_exp = torch.unsqueeze(v, <span class="number">2</span>)</span><br><span class="line">            v_exp = v_exp.expand(-<span class="number">1</span>, -<span class="number">1</span>, query_num, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        output = attn_orig_softmax_exp * v_exp  <span class="comment"># (batch,5,channel,size,size)</span></span><br><span class="line">        output_sum = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output_sum, attn_orig_softmax</span><br></pre></td></tr></table></figure><p>训练的时候基本就拿这些特征给分类和回归的head做输出了.但是inference的时候设置了多种输出.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> inference == <span class="string">&#x27;softmax&#x27;</span>:</span><br><span class="line">              action = torch.argmax(prob_action, dim=<span class="number">2</span>)</span><br><span class="line">              num_connect = <span class="number">4</span></span><br><span class="line">              <span class="keyword">return</span> pred, prob_action, action, num_connect</span><br><span class="line">          <span class="keyword">elif</span> inference == <span class="string">&#x27;argmax_test&#x27;</span>:</span><br><span class="line">              action = torch.argmax(prob_action, dim=<span class="number">2</span>)</span><br><span class="line">              feat_argmax, num_connect = self.argmax_select(feat_map1, feat_map2, feat_map3, feat_map4, feat_map5,</span><br><span class="line">                                                            action, batch_size)</span><br><span class="line">              featmaps_argmax = feat_argmax.detach()</span><br><span class="line">              pred_argmax = self.decoder(featmaps_argmax)</span><br><span class="line">              <span class="keyword">return</span> pred_argmax, prob_action, action, num_connect</span><br><span class="line">          <span class="keyword">elif</span> inference == <span class="string">&#x27;activated&#x27;</span>:</span><br><span class="line">              feat_act, action, num_connect = self.activated_select(vals, prob_action)</span><br><span class="line">              featmaps_act = feat_act.detach()</span><br><span class="line">              pred_act = self.decoder(featmaps_act)</span><br><span class="line">              <span class="keyword">return</span> pred_act, prob_action, action, num_connect</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">              <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Incorrect inference mode&#x27;</span>)</span><br></pre></td></tr></table></figure><p>argmax_select和activated分别如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax_select</span>(<span class="params">self, val_mat, prob_action</span>):</span></span><br><span class="line">        <span class="comment"># v(batch, query_num, channel, size, size)</span></span><br><span class="line">        cls_num = prob_action.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment">#  进行one hot编码,</span></span><br><span class="line">        coef_argmax = F.one_hot(prob_action.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>],  num_classes=cls_num).<span class="built_in">type</span>(torch.cuda.FloatTensor)</span><br><span class="line">        coef_argmax = coef_argmax.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        attn_shape = coef_argmax.shape</span><br><span class="line">        bats, key_num, query_num = attn_shape[<span class="number">0</span>], attn_shape[<span class="number">1</span>], attn_shape[<span class="number">2</span>]</span><br><span class="line">        coef_argmax_exp = coef_argmax.view(bats, key_num, query_num, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        v_exp = torch.unsqueeze(val_mat, <span class="number">2</span>)</span><br><span class="line">        v_exp = v_exp.expand(-<span class="number">1</span>, -<span class="number">1</span>, query_num, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        output = coef_argmax_exp * v_exp  <span class="comment"># (batch,4,channel,size,size)</span></span><br><span class="line">        feat_argmax = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute connect</span></span><br><span class="line">        count_coef = copy.deepcopy(coef_argmax)</span><br><span class="line">        ind = np.diag_indices(self.agent_num)</span><br><span class="line">        count_coef[:, ind[<span class="number">0</span>], ind[<span class="number">1</span>]] = <span class="number">0</span></span><br><span class="line">        num_connect = torch.nonzero(count_coef).shape[<span class="number">0</span>] / (self.agent_num * count_coef.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_argmax, coef_argmax, num_connect</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activated_select</span>(<span class="params">self, val_mat, prob_action, thres=<span class="number">0.2</span></span>):</span></span><br><span class="line"></span><br><span class="line">        coef_act = torch.mul(prob_action, (prob_action &gt; thres).<span class="built_in">float</span>())</span><br><span class="line">        attn_shape = coef_act.shape</span><br><span class="line">        bats, key_num, query_num = attn_shape[<span class="number">0</span>], attn_shape[<span class="number">1</span>], attn_shape[<span class="number">2</span>]</span><br><span class="line">        coef_act_exp = coef_act.view(bats, key_num, query_num, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        v_exp = torch.unsqueeze(val_mat, <span class="number">2</span>)</span><br><span class="line">        v_exp = v_exp.expand(-<span class="number">1</span>, -<span class="number">1</span>, query_num, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        output = coef_act_exp * v_exp  <span class="comment"># (batch,4,channel,size,size)</span></span><br><span class="line">        feat_act = output.<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># (batch,1,channel,size,size)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute connect</span></span><br><span class="line">        count_coef = coef_act.clone()</span><br><span class="line">        ind = np.diag_indices(self.agent_num)</span><br><span class="line">        count_coef[:, ind[<span class="number">0</span>], ind[<span class="number">1</span>]] = <span class="number">0</span></span><br><span class="line">        num_connect = torch.nonzero(count_coef).shape[<span class="number">0</span>] / (self.agent_num * count_coef.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> feat_act, coef_act, num_connect\</span><br></pre></td></tr></table></figure><h3 id="where2comm-2022"><a href="#where2comm-2022" class="headerlink" title="where2comm 2022"></a>where2comm 2022</h3><p><img data-src="https://s2.loli.net/2024/02/28/5jYTmRyw2iIEQeb.png" alt="image-20240228210811764"></p><p><img data-src="https://s2.loli.net/2024/02/28/Cj1SE42UmL9IWYR.png" alt="image-20240228170628090"></p><p>其中 where2comm 包括observation encoder、spatial confidence generator、the spatial confidence-aware communication module、the spatial confidence-aware message fusion和detection decoder.</p><p>在五个模块中，<strong>spatial confidence generator</strong>可生成空间置信度图,基于该空间置信度图，<strong>空间置信度感知通信</strong>(spatial confidence-aware communication)可生成紧凑的信息和稀疏的通信图，以节省通信带宽.<strong>spatial confidence-aware message fusion</strong> module利用信息丰富的空间置信度先验来实现更好的聚合.</p><p>我们使用检测解码器结构来生成检测置信度图。给定第 k 轮通信的特征图 F (k) i，相应的空间置信度图为</p><script type="math/tex; mode=display">\mathbf{C}_i^{(k)}=\Phi_\text{generator}(\mathcal{F}_i^{(k)})\in[0,1]^{H\times W}</script><p>为了在不影响感知的情况下减少通信带宽，我们利用空间置信度图来选择特征图中信息量最大的空间区域（在哪里通信），并决定最有利的合作对象（谁来通信）。</p><p>这个communication包括message packing。message packing决定了要发送的信息中应包含哪些信息。包括：i) 一张request图，表明代理需要了解哪些空间区域的更多信息；ii) 一张空间稀疏但感知关键的特征图。</p><h3 id="what2comm-2023"><a href="#what2comm-2023" class="headerlink" title="what2comm 2023"></a>what2comm 2023</h3><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>多智能体协同感知作为驾驶场景的新兴应用受到越来越多的关注。尽管以前的方法取得了进步，但由于<strong>冗余的通信模式</strong>和<strong>脆弱的协作过程</strong>，挑战仍然存在。</p><p>为了解决这些问题，我们提出了What2comm，一个<strong>端到端协作感知框架，以实现感知性能和通信带宽之间的权衡</strong>。我们的新奇性在于三个方面</p><p>首先，我们设计了一种基于<strong>特征解耦的高效通信机制</strong>，在异构代理之间传输排他的和共同的特征映射，以提供感知上的整体消息。</p><p>其次，<strong>引入了一个时空协作模块来整合来自协作者的互补信息和时间自我线索</strong>，从而形成一个<strong>针对传输延迟和定位误差</strong>的鲁棒协作过程。</p><p>最后，我们提出了一种<strong>公共感知的融合策略</strong>来细化具有信息共同特征的最终表示。</p><p>在真实世界和模拟场景中进行的综合实验证明了What2通信的有效性。</p><p>DAIR-V2X:第一个用于支持协作感知的大规模真实世界数据集，它包含了标记的车辆和基础设施的激光雷达点云。它包括100个自动驾驶场景和18000个数据样本，其中训练/验证/测试集以5：2：3的比例被分割。</p><p>V2XSet </p><p>OPV2V</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>元数据编码和特征投影、基于解耦的通信机制、时空协作模块、common感知融合策略和检测解码器。</p><p> This framework comprises five parts: metadata encoding and feature projection, decoupling-based communication mechanism, spatio-temporal collaboration module, common-aware</p><p>fusion strategy, and detection decoders</p><blockquote><p><strong>特征解耦</strong>前提是学习特征，<strong>解耦是分离出任务相关特征和无关特征</strong>，以分类为例，解耦的是类别特征和无关的背景及样式等特征。特征解耦一般利用信息熵或者变换空间后的数学特性来完成。</p><p>只要两个对象之间存在一方依赖一方的关系，那么我们就称这两个对象之间存在耦合。</p><p>作者：大虎甜面酱<br>链接：<a href="https://www.jianshu.com/p/67dc5f5e05da">https://www.jianshu.com/p/67dc5f5e05da</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p></blockquote><p><img data-src="https://s2.loli.net/2024/02/28/Jr9OnUyvfEkcxtD.png" alt="image-20240228101157638"></p><p><img data-src="https://s2.loli.net/2024/02/28/WFc8MJjfDOny1Zt.png" alt="image-20240228165036544"></p><p>创新点:feature decoupling,latency-aware 使用过去的特征.</p><h3 id="how2comm-2023"><a href="#how2comm-2023" class="headerlink" title="how2comm 2023"></a>how2comm 2023</h3><p>系what2comm同作者</p><h2 id="Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception"><a href="#Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception" class="headerlink" title="Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception"></a>Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception</h2><p>在接收到自我代理播放的元数据（如姿势和外部特征）后，合作者将其本地激光雷达点云投射到自我代理的坐标系中。同样，<strong>自我代理之前的点云帧也会同步到当前帧</strong>。</p><p>给定第 k 个代理在时间戳 t 处的点云 X (t) k，提取的特征为 F (t) k =f enc (X (t) k )∈R C ×H ×W ，其中 f enc (-) 是所有代理共享的 PointPillar编码器，C、H、W 分别代表通道、高度和宽度。</p><h3 id="Context-aware-Information-Aggregation"><a href="#Context-aware-Information-Aggregation" class="headerlink" title="Context-aware Information Aggregation"></a>Context-aware Information Aggregation</h3><p>解决latency的问题</p><p><img data-src="https://s2.loli.net/2024/03/04/4Qqgwk9uGciJBYj.png" alt="image-20240304214842491"></p><p>遗憾的是，目前的多机器人协作总是专注于探索当前帧，而忽略了之前帧的上下文线索。由于点云的稀疏性和不足，单帧解决方案无法有效检测快速移动的物体（如周围的车辆）。为此，我们提出了一个情境感知信息聚合（CIA）组件，用于捕捉自我代理<strong>之前帧的时空表征，以融合有价值的语义</strong>。</p><p>选择性信息过滤。这一阶段的目的是通过过滤目标 F (t) i ∈R C ×H ×W 中的冗余特征，并从先前的 F^(t-τ)^~i~ ∈R τ ×C×H×W 中提炼出有意义的特征，从而提取精炼信息，其中 τ 是时间偏移。</p><p>具体来说，首先利用通道平均和最大池化运算 Ψ a/m (-) 聚合丰富的通道语义</p><script type="math/tex; mode=display">\mathcal{U}=\sigma\cdot\aleph(\mathcal{M}_{a}^{(t)}\|\mathcal{M}_{m}^{(t)}+\mathcal{M}_{a}^{(\tau)}\|\mathcal{M}_{m}^{(\tau)})\in\mathbb{R}^{H\times W}</script><p>将过去帧相加做个max与avg池化然后concat起来,当前的帧也同样处理,然后加起来做个conv.将这些细化的特征图结合起来，就能得到一个精心选择的空间选择图</p><script type="math/tex; mode=display">H_i^{(\tau)}=(1-\mathcal{U})\odot tanh(F_i^{(t)})+\mathcal{U}\odot F_i^{(t-\tau)}</script><h4 id="Spatio-temporal-Feature-Integration"><a href="#Spatio-temporal-Feature-Integration" class="headerlink" title="Spatio-temporal Feature Integration."></a>Spatio-temporal Feature Integration.</h4><p>为了整合historical prototype以提高当前表征的感知能力，我们引入了金字塔 LSTM来学习帧间特征 F (t) i ∥H (τ ) i 的上下文依赖关系。</p><p>在实践中，多尺度空间特征是通过在不同尺度之间连续进行两次二维卷积，然后进行批量归一化和 ReLU 激活来提取的。为了实现多层次空间语义融合，<strong>降低采样率的特征会通过横向连接逐步插值到提高采样率的层</strong>。</p><h3 id="Confidence-aware-Cross-agent-Collaboration"><a href="#Confidence-aware-Cross-agent-Collaboration" class="headerlink" title="Confidence-aware Cross-agent Collaboration"></a>Confidence-aware Cross-agent Collaboration</h3><p>跨代理协作的目标是通过聚合协作者共享特征的互补语义来增强自我代理的视觉表征。</p><p>现有研究提出了基于注意力的per-location特征融合方法，但这种方法容易受到定位误差的影响，而且忽略了点云的稀疏性。为了解决这些问题，我们采用了a <strong>novel Confidenceaware Cross-agent Collaboration (CCC) component</strong></p><p><img data-src="https://s2.loli.net/2024/03/04/4zjauARgEMekoSt.png" alt="image-20240304221451619"></p><p>CCC 组件将特征和置信度图编码为三个尺度，<strong>并在每个尺度上进行特征融合</strong>。</p><p>F^(t)^~k,l~ 和 S^(t)^~k,l~ 表示第 l 个尺度的特征图和置信度图.</p><p>为了预测包含有意义物体信息的空间位置，我们将所有置信度图的元素求和.</p><p>由于置信度图反映的是空间临界水平，S^(t)^~sum,l~ 显示的是探测范围内目标的潜在位置，称为参考点。</p><p>因此，我们采用基于阈值的选择函数 fsel(-) 来提取参考点 S^(t)^~re,l~。这种设计可以积极引导后续的融合网络集中在重要的空间区域。</p><p><strong>Deformable Cross-attention Module</strong> 我们在参考点提取自我代理的特征 F^(t)^ ~i,l~ 作为初始查询嵌入，并<strong>应用线性层将参考点的位置编码为位置嵌入</strong></p><p>为了解决特征图的不对齐问题，并获得更稳健的表征以抵御定位误差，可变形交叉注意模块（DCM）通过可变形交叉注意层聚合来自采样关键点的信息</p><script type="math/tex; mode=display">\mathrm{DCM}(q)=\sum_{a=1}^{\Lambda}W_{a}[\sum_{k=1}^{K}\sum_{m=1}^{M}\phi(W_{b}F_{i,l}^{(t)}(q))F_{k,l}^{(t)}(q+\Delta q_{m})],</script><p>Wa/b 是可学习权重，φ(-) 是软最大函数。最后，我们得出一个填充操作，根据初始位置 q 将 DCM(q) 填充到自我代理的特征 F (t) i,l 中，并输出 Z(t) i,l</p><p>三个尺度下的输出增强特征被编码成相同的大小，并在通道维度上进行串联。我们利用 1 × 1 卷积层融合三个尺度的信息，得到最终的协作特征 Z^(t)^~i~∈ R^C×H×W^</p><h3 id="Importance-aware-Adaptive-Fusion"><a href="#Importance-aware-Adaptive-Fusion" class="headerlink" title="Importance-aware Adaptive Fusion"></a>Importance-aware Adaptive Fusion</h3><p>尽管之前的研究通过汇总协作信息的自我特征取得了令人印象深刻的性能，但它们可能会受到异步测量的协作者带来的噪声干扰。A promising solution is to <strong>consider purely ego-centered characteristics</strong>, which contain the natural perception advantages of the target agent.</p><p>我们提出了一种重要性感知自适应融合（IAF）组件，根据多源特征的互补性对其进行融合。</p><script type="math/tex; mode=display">\mathcal{H}_{i}^{(t)},\mathcal{Z}_{i}^{(t)},\mathcal{S}_{i}^{(t)}=\sigma\cdot\Psi_{m}(f_{gen}(H_{i}^{(t)},Z_{i}^{(t)},F_{i}^{(t)}))</script><script type="math/tex; mode=display">\mathcal{E}_{\mathcal{H}}^{(t)}=\phi(\mathcal{H}_{i}^{(t)})=\frac{exp(\mathcal{H}_{i}^{(t)})}{exp(\mathcal{H}_{i}^{(t)})+exp(\mathcal{Z}_{i}^{(t)})+exp(\mathcal{S}_{i}^{(t)})}.$$​$$\mathcal{F}_i^{(t)}=\mathcal{E}_{\mathcal{H}}^{(t)}\odot H_i^{(t)}+\mathcal{E}_{\mathcal{Z}}^{(t)}\odot Z_i^{(t)}+\mathcal{E}_{\mathcal{S}}^{(t)}\odot F_i^{(t)}.</script><h3 id="FPV-RCNN-2021"><a href="#FPV-RCNN-2021" class="headerlink" title="FPV-RCNN 2021"></a>FPV-RCNN 2021</h3><p><a href="https://arxiv.org/abs/2109.11615">[2109.11615] Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of Autonomous Driving (arxiv.org)</a></p><h3 id="Collaborative-3d-object-detection-for-automatic-vehicle-systems-via-learnable-communications-2022"><a href="#Collaborative-3d-object-detection-for-automatic-vehicle-systems-via-learnable-communications-2022" class="headerlink" title="Collaborative 3d object detection for automatic vehicle systems via learnable communications 2022"></a>Collaborative 3d object detection for automatic vehicle systems via learnable communications 2022</h3><p><a href="https://arxiv.org/pdf/2205.11849.pdf">2205.11849.pdf (arxiv.org)</a></p><p><img data-src="https://s2.loli.net/2024/02/29/RANi2pLbKPZslu5.png" alt="image-20240229172548113"></p><p><img data-src="https://s2.loli.net/2024/02/29/RP1nMsk5h2B4pzj.png" alt="image-20240229172522190"></p><h2 id="Customized-Loss"><a href="#Customized-Loss" class="headerlink" title="Customized Loss"></a>Customized Loss</h2><p>除了分类和回归损失之外，虽然 V2V 通信为自我车辆提供了相对丰富的感知视野，但<strong>共享信息的冗余性</strong>和<strong>不确定性</strong>带来了新的挑战。</p><p>在协作场景中，邻居代理提供的类似信息对自我车辆来说是冗余的。为了有效利用协作信息，Luo 等人提出了一种互补增强和冗余最小化的协作网络（CRCNet）。具体来说，CRCNet 有两个模块来引导网络。在互补性增强模块中，CRCNet 利用对比学习来增强信息增益。在冗余最小化模块中，CRCNet 利用互信息鼓励融合特征对中的依赖性。在上述模块的指导下，CRCNet 能够在融合特征时从相邻代理中选择互补信息。</p><script type="math/tex; mode=display">P_{i}=P_{i}+W_{k\rightarrow i}^{C}\odot P_{k\rightarrow i}\odot W_{k\rightarrow i}^{s} \\\delta_{k}=\sum_{n}L_{cls}\big(p_{j}^{n}(P_{i}),y_{j}^{n}\big)-\sum_{n}L_{cls}\big(p_{j}^{n}(P_{i}+T_{i}^{k}),y_{j}^{n}\big) \\L_{eff}=\sum_k\min(\delta_k-\delta_{thd},0)^2 \\I[T_i^k;T_i^l]=\sum\limits_{x\in T_i^k}\sum\limits_{y\in T_i^l}p(x,y)\log\frac{p(x,y)}{p(x)p(y)} \\\begin{aligned}I[T_{i}^{k};T_{i}^{l}]=& \mathbb{E}_{p(T_{i}^{k};T_{i}^{l})}[\logq_{\theta_{2}}(T_{i}^{l}/T_{i}^{k})]  \\&-\mathbb{E}_{p(T_{i}^{k})}\mathbb{E}_{p(T_{i}^{l})}[\logq_{\theta_{2}}(T_{i}^{l}/T_{i}^{k})],\end{aligned} \\L_{red}=\sum_k\sum_l[\logq_{\theta_2}(T_i^l/T_i^k)-\logq_{\theta_2}(T_i^l/T_n^k)]\\min_{Q}L_{KL}=KL(p(T_i^k/T_i^l)||q_{\theta_2}(T_i^k/T_i^l) \\L=L_{cls}+L_{loc}+L_{red}+L_{eff}\\</script><p><img data-src="https://s2.loli.net/2024/02/29/a5NIGnJloEwK4Hp.png" alt="image-20240229180846509"></p><p>除了冗余信息，协作信息还包含感知上的不确定性，这反映了感知上的不准确或传感器噪声。Su 等人首先探讨了协作感知中的不确定性。具体来说，他们设计了一种量身定制的移动块引导方法来估计模型和数据的不确定性，并设计了一个良好的损失函数来直接捕捉数据的不确定性。实验表明，在不同的协作方案中，不确定性估计可以减少不确定性并提高准确性。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;代码还是很重要的,虽然发现有些代码库不怎么样.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>transformer and attention(二):various attention modules</title>
    <link href="https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/"/>
    <id>https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/</id>
    <published>2024-01-23T12:18:17.000Z</published>
    <updated>2024-01-24T06:01:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码.<br><span id="more"></span></p><h2 id="Squeeze-and-Excitation-Networks-2018"><a href="#Squeeze-and-Excitation-Networks-2018" class="headerlink" title="Squeeze-and-Excitation Networks 2018"></a>Squeeze-and-Excitation Networks 2018</h2><p><img data-src="https://s2.loli.net/2024/01/10/Lq6VRkQuoUpYSmc.png" alt="image-20240110094833740"></p><blockquote><ol><li>SENet通过学习channel之间的相关性，筛选出了针对通道的注意力，稍微增加了一点计算量，但是效果提升较明显</li><li>Squeeze-and-Excitation(SE) block是一个子结构，可以有效地嵌到其他分类或检测模型中。</li><li>SENet的核心思想在于通过网络根据loss去学习feature map的特征权重来使模型达到更好的结果</li><li>SE模块本质上是一种attention机制</li></ol></blockquote><p><img data-src="https://s2.loli.net/2024/01/10/ZrhKeEALunoDxpF.png" alt="image-20240110095007870"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># implement SEAttention</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SEAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channel=<span class="number">512</span>, reduction=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SEAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(channel // reduction, channel),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                init.normal_(m.weight, std=<span class="number">0.001</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x * y.expand_as(x)</span><br></pre></td></tr></table></figure><h2 id="Bottlenet-attention-Module-BAM-2018"><a href="#Bottlenet-attention-Module-BAM-2018" class="headerlink" title="Bottlenet attention Module (BAM) 2018"></a>Bottlenet attention Module (BAM) 2018</h2><p><img data-src="https://s2.loli.net/2024/01/23/7XzeCTDLwFEuiSM.png" alt="image-20240123200825093"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Flatten</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>.view(<span class="built_in">input</span>.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,channel,reduction:<span class="built_in">int</span>=<span class="number">16</span>,num_layer:<span class="built_in">int</span>=<span class="number">3</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        gate_channels = [channel]</span><br><span class="line">        gate_channels += [channel // reduction] * num_layer</span><br><span class="line">        gate_channels += [channel]</span><br><span class="line"></span><br><span class="line">        self.ca = nn.Sequential()</span><br><span class="line">        self.ca.add_module(<span class="string">&#x27;flatten&#x27;</span>,Flatten())</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layer):</span><br><span class="line">            self.ca.add_module(<span class="string">&#x27;fc&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i),nn.Linear(gate_channels[i],gate_channels[i+<span class="number">1</span>]))</span><br><span class="line">            self.ca.add_module(<span class="string">&#x27;bn%d&#x27;</span> % i, nn.BatchNorm1d(gate_channels[i+<span class="number">1</span>]))</span><br><span class="line">            self.ca.add_module(<span class="string">&#x27;relu&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i),nn.ReLU())</span><br><span class="line"></span><br><span class="line">        self.ca.add_module(<span class="string">&#x27;last_fc&#x27;</span>,nn.Linear(gate_channels[-<span class="number">2</span>],gate_channels[-<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        res = self.avg_pool(x)</span><br><span class="line">        res = self.ca(res)</span><br><span class="line">        <span class="keyword">return</span> res.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>).expand_as(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,channel,reduction=<span class="number">16</span>,num_layers=<span class="number">3</span>,dia_val=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.sa = nn.Sequential()</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;conv_reduce1&#x27;</span>,nn.Conv2d(in_channels=channel,out_channels=channel//reduction,kernel_size=<span class="number">1</span>))</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;bn_reduce1&#x27;</span>,nn.BatchNorm2d(channel//reduction))</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;relu_reduce1&#x27;</span>,nn.ReLU())</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            self.sa.add_module(<span class="string">&#x27;conv_%d&#x27;</span> % i,nn.Conv2d(in_channels=channel//reduction,out_channels=channel//reduction,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>,dilation=dia_val))</span><br><span class="line">            self.sa.add_module(<span class="string">&#x27;bn_%d&#x27;</span> % i,nn.BatchNorm2d(channel//reduction))</span><br><span class="line">            self.sa.add_module(<span class="string">&#x27;relu_%d&#x27;</span> % i,nn.ReLU())</span><br><span class="line">        self.sa.add_module(<span class="string">&#x27;conv_last&#x27;</span>,nn.Conv2d(in_channels=channel//reduction,out_channels=channel,kernel_size=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        res = self.sa(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res.expand_as(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BAMBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,channel:<span class="built_in">int</span>=<span class="number">512</span>,reduction:<span class="built_in">int</span>=<span class="number">16</span>,dia_val:<span class="built_in">int</span>=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.ca = ChannelAttention(channel=channel,reduction=reduction)</span><br><span class="line">        self.sa = SpatialAttention(channel=channel,reduction=reduction,dia_val=dia_val)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">        self.init_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        sa_out = self.sa(x)</span><br><span class="line">        ca_out = self.ca(x)</span><br><span class="line">        weight = self.sigmoid(sa_out + ca_out)</span><br><span class="line">        out = (<span class="number">1</span> + weight) * x</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># initial weights for the model</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_in&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m,nn.BatchNorm2d):</span><br><span class="line">                init.constant_(m.weight,<span class="number">1</span>)</span><br><span class="line">                init.constant_(m.bias,<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m,nn.Linear):</span><br><span class="line">                init.normal_(m.weight,std=<span class="number">0.001</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    init.constant_(m.bias,<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/23/3PEUjp2y9aMLI8u.png" alt="image-20240123200842336"></p><h2 id="DANet-Dual-Attention-Network-2018"><a href="#DANet-Dual-Attention-Network-2018" class="headerlink" title="DANet: Dual Attention Network 2018"></a>DANet: Dual Attention Network 2018</h2><p><img data-src="https://s2.loli.net/2024/01/23/R9GMVDrs23ca7Qp.png" alt="image-20240123210612879"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionAttentionModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-<span class="number">1</span>)//<span class="number">2</span>)</span><br><span class="line">        self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        bs,c,h,w=x.shape</span><br><span class="line">        y=self.cnn(x)</span><br><span class="line">        y=y.view(bs,c,-<span class="number">1</span>).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#bs,h*w,c</span></span><br><span class="line">        y=self.pa(y,y,y) <span class="comment">#bs,h*w,c</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttentionModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-<span class="number">1</span>)//<span class="number">2</span>)</span><br><span class="line">        self.pa=SimplifiedScaledDotProductAttention(H*W,h=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        bs,c,h,w=x.shape</span><br><span class="line">        y=self.cnn(x)</span><br><span class="line">        y=y.view(bs,c,-<span class="number">1</span>) <span class="comment">#bs,c,h*w</span></span><br><span class="line">        y=self.pa(y,y,y) <span class="comment">#bs,c,h*w</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DAModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.position_attention_module=PositionAttentionModule(d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span>)</span><br><span class="line">        self.channel_attention_module=ChannelAttentionModule(d_model=<span class="number">512</span>,kernel_size=<span class="number">3</span>,H=<span class="number">7</span>,W=<span class="number">7</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span></span><br><span class="line">        bs,c,h,w=<span class="built_in">input</span>.shape</span><br><span class="line">        p_out=self.position_attention_module(<span class="built_in">input</span>)</span><br><span class="line">        c_out=self.channel_attention_module(<span class="built_in">input</span>)</span><br><span class="line">        p_out=p_out.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>).view(bs,c,h,w)</span><br><span class="line">        c_out=c_out.view(bs,c,h,w)</span><br><span class="line">        <span class="keyword">return</span> p_out+c_out</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="CBAM-Convolutional-Block-Attention-Module-2018"><a href="#CBAM-Convolutional-Block-Attention-Module-2018" class="headerlink" title="CBAM: Convolutional Block Attention Module 2018"></a>CBAM: Convolutional Block Attention Module 2018</h2><p><img data-src="https://s2.loli.net/2024/01/10/uPRhgXEveC9JbFS.png" alt="image-20240110104503985"></p><p>通道注意力</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_planes, ratio=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1   = nn.Conv2d(in_planes, in_planes // <span class="number">16</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2   = nn.Conv2d(in_planes // <span class="number">16</span>, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))</span><br><span class="line">        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))</span><br><span class="line">        out = avg_out + max_out</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(out)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/10/wxDGep963Qzs5tq.png" alt="image-20240110104513785"></p><p>空间注意力</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">&#x27;kernel size must be 3 or 7&#x27;</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        max_out, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/10/hyUFPErbDKB3TwI.png" alt="image-20240110104523806"></p><script type="math/tex; mode=display">\begin{aligned}\mathbf{F^{\prime}=M_c(F)\otimes F,}\\\mathbf{F^{\prime\prime}=M_s(F^{\prime})\otimes F^{\prime},}\end{aligned}</script><script type="math/tex; mode=display">\begin{gathered}\mathbf{M_{c}}(\mathbf{F}) =\sigma(MLP(AvgPool(\mathbf{F}))+MLP(MaxPool(\mathbf{F}))) \\=\sigma(\mathbf{W_1}(\mathbf{W_0}(\mathbf{F_{avg}^c}))+\mathbf{W_1}(\mathbf{W_0}(\mathbf{F_{max}^c}))), \end{gathered}</script><script type="math/tex; mode=display">\begin{aligned}\mathbf{M_{s}}(\mathbf{F})& =\sigma(f^{7\times7}([AvgPool(\mathbf{F});MaxPool(\mathbf{F})]))  \\&=\sigma(f^{7\times7}([\mathbf{F_{avg}^{s}};\mathbf{F_{max}^{s}}])),\end{aligned}</script><p><img data-src="https://s2.loli.net/2024/01/10/MQNWLjZP2yH8cwd.png" alt="image-20240110142553774"></p><h2 id="Non-Local-2018"><a href="#Non-Local-2018" class="headerlink" title="Non-Local 2018"></a>Non-Local 2018</h2><p><img data-src="https://s2.loli.net/2024/01/11/IW6cKRTQN178kp4.png" alt="image-20240111161108109"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NonLocalNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_dim=<span class="number">64</span>, output_dim=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NonLocalNet, self).__init__()</span><br><span class="line">        intermediate_dim = input_dim // <span class="number">2</span></span><br><span class="line">        self.to_q = nn.Conv2d(input_dim, intermediate_dim, <span class="number">1</span>)</span><br><span class="line">        self.to_k = nn.Conv2d(input_dim, intermediate_dim, <span class="number">1</span>)</span><br><span class="line">        self.to_v = nn.Conv2d(input_dim, intermediate_dim, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Conv2d(intermediate_dim, output_dim, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        q = self.to_q(x).squeeze()</span><br><span class="line">        k = self.to_k(x).squeeze()</span><br><span class="line">        v = self.to_v(x).squeeze()</span><br><span class="line"></span><br><span class="line">        u = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        u = torch.softmax(u, dim=<span class="number">1</span>)</span><br><span class="line">        out = torch.bmm(u, v)</span><br><span class="line">        out = out.unsqueeze(<span class="number">2</span>)</span><br><span class="line">        out = self.conv(out)</span><br><span class="line">        <span class="keyword">return</span> out + x</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img data-src="https://s2.loli.net/2024/01/19/9eNWHCpuiFsYLtU.png" alt="image-20240119110302126"></p><h2 id="SKNet-2019"><a href="#SKNet-2019" class="headerlink" title="SKNet 2019"></a>SKNet 2019</h2><p><img data-src="https://s2.loli.net/2024/01/23/ypZfsSKPBq9iLV6.png" alt="image-20240123192700386"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SKConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    https://arxiv.org/pdf/1903.06586.pdf</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, feature_dim, WH, M, G, r, stride=<span class="number">1</span>, L=<span class="number">32</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Constructor</span></span><br><span class="line"><span class="string">         Args:</span></span><br><span class="line"><span class="string">             features: input channel dimensionality.</span></span><br><span class="line"><span class="string">             WH: input spatial dimensionality, used for GAP kernel size.</span></span><br><span class="line"><span class="string">             M: the number of branchs.</span></span><br><span class="line"><span class="string">             G: num of convolution groups.</span></span><br><span class="line"><span class="string">             r: the radio for compute d, the length of z.</span></span><br><span class="line"><span class="string">             stride: stride, default 1.</span></span><br><span class="line"><span class="string">             L: the minimum dim of the vector z in paper, default 32.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        d = <span class="built_in">max</span>(<span class="built_in">int</span>(feature_dim / r), L)</span><br><span class="line">        self.M = M</span><br><span class="line">        self.feature_dim = feature_dim</span><br><span class="line">        self.convs = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">            self.convs.append(nn.Sequential(</span><br><span class="line">                nn.Conv2d(feature_dim, feature_dim, kernel_size=<span class="number">3</span> + i * <span class="number">2</span>, stride=stride, padding=<span class="number">1</span> + i, groups=G),</span><br><span class="line">                nn.BatchNorm2d(feature_dim),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">            ))</span><br><span class="line">        self.gap = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(feature_dim, d)</span><br><span class="line">        self.fcs = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">            self.fcs.append(</span><br><span class="line">                nn.Linear(d, feature_dim)</span><br><span class="line">            )</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i, conv <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.convs):</span><br><span class="line">            feat = conv(x).unsqueeze_(dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                feas = feat</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                feas = torch.cat((feas, feat), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        fea_U = torch.<span class="built_in">sum</span>(feas, dim=<span class="number">1</span>)</span><br><span class="line">        fea_s = self.gap(fea_U).squeeze_()</span><br><span class="line">        fea_z = self.fc(fea_s)</span><br><span class="line">        <span class="keyword">for</span> i, fc <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.fcs):</span><br><span class="line">            vector = fc(fea_z).unsqueeze_(dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                attention_vectors = vector</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                attention_vectors = torch.cat((attention_vectors, vector), dim=<span class="number">1</span>)</span><br><span class="line">        attention_vectors = self.softmax(attention_vectors)</span><br><span class="line">        attention_vectors = attention_vectors.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        fea_v = (feas*attention_vectors).<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> fea_v</span><br></pre></td></tr></table></figure><h2 id="CC-Net和Axial-Attention"><a href="#CC-Net和Axial-Attention" class="headerlink" title="CC-Net和Axial Attention"></a>CC-Net和Axial Attention</h2><p>看论文时提到了CC-Net使用了交叉注意了.</p><p>参考<a href="https://www.codenong.com/cs106760382/">Axial Attention 和 Criss-Cross Attention及其代码实现 | 码农家园 (codenong.com)</a>这篇blog,写的不错.</p><h2 id="Axial-Attention"><a href="#Axial-Attention" class="headerlink" title="Axial Attention"></a>Axial Attention</h2><p>轴向注意力,Axial Attention 的感受野是目标像素的同一行(或者同一列) 的W(或H)个像素</p><p>比如row attention</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实现轴向注意力中的 row Attention</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Softmax</span><br><span class="line"></span><br><span class="line"><span class="comment"># device = torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RowAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, q_k_dim, device</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        in_dim : int</span></span><br><span class="line"><span class="string">            channel of input img tensor</span></span><br><span class="line"><span class="string">        q_k_dim: int</span></span><br><span class="line"><span class="string">            channel of Q, K vector</span></span><br><span class="line"><span class="string">        device : torch.device</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(RowAttention, self).__init__()</span><br><span class="line">        self.in_dim = in_dim</span><br><span class="line">        self.q_k_dim = q_k_dim</span><br><span class="line">        self.device = device</span><br><span class="line">        </span><br><span class="line">        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.in_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">2</span>)</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>)).to(self.device)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        x : Tensor</span></span><br><span class="line"><span class="string">            4-D , (batch, in_dims, height, width) -- (b,c1,h,w)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## c1 = in_dims; c2 = q_k_dim</span></span><br><span class="line">        b, _, h, w = x.size()</span><br><span class="line">        </span><br><span class="line">        Q = self.query_conv(x) <span class="comment">#size = (b,c2, h,w)</span></span><br><span class="line">        K = self.key_conv(x)   <span class="comment">#size = (b, c2, h, w)</span></span><br><span class="line">        V = self.value_conv(x) <span class="comment">#size = (b, c1,h,w)</span></span><br><span class="line">        </span><br><span class="line">        Q = Q.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(b*h, -<span class="number">1</span>,w).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#size = (b*h,w,c2)</span></span><br><span class="line">        K = K.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(b*h, -<span class="number">1</span>,w)  <span class="comment">#size = (b*h,c2,w)</span></span><br><span class="line">        V = V.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(b*h, -<span class="number">1</span>,w)  <span class="comment">#size = (b*h, c1,w)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*h,w,w) [:,i,j] 表示Q的所有h的第 Wi行位置上所有通道值与 K的所有h的第 Wj列位置上的所有通道值的乘积，</span></span><br><span class="line">        <span class="comment"># 即(1,c2) * (c2,1) = (1,1)</span></span><br><span class="line">        row_attn = torch.bmm(Q,K) </span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        <span class="comment">#此时的 row_atten的[:,i,0:w] 表示Q的所有h的第 Wi行位置上所有通道值与 K的所有行的 所有列(0:w)的逐个位置上的所有通道值的乘积</span></span><br><span class="line">        <span class="comment">#此操作即为 Q的某个（i,j）与 K的（i,0:w）逐个位置的值的乘积，得到行attn</span></span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#对row_attn进行softmax</span></span><br><span class="line">        row_attn = self.softmax(row_attn) <span class="comment">#对列进行softmax，即[k,i,0:w] ，某一行的所有列加起来等于1，</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*h,c1,w) 这里先需要对row_atten进行 行列置换，使得某一列的所有行加起来等于1</span></span><br><span class="line">        <span class="comment">#[:,i,j]即为V的所有行的某个通道上，所有列的值 与 row_attn的行的乘积，即求权重和</span></span><br><span class="line">        out = torch.bmm(V,row_attn.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)) </span><br><span class="line">        <span class="comment">#size = (b,c1,h,2)</span></span><br><span class="line">        out = out.view(b,h,-<span class="number">1</span>,w).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)  </span><br><span class="line">        out = self.gamma*out + x </span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment">#实现轴向注意力中的 cols Attention</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">20</span>).to(device)</span><br><span class="line">row_attn = RowAttention(in_dim = <span class="number">8</span>, q_k_dim = <span class="number">4</span>,device = device).to(device)</span><br><span class="line"><span class="built_in">print</span>(row_attn(x).size())</span><br></pre></td></tr></table></figure><p>列注意力同理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实现轴向注意力中的 column Attention</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Softmax</span><br><span class="line"></span><br><span class="line"><span class="comment"># device = torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, q_k_dim, device</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        in_dim : int</span></span><br><span class="line"><span class="string">            channel of input img tensor</span></span><br><span class="line"><span class="string">        q_k_dim: int</span></span><br><span class="line"><span class="string">            channel of Q, K vector</span></span><br><span class="line"><span class="string">        device : torch.device</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ColAttention, self).__init__()</span><br><span class="line">        self.in_dim = in_dim</span><br><span class="line">        self.q_k_dim = q_k_dim</span><br><span class="line">        self.device = device</span><br><span class="line">        </span><br><span class="line">        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.in_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">2</span>)</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>)).to(self.device)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        x : Tensor</span></span><br><span class="line"><span class="string">            4-D , (batch, in_dims, height, width) -- (b,c1,h,w)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## c1 = in_dims; c2 = q_k_dim</span></span><br><span class="line">        b, _, h, w = x.size()</span><br><span class="line">        </span><br><span class="line">        Q = self.query_conv(x) <span class="comment">#size = (b,c2, h,w)</span></span><br><span class="line">        K = self.key_conv(x)   <span class="comment">#size = (b, c2, h, w)</span></span><br><span class="line">        V = self.value_conv(x) <span class="comment">#size = (b, c1,h,w)</span></span><br><span class="line">        </span><br><span class="line">        Q = Q.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(b*w, -<span class="number">1</span>,h).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#size = (b*w,h,c2)</span></span><br><span class="line">        K = K.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(b*w, -<span class="number">1</span>,h)  <span class="comment">#size = (b*w,c2,h)</span></span><br><span class="line">        V = V.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(b*w, -<span class="number">1</span>,h)  <span class="comment">#size = (b*w,c1,h)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*w,h,h) [:,i,j] 表示Q的所有W的第 Hi行位置上所有通道值与 K的所有W的第 Hj列位置上的所有通道值的乘积，</span></span><br><span class="line">        <span class="comment"># 即(1,c2) * (c2,1) = (1,1)</span></span><br><span class="line">        col_attn = torch.bmm(Q,K) </span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        <span class="comment">#此时的 col_atten的[:,i,0:w] 表示Q的所有W的第 Hi行位置上所有通道值与 K的所有W的 所有列(0:h)的逐个位置上的所有通道值的乘积</span></span><br><span class="line">        <span class="comment">#此操作即为 Q的某个（i,j）与 K的（i,0:h）逐个位置的值的乘积，得到列attn</span></span><br><span class="line">        <span class="comment">########</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#对row_attn进行softmax</span></span><br><span class="line">        col_attn = self.softmax(col_attn) <span class="comment">#对列进行softmax，即[k,i,0:w] ，某一行的所有列加起来等于1，</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b*w,c1,h) 这里先需要对col_atten进行 行列置换，使得某一列的所有行加起来等于1</span></span><br><span class="line">        <span class="comment">#[:,i,j]即为V的所有行的某个通道上，所有列的值 与 col_attn的行的乘积，即求权重和</span></span><br><span class="line">        out = torch.bmm(V,col_attn.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)) </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#size = (b,c1,h,w)</span></span><br><span class="line">        out = out.view(b,w,-<span class="number">1</span>,h).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        out = self.gamma*out + x </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"><span class="comment">#实现轴向注意力中的 cols Attention</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">20</span>).to(device)</span><br><span class="line">col_attn = ColAttention(<span class="number">8</span>, <span class="number">4</span>, device = device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(col_attn(x).size())</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Criss-Cross-Attention-Module-2019"><a href="#Criss-Cross-Attention-Module-2019" class="headerlink" title="Criss-Cross Attention Module 2019"></a>Criss-Cross Attention Module 2019</h2><p><img data-src="https://pic4.zhimg.com/80/v2-322dae3099e1ed29c2751c7c7efd88b7_720w.webp" alt="img"></p><p>CC-Attention 的感受野是与目标像素的同一行和同一列的(H + W - 1)个像素,目标元素的同一行和同一列.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrissCrossAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Criss-Cross Attention Module</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    reference: https://github.com/speedinghzl/CCNet</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CrissCrossAttention,self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.query_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">        self.key_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">        self.value_conv = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(in_dim,eps=<span class="number">1e-5</span>, momentum=<span class="number">0.01</span>, affine=<span class="literal">True</span>),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.softmax = Softmax(dim=<span class="number">3</span>)</span><br><span class="line">        self.INF = INF</span><br><span class="line">        self.gamma = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, query, key, value</span>):</span></span><br><span class="line">        m_batchsize, _, height, width = query.size()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        proj_query = self.query_conv(query)</span><br><span class="line">        proj_query_H = proj_query.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        proj_query_W = proj_query.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        proj_key = self.key_conv(key)</span><br><span class="line">        proj_key_H = proj_key.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height)</span><br><span class="line">        proj_key_W = proj_key.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        proj_value = self.value_conv(value)</span><br><span class="line">        proj_value_H = proj_value.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(m_batchsize*width,-<span class="number">1</span>,height)</span><br><span class="line">        proj_value_W = proj_value.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*height,-<span class="number">1</span>,width)</span><br><span class="line">        energy_H = (torch.bmm(proj_query_H, proj_key_H)+self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        energy_W = torch.bmm(proj_query_W, proj_key_W).view(m_batchsize,height,width,width)</span><br><span class="line">        concate = self.softmax(torch.cat([energy_H, energy_W], <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        att_H = concate[:,:,:,<span class="number">0</span>:height].permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>).contiguous().view(m_batchsize*width,height,height)</span><br><span class="line">        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width)</span><br><span class="line">        out_H = torch.bmm(proj_value_H, att_H.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)).view(m_batchsize,width,-<span class="number">1</span>,height).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">        out_W = torch.bmm(proj_value_W, att_W.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)).view(m_batchsize,height,-<span class="number">1</span>,width).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">return</span> self.gamma*(out_H + out_W) + value</span><br></pre></td></tr></table></figure><p><img data-src="https://pic4.zhimg.com/80/v2-03942c1de5a5a77aafbdb1a1fe697fb3_720w.webp" alt="img"></p><h2 id="Coordinate-Attention-2021"><a href="#Coordinate-Attention-2021" class="headerlink" title="Coordinate Attention 2021"></a>Coordinate Attention 2021</h2><p><img data-src="https://s2.loli.net/2024/01/19/ZrmAMkChLcbFpfg.png" alt="image-20240119195945841"></p><p>在通道注意力的基础上兼顾其位置关系，将通道注意力与空间注意力联合起来</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">h_sigmoid</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplace=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(h_sigmoid, self).__init__()</span><br><span class="line">        self.relu = nn.ReLU6(inplace=inplace)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.relu(x + <span class="number">3</span>) / <span class="number">6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">h_swish</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplace=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(h_swish, self).__init__()</span><br><span class="line">        self.sigmoid = h_sigmoid(inplace=inplace)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * self.sigmoid(</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CA</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inp, reduction</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CA, self).__init__()</span><br><span class="line">        <span class="comment"># h:height(行)   w:width(列)</span></span><br><span class="line">        self.pool_h = nn.AdaptiveAvgPool2d((<span class="literal">None</span>, <span class="number">1</span>))  <span class="comment"># (b,c,h,w)--&gt;(b,c,h,1)</span></span><br><span class="line">        self.pool_w = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="literal">None</span>))  <span class="comment"># (b,c,h,w)--&gt;(b,c,1,w)</span></span><br><span class="line"></span><br><span class="line">         <span class="comment"># mip = max(8, inp // reduction)  论文作者所用</span></span><br><span class="line">        mip =  inp // reduction  </span><br><span class="line"> </span><br><span class="line">        self.conv1 = nn.Conv2d(inp, mip, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(mip)</span><br><span class="line">        self.act = h_swish()</span><br><span class="line"> </span><br><span class="line">        self.conv_h = nn.Conv2d(mip, inp, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.conv_w = nn.Conv2d(mip, inp, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        identity = x</span><br><span class="line"> </span><br><span class="line">        n, c, h, w = x.size()</span><br><span class="line">        x_h = self.pool_h(x)  <span class="comment"># (b,c,h,1)</span></span><br><span class="line">        x_w = self.pool_w(x).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)  <span class="comment"># (b,c,w,1)</span></span><br><span class="line"> </span><br><span class="line">        y = torch.cat([x_h, x_w], dim=<span class="number">2</span>)</span><br><span class="line">        y = self.conv1(y)</span><br><span class="line">        y = self.bn1(y)</span><br><span class="line">        y = self.act(y)</span><br><span class="line"> </span><br><span class="line">        x_h, x_w = torch.split(y, [h, w], dim=<span class="number">2</span>)</span><br><span class="line">        x_w = x_w.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">        a_h = self.conv_h(x_h).sigmoid()</span><br><span class="line">        a_w = self.conv_w(x_w).sigmoid()</span><br><span class="line"> </span><br><span class="line">        out = identity * a_w * a_h</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h2 id="Attentional-Feature-Fusion-2021"><a href="#Attentional-Feature-Fusion-2021" class="headerlink" title="Attentional Feature Fusion  2021"></a>Attentional Feature Fusion  2021</h2><p><a href="https://openaccess.thecvf.com/content/WACV2021/html/Dai_Attentional_Feature_Fusion_WACV_2021_paper.html">WACV 2021 Open Access Repository (thecvf.com)</a></p><p><a href="https://github.com/YimianDai/open-aff">YimianDai/open-aff: code and trained models for “Attentional Feature Fusion” (github.com)</a></p><p>这些注意力模块通常用在一些block(或叫unit)块中,然后一般把这些块放到多尺度的网络下</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://blog.csdn.net/weixin_43718675/article/details/106760382">Axial Attention 和 Criss-Cross Attention及其代码实现_cross attention代码-CSDN博客</a></li><li><a href="https://blog.csdn.net/qwedsaewq/article/details/89052643">sknet阅读笔记及pytorch实现代码_pytorch sknet-CSDN博客</a></li><li><a href="https://blog.csdn.net/weixin_43427721/article/details/124652525?ops_request_misc=%7B%22request%5Fid%22%3A%22170601489116800226596213%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&amp;request_id=170601489116800226596213&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-124652525-null-null.nonecase&amp;utm_term=注意力&amp;spm=1018.2226.3001.4450">【注意力机制集锦】Channel Attention通道注意力网络结构、源码解读系列一_通道注意力机制结构图-CSDN博客</a></li><li><a href="https://blog.csdn.net/weixin_43427721/article/details/124766242">【注意力机制集锦2】BAM&amp;SGE&amp;DAN原文、结构、源码详解_bam注意力机制-CSDN博客</a></li></ol><p>Thanks to <a href="https://github.com/lyp2333/External-Attention-pytorch/tree/master">lyp2333/External-Attention-pytorch (github.com)</a> and <a href="https://github.com/xmu-xiaoma666/External-Attention-pytorch">xmu-xiaoma666/External-Attention-pytorch: 🍀 Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.⭐⭐⭐ (github.com)</a></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码.&lt;br&gt;</summary>
    
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/categories/deep-learning/"/>
    
    
    <category term="deep learning" scheme="https://www.sekyoro.top/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>Golang学习:使用Gin</title>
    <link href="https://www.sekyoro.top/2024/01/17/Golang%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8Gin/"/>
    <id>https://www.sekyoro.top/2024/01/17/Golang%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8Gin/</id>
    <published>2024-01-17T10:17:45.000Z</published>
    <updated>2024-01-17T10:46:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Go语言simple并且easy,内置了很多有用的库,对并发支持比较好并且官方(指Google)还是比较重视的.<br><span id="more"></span><br>Go的官方资料就比较好学习<a href="https://go.dev/">The Go Programming Language</a>,有个tutorial还有个examples.写了个使用Colly用来爬取图片和Gin用来显示图片的代码.</p><p>目录结构比较简单</p><p><img data-src="https://s2.loli.net/2024/01/17/xMBdCzhvfZEgVAT.png" alt="image-20240117183718713"></p><p>使用Go的mod进行配置项目,比如<code>go mod init &lt;project name&gt;</code>初始化</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/gin-gonic/gin&quot;</span></span><br><span class="line"><span class="string">&quot;sekyoro.top/Goimg/routes&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">router := gin.Default()</span><br><span class="line">r := router.Group(<span class="string">&quot;/api&quot;</span>)</span><br><span class="line">router.Static(<span class="string">&quot;/img&quot;</span>, <span class="string">&quot;./imgs&quot;</span>)</span><br><span class="line">routes.DownloadPicRoutes(r)</span><br><span class="line">routes.ShowPicRoutes(r)</span><br><span class="line">routes.GetPicRoutes(r</span><br><span class="line">router.Run(<span class="string">&quot;:8080&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里设置了静态资源并使用分组路由构建路由到处理的方法.</p><p>在routes文件夹下就有对应的路由,比如在下载文件下,设置了两个路由.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> routes</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/gin-gonic/gin&quot;</span></span><br><span class="line"><span class="string">&quot;sekyoro.top/Goimg/handlers&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DownloadPicRoutes</span><span class="params">(router *gin.RouterGroup)</span></span> &#123;</span><br><span class="line">router.GET(<span class="string">&quot;/pix&quot;</span>, handlers.DownloadPixvisionPicHandler)</span><br><span class="line">router.GET(<span class="string">&quot;/booru/:type&quot;</span>, handlers.DownloadBooruPicHandler)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在downloader目录下写进行处理的方法.比如下面是<code>DownloadPixvisionPicHandler.go</code>去爬取图片并保存到本地</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> handlers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;log&quot;</span></span><br><span class="line"><span class="string">&quot;net/http&quot;</span></span><br><span class="line"><span class="string">&quot;os&quot;</span></span><br><span class="line"><span class="string">&quot;path/filepath&quot;</span></span><br><span class="line"><span class="string">&quot;time&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;github.com/gin-gonic/gin&quot;</span></span><br><span class="line"><span class="string">&quot;github.com/gocolly/colly/v2&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DownloadPixvisionPicHandler</span><span class="params">(ctx *gin.Context)</span></span> &#123;</span><br><span class="line">counter  := <span class="number">0</span></span><br><span class="line">allow_img_site := checkAllowSite()</span><br><span class="line"><span class="comment">// fmt.Println(allow_img_site)</span></span><br><span class="line">c := colly.NewCollector(colly.UserAgent(userAgent), colly.AllowedDomains(allow_img_site...),</span><br><span class="line">colly.Async())</span><br><span class="line">c.SetRequestTimeout(<span class="number">20</span> * time.Second)</span><br><span class="line"></span><br><span class="line">c.Limit(&amp;colly.LimitRule&#123;</span><br><span class="line">DomainGlob:  <span class="string">&quot;*pximg.*&quot;</span>,</span><br><span class="line">Parallelism: <span class="number">5</span>,</span><br><span class="line"><span class="comment">//Delay:      5 * time.Second,</span></span><br><span class="line">RandomDelay: <span class="number">500</span> * time.Duration(time.Millisecond),</span><br><span class="line">&#125;)</span><br><span class="line">c.Limit(&amp;colly.LimitRule&#123;</span><br><span class="line">DomainGlob:  <span class="string">&quot;*pixivision.*&quot;</span>,</span><br><span class="line">Parallelism: <span class="number">5</span>,</span><br><span class="line">Delay:       <span class="number">200</span> * time.Duration(time.Millisecond),</span><br><span class="line">RandomDelay: <span class="number">500</span> * time.Duration(time.Millisecond),</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">if</span> proxy != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> proxy[<span class="string">&quot;http&quot;</span>] != <span class="literal">nil</span> &#123;</span><br><span class="line">err := c.SetProxy(fmt.Sprintf(<span class="string">&quot;http://%s&quot;</span>, proxy[<span class="string">&quot;http&quot;</span>].(<span class="keyword">string</span>)))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Panic(err.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> proxy[<span class="string">&quot;socks5&quot;</span>] != <span class="literal">nil</span> &#123;</span><br><span class="line">err := c.SetProxy(fmt.Sprintf(<span class="string">&quot;socks5://%s&quot;</span>, proxy[<span class="string">&quot;socks5&quot;</span>].(<span class="keyword">string</span>)))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Panic(err.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">limit_page, ok := conf[<span class="string">&quot;limit_page&quot;</span>].(<span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">log.Panic(<span class="string">&quot;爬取图片目录数配置出错&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">log.Panic(<span class="string">&quot;下载路径配置出错&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Find and visit all links</span></span><br><span class="line">c.OnHTML(<span class="string">&quot;a[href]&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(e *colly.HTMLElement)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> e.DOM.Parent().HasClass(<span class="string">&quot;arc__title&quot;</span>) &#123;</span><br><span class="line">log.Default().Println(<span class="string">&quot;Link found:&quot;</span>, e.Attr(<span class="string">&quot;href&quot;</span>))</span><br><span class="line"><span class="keyword">if</span> counter &gt;= limit_page &#123;</span><br><span class="line">ctx.JSON(http.StatusOK, fmt.Sprintf(<span class="string">&quot;success! %d directory image&quot;</span>, limit_page))</span><br><span class="line">&#125;</span><br><span class="line">e.Request.Visit(e.Attr(<span class="string">&quot;href&quot;</span>))</span><br><span class="line">counter += <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">c.OnHTML(<span class="string">&quot;div[class=&#x27;_article-main&#x27;]&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(e *colly.HTMLElement)</span></span> &#123;</span><br><span class="line">title := e.ChildText(<span class="string">&quot;h1[class=&#x27;am__title&#x27;]&quot;</span>)</span><br><span class="line"><span class="comment">// log.Default().Println(&quot;title:&quot;, title)</span></span><br><span class="line"><span class="comment">// p := Pics&#123;title: title, pics: make(map[string]string)&#125;</span></span><br><span class="line">err := os.MkdirAll(filepath.Join(download_root_folder, title), os.ModePerm)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Default().Println(err.Error())</span><br><span class="line">&#125;</span><br><span class="line">e.ForEach(<span class="string">&quot;div.article-item:not(._feature-article-body__paragraph) div.am__work__main&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(i <span class="keyword">int</span>, h *colly.HTMLElement)</span></span> &#123;</span><br><span class="line">log.Default().Println(<span class="string">&quot;pic:&quot;</span>, h.ChildAttr(<span class="string">&quot;img&quot;</span>, <span class="string">&quot;src&quot;</span>))</span><br><span class="line">img_src := h.ChildAttr(<span class="string">&quot;img&quot;</span>, <span class="string">&quot;src&quot;</span>)</span><br><span class="line">h.Request.Visit(img_src)</span><br><span class="line">h.Request.Ctx.Put(<span class="string">&quot;title&quot;</span>, title)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">&#125;)</span><br><span class="line">c.OnResponse(<span class="function"><span class="keyword">func</span><span class="params">(r *colly.Response)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> img_url URL_path = url_path(r.Request.URL.Path)</span><br><span class="line"><span class="comment">// log.Default().Println(&quot;img_name:&quot;, img_name)</span></span><br><span class="line"><span class="keyword">if</span> img_url.isPic() &#123;</span><br><span class="line">img_path := filepath.Join(download_root_folder,r.Ctx.Get(<span class="string">&quot;title&quot;</span>), <span class="keyword">string</span>(img_url.(url_path)))</span><br><span class="line">r.Save(img_path)</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">c.OnRequest(<span class="function"><span class="keyword">func</span><span class="params">(r *colly.Request)</span></span> &#123;</span><br><span class="line">log.Default().Println(<span class="string">&quot;Visiting&quot;</span>, r.URL)</span><br><span class="line"><span class="keyword">if</span> r.URL.Host == <span class="string">&quot;i.pximg.net&quot;</span> &#123;</span><br><span class="line">r.Headers.Set(<span class="string">&quot;Referer&quot;</span>, <span class="string">&quot;https://www.pixivision.net/&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">c.OnError(<span class="function"><span class="keyword">func</span><span class="params">(r *colly.Response, err error)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">log.Default().Println(<span class="string">&quot;Request URL:&quot;</span>, r.Request.URL, <span class="string">&quot;failed with response:&quot;</span>, <span class="keyword">string</span>(r.Body), <span class="string">&quot;\nError:&quot;</span>, err.Error())</span><br><span class="line">&#125;)</span><br><span class="line">c.Visit(pixivision_site)</span><br><span class="line">c.Wait()</span><br><span class="line">ctx.JSON(http.StatusOK, fmt.Sprintf(<span class="string">&quot;success! %d directory image&quot;</span>, limit_page))</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在<code>configure.yaml</code>中进行配置相关信息.</p><p>最后部署可以考虑使用render<a href="https://render.com/">Cloud Application Hosting for Developers | Render</a>,来玩玩吧<a href="https://go-img.onrender.com/api/show">https://go-img.onrender.com/api/show</a></p><p>完整代码可以在我的github<a href="https://github.com/drowning-in-codes/myGo">drowning-in-codes/myGo (github.com)</a>上看,我也上传了docker<a href="https://hub.docker.com/r/proanimer/goimg">proanimer/goimg - Docker Image</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull proanimer/goimg</span><br></pre></td></tr></table></figure><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Go语言simple并且easy,内置了很多有用的库,对并发支持比较好并且官方(指Google)还是比较重视的.&lt;br&gt;</summary>
    
    
    
    
    <category term="Golang" scheme="https://www.sekyoro.top/tags/Golang/"/>
    
    <category term="Gin" scheme="https://www.sekyoro.top/tags/Gin/"/>
    
  </entry>
  
  <entry>
    <title>gRPC学习</title>
    <link href="https://www.sekyoro.top/2024/01/05/grpc%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2024/01/05/grpc%E5%AD%A6%E4%B9%A0/</id>
    <published>2024-01-05T11:16:58.000Z</published>
    <updated>2024-01-06T08:03:34.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>RPC是远程调用,而google实现了grpc比较方便地实现了远程调用,gRPC是一个现代的开源远程过程调用(RPC)框架<br><span id="more"></span></p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><p>在gRPC中，客户端应用程序可以直接调用另一台计算机上的服务器应用程序上的方法，就好像它是本地对象一样。</p><blockquote><p>远程过程调用是一个分布式计算的客户端-服务器（Client/Server）的例子，它简单而又广受欢迎。<br>远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。<br>由于存在各式各样的变体和细节差异，对应地派生了各式远程过程调用协议，而且它们并不互相兼容。</p><p>为了允许不同的客户端均能访问服务器，<strong>许多标准化的 RPC 系统应运而生了。其中大部分采用接口描述语言（Interface Description Language，IDL），方便跨平台的远程过程调用</strong>。</p></blockquote><p>与许多RPC系统一样，gRPC基于定义服务的思想，指定可以通过其参数和返回类型远程调用的方法。在服务器端，服务器实现了这个接口，并运行gRPC服务器来处理客户端调用。在客户端，客户端有一个stub（在某些语言中称为客户端），它提供与服务器相同的方法。</p><p>它具有许多特性</p><ol><li><strong>强大的IDL特性</strong><br>RPC使用ProtoBuf来定义服务，ProtoBuf是由Google开发的一种数据序列化协议，性能出众，得到了广泛的应用。</li><li>支持多种语言<br>支持C++、Java、Go、Python、Ruby、C#、Node.js、Android Java、Objective-C、PHP等编程语言。</li><li>基于<strong>HTTP/2</strong>标准设计</li></ol><p><img data-src="https://grpc.io/img/landing-2.svg" alt="Concept Diagram"></p><p>默认情况下，gRPC使用<strong>Protocol Buffers</strong>，这是谷歌成熟的开源机制，<strong>用于序列化结构化数据(尽管它可以与JSON等其他数据格式一起使用)</strong></p><h3 id="与REST差异"><a href="#与REST差异" class="headerlink" title="与REST差异"></a>与REST差异</h3><p>RPC 的消息传输可以通过 TCP、UDP 或者 HTTP等，所以有时候我们称之为 RPC over TCP、 RPC over HTTP。</p><p>RPC 通过 HTTP 传输消息的时候和 RESTful的架构是类似的，但是也有不同。</p><blockquote><ul><li>gRPC使用HTTP/2，而REST使用HTTP1.1</li><li>gRPC使用协议缓冲区数据格式，而不是REST API中通常使用的标准JSON数据格式</li><li>使用gRPC,可以利用HTTP/2功能，如服务器端流式传输、客户端流式传输，甚至双向流式传输</li></ul></blockquote><p>首先 RPC 的客户端和服务器端师紧耦合的，客户端需要知道调用的过程的名字，过程的参数以及它们的类型、顺序等。<strong>一旦服务器更改了过程的实现，客户端的实现很容易出问题</strong>。RESTful基于 http的语义操作资源，参数的顺序一般没有关系，也很容易的<strong>通过代理转换链接和资源位置</strong>，从这一点上来说，RESTful 更灵活。</p><p>其次，它们操作的对象不一样。 RPC 操作的是方法和过程，它要操作的是方法对象。 RESTful 操作的是资源(resource)，而不是方法。</p><p>第三，RESTful执行的是对资源的操作，增加、查找、修改和删除等,主要是CURD，所以如果你要实现一个特定目的的操作，比如为名字姓张的学生的数学成绩都加上10这样的操作，<br>RESTful的API设计起来就不是那么直观或者有意义。在这种情况下, RPC的实现更有意义，它可以实现一个直接的方法方法供客户端调用</p><p><strong>RPC over TCP可以通过长连接减少连接的建立所产生的花费</strong>，在调用次数非常巨大的时候(这是目前互联网公司经常遇到的情况,大并发的情况下)，这个花费影响是非常巨大的。<br>当然 RESTful 也可以通过 keep-alive 实现长连接, 但是它最大的一个问题是它的<strong>request-response模型是阻塞的</strong> (http1.0和 http1.1, http 2.0没这个问题)，<br>发送一个请求后只有等到response返回才能发送第二个请求 (有些http server实现了pipeling的功能，但不是标配), RPC的实现没有这个限制。</p><h3 id="其他RPC框架"><a href="#其他RPC框架" class="headerlink" title="其他RPC框架"></a>其他RPC框架</h3><p>目前的 RPC 框架大致有两种不同的侧重方向,一种<strong>偏重于服务治理</strong>,另一种<strong>偏重于跨语言调用</strong>。</p><p>服务治理型的 RPC 框架有Alibabs <strong>Dubbo</strong>、Motan 等，这类的 RPC 框架的特点是功能丰富，<strong>提供高性能的远程调用以及服务发现和治理功能</strong>，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。</p><p>跨语言调用型的 RPC 框架有 Thrift、<strong>gRPC</strong>、Hessian、Finagle 等，<strong>这一类的 RPC 框架重点关注于服务的跨语言调用，能够支持大部分的语言进行语言无关的调用</strong>，非常适合于为不同语言提供通用远程服务的场景。但这类框架没有服务发现相关机制，实际使用时一般需要代理层进行请求转发和负载均衡策略控制。</p><p><a href="https://thrift.apache.org/">thrift</a>是Apache的一个跨语言的高性能的服务框架，也得到了广泛的应用。它的功能类似 gRPC, 支持跨语言，不支持服务治理。</p><p><a href="https://github.com/smallnest/rpcx">rpcx</a> 是一个分布式的Go语言的 RPC 框架，支持Zookepper、etcd、consul多种服务发现方式，多种服务路由方式， 是目前性能最好的 RPC 框架之一</p><h3 id="使用protobuf"><a href="#使用protobuf" class="headerlink" title="使用protobuf"></a>使用protobuf</h3><p>定义要在proto文件中序列化的数据的结构：这是一个扩展名为.proto的普通文本文件。协议缓冲区数据被构造为消息，其中每个消息都是一个包含一系列名值对（称为字段）的信息的小逻辑记录。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">  <span class="built_in">string</span> name = <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">int32</span> id = <span class="number">2</span>;</span><br><span class="line">  <span class="built_in">bool</span> has_ponycopter = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>指定了数据结构,就可以<strong>使用协议缓冲区编译器protoc从proto定义中生成首选语言的数据访问类</strong>.</p><p>它们为每个字段提供了简单的访问器,如name()和set_name()，以及将整个结构序列化到原始字节/从原始字节解析整个结构的方法。</p><p>因此，例如，如果选择的语言是C++，那么在上面的示例中运行编译器将生成一个名为Person的类。然后，您可以在应用程序中使用此类来填充、序列化和检索Person协议缓冲区消息。</p><p>gRPC使用protoc和一个特殊的gRPC插件从proto文件中生成代码：<strong>可以获得生成的gRPC客户端和服务器代码，以及用于填充、序列化和检索消息类型的常规协议缓冲区代码。</strong>(截至目前protobuf最新版本是v3)</p><h2 id="gRPC-in-Go"><a href="#gRPC-in-Go" class="headerlink" title="gRPC in Go"></a>gRPC in Go</h2><h3 id="下载protoc"><a href="#下载protoc" class="headerlink" title="下载protoc"></a>下载protoc</h3><blockquote><p>虽然不是强制性的，但gRPC应用程序通常利用proto buffer进行服务定义和数据序列化。</p></blockquote><p><a href="https://github.com/protocolbuffers/protobuf/releases">Releases · protocolbuffers/protobuf (github.com)</a></p><p>protoc用于编译.proto文件，其中包含服务和消息定义,Linux或Mac直接使用对应包管理器下载即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt install -y protobuf-compiler</span><br><span class="line">protoc --version  <span class="comment"># Ensure compiler version is 3+</span></span><br></pre></td></tr></table></figure><p>Windows在github上下载二进制包<a href="https://github.com/protocolbuffers/protobuf/releases">Releases · protocolbuffers/protobuf (github.com)</a></p><h3 id="protocol-compiler的Go插件"><a href="#protocol-compiler的Go插件" class="headerlink" title="protocol compiler的Go插件"></a>protocol compiler的Go插件</h3><h4 id="下载protoc-go-gen"><a href="#下载protoc-go-gen" class="headerlink" title="下载protoc-go-gen"></a>下载protoc-go-gen</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2</span><br><span class="line">go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28</span><br></pre></td></tr></table></figure><p>下载zip的文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b v1.60.1 --depth 1 https://github.com/grpc/grpc-go</span><br></pre></td></tr></table></figure><h4 id="proto文件"><a href="#proto文件" class="headerlink" title="proto文件"></a>proto文件</h4><p>下面定义了服务</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Interface exported by the server.</span></span><br><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">RouteGuide</span> </span>&#123;</span><br><span class="line">  <span class="comment">// A simple RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Obtains the feature at a given position.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// A feature with an empty name is returned if there&#x27;s no feature at the given</span></span><br><span class="line">  <span class="comment">// position.</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> GetFeature(Point) <span class="keyword">returns</span> (Feature) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A server-to-client streaming RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Obtains the Features available within the given Rectangle.  Results are</span></span><br><span class="line">  <span class="comment">// streamed rather than returned at once (e.g. in a response message with a</span></span><br><span class="line">  <span class="comment">// repeated field), as the rectangle may cover a large area and contain a</span></span><br><span class="line">  <span class="comment">// huge number of features.</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> ListFeatures(Rectangle) <span class="keyword">returns</span> (stream Feature) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A client-to-server streaming RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Accepts a stream of Points on a route being traversed, returning a</span></span><br><span class="line">  <span class="comment">// RouteSummary when traversal is completed.</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> RecordRoute(stream Point) <span class="keyword">returns</span> (RouteSummary) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A Bidirectional streaming RPC.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Accepts a stream of RouteNotes sent while a route is being traversed,</span></span><br><span class="line">  <span class="comment">// while receiving other RouteNotes (e.g. from other users).</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> RouteChat(stream RouteNote) <span class="keyword">returns</span> (stream RouteNote) </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中涉及到一些参数message表示传递数据.</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Points are represented as latitude-longitude pairs in the E7 representation</span></span><br><span class="line"><span class="comment">// (degrees multiplied by 10**7 and rounded to the nearest integer).</span></span><br><span class="line"><span class="comment">// Latitudes should be in the range +/- 90 degrees and longitude should be in</span></span><br><span class="line"><span class="comment">// the range +/- 180 degrees (inclusive).</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">  <span class="built_in">int32</span> latitude = <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">int32</span> longitude = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A latitude-longitude rectangle, represented as two diagonally opposite</span></span><br><span class="line"><span class="comment">// points &quot;lo&quot; and &quot;hi&quot;.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Rectangle</span> </span>&#123;</span><br><span class="line">  <span class="comment">// One corner of the rectangle.</span></span><br><span class="line">  Point lo = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The other corner of the rectangle.</span></span><br><span class="line">  Point hi = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A feature names something at a given point.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If a feature could not be named, the name is empty.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Feature</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The name of the feature.</span></span><br><span class="line">  <span class="built_in">string</span> name = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The point where the feature is detected.</span></span><br><span class="line">  Point location = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A RouteNote is a message sent while at a given point.</span></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">RouteNote</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The location from which the message is sent.</span></span><br><span class="line">  Point location = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The message to be sent.</span></span><br><span class="line">  <span class="built_in">string</span> <span class="class"><span class="keyword">message</span> = 2;</span></span><br><span class="line"><span class="class">&#125;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">// <span class="title">A</span> RouteSummary is received in response to a RecordRoute rpc.</span></span><br><span class="line"><span class="class">//</span></span><br><span class="line"><span class="class">// It contains the number of individual points received, the number of</span></span><br><span class="line"><span class="class">// detected features, and the total distance covered as the cumulative sum of</span></span><br><span class="line"><span class="class">// the distance between each point.</span></span><br><span class="line"><span class="class">message RouteSummary </span>&#123;</span><br><span class="line">  <span class="comment">// The number of points received.</span></span><br><span class="line">  <span class="built_in">int32</span> point_count = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The number of known features passed while traversing the route.</span></span><br><span class="line">  <span class="built_in">int32</span> feature_count = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The distance covered in metres.</span></span><br><span class="line">  <span class="built_in">int32</span> distance = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The duration of the traversal in seconds.</span></span><br><span class="line">  <span class="built_in">int32</span> elapsed_time = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的两个文件包括message实现和用于server,client的代码</p><p>在pb.go文件中对于每个message实现了其type,比如对于<code>Rectangle</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Rectangle <span class="keyword">struct</span> &#123;</span><br><span class="line">state         protoimpl.MessageState</span><br><span class="line">sizeCache     protoimpl.SizeCache</span><br><span class="line">unknownFields protoimpl.UnknownFields</span><br><span class="line"></span><br><span class="line"><span class="comment">// One corner of the rectangle.</span></span><br><span class="line">Lo *Point <span class="string">`protobuf:&quot;bytes,1,opt,name=lo,proto3&quot; json:&quot;lo,omitempty&quot;`</span></span><br><span class="line"><span class="comment">// The other corner of the rectangle.</span></span><br><span class="line">Hi *Point <span class="string">`protobuf:&quot;bytes,2,opt,name=hi,proto3&quot; json:&quot;hi,omitempty&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">Reset</span><span class="params">()</span></span> &#123;</span><br><span class="line">*x = Rectangle&#123;&#125;</span><br><span class="line"><span class="keyword">if</span> protoimpl.UnsafeEnabled &#123;</span><br><span class="line">mi := &amp;file_routeguide_route_guide_proto_msgTypes[<span class="number">1</span>]</span><br><span class="line">ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))</span><br><span class="line">ms.StoreMessageInfo(mi)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">String</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> protoimpl.X.MessageStringOf(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Rectangle)</span> <span class="title">ProtoMessage</span><span class="params">()</span></span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">ProtoReflect</span><span class="params">()</span> <span class="title">protoreflect</span>.<span class="title">Message</span></span> &#123;</span><br><span class="line">mi := &amp;file_routeguide_route_guide_proto_msgTypes[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">if</span> protoimpl.UnsafeEnabled &amp;&amp; x != <span class="literal">nil</span> &#123;</span><br><span class="line">ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))</span><br><span class="line"><span class="keyword">if</span> ms.LoadMessageInfo() == <span class="literal">nil</span> &#123;</span><br><span class="line">ms.StoreMessageInfo(mi)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> ms</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> mi.MessageOf(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Deprecated: Use Rectangle.ProtoReflect.Descriptor instead.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Rectangle)</span> <span class="title">Descriptor</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> file_routeguide_route_guide_proto_rawDescGZIP(), []<span class="keyword">int</span>&#123;<span class="number">1</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">GetLo</span><span class="params">()</span> *<span class="title">Point</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> x != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> x.Lo</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *Rectangle)</span> <span class="title">GetHi</span><span class="params">()</span> *<span class="title">Point</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> x != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> x.Hi</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于Client来说,定义接口.首先使用grpc库中的<code>grpc.ClientConnInterface</code>作为routeGuideClient的成员.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> routeGuideClient <span class="keyword">struct</span> &#123;</span><br><span class="line">cc grpc.ClientConnInterface</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>给结构体<code>routeGuideClient</code>实现多个方法,并定义接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> RouteGuideClient <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// A simple RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the feature at a given position.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A feature with an empty name is returned if there&#x27;s no feature at the given</span></span><br><span class="line"><span class="comment">// position.</span></span><br><span class="line">GetFeature(ctx context.Context, in *Point, opts ...grpc.CallOption) (*Feature, error)</span><br><span class="line"><span class="comment">// A server-to-client streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the Features available within the given Rectangle.  Results are</span></span><br><span class="line"><span class="comment">// streamed rather than returned at once (e.g. in a response message with a</span></span><br><span class="line"><span class="comment">// repeated field), as the rectangle may cover a large area and contain a</span></span><br><span class="line"><span class="comment">// huge number of features.</span></span><br><span class="line">ListFeatures(ctx context.Context, in *Rectangle, opts ...grpc.CallOption) (RouteGuide_ListFeaturesClient, error)</span><br><span class="line"><span class="comment">// A client-to-server streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of Points on a route being traversed, returning a</span></span><br><span class="line"><span class="comment">// RouteSummary when traversal is completed.</span></span><br><span class="line">RecordRoute(ctx context.Context, opts ...grpc.CallOption) (RouteGuide_RecordRouteClient, error)</span><br><span class="line"><span class="comment">// A Bidirectional streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of RouteNotes sent while a route is being traversed,</span></span><br><span class="line"><span class="comment">// while receiving other RouteNotes (e.g. from other users).</span></span><br><span class="line">RouteChat(ctx context.Context, opts ...grpc.CallOption) (RouteGuide_RouteChatClient, error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后通过<code>NewRouteGuideClient</code>返回结构体</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewRouteGuideClient</span><span class="params">(cc grpc.ClientConnInterface)</span> <span class="title">RouteGuideClient</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;routeGuideClient&#123;cc&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现结构体的方法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *routeGuideClient)</span> <span class="title">GetFeature</span><span class="params">(ctx context.Context, in *Point, opts ...grpc.CallOption)</span> <span class="params">(*Feature, error)</span></span> &#123;</span><br><span class="line">out := <span class="built_in">new</span>(Feature)</span><br><span class="line">err := c.cc.Invoke(ctx, RouteGuide_GetFeature_FullMethodName, in, out, opts...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> out, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *routeGuideClient)</span> <span class="title">ListFeatures</span><span class="params">(ctx context.Context, in *Rectangle, opts ...grpc.CallOption)</span> <span class="params">(RouteGuide_ListFeaturesClient, error)</span></span> &#123;</span><br><span class="line">stream, err := c.cc.NewStream(ctx, &amp;RouteGuide_ServiceDesc.Streams[<span class="number">0</span>], RouteGuide_ListFeatures_FullMethodName, opts...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">x := &amp;routeGuideListFeaturesClient&#123;stream&#125;</span><br><span class="line"><span class="keyword">if</span> err := x.ClientStream.SendMsg(in); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> err := x.ClientStream.CloseSend(); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> x, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果涉及stream还有新的结构,定义结构体,方法和接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> RouteGuide_ListFeaturesClient <span class="keyword">interface</span> &#123;</span><br><span class="line">Recv() (*Feature, error)</span><br><span class="line">grpc.ClientStream</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> routeGuideListFeaturesClient <span class="keyword">struct</span> &#123;</span><br><span class="line">grpc.ClientStream</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(x *routeGuideListFeaturesClient)</span> <span class="title">Recv</span><span class="params">()</span> <span class="params">(*Feature, error)</span></span> &#123;</span><br><span class="line">m := <span class="built_in">new</span>(Feature)</span><br><span class="line"><span class="keyword">if</span> err := x.ClientStream.RecvMsg(m); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> m, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于server类似,定义接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> RouteGuideServer <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// A simple RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the feature at a given position.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A feature with an empty name is returned if there&#x27;s no feature at the given</span></span><br><span class="line"><span class="comment">// position.</span></span><br><span class="line">GetFeature(context.Context, *Point) (*Feature, error)</span><br><span class="line"><span class="comment">// A server-to-client streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Obtains the Features available within the given Rectangle.  Results are</span></span><br><span class="line"><span class="comment">// streamed rather than returned at once (e.g. in a response message with a</span></span><br><span class="line"><span class="comment">// repeated field), as the rectangle may cover a large area and contain a</span></span><br><span class="line"><span class="comment">// huge number of features.</span></span><br><span class="line">ListFeatures(*Rectangle, RouteGuide_ListFeaturesServer) error</span><br><span class="line"><span class="comment">// A client-to-server streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of Points on a route being traversed, returning a</span></span><br><span class="line"><span class="comment">// RouteSummary when traversal is completed.</span></span><br><span class="line">RecordRoute(RouteGuide_RecordRouteServer) error</span><br><span class="line"><span class="comment">// A Bidirectional streaming RPC.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Accepts a stream of RouteNotes sent while a route is being traversed,</span></span><br><span class="line"><span class="comment">// while receiving other RouteNotes (e.g. from other users).</span></span><br><span class="line">RouteChat(RouteGuide_RouteChatServer) error</span><br><span class="line">mustEmbedUnimplementedRouteGuideServer()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="实现server和client"><a href="#实现server和client" class="headerlink" title="实现server和client"></a>实现server和client</h4><p>当使用protoc生成文件之后,就可以写server和client了.</p><h5 id="server"><a href="#server" class="headerlink" title="server"></a>server</h5><p>定义结构体,注意定义时加上<code>pb.UnimplementedRouteGuideServer</code>这样避免有些方法没有实现.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> routeGuideServer <span class="keyword">struct</span> &#123;</span><br><span class="line">pb.UnimplementedRouteGuideServer</span><br><span class="line">savedFeatures []*pb.Feature <span class="comment">// read-only after initialized</span></span><br><span class="line"></span><br><span class="line">mu         sync.Mutex <span class="comment">// protects routeNotes</span></span><br><span class="line">routeNotes <span class="keyword">map</span>[<span class="keyword">string</span>][]*pb.RouteNote</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现接口满足的方法.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">GetFeature</span><span class="params">(ctx context.Context, point *pb.Point)</span> <span class="params">(*pb.Feature, error)</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">ListFeatures</span><span class="params">(rect *pb.Rectangle, stream pb.RouteGuide_ListFeaturesServer)</span></span> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">RecordRoute</span><span class="params">(stream pb.RouteGuide_RecordRouteServer)</span></span> </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *routeGuideServer)</span> <span class="title">RouteChat</span><span class="params">(stream pb.RouteGuide_RouteChatServer)</span></span></span><br></pre></td></tr></table></figure><p>然后使用tcp链接新建grpc服务</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">flag.Parse()</span><br><span class="line">lis, err := net.Listen(<span class="string">&quot;tcp&quot;</span>, fmt.Sprintf(<span class="string">&quot;localhost:%d&quot;</span>, *port))</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;failed to listen: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> opts []grpc.ServerOption</span><br><span class="line"><span class="keyword">if</span> *tls &#123;</span><br><span class="line"><span class="keyword">if</span> *certFile == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">*certFile = data.Path(<span class="string">&quot;x509/server_cert.pem&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> *keyFile == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">*keyFile = data.Path(<span class="string">&quot;x509/server_key.pem&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">creds, err := credentials.NewServerTLSFromFile(*certFile, *keyFile)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;Failed to generate credentials: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">opts = []grpc.ServerOption&#123;grpc.Creds(creds)&#125;</span><br><span class="line">&#125;</span><br><span class="line">grpcServer := grpc.NewServer(opts...)</span><br><span class="line">pb.RegisterRouteGuideServer(grpcServer, newServer())</span><br><span class="line">grpcServer.Serve(lis)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面使用<code>pb.RegisterRouteGuideServer</code>注册服务,参数分别是grpc服务和<code>newServer</code>返回的结构体</p><h5 id="client"><a href="#client" class="headerlink" title="client"></a>client</h5><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printFeature</span><span class="params">(client pb.RouteGuideClient, point *pb.Point)</span></span> &#123;</span><br><span class="line">log.Printf(<span class="string">&quot;Getting feature for point (%d, %d)&quot;</span>, point.Latitude, point.Longitude)</span><br><span class="line">ctx, cancel := context.WithTimeout(context.Background(), <span class="number">10</span>*time.Second)</span><br><span class="line"><span class="keyword">defer</span> cancel()</span><br><span class="line">feature, err := client.GetFeature(ctx, point)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;client.GetFeature failed: %v&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">log.Println(feature)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用context创建ctx和cancel,利用<code>client := pb.NewRouteGuideClient(conn)</code>创建client调用方法.</p><p><code>NewRouteGuideClient</code>返回对应的client接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewRouteGuideClient</span><span class="params">(cc grpc.ClientConnInterface)</span> <span class="title">RouteGuideClient</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;routeGuideClient&#123;cc&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="gRPC面临的挑战"><a href="#gRPC面临的挑战" class="headerlink" title="gRPC面临的挑战"></a>gRPC面临的挑战</h2><p>虽然gRPC确实允许您使用这些较新的技术，但gRPC服务的原型设计更具挑战性，因为<strong>无法使用Postman HTTP客户端等工具来轻松地与您公开的gRPC服务交互</strong>。你确实有一些选择可以实现这一点，但这并不是一种在本地就可以获得的东西。</p><p>有一些选项可以使用诸如特使之类的工具来反转代理标准JSON请求，并将其转码为正确的数据格式，但这是一个额外的依赖项，对于简单的项目来说，设置它可能很困难。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://grpc.io/docs/">Documentation | gRPC</a></li><li><a href="https://tutorialedge.net/golang/go-grpc-beginners-tutorial/">Go gRPC Beginners Tutorial | TutorialEdge.net</a></li><li><a href="https://www.bookstack.cn/read/go-rpc-programming-guide/part1-gorpc.md">Go RPC开发简介 - 官方RPC库 - 《Go RPC开发指南 [中文文档]》 - 书栈网 · BookStack</a></li><li><a href="http://ruanyifeng.com/blog/2018/10/restful-api-best-practices.html">RESTful API 最佳实践 - 阮一峰的网络日志 (ruanyifeng.com)</a></li><li><a href="https://grpc.io/docs/languages/go/basics/">Basics tutorial | Go | gRPC</a></li><li><a href="https://grpc.io/docs/what-is-grpc/">What is gRPC? | gRPC</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;RPC是远程调用,而google实现了grpc比较方便地实现了远程调用,gRPC是一个现代的开源远程过程调用(RPC)框架&lt;br&gt;</summary>
    
    
    
    
    <category term="grpc" scheme="https://www.sekyoro.top/tags/grpc/"/>
    
  </entry>
  
  <entry>
    <title>gradio学习</title>
    <link href="https://www.sekyoro.top/2023/12/25/gradio%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/12/25/gradio%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-12-25T13:12:10.000Z</published>
    <updated>2023-12-26T04:22:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Gradio好啊,好啊,好啊.Hugging Face好啊,好啊.<br><span id="more"></span></p><blockquote><p>Gradio是一个开源Python包，允许您为机器学习模型、API或任何任意Python函数快速构建演示或web应用程序。然后，您可以使用Gradio的内置共享功能，在几秒钟内共享演示或web应用程序的链接。无需JavaScript、CSS或网络托管经验！</p></blockquote><h2 id="Hot-reload"><a href="#Hot-reload" class="headerlink" title="Hot reload"></a>Hot reload</h2><p><a href="https://www.gradio.app/guides/developing-faster-with-reload-mode">Developing Faster With Reload Mode (gradio.app)</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradio run.py</span><br></pre></td></tr></table></figure><p>在使用重载模式时,Gradio专门在代码中寻找一个名为demo的Gradio Blocks/Interface演示。如果您将您的demo命名为其他名称，则需要将演示的名称作为代码中的第二个参数传入。所以，如果你的run.py文件是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> my_demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;# Greetings from Gradio!&quot;</span>)</span><br><span class="line">    inp = gr.Textbox(placeholder=<span class="string">&quot;What is your name?&quot;</span>)</span><br><span class="line">    out = gr.Textbox()</span><br><span class="line"></span><br><span class="line">    inp.change(fn=<span class="keyword">lambda</span> x: <span class="string">f&quot;Welcome, <span class="subst">&#123;x&#125;</span>!&quot;</span>,</span><br><span class="line">               inputs=inp,</span><br><span class="line">               outputs=out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    my_demo.launch()<span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> my_demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;# Greetings from Gradio!&quot;</span>)</span><br><span class="line">    inp = gr.Textbox(placeholder=<span class="string">&quot;What is your name?&quot;</span>)</span><br><span class="line">    out = gr.Textbox()</span><br><span class="line"></span><br><span class="line">    inp.change(fn=<span class="keyword">lambda</span> x: <span class="string">f&quot;Welcome, <span class="subst">&#123;x&#125;</span>!&quot;</span>,</span><br><span class="line">               inputs=inp,</span><br><span class="line">               outputs=out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    my_demo.launch()</span><br></pre></td></tr></table></figure><p>使用下面命令启动reload模式</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradio run.py my_demo.</span><br></pre></td></tr></table></figure><p>我发现开发时使用reload最好把launch放在<strong>name</strong> == “<strong>main</strong>“下<a href="https://github.com/gradio-app/gradio/issues/4755">Unable to launch with reload mode with default port · Issue #4755 · gradio-app/gradio (github.com)</a></p><h3 id="launch参数"><a href="#launch参数" class="headerlink" title="launch参数"></a>launch参数</h3><p>在reload模式下没用,开发完毕后可以使用,用于改变端口、获得公网地址用于分享等.</p><h2 id="Interface-Class"><a href="#Interface-Class" class="headerlink" title="Interface Class"></a><strong><code>Interface</code> Class</strong></h2><p>Interface类旨在为机器学习模型创建演示，这些模型接受一个或多个输入，并返回一个或更多输出.</p><p>Interface类有三个核心参数：</p><ul><li>fn：包装用户界面（UI）的函数</li><li>inputs：用于输入的Gradio组件。组件的数量应与函数中的参数数量相匹配。</li><li>outputs：用于输出的Gradio组件。组件的数量应该与函数返回值的数量相匹配。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">demo = gr.Interface(</span><br><span class="line">    fn=greet,</span><br><span class="line">    inputs=[gr.components.Textbox(placeholder=<span class="string">&quot;input your words&quot;</span>), gr.Textbox(placeholder=<span class="string">&quot;&quot;</span>),gr.components.Slider()],</span><br><span class="line">    outputs=[<span class="string">&quot;text&quot;</span>,gr.Checkbox(label=<span class="string">&quot;选择&quot;</span>)],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>可以多个输入,多个输出,输出由fn计算得到,但是貌似这只能构建一个单组件.</p><h2 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h2><blockquote><p>Blocks是Gradio的低级API，它允许您创建比Interfaces更多的自定义web应用程序和演示（但仍然完全使用Python）。</p></blockquote><p>与Interface类相比，Blocks提供了更多的灵活性和控制：</p><p>（1）组件的布局（</p><p>2）触发功能执行的事件</p><p>（3）数据流（例如，输入可以触发输出，这可以触发下一级的输出）</p><p>Blocks还提供了将相关演示分组在一起的方法，例如使用选项卡。块的基本用法如下：创建一个块对象，然后将其用作上下文（使用“with”语句），然后在块上下文中定义布局、组件或事件。最后，调用launch（）方法来启动演示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello&quot;</span> + name + <span class="string">&quot;!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;## Hello World&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> gr.Row():</span><br><span class="line">        textbox = gr.Textbox(placeholder=<span class="string">&quot;input your words&quot;</span>)</span><br><span class="line">        slider = gr.components.Slider()</span><br><span class="line">    btn = gr.Button(<span class="string">&quot;Run&quot;</span>)</span><br><span class="line">    btn.click(fn=update,<span class="built_in">input</span>=textbox,output=slider)</span><br><span class="line">demo.launch()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increase</span>(<span class="params">num</span>):</span></span><br><span class="line">    <span class="keyword">return</span> num + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">    a = gr.Number(label=<span class="string">&quot;a&quot;</span>)</span><br><span class="line">    b = gr.Number(label=<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    atob = gr.Button(<span class="string">&quot;a &gt; b&quot;</span>)</span><br><span class="line">    btoa = gr.Button(<span class="string">&quot;b &gt; a&quot;</span>)</span><br><span class="line">    atob.click(increase, a, b)</span><br><span class="line">    btoa.click(increase, b, a)</span><br><span class="line"></span><br><span class="line">demo.launch()</span><br></pre></td></tr></table></figure><h2 id="TabbedInterface"><a href="#TabbedInterface" class="headerlink" title="TabbedInterface"></a>TabbedInterface</h2><p>TabbedInterface是通过提供一个接口列表来创建的，每个接口都在一个单独的选项卡中呈现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello&quot;</span> + name + <span class="string">&quot;!&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks(theme=gr.themes.Glass()) <span class="keyword">as</span> test:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;## Hello World&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> gr.Row():</span><br><span class="line">        textbox = gr.Textbox(placeholder=<span class="string">&quot;input your words&quot;</span>,label=<span class="string">&quot;name&quot;</span>)</span><br><span class="line">        slider = gr.components.Slider(label=<span class="string">&quot;Greet&quot;</span>,interactive=<span class="literal">True</span>)</span><br><span class="line">    btn = gr.Button(<span class="string">&quot;Run&quot;</span>)</span><br><span class="line">    btn.click(fn=update, inputs=textbox, outputs=slider)</span><br><span class="line"></span><br><span class="line">stt_demo = gr.load(</span><br><span class="line">    <span class="string">&quot;huggingface/facebook/wav2vec2-base-960h&quot;</span>,</span><br><span class="line">    title=<span class="literal">None</span>,</span><br><span class="line">    inputs=<span class="string">&quot;mic&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Let me try to guess what you&#x27;re saying!&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">demo = gr.TabbedInterface([stt_demo,test],[<span class="string">&quot;STT&quot;</span>,<span class="string">&quot;Hello World&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo.launch()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ChatInterface"><a href="#ChatInterface" class="headerlink" title="ChatInterface"></a>ChatInterface</h2><blockquote><p>聊天机器人是大型语言模型的一个流行应用程序。使用gradio，您可以轻松地构建聊天机器人模型的演示并与用户共享，或者使用直观的聊天机器人UI自己尝试。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_response</span>(<span class="params">message, history</span>):</span></span><br><span class="line"> <span class="keyword">return</span> random.choice([<span class="string">&quot;Yes&quot;</span>, <span class="string">&quot;No&quot;</span>])</span><br><span class="line"></span><br><span class="line">gr.ChatInterface(random_response).launch()</span><br></pre></td></tr></table></figure><h3 id="streaming"><a href="#streaming" class="headerlink" title="streaming"></a>streaming</h3><p>如果应用程序预计流量会很大，请使用queue（）方法来控制处理速率。</p><p>可以搭配Openai或者Hugging Face上的大语言模型使用.同时搭配LangChain使用.</p><p>上面就是基本的四个大模块,此外还有许多组件,重点是<strong>一些组件如何组合</strong>,一般来说使用<code>gr.Blocks</code>进行构建.</p><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><ol><li><a href="https://www.gradio.app/guides">Gradio Guides</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Gradio好啊,好啊,好啊.Hugging Face好啊,好啊.&lt;br&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>dpsc:深度学习短课程学习</title>
    <link href="https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    <id>https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-12-24T12:55:08.000Z</published>
    <updated>2023-12-29T10:39:46.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Andrew Ng的Deep Learning短课程<a href="https://www.deeplearning.ai/short-courses/">Short Courses | Learn Generative AI from DeepLearning.AI</a>,此外还有Cousera上的课程.学的东西比较实用还比较新.</p><span id="more"></span><p>这些课程通常会使用一些公司的产品,比如<strong>Hugging Face</strong>的Gradio,diffusers,transformers,或者W&amp;B的wandb等等(这两个我平常都在用),此外还有谷歌、微软以及Langchain,这些工具都比较实用. 如果关注生成领域,那Diffusion Model肯定要看,如果关注LLM以及chatbot那<strong>Langchain</strong>最好利用起来,如果自己训练部署模型,那也可以使用<strong>wandb</strong>.</p><p>这里我主要关注三部分:<strong>生成式人工智能</strong>,<strong>LLM</strong>,<strong>模型部署和训练辅助工具</strong>.</p><h2 id="Reinforcement-Learning-from-Human-Feedback"><a href="#Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="Reinforcement Learning from Human Feedback"></a>Reinforcement Learning from Human Feedback</h2><p><img data-src="https://i.imgur.com/81KDzqo.png" alt="image-20231224221652027"></p><p><img data-src="https://i.imgur.com/TpXVnGU.png" alt="image-20231224231207302"></p><h2 id="Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases"><a href="#Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases" class="headerlink" title="Evaluating and Debugging Generative AI Models Using Weights and Biases"></a>Evaluating and Debugging Generative AI Models Using Weights and Biases</h2><p>作为模型训练者可能会用到的网站.文档<a href="https://docs.wandb.ai/ref/python/">Python Library | Weights &amp; Biases Documentation (wandb.ai)</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wandb.init(</span><br><span class="line">    project=<span class="string">&quot;gpt5&quot;</span>,</span><br><span class="line">    config=config,</span><br><span class="line">)</span><br><span class="line">wandb.log(metrics)</span><br></pre></td></tr></table></figure><p>首先找到项目(如果没有就会另外创建),并且会根据config创建一个run.使用wandb.log输出最后结果.wandb会保存运行时系统环境信息,github repo甚至仓库文件信息.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">config</span>):</span></span><br><span class="line">    <span class="string">&quot;Train a model with a given config&quot;</span></span><br><span class="line">    </span><br><span class="line">    wandb.init(</span><br><span class="line">        project=<span class="string">&quot;gpt5&quot;</span>,</span><br><span class="line">        config=config,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the data</span></span><br><span class="line">    train_dl, valid_dl = get_dataloaders(DATA_DIR, </span><br><span class="line">                                         config.batch_size, </span><br><span class="line">                                         config.slice_size, </span><br><span class="line">                                         config.valid_pct)</span><br><span class="line">    n_steps_per_epoch = math.ceil(<span class="built_in">len</span>(train_dl.dataset) / config.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># A simple MLP model</span></span><br><span class="line">    model = get_model(config.dropout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Make the loss and optimizer</span></span><br><span class="line">    loss_func = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = Adam(model.parameters(), lr=config.lr)</span><br><span class="line"></span><br><span class="line">    example_ct = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(config.epochs), total=config.epochs):</span><br><span class="line">        model.train()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dl):</span><br><span class="line">            images, labels = images.to(DEVICE), labels.to(DEVICE)</span><br><span class="line"></span><br><span class="line">            outputs = model(images)</span><br><span class="line">            train_loss = loss_func(outputs, labels)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            train_loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            example_ct += <span class="built_in">len</span>(images)</span><br><span class="line">            metrics = &#123;</span><br><span class="line">                <span class="string">&quot;train/train_loss&quot;</span>: train_loss,</span><br><span class="line">                <span class="string">&quot;train/epoch&quot;</span>: epoch + <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;train/example_ct&quot;</span>: example_ct</span><br><span class="line">            &#125;</span><br><span class="line">            wandb.log(metrics)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># Compute validation metrics, log images on last epoch</span></span><br><span class="line">        val_loss, accuracy = validate_model(model, valid_dl, loss_func)</span><br><span class="line">        <span class="comment"># Compute train and validation metrics</span></span><br><span class="line">        val_metrics = &#123;</span><br><span class="line">            <span class="string">&quot;val/val_loss&quot;</span>: val_loss,</span><br><span class="line">            <span class="string">&quot;val/val_accuracy&quot;</span>: accuracy</span><br><span class="line">        &#125;</span><br><span class="line">        wandb.log(val_metrics)</span><br><span class="line">    </span><br><span class="line">    wandb.finish()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如何在同一个run更改,更新现有运行的配置.下面是我匿名使用wandb跑的一次run</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.<span class="built_in">Api</span>()</span><br><span class="line"></span><br><span class="line">run = api.<span class="built_in">run</span>(<span class="string">&quot;anony-mouse-988582345570149472/gpt5/&lt;run_id&gt;&quot;</span>)</span><br><span class="line">run.config[<span class="string">&quot;key&quot;</span>] = updated_value</span><br><span class="line">run.<span class="built_in">update</span>()</span><br></pre></td></tr></table></figure><p>将单个运行的指标导出到CSV文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.Api()</span><br><span class="line"></span><br><span class="line"><span class="comment"># run is specified by &lt;entity&gt;/&lt;project&gt;/&lt;run_id&gt;</span></span><br><span class="line">run = api.run(<span class="string">&quot;anony-mouse-946987442323310233/dlai_sprite_diffusion/&lt;run_id&gt;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save the metrics for the run to a csv file</span></span><br><span class="line">metrics_dataframe = run.history()</span><br><span class="line">metrics_dataframe.to_csv(<span class="string">&quot;metrics.csv&quot;</span>)</span><br></pre></td></tr></table></figure><p>读取运行指标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.Api()</span><br><span class="line"></span><br><span class="line">run = api.run(<span class="string">&quot;anony-mouse-946987442323310233/dlai_sprite_diffusion/&lt;run_id&gt;&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> run.state == <span class="string">&quot;finished&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i, row <span class="keyword">in</span> run.history().iterrows():</span><br><span class="line">      <span class="built_in">print</span>(row[<span class="string">&quot;_timestamp&quot;</span>], row[<span class="string">&quot;accuracy&quot;</span>])</span><br></pre></td></tr></table></figure><p>当您从历史中提取数据时，默认情况下会对其采样到500点。使用run.scan_history（）获取所有记录的数据点。下面是下载所有记录在历史中的丢失数据点的示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">api = wandb.Api()</span><br><span class="line"></span><br><span class="line">run = api.run(<span class="string">&quot;anony-mouse-946987442323310233/dlai_sprite_diffusion/&lt;run_id&gt;&quot;</span>)</span><br><span class="line">history = run.scan_history()</span><br><span class="line">losses = [row[<span class="string">&quot;loss&quot;</span>] <span class="keyword">for</span> row <span class="keyword">in</span> history]</span><br></pre></td></tr></table></figure><h3 id="wandb-Table"><a href="#wandb-Table" class="headerlink" title="wandb Table"></a>wandb Table</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">table = wandb.Table(columns=[<span class="string">&quot;input_noise&quot;</span>, <span class="string">&quot;ddpm&quot;</span>, <span class="string">&quot;ddim&quot;</span>, <span class="string">&quot;class&quot;</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> noise, ddpm_s, ddim_s, c <span class="keyword">in</span> <span class="built_in">zip</span>(noises, </span><br><span class="line">                                    ddpm_samples, </span><br><span class="line">                                    ddim_samples, </span><br><span class="line">                                    to_classes(ctx_vector)):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># add data row by row to the Table</span></span><br><span class="line">    table.add_data(wandb.Image(noise),</span><br><span class="line">                   wandb.Image(ddpm_s), </span><br><span class="line">                   wandb.Image(ddim_s),</span><br><span class="line">                   c)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> wandb.init(project=<span class="string">&quot;dlai_sprite_diffusion&quot;</span>, </span><br><span class="line">                job_type=<span class="string">&quot;samplers_battle&quot;</span>, </span><br><span class="line">                config=config):</span><br><span class="line">    </span><br><span class="line">    wandb.log(&#123;<span class="string">&quot;samplers_table&quot;</span>:table&#125;)</span><br></pre></td></tr></table></figure><p>先创建<code>wandb.Table</code>,再使用其添加数据,最后使用log推上去</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">table = wandb.Table(columns=[<span class="string">&quot;prompt&quot;</span>, <span class="string">&quot;generation&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> prompt <span class="keyword">in</span> prompts:</span><br><span class="line">    input_ids = tokenizer.encode(prefix + prompt, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">    output = model.generate(input_ids, do_sample=<span class="literal">True</span>, max_new_tokens=<span class="number">50</span>, top_p=<span class="number">0.3</span>)</span><br><span class="line">    output_text = tokenizer.decode(output[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    table.add_data(prefix + prompt, output_text)</span><br><span class="line">    </span><br><span class="line">wandb.log(&#123;<span class="string">&#x27;tiny_generations&#x27;</span>: table&#125;)</span><br></pre></td></tr></table></figure><h3 id="使用W-amp-B-sweep进行超参搜索调整"><a href="#使用W-amp-B-sweep进行超参搜索调整" class="headerlink" title="使用W&amp;B sweep进行超参搜索调整"></a>使用W&amp;B sweep进行超参搜索调整</h3><blockquote><p>在高维超参数空间中搜索以找到最具性能的模型可能会变得非常困难。超参数扫描提供了一种有组织、高效的方式来进行一系列模型的战斗，并选择最准确的模型。它们通过自动搜索超参数值的组合（例如学习率、批量大小、隐藏层的数量、优化器类型）来找到最优化的值。Sweep结合了一种尝试一堆超参数值的策略和评估代码</p></blockquote><ol><li>定义sweep：通过创建一个字典或YAML文件来实现这一点，该文件指定了要搜索的参数、搜索策略、优化指标等。</li></ol><p>首先选择搜索策略,包括网格,随机和贝叶斯.</p><blockquote><ul><li><strong><code>grid</code> Search</strong> – Iterate over every combination of hyperparameter values. Very effective, but can be computationally costly.</li><li><strong><code>random</code> Search</strong> – Select each new combination at random according to provided <code>distribution</code>s. Surprisingly effective!</li><li><strong><code>bayes</code>ian Search</strong> – Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sweep_config = &#123;</span><br><span class="line">    <span class="string">&#x27;method&#x27;</span>: <span class="string">&#x27;random&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">metric = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;loss&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;goal&#x27;</span>: <span class="string">&#x27;minimize&#x27;</span>   </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">sweep_config[<span class="string">&#x27;metric&#x27;</span>] = metric</span><br></pre></td></tr></table></figure><p>然后是训练网络的一些超参</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">parameters_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;values&#x27;</span>: [<span class="string">&#x27;adam&#x27;</span>, <span class="string">&#x27;sgd&#x27;</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&#x27;fc_layer_size&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;values&#x27;</span>: [<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&#x27;dropout&#x27;</span>: &#123;</span><br><span class="line">          <span class="string">&#x27;values&#x27;</span>: [<span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">sweep_config[<span class="string">&#x27;parameters&#x27;</span>] = parameters_dict</span><br></pre></td></tr></table></figure><p>通常情况下，有些超参数我们不想在这次扫描中发生变化，但我们仍然想在扫描_配置中设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parameters_dict.update(&#123;</span><br><span class="line">    <span class="string">&#x27;epochs&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;value&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><p><code>`rand</code>搜索策略可以指定一个正态分布进行选参数,默认是均匀分布.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">parameters_dict.update(&#123;</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: &#123;</span><br><span class="line">        <span class="comment"># a flat distribution between 0 and 0.1</span></span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;min&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&#x27;max&#x27;</span>: <span class="number">0.1</span></span><br><span class="line">      &#125;,</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: &#123;</span><br><span class="line">        <span class="comment"># integers between 32 and 256</span></span><br><span class="line">        <span class="comment"># with evenly-distributed logarithms </span></span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;q_log_uniform_values&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;q&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">&#x27;min&#x27;</span>: <span class="number">32</span>,</span><br><span class="line">        <span class="string">&#x27;max&#x27;</span>: <span class="number">256</span>,</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><p>所以参数包括<code>metho</code>,<code>metric</code>和<code>parameter</code>.此外还有一些这里就不介绍了</p><ol><li>初始化扫描：用一行代码初始化扫描并传入扫描配置字典：sweep_id=wandb.sweep（sweep_config）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sweep_id = wandb.sweep(sweep_config, project=<span class="string">&quot;pytorch-sweeps-demo&quot;</span>)</span><br></pre></td></tr></table></figure><p>创建一个sweep</p><ol><li>运行扫描代理：也可以用一行代码完成，我们调用wandb.agent（）并传递要运行的sweep_id，以及一个定义模型架构并对其进行训练的函数：wandb.agent（sweep_id，function=train）</li></ol><p>开始正常的训练.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">config=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># Initialize a new wandb run</span></span><br><span class="line">    <span class="keyword">with</span> wandb.init(config=config):</span><br><span class="line">        <span class="comment"># If called by wandb.agent, as below,</span></span><br><span class="line">        <span class="comment"># this config will be set by Sweep Controller</span></span><br><span class="line">        config = wandb.config</span><br><span class="line"></span><br><span class="line">        loader = build_dataset(config.batch_size)</span><br><span class="line">        network = build_network(config.fc_layer_size, config.dropout)</span><br><span class="line">        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.epochs):</span><br><span class="line">            avg_loss = train_epoch(network, loader, optimizer)</span><br><span class="line">            wandb.log(&#123;<span class="string">&quot;loss&quot;</span>: avg_loss, <span class="string">&quot;epoch&quot;</span>: epoch&#125;)           </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wandb.agent(sweep_id, train, count=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>使用Sweep Controller返回的随机生成的超参数值，启动一个运行训练5次的agents</p><p><img data-src="https://s2.loli.net/2023/12/29/2EruyQMvpSNoeRm.png" alt="image-20231229183908912" style="zoom:67%;" /></p><p>另外课程还讲了Tracer等,现在我用不上….主要还是上传loss和acc这些结果.</p><h2 id="How-Diffusion-Models-Work"><a href="#How-Diffusion-Models-Work" class="headerlink" title="How Diffusion Models Work"></a>How Diffusion Models Work</h2><p>Diffusion Models在前段时间非常火,也是现在prompt生成图像的主要模型.</p><p><img data-src="https://i.imgur.com/MkB11s7.png" alt="image-20231225195441214"></p><p><img data-src="https://i.imgur.com/lm5t6Jr.png" alt="image-20231225200851364"></p><p><img data-src="https://s2.loli.net/2023/12/28/LQaYoIzTJWd1yNs.png" alt="image-20231228224804703"></p><p><img data-src="https://s2.loli.net/2023/12/28/G7JTpmDg4zF1neq.png" alt="image-20231228232748110"></p><p>训练的预测噪声网络是Unet</p><p><img data-src="https://s2.loli.net/2023/12/29/8VAft1WN9L6lrmG.png" alt="image-20231229151559530"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ContextUnet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, n_feat=<span class="number">256</span>, n_cfeat=<span class="number">10</span>, height=<span class="number">28</span></span>):</span>  <span class="comment"># cfeat - context features</span></span><br><span class="line">        <span class="built_in">super</span>(ContextUnet, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># number of input channels, number of intermediate feature maps and number of classes</span></span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.n_feat = n_feat</span><br><span class="line">        self.n_cfeat = n_cfeat</span><br><span class="line">        self.h = height  <span class="comment">#assume h == w. must be divisible by 4, so 28,24,20,16...</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the initial convolutional layer</span></span><br><span class="line">        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the down-sampling path of the U-Net with two levels</span></span><br><span class="line">        self.down1 = UnetDown(n_feat, n_feat)        <span class="comment"># down1 #[10, 256, 8, 8]</span></span><br><span class="line">        self.down2 = UnetDown(n_feat, <span class="number">2</span> * n_feat)    <span class="comment"># down2 #[10, 256, 4,  4]</span></span><br><span class="line">        </span><br><span class="line">         <span class="comment"># original: self.to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())</span></span><br><span class="line">        self.to_vec = nn.Sequential(nn.AvgPool2d((<span class="number">4</span>)), nn.GELU())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Embed the timestep and context labels with a one-layer fully connected neural network</span></span><br><span class="line">        self.timeembed1 = EmbedFC(<span class="number">1</span>, <span class="number">2</span>*n_feat)</span><br><span class="line">        self.timeembed2 = EmbedFC(<span class="number">1</span>, <span class="number">1</span>*n_feat)</span><br><span class="line">        self.contextembed1 = EmbedFC(n_cfeat, <span class="number">2</span>*n_feat)</span><br><span class="line">        self.contextembed2 = EmbedFC(n_cfeat, <span class="number">1</span>*n_feat)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the up-sampling path of the U-Net with three levels</span></span><br><span class="line">        self.up0 = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">2</span> * n_feat, <span class="number">2</span> * n_feat, self.h//<span class="number">4</span>, self.h//<span class="number">4</span>), <span class="comment"># up-sample  </span></span><br><span class="line">            nn.GroupNorm(<span class="number">8</span>, <span class="number">2</span> * n_feat), <span class="comment"># normalize                       </span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">        )</span><br><span class="line">        self.up1 = UnetUp(<span class="number">4</span> * n_feat, n_feat)</span><br><span class="line">        self.up2 = UnetUp(<span class="number">2</span> * n_feat, n_feat)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize the final convolutional layers to map to the same number of channels as the input image</span></span><br><span class="line">        self.out = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">2</span> * n_feat, n_feat, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># reduce number of feature maps   #in_channels, out_channels, kernel_size, stride=1, padding=0</span></span><br><span class="line">            nn.GroupNorm(<span class="number">8</span>, n_feat), <span class="comment"># normalize</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(n_feat, self.in_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># map to same number of channels as input</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, t, c=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x : (batch, n_feat, h, w) : input image</span></span><br><span class="line"><span class="string">        t : (batch, n_cfeat)      : time step</span></span><br><span class="line"><span class="string">        c : (batch, n_classes)    : context label</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># x is the input image, c is the context label, t is the timestep, context_mask says which samples to block the context on</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># pass the input image through the initial convolutional layer</span></span><br><span class="line">        x = self.init_conv(x)</span><br><span class="line">        <span class="comment"># pass the result through the down-sampling path</span></span><br><span class="line">        down1 = self.down1(x)       <span class="comment">#[10, 256, 8, 8]</span></span><br><span class="line">        down2 = self.down2(down1)   <span class="comment">#[10, 256, 4, 4]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># convert the feature maps to a vector and apply an activation</span></span><br><span class="line">        hiddenvec = self.to_vec(down2)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># mask out context if context_mask == 1</span></span><br><span class="line">        <span class="keyword">if</span> c <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            c = torch.zeros(x.shape[<span class="number">0</span>], self.n_cfeat).to(x)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># embed context and timestep</span></span><br><span class="line">        cemb1 = self.contextembed1(c).view(-<span class="number">1</span>, self.n_feat * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)     <span class="comment"># (batch, 2*n_feat, 1,1)</span></span><br><span class="line">        temb1 = self.timeembed1(t).view(-<span class="number">1</span>, self.n_feat * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        cemb2 = self.contextembed2(c).view(-<span class="number">1</span>, self.n_feat, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        temb2 = self.timeembed2(t).view(-<span class="number">1</span>, self.n_feat, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print(f&quot;uunet forward: cemb1 &#123;cemb1.shape&#125;. temb1 &#123;temb1.shape&#125;, cemb2 &#123;cemb2.shape&#125;. temb2 &#123;temb2.shape&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        up1 = self.up0(hiddenvec)</span><br><span class="line">        up2 = self.up1(cemb1*up1 + temb1, down2)  <span class="comment"># add and multiply embeddings</span></span><br><span class="line">        up3 = self.up2(cemb2*up2 + temb2, down1)</span><br><span class="line">        out = self.out(torch.cat((up3, x), <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>训练的时候是random一个timestamp得到噪声,sampling的时候是根据步数进行依次sampling</p><h3 id="control-and-speed-up"><a href="#control-and-speed-up" class="headerlink" title="control and speed up"></a>control and speed up</h3><p>加入context_vector进行控制输出,使用DDIM替换DDPM进行加速samping</p><p><img data-src="https://s2.loli.net/2023/12/29/MAifZF7OlmPtbWs.png" alt="image-20231229152240050"></p><p><img data-src="https://s2.loli.net/2023/12/29/hqbUoyE9iRpdgNA.png" alt="image-20231229152302772"></p><p><img data-src="https://s2.loli.net/2023/12/29/jLaNo19nuCwDJQG.png" alt="image-20231229152531542"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define sampling function for DDIM   </span></span><br><span class="line"><span class="comment"># removes the noise using ddim</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">denoise_ddim</span>(<span class="params">x, t, t_prev, pred_noise</span>):</span></span><br><span class="line">    ab = ab_t[t]</span><br><span class="line">    ab_prev = ab_t[t_prev]</span><br><span class="line">    </span><br><span class="line">    x0_pred = ab_prev.sqrt() / ab.sqrt() * (x - (<span class="number">1</span> - ab).sqrt() * pred_noise)</span><br><span class="line">    dir_xt = (<span class="number">1</span> - ab_prev).sqrt() * pred_noise</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x0_pred + dir_xt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fast sampling algorithm with context</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_ddim_context</span>(<span class="params">n_sample, context, n=<span class="number">20</span></span>):</span></span><br><span class="line">    <span class="comment"># x_T ~ N(0, 1), sample initial noise</span></span><br><span class="line">    samples = torch.randn(n_sample, <span class="number">3</span>, height, height).to(device)  </span><br><span class="line"></span><br><span class="line">    <span class="comment"># array to keep track of generated steps for plotting</span></span><br><span class="line">    intermediate = [] </span><br><span class="line">    step_size = timesteps // n</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(timesteps, <span class="number">0</span>, -step_size):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;sampling timestep <span class="subst">&#123;i:3d&#125;</span>&#x27;</span>, end=<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reshape time tensor</span></span><br><span class="line">        t = torch.tensor([i / timesteps])[:, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>].to(device)</span><br><span class="line"></span><br><span class="line">        eps = nn_model(samples, t, c=context)    <span class="comment"># predict noise e_(x_t,t)</span></span><br><span class="line">        samples = denoise_ddim(samples, i, i - step_size, eps)</span><br><span class="line">        intermediate.append(samples.detach().cpu().numpy())</span><br><span class="line"></span><br><span class="line">    intermediate = np.stack(intermediate)</span><br><span class="line">    <span class="keyword">return</span> samples, intermediate</span><br></pre></td></tr></table></figure><h2 id="ChatGPT-Prompt-Engineering-for-Developers"><a href="#ChatGPT-Prompt-Engineering-for-Developers" class="headerlink" title="ChatGPT Prompt Engineering for Developers"></a>ChatGPT Prompt Engineering for Developers</h2><p>使用ChatGPT辅助,感觉已经成为现代社会一种普通工具了</p><p><img data-src="https://s2.loli.net/2023/12/28/PmOSaTEFH8pVuqe.png" alt="image-20231228232329050"></p><p><img data-src="https://s2.loli.net/2023/12/28/sh6MfqxQEUnuG5j.png" alt="image-20231228232417399"></p><h2 id="Finetuning-Large-Language-Models"><a href="#Finetuning-Large-Language-Models" class="headerlink" title="Finetuning Large Language Models"></a>Finetuning Large Language Models</h2><p>大模型的finetune,了解原理即可</p><p><img data-src="https://s2.loli.net/2023/12/28/zyAIapuUNi9EeSw.png" alt="image-20231228232508902"></p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;Andrew Ng的Deep Learning短课程&lt;a href=&quot;https://www.deeplearning.ai/short-courses/&quot;&gt;Short Courses | Learn Generative AI from DeepLearning.AI&lt;/a&gt;,此外还有Cousera上的课程.学的东西比较实用还比较新.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Github_bot创建</title>
    <link href="https://www.sekyoro.top/2023/12/24/Github-bot%E5%88%9B%E5%BB%BA/"/>
    <id>https://www.sekyoro.top/2023/12/24/Github-bot%E5%88%9B%E5%BB%BA/</id>
    <published>2023-12-24T06:50:24.000Z</published>
    <updated>2023-12-24T07:15:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在看一些开源项目时,会发现一些帮忙处理issue和PR的bot,这些bot都是基于Github的Apps<a href="https://docs.github.com/en/apps/overview">GitHub Apps overview - GitHub Docs</a></p><span id="more"></span><h2 id="GitHub-Apps"><a href="#GitHub-Apps" class="headerlink" title="GitHub Apps"></a>GitHub Apps</h2><blockquote><p>GitHub应用程序是扩展GitHub功能的工具。GitHub应用程序可以在GitHub上做一些事情，比如打开问题、评论拉取请求和管理项目。他们也可以根据GitHub上发生的事件在GitHub之外做事情。例如，当在GitHub上打开问题时，GitHub应用程序可以在Slack上发布。</p></blockquote><p>可以在<a href="https://github.com/marketplace">GitHub Marketplace</a>上查找Github Apps,然后进行安装,有些是需要付费的.</p><p>关于使用直接安装然后看文档进行配置就行了。</p><h3 id="如何开发"><a href="#如何开发" class="headerlink" title="如何开发"></a>如何开发</h3><p><a href="https://github.com/github/github-app-js-sample?tab=readme-ov-file">github/github-app-js-sample: Sample of a GitHub App that comments new pull requests</a></p><p><img data-src="https://i.imgur.com/trK7YAv.png" alt="image-20231224150632938"></p><p>由于本地开发涉及到需要接受github发来的东西,需要涉及到内网穿透啥的,推荐使用smee或者ngrok进行本地开发.建议搭配下面介绍的probot进行开发.<a href="https://probot.github.io/docs/development/#installing-the-app-on-a-repository">probot.github.io/docs/development/#installing-the-app-on-a-repository</a></p><h2 id="Probot"><a href="#Probot" class="headerlink" title="Probot"></a>Probot</h2><blockquote><p>Probot是一个在Node.js中构建GitHub应用程序的框架。它旨在消除所有的繁琐工作，比如接收和验证Webhook，以及进行身份验证倒立，这样你就可以专注于你想要构建的功能。Probet应用程序易于编写、部署和共享。许多最流行的Probet应用程序都是托管的，所以没有什么可供您部署和管理的。</p></blockquote><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = <span class="function">(<span class="params">app</span>) =&gt;</span> &#123;</span><br><span class="line">  app.on(<span class="string">&quot;issues.opened&quot;</span>, <span class="keyword">async</span> (context) =&gt; &#123;</span><br><span class="line">    <span class="keyword">const</span> issueComment = context.issue(&#123;</span><br><span class="line">      <span class="attr">body</span>: <span class="string">&quot;Thanks for opening this issue!&quot;</span>,</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> context.octokit.issues.createComment(issueComment);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  app.onAny(<span class="keyword">async</span> (context) =&gt; &#123;</span><br><span class="line">    context.log.info(&#123; <span class="attr">event</span>: context.name, <span class="attr">action</span>: context.payload.action &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  app.onError(<span class="keyword">async</span> (error) =&gt; &#123;</span><br><span class="line">    app.log.error(error);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="Repo-Automation-Bots"><a href="#Repo-Automation-Bots" class="headerlink" title="Repo Automation Bots"></a>Repo Automation Bots</h2><p><a href="https://github.com/googleapis/repo-automation-bots?tab=readme-ov-file">googleapis/repo-automation-bots: A collection of bots, based on probot, for performing common maintenance tasks across the open-source repos managed by Google on GitHub.</a>一组基于probot的机器人,用于谷歌在GitHub上管理的开源转发中执行常见维护任务。下面是一些可用的bot</p><div class="table-container"><table><thead><tr><th><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/auto-approve">auto-approve</a></th><th>Automatically approves and merges PRs matching user-specified configs</th><th><a href="https://github.com/apps/auto-approve-bot">install</a></th></tr></thead><tbody><tr><td><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/auto-label">auto-label</a></td><td>Automatically labels issues and PRs with product, language, or directory based labels</td><td><a href="https://github.com/apps/product-auto-label">install</a></td></tr><tr><td><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/blunderbuss">blunderbuss</a></td><td>Assigns issues and PRs randomly to a specific list of users</td><td><a href="https://github.com/apps/blunderbuss-gcf">install</a></td></tr><tr><td><a href="https://github.com/googleapis/repo-automation-bots/tree/main/packages/cherry-pick-bot">cherry-pick-bot</a></td><td>Cherry-pick merged PRs between branches</td><td><a href="https://github.com/apps/gcp-cherry-pick-bot">install</a></td></tr></tbody></table></div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://probot.github.io/docs/">probot.github.io/docs/</a></li><li><a href="https://dev.to/pragativerma18/github-bots-for-every-open-source-project-47hl">GitHub Bots for every open-source project - DEV Community</a></li><li><a href="https://github.com/googleapis/repo-automation-bots?tab=readme-ov-file">googleapis/repo-automation-bots: A collection of bots, based on probot, for performing common maintenance tasks across the open-source repos managed by Google on GitHub.</a></li><li><a href="https://smee.io/dSzRk0AnpSDDOf0T">smee.io | Webhook deliveries</a></li><li><a href="https://ngrok.com/">ngrok | Unified Application Delivery Platform for Developers</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在看一些开源项目时,会发现一些帮忙处理issue和PR的bot,这些bot都是基于Github的Apps&lt;a href=&quot;https://docs.github.com/en/apps/overview&quot;&gt;GitHub Apps overview - GitHub Docs&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>目标检测综述</title>
    <link href="https://www.sekyoro.top/2023/12/22/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/"/>
    <id>https://www.sekyoro.top/2023/12/22/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BB%BC%E8%BF%B0/</id>
    <published>2023-12-22T11:38:36.000Z</published>
    <updated>2023-12-23T12:04:10.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>2023年的目标检测综述<strong>A comprehensive review of object detection with deep learning</strong>以及<strong>3D Object Detection for Autonomous Driving: A Comprehensive Survey</strong>,之前写了一些单阶段和双阶段的2D目标检测,可以好好回顾一下.</p><span id="more"></span><h2 id="Abs"><a href="#Abs" class="headerlink" title="Abs"></a>Abs</h2><p>本综述详细介绍了物体检测及其各个方面。随着用于检测物体的深度学习算法逐渐发展，物体检测模型的性能也有了显著提高。但是，这并不意味着在深度学习出现之前已经发展了几十年的传统物体检测方法已经过时。<strong>在某些情况下，具有全局特征的传统方法是更优的选择</strong>。<strong>本综述论文首先简要概述了物体检测，然后介绍了物体检测框架、骨干卷积神经网络、常见数据集概述以及评估指标</strong>。此外，还详细研究了物体检测问题和应用。还<strong>讨论了设计深度神经网络的一些未来研究挑战</strong>。最后，比较了对象检测模型在 PASCAL VOC 和 MS COCO 数据集上的性能，并得出结论。</p><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>物体检测的主要目的是检测特定类别的视觉物体，如电视/显示器、书籍、猫、人类等，并使用边界框定位它们，然后将它们归入特定物体的类别中。</p><p>通用对象检测还有其他几个术语，例如通用对象类别检测、对象类别检测、类别级对象检测和对象类别检测。它也侧重于识别一些预设类别的实例.</p><p>物体检测的发展通常分为两个历史阶段。<strong>2014 年之前是传统方法阶段，2014 年之后则是基于深度学习的方法阶段</strong>。本文将重点讨论基于深度学习的方法。由于 CNN 在物体检测算法的实施中发挥着重要作用，因此本文将利用 CNN 来获得最佳结果。这两个阶段的架构在精度、速度和硬件资源方面各不相同。将 CNN 与传统技术相比，CNN 具有更好的架构和更强的表现力。</p><p>在讨论基于深度学习的物体检测算法之前，重要的是要了解传统技术的工作原理，并知道为什么基于深度学习的方法要优越得多。这将有助于研究人员更好地理解现代物体检测方法。</p><h3 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h3><p>传统目标检测方法分为三个阶段。这些阶段及其各自的缺点如下:</p><p><strong>区域选择</strong> – 由于对象具有不同的大小和纵横比，因此它们可能出现在图像的不同区域。因此，在第一阶段，必须确定物体的区域。因此，使用多尺度滑动窗口方法检查整个图像以检测物体。然而，这种方法的计算成本很高，并且还会导致大量非必要的选择。</p><p><strong>特征提取</strong> – 定位对象后，执行特征提取过程以提供可靠的表示。<strong>HOG、Haar-like 、SIFT</strong> 等方法用于提取特征以进行目标识别，以提供有意义的表示。然而，由于对比鲜明的背景、照明环境和透视差异，手动构建一个能够正确识别各种对象的综合特征描述符是极其困难的。</p><p><strong>分类</strong> – 在这个阶段，使用分类器（如 Adaboost ）来识别目标对象，并构建更有条理、更有意义的视觉感知模型。</p><p>从以上几点可以清楚地看出，<strong>在传统方法中，手工制作的特征并不总是足以正确表示对象</strong>。除此之外，用于生成边界框的滑动窗口方法在计算上成本高昂且效率低下。传统的技术包括HOG、SIFT 、Haar、VJ检测器和其他算法，如。在HOG 中，识别一个物体需要很长时间，因为它采用滑动窗口方法来提取特征。SIFT算法速度极慢，计算成本高，也不擅长光照变化。在VJ检测器中，训练持续时间非常长，仅限于二元分类。因此，深度学习技术正在被用于克服传统方法的问题</p><p>深度学习的出现有可能解决传统技术的一些局限性。最近，深度学习方法在自动从数据中学习特征表示方面变得突出。这些方法显著改善了目标检测。基于深度学习的方法有 <strong>Faster RCNN、SSD、YOLO</strong> 等等。</p><p><img data-src="https://i.imgur.com/lJA5oxG.png" alt="image-20231222203515697"></p><p>由于深度 CNN 具有很高的特征表示能力，因此它们被用于对象检测架构。有两种类型的探测器：两级和一级探测器.</p><p>两阶段目标检测框架<strong>将目标定位和目标分类任务分开</strong>。简单来说，<strong>首先在对象所处的地方生成区域建议，然后根据其特定类别对该区域进行分类</strong>。这就是为什么它被称为两阶段的原因。两级目标探测器的主要优点是检测精度高，缺点是检测速度慢。</p><h4 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h4><p>基于区域的卷积神经网络（RCNN）在使用深度学习方法检测目标方面进行了深入研究。其架构如图所示。RCNN的过程在下面分四个阶段进行解释</p><p><img data-src="https://i.imgur.com/tIKAWn2.png" alt="image-20231222204652846"></p><p>第 1 阶段 :使用<strong>选择性搜索方法提取区域建议</strong>。选择性搜索<strong>根据不同的比例、外壳、纹理和颜色模式来识别这些区域</strong>。它<strong>从每张图像中提取大约 2000 个区域</strong></p><p>第 2 阶段 – 由于全连接层需要固定长度的输入向量，因此<strong>所有这些区域建议都重新缩放为相同的图像大小以匹配 CNN 输入大小</strong>。<strong>使用 CNN 提取每个候选区域的特征</strong>。</p><p>第 3 阶段 – 提取特征后，<strong>使用 SVM 分类器检测对象是否存在于每个区域</strong>中。</p><p>第 4 阶段 – 最后，对于图像中的每个已识别对象，使用线性回归模型在其周围生成更紧密的边界框。尽管RCNN在目标检测方面取得了很大的进步，但仍然存在一些局限性，如目标检测速度慢、多阶段流水线训练和选择性搜索方法的僵化。</p><h4 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h4><p>由于 RCNN 为每张图像生成 2000 个区域建议，因此从这些区域提取 CNN 特征是主要障碍。<strong>固定输入大小的约束只是因为全连接层</strong>。因此，<strong>为了克服这一困难，引入了一种称为空间金字塔池化网络层（SPP-Net）的新技术</strong>。<strong>将 SPP 层添加到最终卷积层的顶部，以生成全连接层的固定长度特征</strong>，无论 RoI（感兴趣区域）的大小如何，并且不会重新缩放它，这可能会导致信息丢失(相当于替代RCNN中的warp操作).</p><p><img data-src="https://i.imgur.com/GyXhKPL.png" alt="image-20231222205054546"></p><p>通过使用SPPNet层，RCNN的速度有了很大的提高，而检测质量没有任何损失。这是因为卷积层<strong>只需要在完整的测试图像上运行一次，就可以为随机大小的区域建议创建固定长度的特征</strong>。这里 SPP 层的输出是 256×M-d 向量。256 是卷积滤波器的数量，M 是bin的数量。全连接层接收固定长度的维向量。</p><h4 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h4><p>尽管SPPNet在效率和准确性方面优于RCNN，但它仍然存在一些问题，例如它大致遵循与RCNN相同的过程，包括网络微调、特征提取和边界框回归。</p><p>Girshick， R. 在 RCNN 和 SPPNet 方面表现出进一步的改进，并提出了一种名为 Fast RCNN 的新探测器 。<strong>它允许对检测器进行端到端训练，同时学习 softmax 分类器和特定于类的边界框回归，同时进行多任务损失，而不是像在 RCNN 和 SPPNet 中那样单独训练它们</strong>。</p><p>在 Fast RCNN 中，它不是对每张图像执行 2000 次 CNN，<strong>而是只运行一次并获取所有感兴趣的区域。然后，在最终卷积层和初始全连接层之间添加RoI池化层，从而提取出所有区域建议的固定长度向量特征</strong>。</p><p>1st – Fast RCNN 获取完整的输入图像并将其传递给 CNN 以生成特征图。</p><p>第 2 个 – 感兴趣区域 （RoI） 是使用选择性搜索方法生成的。</p><p>第三 – 在提取的 RoI 上应用 RoI 池化层以生成固定长度的特征向量。它确保所有区域都具有相同的量级。</p><p>第 4 次 – 然后<strong>将提取的特征发送到全连接层，同时使用 softmax 层和线性回归层进行分类和定位</strong>。</p><p>Fast RCNN消耗的计算时间更少，检测精度更高。然而，<strong>它基于传统的区域建议方法，使用选择性搜索方法，使其非常耗时</strong>。</p><h4 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h4><p>尽管Fast RCNN在速度和准确性方面取得了长足的进步，<strong>但它使用选择性搜索方法生成了2000个region proposals，这是一个非常缓慢的过程</strong>。任，S.等人致力于这个问题，并开发了一种新的检测器，名为Faster RCNN，作为第一个端到端深度学习检测器。<strong>它还通过将传统的region proposal算法（如选择性搜索、多尺度组合分组或边缘框）替换为称为区域建议网络（RPN）的CNN</strong>，提高了Fast RCNN的检测速度。</p><p>a） CNN 将图像作为输入，并提供图像的特征图作为输出。</p><p>b） <strong>RPN 应用于生成的特征图，返回对象建议 （RoI） 及其对象性分数</strong>。</p><p>c） 提取 RoI 后，将 RoI 池化层应用于其，以将所有提案置于固定维度。</p><p>d） <strong>将派生的特征向量提供给连续的全连接层中，顶部有一层 softmax 和回归层，用于对对象的边界框进行分类和输出</strong></p><p><img data-src="https://i.imgur.com/D9dXGsH.png" alt="image-20231222205738677" style="zoom:67%;" /></p><p>RPN 的工作 – 区域提案网络是一个完全卷积网络，它连接到骨干网络的最后一个卷积层 。<strong>它接收特征图，并使用这些特征图上的滑动窗口输出多个对象建议</strong>。<strong>在每个窗口上，网络生成 k 个不同大小和纵横比的锚框</strong>（也称为参考框）。</p><p><strong>只有从锚点框获得的特征是特定于类的，而不是锚点的位置</strong>。</p><p>每个对象提案由 4 个坐标和一个分数组成，用于确定对象是否存在。<strong>每个锚点映射到一个低维向量，并传递给两个全连接层，一个是对象类别分类层，另一个是box回归层</strong></p><h4 id="Feature-pyramid-network"><a href="#Feature-pyramid-network" class="headerlink" title="Feature pyramid network"></a>Feature pyramid network</h4><p>Lin， T. Y. et al. 提出了特征金字塔网络 （FPN）</p><p>DCNN 固有的多尺度金字塔层次结构，以低成本构建特征金字塔。它将任何大小的图像作为输入，并在多个级别输出相同大小的特征图。这种方法在许多应用中显示出相当大的增强。</p><p><img data-src="https://i.imgur.com/or3OwoO.png" alt="image-20231222210741517"></p><p>FPN 不是对象检测器。它是一种特征提取器，与对象检测器结合使用。<strong>FPN的架构使用自上而下的通路和横向连接将语义上较强的低分辨率特征与语义较弱的高分辨率特征相结合。FPN使用CNN架构的序列，通过横向连接构建自下而上的路径和自上而下的路径。在自下而上的路径（红色）中，图像作为输入传递给 CNN，它使用池化层将特征图设置为相同的大小。对于FPN的每个阶段（即每个分辨率级别），定义了一个金字塔级别</strong></p><p>在自上而下的路径（以蓝色显示）中，<strong>通过将特征图上采样回与自下而上部分相同的大小来使用更高分辨率的特征。然后使用横向连接，这些特征通过自下而上途径的特征进行增强</strong>。每个横向连接都从自下而上和自上而下路径组合了相同大小的特征图</p><p>FPN 的过程为生成具有大量语义内容的多尺度特征图提供了广泛的解决方案。F<strong>PN 不依赖于 CNN 的架构，可以强制执行到对象检测的不相同阶段</strong>，例如 RPN、Fast RCNN.尽管DCNN具有强大的表征能力，但<strong>有必要通过金字塔表示来解决多尺度挑战</strong></p><h4 id="Mask-RCNN"><a href="#Mask-RCNN" class="headerlink" title="Mask RCNN"></a>Mask RCNN</h4><p>He， K. et al.设计了一款名为Mask RCNN的目标检测器，这是对Faster RCNN的增强，用于解决进行目标检测和语义分割作业的实例分割问题。这两个任务是自力更生的过程。Mask RCNN 的目标是执行像素级分割。蒙版RCNN检查每个像素并估计它是否是对象的一部分。</p><p>Mask R-CNN 遵循 Faster R-CNN 的架构;两者都使用相同的RPN，<strong>但区别在于掩码RCNN对每个对象提案有三个输出，即.class标签，边界框偏移量和对象检测掩码</strong>。在 Mask RCNN 中，RoIAlign 层用于将提取的特征与对象的输入位置相关联。RoIAlign 层的目的是修复 RoI 池化层中的错位问题。它无需测量 RoI 阈值，而是使用双线性插值来评估每个采样点的实际特征值。Mask RCNN 在实例分割方面实现了最先进的性能</p><p><strong>基于区域提案的框架由各个阶段组成，这些阶段相互连接并分别进行训练。这些是区域建议生成、使用 CNN 提取特征、分类和边界框回归</strong>。尽管这些方法能够实现高精度，但仍存在一些与实时速度相关的问题。这个问题可以通过统一的阶段检测器来克服，<strong>方法是删除区域建议阶段，并在单个CNN中实现特征提取、建议回归和预测</strong></p><p>损失或成本函数，如Hinge损失、L1 和 L2 损失、对数损失 [52]是预期输出和预测输出之间差异的度量。建议读者参考相应的物体检测器论文以获取更多信息</p><h3 id="One-stage-object-detectors"><a href="#One-stage-object-detectors" class="headerlink" title="One-stage object detectors"></a>One-stage object detectors</h3><p>单阶段对象检测框架使用 DCNN <strong>同时进行定位和分类</strong>，而无需将它们划分为两个部分。</p><p>在这种情况下，只需要通过神经网络进行一次传递。它具有前馈神经网络，可<strong>以一次预测所有边界框。它们将图像像素直接映射到边界框坐标和类概率</strong>。</p><h4 id="DetectorNet"><a href="#DetectorNet" class="headerlink" title="DetectorNet"></a>DetectorNet</h4><p>Szegedy， C.等将DetectorNet框架实现为回归问题。</p><p>它能够学习特征进行分类并获取一些几何信息。它<strong>使用 AlexNet 作为骨干网络，并将 softmax 层替换为回归层</strong>。为了预测前景像素，DetectorNet 将输入图像分割成coarse grid。它的训练过程非常缓慢，因为网络要针对每种对象类型和掩码类型进行训练。此外，DetectorNet 无法处理类似类的多个对象。当它与多尺度从粗到细方法结合使用时，基于 DNN 的对象掩码回归会产生出色的结果</p><h4 id="Overfeat"><a href="#Overfeat" class="headerlink" title="Overfeat"></a>Overfeat</h4><p>Sermanet， P.等提出了一种统一的结构，即<strong>使用卷积网络通过多尺度滑动窗口方法进行定位、分类和检测</strong>。它是最强大的目标检测框架之一，应用于 ImageNet 大规模视觉识别挑战赛 2013 （ILSVRC），在检测和定位方面排名第一 。它是<strong>第一个基于全卷积深度网络的单级检测器，它通过全卷积层使用单次前向通道来检测物体</strong>。</p><p>OverFeat 充当后来出现的算法的基础模型，即 YOLO 及其版本、SSD 等。主要区别在于<strong>分类器和回归器的训练是在 OverFeat 中连续完成的</strong></p><h4 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h4><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/yolo-network-architecture.png" alt="img"></p><p>You Only Look Once（YOLO）是由Redmon， J.等人设计的单级目标检测器，<strong>其中目标检测作为回归问题进行。它预测对象的边界框的坐标，并确定它所关联的类别的可能性</strong>。由于仅使用单个网络，因此可以实现端到端优化。它<strong>使用有限的候选区域选择直接预测检测。与基于区域的方法不同，这些方法使用来自特定区域的特征</strong>，而YOLO广泛使用来自整个图像的特征</p><p>在YOLO目标检测中，图像被划分为S×S网格;每个网格由五个元组（x、y、w、h 和置信度分数）组成。单个对象的置信度分数基于概率。这个分数是给每个类的，无论哪个类的概率很高，该类都会优先。</p><p>边界框的参数宽度 （W） 和高度 （H） 是根据对象的大小来预测的。从重叠的边界框中，选择具有最高 IOU 的框，并删除其余框。</p><p>YOLOv2是YOLOv1的增强版本，由Redmon， J.等人]给出。在这个版本中，应用了不同的思想<strong>，如批量归一化、卷积锚框、高分辨率分类器</strong>、<strong>细粒度特征和多尺度训练</strong>来提高 YOLO 的性能。它使用 Darknet-19 作为包含 19 个卷积层和 5 个最大池化层的骨干分类，这些层需要更少的过程来分析图像，同时实现最佳精度</p><p>YOLOv3 是 YOLOv2  的渐进形式，它使用<strong>逻辑回归来估计每个边界框的客观性分数。边界框中包含多个类，为了预测这些类，使用了多标签分类</strong>。它还使用二进制交叉熵损失、数据增强技术和批量归一化。YOLOv3 使用一个名为 Darknet-53 的健壮特征提取器</p><p>YOLOv4 是一种先进的目标检测器，比以前所有版本的YOLO更准确、更快。它包括一种称为“Bag of freebies”的方法，该方法在不影响推理时间的情况下增加了训练时间。该方法利用<strong>数据增强技术、自对抗训练、交叉小批量归一化 （CmBN）、CIoU 损失 、DropBlock 正则化、余弦退火调度器来改进训练。YOLOv4 还包含了那些只影响推理时间的方法，称为“Bag of specials”;它包括 Mish 激活、多输入加权残差连接 （MiWRC）、SPP 模块 [26]、PAN 路径聚合模块 [58]、跨级部分连接 （CSP）和空间注意力模块模块</strong>。YOLOv4 可以在单个 GPU 上训练，并使用遗传算法来选择超参数</p><p>在 YOLOv4 发布后不久，Ultralytics 公司推出了 YOLOv5 存储库，与以前的 YOLO 模型相比，它有相当大的增强,由于 YOLOv5 不是作为同行评议的研究发表的，因此它引起了许多关于其合法性的争论;但它仍然被用于各种应用，并在产生模型可靠性的同时提供有效的结果。它以 140 fps 的推理速度运行。YOLOv5使用PyTorch，这使得模型的部署更快、更容易、更准确[60]。虽然 YOLOv4 和 YOLOv5 框架相似，因此很难比较它们之间的区别，但后来，YOLOv5 在某些情况下获得了比 YOLOv4 更高的性能。YOLOv5 模型有五种类型：nano、small、medium、large、extralarge。根据数据集选择模型类型。此外，YOLOv5 模型的轻量级模型随 6.0 版本发布;推理速度提高至 1666 fps.</p><h4 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h4><p><img data-src="https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/SSD-architecture.png" alt="img"></p><p>SSD是一种用于多个类别的快速单次多box检测器，由Liu， W.等人实现。它构建了一个统一的检测器框架</p><p>该框架与 YOLO 一样快，与 Faster-RCNN 一样准确。SSD的设计结合了YOLO模型的回归思想和Faster R-CNN算法的锚定过程。通过使用 YOLO 的回归，SSD 降低了神经网络的计算复杂性，以确保实时性能。通过锚点程序，SSD能够提取各种大小和纵横比的特征，以确保检测精度。SSD 使用 VGG-16 作为骨干检测器</p><p>SSD的过程基于前馈CNN，该CNN为这些框中是否存在对象类实例生成固定大小和对象性分数的边界框，然后应用NMS（非最大抑制）进行最终检测。它还使用RPN的概念来获得快速的检测速度，同时保持高检测质量。通过一些辅助数据增强和硬负挖掘方法，SSD 在各种基准数据集上实现了最先进的性能</p><h3 id="Backbone-networks"><a href="#Backbone-networks" class="headerlink" title="Backbone networks"></a>Backbone networks</h3><p>DCNN作为目标检测模型的骨干网络。为了改善特征表示行为，网络的结构变得更加复杂，这意味着网络层会变得更深，其参数也会增加。骨干CNN用于提取基于DCNN的目标检测系统的特征。</p><p><strong>骨干网络作为目标检测方法的主要特征提取器，将图像作为输入，并为每个输入图像生成特征图作为输出</strong>。根据精度和效率的需要;可以使用密集连接的骨干网，如ResNet 、ResNext等。当需要高精度和构建精确的应用程序时，需要复杂的主干网。</p><p>AlexNet是一种重要的CNN架构，由5个卷积层和3个全连接层组成。在为图像提供固定大小（224 × 224）的输入后，网络一遍又一遍地卷积并汇集激活，然后将结果传输到完全连接的层。该网络在ImageNet上进行训练，并结合了多种正则化方法，例如数据增强，dropout等。为了加速数据处理，提高收敛速度，首次使用了ReLu激活函数和GPU。</p><h3 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h3><p>在AlexNet取得成功之后，研究人员想知道卷积层可视化背后的机制，以了解CNN如何学习特征以及如何检查每层图像特征图的差异。</p><p>因此，Zeiler， M. D. et al. 设计了一种<strong>使用反卷积层、解池层和ReLU非线性来可视化特征图的方法。与 AlexNet 一样，第一层的滤波器大小为 11×11，步幅为 4，但在 ZFNet 中，它减少到 7×7，步幅设置为 2 而不是 4</strong>。这样做的原因是第一层的滤波器包含频率信息的变化;它可以是高的，也可以是低的，并且具有非常小的中频百分比。该方法的性能优于AlexNet，并证明了网络的深度会影响深度学习模型的性能</p><h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p>VGG 进一步将AlexNet的深度扩大到16-19层，从而细化了网络的特征表示。VGG16 和 VGG19 是两种流行的 VGG 网络架构。在每一层中，它采用大小为 3×3 的内核，步幅为 1。小内核和步幅更有利于提取图像中物体位置的细节。它的好处是通过合并额外的卷积层来扩展网络的深度。最小化参数可以提高网络的特征表示能力</p><h4 id="GoogLeNet-或-inception-v1"><a href="#GoogLeNet-或-inception-v1" class="headerlink" title="GoogLeNet 或 inception v1"></a>GoogLeNet 或 inception v1</h4><p>GoogleNet  的主要目的Inception v1 架构旨在通过降低计算成本来实现高精度。向网络添加 1×1 卷积层，其深度增加。这种滤波器大小首先用于名为Network-in-Network的技术，主要用作降维以消除计算瓶颈并增加网络的宽度和高度。</p><p>GoogleNet 是一个 22 层的深度架构，是 ILSVRC 2014 竞赛的获胜者。基于这一思路，作者开发了一个具有降维功能的初始模块。通过使用 inception 模块，GoogLeNet 参数的数量减少了。Inception 模块由 1x1、3x3 和 5x5 滤波器大小的卷积层和相互平行组装的最大池化层组成。Inception v2 系列是第一个提出批量归一化的网络 ，从而实现快速训练</p><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>随着网络深度的增加，可能会出现精度在达到饱和点后下降的情况。这被称为退化问题，为了解决这个问题，提出了一个残差学习（ResNet）模块。与早期设计的架构（如AlexNet 和VGGNet）相比，它的计算复杂度更低。通常使用层数为50和101层的ResNet骨干网络。在 ResNet50 中，使用跳过连接来保留更深层的梯度，并且精度有所提高。在 ResNet101 中，该模块的性能与 VGG 网络相同，但参数数量较少，遵循 GoogLeNet 中的全局平均池化和瓶颈</p><h4 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h4><p>Huang， G. et al. 提出了由密集块组成的 DenseNet 架构，该架构以前馈方式将每一层与其他层连接起来，从而带来特征重用、参数有效性和隐式深度监督等好处。DenseNet 减少了梯度消失的问题</p><h3 id="Problems-of-object-detection-and-its-solutions"><a href="#Problems-of-object-detection-and-its-solutions" class="headerlink" title="Problems of object detection and its solutions"></a>Problems of object detection and its solutions</h3><h4 id="Small-object-detection"><a href="#Small-object-detection" class="headerlink" title="Small object detection"></a>Small object detection</h4><p>检测小尺寸物体是物体检测中最困难的问题之一。Faster RCNN 和 YOLO等目标检测算法在检测小尺寸物体方面不足。在深度卷积神经网络中，由于独立特征层在实际图像中仅占据很小的像素尺寸，因此缺乏足够的知识。由于低分辨率的小尺寸物体携带有限的上下文细节，因此很难检测到它们。为了克服这个问题，可以<strong>通过增强生成更多的数据，或者可以提高模型的输入分辨率</strong>等</p><h4 id="Multi-scale-object-detection"><a href="#Multi-scale-object-detection" class="headerlink" title="Multi-scale object detection"></a>Multi-scale object detection</h4><p>在目标检测领域，多尺度目标检测是一项具有挑战性的任务。<strong>深度CNN的每一层都会生成特征图，而这些特征图生成的信息是相互独立的。多尺度对象的判别细节可以出现在骨干网络的任一层中，而对于小尺度对象，它出现在初始层中，并在后面的层中消散</strong>。在目标检测算法（一级和两级）中，预测是从最顶层进行的，这给检测多尺度对象（通常是小对象）的方式造成了障碍。为了克服这个困难;该文提出<strong>信息融合与DCNNs分层结构相结合的多层检测和特征融合</strong></p><p>代表性方法包括多尺度深度CNN 、深度监督目标检测（DSOD）和SSD。为了提高多尺度目标检测的可靠性，可以合并多层特征融合和多层检测。这包括特征金字塔网络（FPN）、反卷积单次检测器（DSSD）、尺度可转移检测网络（STDN）、与对象先验网络的反向连接（RON）、自上而下的调制（TDM）等几个具有代表性的框架。</p><h4 id="Intraclass-variation"><a href="#Intraclass-variation" class="headerlink" title="Intraclass variation"></a>Intraclass variation</h4><p>类内variation是指<strong>同一类的不同图像之间发生的variation</strong>。<strong>它们的形状、大小、颜色、材料、质地等各不相同</strong>。对象实例看起来很灵活，可以在缩放和旋转方面轻松转换。这些被称为内在因素。外部因素也会产生一些明显的影响。<strong>它包括照明不当、天气条件、照明、低质量相机等。这种差异可能由多种因素引起</strong>，如遮挡、照明、位置、透视等。这个问题可以通过验证训练数据是否具有良好的多样性（包括上述所有因素）来克服</p><h4 id="Class-imbalance"><a href="#Class-imbalance" class="headerlink" title="Class imbalance"></a>Class imbalance</h4><p>类之间的不规则数据分布称为类不平衡。简单来说，<strong>可以说当类包含不成比例数量的实例时，即在一个数据集中比另一个数据集中的标本多</strong>。从对象检测的角度来看，类不平衡可以分为两种类型：前景-背景不平衡和前景-前景不平衡。前者发生在训练过程中，与数据集中的类别数量无关。后者是指在样本数量范围内批次水平的不平衡，涉及正类。<strong>一般来说，一级目标探测器的精度低于两级目标探测器，其背后的原因之一是类别不平衡。为了解决这个问题，可以对类进行上采样和下采样，或者使用合成少数过采样技术（SMOTE）等生成合成数据</strong></p><h4 id="Generalization-issues"><a href="#Generalization-issues" class="headerlink" title="Generalization issues"></a>Generalization issues</h4><p>当模型欠拟合或过拟合时，就会出现目标检测中的泛化问题。欠拟合可以在训练阶段的初始阶段识别出来，这个问题可以通过增加训练周期的数量或模型的复杂性来解决。对于过拟合，我们可以使用重要的方法，例如<strong>增加训练数据、提前停止、正则化方法（L1、L2）或丢弃层</strong></p><h2 id="3D-Object-Detection-for-Autonomous-Driving-A-Comprehensive-Survey"><a href="#3D-Object-Detection-for-Autonomous-Driving-A-Comprehensive-Survey" class="headerlink" title="3D Object Detection for Autonomous Driving: A Comprehensive Survey"></a>3D Object Detection for Autonomous Driving: A Comprehensive Survey</h2><h3 id="abs"><a href="#abs" class="headerlink" title="abs"></a>abs</h3><p>近年来，自动驾驶因其减轻驾驶员负担和提高驾驶安全性的潜力而受到越来越多的关注。在现代自动驾驶管道中，感知系统是不可或缺的组成部分，<strong>旨在准确估计周围环境的状态，并为预测和规划提供可靠的观测结果。3D 物体检测旨在预测自动驾驶汽车附近 3D 物体的位置、大小和类别</strong>，是感知系统的重要组成部分。本文综述了自动驾驶三维目标检测的研究进展。首先，我们<strong>介绍了3D目标检测的背景，并讨论了该任务的挑战。其次，我们从模型和感官输入方面对3D目标检测的进展进行了全面调查，包括基于激光雷达、基于相机和多模态检测方法。我们还对每类方法的潜力和挑战进行了深入分析</strong>。此外，我们还系统地研究了3D目标检测在驾驶系统中的应用。最后，对三维目标检测方法进行了性能分析，进一步总结了多年来的研究趋势，并展望了该领域的未来发展方向。</p><h3 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h3><p>自动驾驶技术已广泛应用于许多场景，包括自动驾驶卡车、机器人出租车、送货机器人等，能够减少人为错误并增强道路安全性。作为自动驾驶系统的核心组成部分，汽车感知帮助自动驾驶汽车通过感官输入了解周围环境。<strong>感知系统通常以多模态数据（摄像头图像、激光雷达扫描仪点云、高清地图等）为输入，预测道路上关键要素的几何和语义信息。高质量的感知结果可作为目标跟踪、轨迹预测和路径规划等后续步骤的可靠观测</strong></p><p><img data-src="https://i.imgur.com/02X39qA.png" alt="image-20231222223259144"></p><p>3D 对象检测旨在根据感官输入预测驾驶场景中 3D 对象的边界框。3D 目标检测的一般公式可以表示为</p><script type="math/tex; mode=display">\begin{equation}\mathcal{B}=f_{det}(\mathcal{I}_{sensor}),\end{equation}</script><p>f~det~ 是 3D 对象检测模型，I~sensor~ 是一个或多个感官输入,B = {B1， · · · ， BN } 是场景中 N 个 3D 对象的集合。</p><p>如何表示 3D 对象 Bi 是此任务中的一个关键问题，因为它决定了应为以下预测和规划步骤提供哪些 3D 信息。在大多数情况下，3D 对象表示为包含此对象的 3D 长方体，</p><script type="math/tex; mode=display">\begin{equation}B=[x_c,y_c,z_c,l,w,h,\theta,class],\end{equation}</script><p>其中 （x~c~， y~c~， z~c~） 是长方体的 3D 中心坐标，l、w、h 分别是长方体的长度、宽度和高度，θ 是长方体在地平面上的航向角，即偏航角，class 表示 3D 对象的类别，例如汽车、卡车、行人、骑自行车的人。此外也有其他模型使用了更多参数的.</p><p><strong>Sensory inputs</strong></p><p>有许多类型的传感器可以为 3D 物体检测提供原始数据。<strong>在传感器中，雷达、摄像头和LiDAR（光探测和测距）传感器是三种最广泛采用的传感类型</strong>。雷达具有较长的探测范围，并且对不同的天气条件具有鲁棒性。由于多普勒效应，雷达可以提供额外的速度测量。摄像头价格便宜且易于获取，对于理解语义（例如交通标志的类型）至关重要。尽管价格便宜，但相机在用于 3D 物体检测方面存在固有的局限性<strong>。相机只能捕获外观信息，无法直接获取场景的 3D 结构信息</strong>。另一方面，<strong>3D物体检测通常需要在3D空间中进行精确定位，而从图像中估计的3D信息（例如深度）通常具有较大的误差</strong>。图像的变形通常<strong>容易受到极端天气和时间条件的影响</strong>。在<strong>夜间或雾天从图像中检测物体比在晴天检测要困难得多</strong>，这导致了实现自动驾驶的足够鲁棒性的挑战。</p><p><img data-src="https://i.imgur.com/lS0F3vq.png" alt="image-20231222225107201"></p><p>作为替代解决方案，<strong>LiDAR 传感器可以通过发射激光束然后测量其反射信息来获得场景的细粒度 3D 结构。</strong>一个激光雷达传感器发射 m 束并在一个扫描周期内进行 n 次测量，可以产生 I~range~ ∈ R^m×n×3^ 的距离图像,其中,范围图像的<strong>每个像素都包含球面坐标系中的距离 r、方位角α和倾角φ以及反射强度</strong>。</p><p><strong>范围(Range)图像是LiDAR传感器获得的原始数据格式，可以通过将球面坐标转换为笛卡尔坐标来进一步转换为点云。</strong></p><p>点云可以表示为 I~point~ ∈ R^N×3^，其中 N 表示场景中的点数，每个点有 3 个 xyz 坐标通道。<strong>距离图像和点云都包含由LiDAR传感器直接获取的精确3D信息</strong>。</p><p>因此，<strong>与相机相比，LiDAR 传感器更适合检测 3D 空间中的物体，并且 LiDAR 传感器也不太容易受到时间和天气变化的影响</strong>。然而，LiDAR 传感器比摄像头贵得多，这可能会限制在驾驶场景中的应用</p><p>2D 目标检测旨在<strong>在图像上生成 2D 边界框</strong>，是计算机视觉中的一个基本问题。</p><p>3D 目标检测方法借鉴了 2D 对应物的许多设计范式：<strong>region proposals生成和细化、锚点、非最大抑制等</strong>。然而，从很多方面来看，3D目标检测并不是2D目标检测方法对3D空间的简单改变。</p><p>（1）3D目标检测方法必须处理异构数据表示<strong>。点云检测需要新型算子和网络来处理不规则的点数据</strong>，而点云和图像的检测需要特殊的融合机制。</p><p>（2） 3D 目标检测方法通常<strong>利用不同的投影视图来生成对象预测</strong>。</p><p>与从透视图检测对象的 2D 对象检测方法相反，<strong>3D 方法必须考虑不同的视图来检测 3D 对象，例如从鸟瞰图、点视图和圆柱视图</strong>。（3）3D物体检测对物体在3D空间中的精确定位有很高的要求。分米级的定位误差可能导致行人和骑自行车的人等小物体的检测失败，而在二维物体检测中，几个像素的定位误差仍可能在预测边界框和地面实况边界框之间保持较高的交并 （IoU）。因此，精确的 3D 几何信息对于从点云或图像进行 3D 物体检测是必不可少的。</p><p>（1） LiDAR 和 RGB-D 传感器的点云分布不同。在室内场景中，点相对均匀地分布在扫描表面上，大多数 3D 对象在其表面上接收到足够数量的点。然而，在驾驶场景中，大多数点都落在 LiDAR 传感器的附近，而那些远离传感器的 3D 物体只会获得几个点。因此，在驾驶场景中，<strong>特别需要处理各种点云密度的三维物体，并准确检测那些远距离和稀疏的物体。</strong></p><p>（2）驾驶场景下的检测对推理时延有特殊要求。<strong>驾驶场景中的感知必须是实时的</strong>，以避免事故发生。因此，这些方法必须具有计算效率，否则它们将无法应用于实际应用。</p><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><p><img data-src="https://i.imgur.com/HiTj4TF.png" alt="image-20231222230257242"></p><h3 id="LiDAR-based-3D-Object-Detection"><a href="#LiDAR-based-3D-Object-Detection" class="headerlink" title="LiDAR-based 3D Object Detection"></a>LiDAR-based 3D Object Detection</h3><p>我们将介绍基于LiDAR数据的3D目标检测方法，即点云或距离图像。回顾和分析了基于不同数据表示的基于 LiDAR 的 3D 目标检测模型，包括<strong>基于点</strong>、<strong>基于网格</strong>、<strong>基于点体素</strong>和<strong>基于距离</strong>的方法。(point-based, grid-based, point-voxel based, and range-based)</p><p><img data-src="https://i.imgur.com/7LLjGj3.png" alt="image-20231222230749845"></p><h4 id="Data-representations-for-3D-object-detection"><a href="#Data-representations-for-3D-object-detection" class="headerlink" title="Data representations for 3D object detection"></a>Data representations for 3D object detection</h4><p><strong>与像素有规律地分布在图像平面上的图像相比，点云是一种稀疏且不规则的 3D 表示</strong>，需要专门设计的模型进行特征提取。<strong>范围图像是一种密集而紧凑的表示形式，但范围像素包含 3D 信息而不是 RGB 值</strong>。因此，在范围图像上直接应用传统的卷积网络可能不是最佳解决方案。另一方面，自动驾驶场景中的检测通常具有实时推理的要求。因此，如何开发一个既<strong>能有效处理点云或范围图像数据又能保持高效率的模型</strong>，仍然是研究界面临的一个公开挑战。</p><h4 id="Point-based-3D-object-detection"><a href="#Point-based-3D-object-detection" class="headerlink" title="Point-based 3D object detection"></a>Point-based 3D object detection</h4><p>基于点的3D目标检测方法通常继承了点云深度学习技术的成功，并<strong>提出了直接从原始点检测3D对象的多种架构</strong>。</p><p>点云首先通过基于<strong>点的骨干网络</strong>，在该网络中，点逐渐采样，点云操作学习特征。然后，根据下采样点和特征预测 3D 边界框。</p><p><img data-src="https://i.imgur.com/Vl1RhDd.png" alt="image-20231222233252147"></p><p>基于点的 3D 对象检测器有两个基本组件：<strong>点云采样</strong>和<strong>特征学习</strong>。</p><p><strong>Point Cloud Sampling</strong>:PointNet++中的<strong>最远点采样（FPS）已被广泛用于基于点的检测器中</strong>，其中最远的点是<strong>从原始点集中依次选择的</strong>。PointRCNN 是一项开创性的工作，<strong>它采用 FPS 逐步对输入点云进行下采样，并从下采样点生成 3D 建议</strong>。类似的设计范式也被用于后续的许多工作，并进行了改进，如分割引导滤波、特征空间采样、随机采样、基于体素的采样(voxel-based sampling)和坐标细化(coordinate refinement)。</p><p><strong>Point Cloud Feature Learning</strong>:具体来说，首先通过球查询(ball query)在预定义的半径内收集上下文点。然后，通过多层感知器和maxpooling对上下文点和特征进行聚合，得到新的特征。还有其他使用不同点云算子的工作，包括图算子，注意力算子和Transformer。</p><p>基于点的检测器的表示能力主要受两个因素的限制：<strong>特征学习中采用的上下文点数和上下文半径</strong>。增加上下文点的数量将获得更多的表示能力，但代价是增加大量的内存消耗。球查询中合适的上下文半径也是一个重要因素：如果半径太小，上下文信息可能不足，如果半径过大，细粒度的 3D 信息可能会丢失。必须仔细确定这两个因素，以平衡检测模型的有效性和效率。</p><p><strong>增加上下文点的数量将获得更多的表示能力，但代价是增加大量的内存消耗</strong>。球查询中合适的上下文半径也是一个重要因素：如果半径太小，上下文信息可能不足，如果半径过大，细粒度的 3D 信息可能会丢失。必须仔细确定这两个因素，以平衡检测模型的有效性和效率。可并行进行随机均匀采样，效率高。然而，考虑到LiDAR扫描中的点不是均匀分布的，<strong>随机均匀采样可能倾向于对那些高点云密度的区域进行过度采样，而对那些稀疏区域进行采样不足，这通常会导致与最远点采样相比性能较差。</strong></p><p><strong>最远点采样及其变体可以通过从现有点集中依次选择最远的点来获得更均匀的采样结果。然而，最远点采样本质上是一种顺序算法，不能变得高度并行</strong>。因此，最远点采样通常很耗时，并且无法进行实时检测。</p><h4 id="Grid-based-3D-object-detection"><a href="#Grid-based-3D-object-detection" class="headerlink" title="Grid-based 3D object detection"></a>Grid-based 3D object detection</h4><p><img data-src="https://i.imgur.com/O8n1SeP.png" alt="image-20231223135445200"></p><p>基于网格的 3D 对象检测器首先<strong>将点云栅格化为离散的网格表示</strong>，即<strong>体素、柱子和鸟瞰图 （BEV） 特征图</strong>。然后，他们<strong>应用传统的 2D 卷积神经网络或 3D 稀疏神经网络</strong>从网格中提取特征。最后，可以从BEV网格单元中检测到3D物体。基于网格的 3D 目标检测图如图  所示。基于网格的检测器有两个基本组件：<strong>基于网格的表示</strong>和<strong>基于网格的神经网络</strong></p><p><strong>Grid-based representations</strong>:</p><p><strong>voxels</strong>。如果<strong>将检测空间栅格化为规则的 3D 格网</strong>，则体素就是格网像元。<strong>如果点云落入此格网像元中，则体素可以为非空。</strong>由于点云分布稀疏，因此 3D 空间中的大多数体素单元格都是空的，不包含任何点。<strong>在实际应用中，只有那些非空体素才会被存储并用于特征提取。</strong>VoxelNet是一项开创性的工作，它利用稀疏的体素网格，提出了一种新的体素特征编码（VFE）层，从体素单元内的点中提取特征。</p><p>随后的一系列工作采用了类似的体素编码策略。此外，还有两类方法试图改进 3D 目标检测的体素表示：（1） <strong>多视图体素</strong>。一些方法从不同的视角提出了动态体素化和融合方案，例如鸟瞰图和透视图、圆柱面和球面视角、距离视角。（2）<strong>多尺度体素</strong>。一些论文生成不同尺度的体素或使用可重构的体素</p><p><strong>Pillars</strong>:柱子可以看作是特殊的体素，<strong>其中体素大小在垂直方向上是无限的</strong>。<strong>支柱特征可以通过PointNet从点聚合，然后散射回来</strong>，构建2D BEV图像进行特征提取。PointPillars 是一部开创性的著作，它引入了Pillar表示</p><p><strong>BEV feature maps</strong>:鸟瞰图特征图是一种密集的 2D 表示，其中<strong>每个像素对应于一个特定区域</strong>，<strong>并对该区域中的点信息进行编码</strong>。BEV特征图可以通过将3D特征投影到鸟瞰图中，从体素和柱子中获取，也可以通过汇总像素区域内的点统计数据，直接从原始点云中获取。</p><p><strong>Grid-based neural networks</strong>:基于网格的网络主要有两种类型：<strong>用于 BEV 特征图</strong>和<strong>Pillar的 2D 卷积神经网络</strong>，以及<strong>用于体素的 3D 稀疏神经网络</strong>。</p><p>2D convolutional neural networks:传统的 2D 卷积神经网络可以应用于 BEV 特征图，以从鸟瞰图检测 3D 对象。在大多数作品中，2D网络架构通常都是从2D目标检测中的成功设计中改编而来的,比如ResNet，区域建议网络（RPN）和特征金字塔网络（FPN）</p><p>3D 稀疏神经网络。3D稀疏卷积神经网络基于两个专门的3D卷积算子：sparse convolutions和submanifold convolutions，<strong>它们只能在那些非空体素上有效地进行3D卷积。与在整个体素空间上执行标准3D卷积相比，稀疏卷积算子效率更高</strong>，可以获得实时推理速度。</p><p>SECOND是一项开创性的工作，它使用基于 GPU 的哈希表实现了这两个稀疏算子，并构建了一个稀疏卷积网络来提取 3D 体素特征。</p><p>这种网络架构已在许多工程中得到应用，并成为基于体素的探测器中使用最广泛的骨干网络。还有一系列工作试图改进稀疏算子，将扩展为两级检测器，并将Transformer架构引入基于体素的检测。</p><p>与 BEV 特征图和Pillar等 2D 表示相比，体素包含更结构化的 3D 信息。此外，<strong>深度体素特征可以通过 3D 稀疏网络学习</strong>。然而，<strong>3D 神经网络会带来额外的时间和内存成本</strong>。<strong>BEV 特征图是最有效的网格表示，可直接将点云投影到 2D 伪图像中，而无需专门的 3D 运算符</strong>，如稀疏卷积或柱状编码。<strong>2D检测技术也可以无缝应用于BEV特征图，无需太多修改。</strong>基于BEV的检测方法通常可以获得高效率和实时推理速度。但是，<strong>简单地汇总像素区域内的点统计数据会丢失太多的 3D 信息</strong>，与基于体素的检测相比，这会导致检测结果的准确性较低。基于Pillar的检测方法利用 PointNet 对Pillar内的 3D 点信息进行编码，然后将特征分散回 2D 伪图像中以实现高效检测，从而平衡了 3D 目标检测的有效性和效率</p><p><strong>challenges of the grid-based detection methods</strong>:所有基于网格的方法都必须面对的一个关键问题是选择适当大小的网格单元。<strong>网格表示本质上是点云的离散格式</strong>，通过将连续的点坐标转换为离散的网格索引。</p><p>量化过程不可避免地会丢失一些 3D 信息<strong>，其有效性很大程度上取决于网格单元的大小：网格尺寸越小，网格就越高分辨率，因此可以保留更细粒度的细节，这对于准确的 3D 对象检测至关重要</strong>,然而，减小网格单元的大小会导致 2D 网格表示（如 BEV 特征图或支柱）的内存消耗呈二次增加。至于像体素这样的 3D 网格表示，问题可能会变得更加严重。因此，<strong>如何平衡较小网格尺寸带来的功效和内存增加影响的效率仍然是所有基于网格的三维目标检测方法面临的一个悬而未决的挑战</strong>。</p><h4 id="Point-voxel-based-3D-object-detection"><a href="#Point-voxel-based-3D-object-detection" class="headerlink" title="Point-voxel based 3D object detection"></a><strong>Point-voxel based 3D object detection</strong></h4><p>基于点体素的方法采用混合架构，<strong>利用点和体素进行 3D 对象检测</strong>。这些方法可以分为两类：单阶段和两阶段检测框架。</p><p><strong>Single-stage point-voxel detection frameworks.</strong></p><p>基于单级点体素的 3D 目标检测器<strong>试图将点和体素的特征与骨干网络中的点到体素和体素到点变换联系起来</strong></p><p><strong>点包含细粒度的几何信息，体素的计算效率很高，在特征提取阶段将它们组合在一起自然会从这两种表示中受益</strong>。在骨干网中利用点-体素特征融合的思想已被许多著作探索，其贡献包括点-体素卷积，辅助点网络和多尺度特征融合.</p><p><strong>Two-stage point-voxel detection frameworks</strong></p><p>基于点体素的两级 3D 对象检测器<strong>针对不同的检测阶段采用不同的数据表示</strong>。</p><p>具体来说，在第一阶段，采用<strong>基于体素的检测框架来生成一组 3D 对象建议</strong>,在第二阶段，<strong>首先从输入点云中对关键点进行采样，然后通过新的点算子从关键点进一步细化3D建议</strong>。</p><p>基于点体素的方法自然可以受益于从点获得的细粒度 3D 形状和结构信息以及体素带来的计算效率。然而，这些方法仍然存在一些挑战。对于混合点-体素骨干网，点-体素特征的融合一般<strong>依赖于体素-点和点-体素变换机制，可以带来不可忽视的时间成本</strong>。对于两阶段点体素检测框架，一个关键的挑战是<strong>如何有效地聚合 3D 提案的点特征，因为现有的模块和运算符通常非常耗时</strong>。综上所述，与纯基于体素的检测方法相比，基于点体素的检测方法可以获得更好的检测精度，但代价是增加了推理时间。</p><h4 id="Range-based-3D-object-detection"><a href="#Range-based-3D-object-detection" class="headerlink" title="Range-based 3D object detection"></a>Range-based 3D object detection</h4><p>范围图像是一种密集而紧凑的 2D 表示，其中<strong>每个像素都包含 3D 距离信息，而不是 RGB 值</strong>。基于距离的方法从两个方面解决了检测问题：<strong>设计适合距离图像的新模型和算子</strong>，以及<strong>选择合适的视图进行检测</strong>。</p><p><img data-src="https://i.imgur.com/r7H1L1T.png" alt="image-20231223162320834" style="zoom:67%;" /></p><p><strong>Range-based detection models</strong></p><p>由于距离图像是与RGB图像一样的2D表示，因此基于范围的3D对象检测器可以自然地借用2D对象检测中的模型来处理范围图像。</p><p>LaserNet 是一项开创性的工作，它利用深层聚合网络 （DLA-Net）从距离图像中获取多尺度特征并检测 3D 对象。一些论文还采用了其他 2D 目标检测架构</p><p><strong>Range-based operators</strong></p><p>距离图像的像素包含 3D 距离信息而不是颜色值，<strong>因此传统 2D 网络架构中的标准卷积算子对于基于范围的检测来说不是最佳选择</strong>，因为滑动窗口中的像素在 3D 空间中可能彼此相距很远。一些工作采用新颖的算子来有效地从范围像素中提取特征，包括范围扩展卷积、图算子和元核卷积</p><p><strong>Views for range-based detection</strong></p><p>范围图像是从范围视图 （RV） 捕获的，理想情况下，范围视图是点云的球面投影。</p><p>然而，从距离视图进行检测时，<strong>不可避免地会受到球面投影带来的遮挡和尺度变化问题的影响</strong>。</p><p>为了规避这些问题，许多方法都在<strong>利用其他视图来预测3D物体，例如中采用的圆柱视图（CYV），在中采用的距离视图、鸟瞰视图（BEV）和/或点视图（PV）的组合</strong></p><p><strong>Analysis: potentials and challenges of the range-based methods</strong></p><p>范围图像是一种密集而紧凑的 2D 表示，因此<strong>传统或专用的 2D 卷积可以无缝地应用于范围图像</strong>，这使得特征提取过程非常高效.然而，<strong>与鸟瞰图检测相比，距离图检测容易受到遮挡和尺度变化的影响</strong>。因此，<strong>从距离视图中提取特征</strong>，<strong>从鸟瞰图进行目标检测</strong>，成为基于距离的3D目标检测最实用的解决方案。</p><h3 id="Learning-objectives-for-3D-object-detection"><a href="#Learning-objectives-for-3D-object-detection" class="headerlink" title="Learning objectives for 3D object detection"></a>Learning objectives for 3D object detection</h3><p>学习目标在对象检测中至关重要。<strong>由于 3D 物体相对于整个检测范围非常小，因此在 3D 检测中非常需要特殊的机制来增强小物体的定位</strong>。另一方面，<strong>考虑到点云稀疏且物体通常具有不完整的形状</strong>，准确估计 3D 物体的中心和大小是一项长期存在的挑战。</p><h4 id="Anchor-based-3D-object-detection"><a href="#Anchor-based-3D-object-detection" class="headerlink" title="Anchor-based 3D object detection"></a>Anchor-based 3D object detection</h4><p>锚点(anchors)是具有固定形状的预定义长方体,可以放置在 3D 空间中。</p><p><img data-src="https://i.imgur.com/jFknBKH.png" alt="image-20231223174714325"></p><p>3D 对象可以基于与真实值具有高交集 （IoU） 的正锚点进行预测。将从锚点配置和损失函数方面介绍基于锚点的三维目标检测方法。</p><p>Anchor configurations:基于锚点的 3D 对象检测方法通常<strong>从鸟瞰图检测 3D 对象</strong>,其中 3D 锚框放置在 BEV 特征图的每个网格单元上。3D 锚点通常对每个类别具有固定大小，因为同一类别的对象具有相似的大小</p><p>Loss functions:基于锚点的方法利用分类损失Lcls来学习正负锚点，利用回归损失Lreg来学习基于正锚点的物体的大小和位置。此外，L~θ~ 用于学习物体的航向角。</p><script type="math/tex; mode=display">\begin{equation}L_{det}=L_{cls}+L_{reg}+L_\theta.\end{equation}</script><p>回归目标可以进一步应用于这些正锚点,以学习 3D 对象的大小和位置.</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}\Delta x&=\frac{x^g-x^a}{d^a},\Delta y=\frac{y^g-y^a}{d^a},\Delta z=\frac{z^g-z^a}{h^a},\\\Delta l&=\log(\frac{l^g}{l^a}),\Delta w=\log(\frac{w^g}{w^a}),\Delta h=\log(\frac{h^g}{h^a}),\end{aligned}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}L_{cls}^{bce}=-[q\cdot\log(p)+(1-q)\cdot\log(1-p)]\end{equation}</script><p>p 是每个锚点的预测概率，如果锚点为正，则目标 q 为 1，否则为 0</p><script type="math/tex; mode=display">\begin{equation}d^a=\sqrt{(l^a)^2+(w^a)^2}\end{equation}</script><p>此外还有使用Focal Loss,</p><script type="math/tex; mode=display">\begin{equation}L_{cls}^{focal}=-\alpha(1-p)^\gamma\log(p),\end{equation}</script><p>使用SmoothL1 loss用于回归</p><script type="math/tex; mode=display">\begin{equation}L_{reg}=\sum_{\begin{array}{c}u\in\{x,y,z,l,w,h\},\\v\in\{\Delta x,\Delta y,\Delta z,\Delta l,\Delta w,\Delta h\}\end{array}}\text{SmoothL1}(u-v).\end{equation}</script><p>为了学习航向角 θ，弧度方向偏移量可以直接用 SmoothL1 损失回归</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}\Delta\theta&=\theta^g-\theta^a,\\L_\theta&=\text{SmoothL}1(\theta-\Delta\theta).\end{aligned}\end{equation}</script><p>然而，由于回归范围较大,直接回归弧度偏移通常很困难,另外<strong>,基于bin的航向估计</strong>是学习航向角的较好解，其中<strong>首先将角度空间划分为bin,并采用基于bin的分类L~dir~和残差回归</strong>.</p><script type="math/tex; mode=display">\begin{equation}L_\theta=L_{dir}+\text{SmoothL}1(\theta-\Delta\theta^{\prime}),\end{equation}</script><p>正弦函数也可用于对弧度偏移进行编码</p><script type="math/tex; mode=display">\begin{equation}\Delta\theta=\sin(\theta^g-\theta^a),\end{equation}</script><p>除了分别学习<strong>物体大小</strong>、<strong>位置</strong>和<strong>方向</strong>的损失函数外，将所有物体参数视为一个整体的交并（IoU）损失也可以应用于3D物体检测</p><script type="math/tex; mode=display">\begin{equation}L_{IoU}=1-IoU(b^g,b),\end{equation}</script><p>其中 C^G^ ~i~ 和 C~I~ 分别是地面实况和预测长方体的第 i 个角。</p><p>基于锚点的方法可以从同一类别的 3D 对象应该具有相似形状的先验知识中受益，因此它们可以在 <strong>3D 锚点的帮助下生成准确的对象预测</strong>。然而，<strong>由于3D物体相对于检测范围相对较小，因此需要大量的锚点来确保整个检测范围的完全覆盖</strong>，例如，在KITTI 数据集的中使用了大约70k个锚点。<strong>此外，对于那些非常小的物体，如行人和骑自行车的人，应用基于锚点的分配可能非常具有挑战性</strong>。考虑到锚点通常放置在每个网格单元的中心，如果网格单元较大而单元中的对象较小，则该单元的锚点可能与小对象具有较低的 IoU，这可能会阻碍训练过程。</p><h3 id="Anchor-free-3D-object-detection"><a href="#Anchor-free-3D-object-detection" class="headerlink" title="Anchor-free 3D object detection"></a>Anchor-free 3D object detection</h3><p>无anchor box方法消除了复杂的anchor box设计，可以灵活地应用于不同的视图，例如鸟瞰图、点视图和范围视图。</p><p><img data-src="https://i.imgur.com/6IcyJdX.png" alt="image-20231223190845168"></p><p>基于锚点和无锚点方法之间的<strong>主要区别在于正样本和负样本的选择</strong>。</p><p><strong>Grid-based assignment</strong>:与依赖于带有锚点的 IoU 来确定正负样本的基于锚点的方法相比，无锚点方法<strong>利用各种基于grid的分配策略来评估 BEV 网格单元、Pillar和体素</strong></p><p>PIXOR是一项开创性的工作，它<strong>利用地面实况 3D 物体内部的网格单元作为正例，而其他则作为负例。</strong>Pillar-based object detection for autonomous driving.采用了这种内部对象分配策略，并在中通过选择最接近对象中心的网格单元进一步改进。CenterPoint利用每个对象中心的高斯核来分配正标签。</p><p>损失函数上,分类损失基本不变.但回归损失改变如下</p><script type="math/tex; mode=display">\begin{equation}\Delta=[dx,dy,z^g,\log(l^g),\log(w^g),\log(h^g),\sin(\theta^g),\cos(\theta^g)],\end{equation}</script><p>DX 和 DY 是正grid cells和对象中心之间的偏移量。</p><p><strong>Point-based assignment.</strong></p><p>大多数基于点的检测方法<strong>采用无锚点和基于点的分配策略</strong>，其中<strong>首先对点进行分割，然后选择 3D 对象内部或附近的前景点作为正样本</strong>，最后从这些前景点中学习 3D 边界框。<strong>大多数基于点的检测器都采用了这种前景点分割策略，并进行了改进，例如增加了中心度分数</strong></p><p><strong>Range-based assignment</strong></p><p>无锚点分配也可以用于范围图像。<strong>一种常见的解决方案是选择 3D 对象内部的范围像素作为正样本</strong>。与其他回归目标基于全局三维坐标系的方法不同，<strong>基于范围的方法采用以对象为中心的坐标系进行回归</strong>。</p><p><strong>Set-to-set assignment.</strong>DETR是一种颇具影响力的 2D 检测方法，它引入了<strong>一种集到集的分配策略</strong>，通过匈牙利算法自动将预测分配给相应的地面实况</p><script type="math/tex; mode=display">\begin{equation}\mathcal{M}^*=\underset{\mathcal{M}}{\operatorname*{argmin}}\sum_{(i\to j)\in\mathcal{M}}L_{det}(b_i^g,b_j),\end{equation}</script><p>其中 M 是从每个阳性样本到 3D 对象的一对一映射。</p><h3 id="3D-object-detection-with-auxiliary-tasks"><a href="#3D-object-detection-with-auxiliary-tasks" class="headerlink" title="3D object detection with auxiliary tasks"></a>3D object detection with auxiliary tasks</h3><p>许多方法都采用辅助任务来增强空间特征，<strong>并为精确的 3D 目标检测提供隐式指导。常用的辅助任务包括语义分割、交集并集预测、对象形状补全和对象部分估计</strong>。</p><p><img data-src="https://i.imgur.com/TkWPitq.png" alt="image-20231223195729269"></p><p><strong>Semantic segmentation</strong>:语义分割可以从3个方面帮助3D目标检测：（1）前景分割可以提供对象位置的隐性信息。在大多数基于点的 3D 目标检测器 中，逐点前景分割已被广泛采用，用于生成提案。（2）空间特征可以通过分割来增强。在文献[347]中，利用语义上下文编码器来增强具有语义知识的空间特征。（3）语义分割可以作为预处理步骤，过滤掉背景样本，使3D目标检测更加高效。</p><p><strong>IoU prediction</strong>:交集并集 （IoU） 可以作为纠正对象置信度分数的有用监督信号。Cia-ssd: Confident iou-aware single-stage object detector from point cloud. In: AAAI<strong>提出了一个辅助分支来预测每个检测到的 3D 对象的 IoU 分数 S~IoU~</strong>。</p><script type="math/tex; mode=display">\begin{equation}S_{conf}=S_{cls}\cdot(S_{IoU})^\beta,\end{equation}</script><p>在推理过程中,来自传统分类分支的原始置信度分数 S~con~f = S~cls~ 被 IoU 分数 SIoU 进一步校正.其中，超参数β控制抑制低 IoU 预测和增强高 IoU 预测的程度。<strong>通过 IoU 校正,更容易选择高质量的 3D 对象作为最终预测</strong>。</p><p><strong>Object shape completion</strong></p><p>由于LiDAR传感器的性质，<strong>远处物体通常只在其表面上接收到几个点，因此3D物体通常是稀疏和不完整的</strong>。提高检测性能的一种直接方法是从稀疏点云中完成物体形状。完整的形状可以为准确和稳健的检测提供更多有用的信息<strong>。在3D检测中已经提出了许多形状补全技术，包括形状解码器、形状特征和概率占用网格</strong></p><p><strong>Object part estimation.</strong></p><p>识别对象内部的零件信息有助于 3D 对象检测，因为它可以显示对象的更细粒度的 3D 结构信息。</p><p>3D 对象检测与许多其他 3D 感知和生成任务具有内在关联性。与独立训练 3D 目标检测器相比，3D 检测和分割的多任务学习更有利，形状补全也有助于 3D 目标检测。还有其他任务可以帮助提高 3D 对象检测器的性能。例如，场景流估计可以识别静态和移动对象，在点云序列中跟踪相同的 3D 对象可以更准确地估计该对象。因此，将更多的感知任务集成到现有的3D目标检测管道中将是有希望的。</p><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;2023年的目标检测综述&lt;strong&gt;A comprehensive review of object detection with deep learning&lt;/strong&gt;以及&lt;strong&gt;3D Object Detection for Autonomous Driving: A Comprehensive Survey&lt;/strong&gt;,之前写了一些单阶段和双阶段的2D目标检测,可以好好回顾一下.&lt;/p&gt;</summary>
    
    
    
    
    <category term="object detection" scheme="https://www.sekyoro.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>Python的工程化之路</title>
    <link href="https://www.sekyoro.top/2023/12/04/Python%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%8C%96%E4%B9%8B%E8%B7%AF/"/>
    <id>https://www.sekyoro.top/2023/12/04/Python%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%8C%96%E4%B9%8B%E8%B7%AF/</id>
    <published>2023-12-04T07:54:52.000Z</published>
    <updated>2023-12-23T12:54:54.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在工程化上,Python相比于Java,C#这类语言还是差了不少,不过整个生态还是不错的.</p><span id="more"></span><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>一般有两种,一种称为flat另一种为src.</p><ol><li><blockquote><p>├── sample<br>│   ├── AUTHORS.rst<br>│   ├── docs<br>|   |   ├── conf.py<br>│   │   └── index.rst<br>│   ├── HISTORY.rst<br>│   ├── LICENSE<br>│   ├── makefile<br>│   ├── MANIFEST.in<br>│   ├── README.rst<br>│   ├── requirements.txt<br>│   ├── sample<br>|   |   ├── app.py<br>│   │   └── helper.py<br>|   ├── setup.cfg<br>|   ├── setup.py<br>│   └── tests<br><img data-src="https://s2.loli.net/2023/12/04/zSZesqwjb72IaUD.png" alt="image-20231204170021714"></p></blockquote></li></ol><ol><li><img data-src="https://s2.loli.net/2023/12/04/B5I7NEVSCRilscz.png" alt="image-20231204171740258"></li></ol><p>主要是使用poetry等工具打包的时候需要注意一下,因为<code>pyproject.toml</code>字段不完全相同.</p><h3 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h3><ol><li>ImportError: attempted relative import with no known parent package</li></ol><p>包中的模块使用相对导入时不能直接运行该模块,一般是其他包或顶级模块进行调用</p><h2 id="工具链"><a href="#工具链" class="headerlink" title="工具链"></a>工具链</h2><h3 id="版本管理工具"><a href="#版本管理工具" class="headerlink" title="版本管理工具"></a>版本管理工具</h3><p>Anaconda可以同时解决Python版本和包管理的问题,但如果只是想开发个包,没有必要使用conda,在linux上可以考虑pyenv+poetry,windows上有对应的pyenv-windows+poetry.</p><p>pyenv允许您轻松地在多个版本的Python之间切换。它简单、不引人注目，并且遵循了UNIX传统的单用途工具，可以很好地完成一件事。</p><p><a href="https://github.com/pyenv/pyenv">pyenv/pyenv: Simple Python version management (github.com)</a></p><h3 id="包管理工具"><a href="#包管理工具" class="headerlink" title="包管理工具"></a>包管理工具</h3><p>目前开发Python包我推荐Poetry或者PDM,如果是搞数据计算直接Anaconda.</p><h4 id="Poetry"><a href="#Poetry" class="headerlink" title="Poetry"></a>Poetry</h4><p><a href="https://python-poetry.org/docs/">Introduction | Documentation | Poetry - Python dependency management and packaging made easy (python-poetry.org)</a></p><p>某种程度上告别<code>setup.py</code>,除了一般的虚拟环境和包管理之外,打包和发布到PYPI等都支持,也是现在比较火的工具.</p><p>虚拟环境管理类似conda,会在某个目录下放所有的虚拟环境</p><p><img data-src="https://s2.loli.net/2023/12/04/zg1ChV4DXyoQeEt.png" alt="image-20231204163324338"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poetry init</span><br><span class="line">poetry install </span><br><span class="line">poetry shell</span><br></pre></td></tr></table></figure><p>通过初始化一个新的Poetry项目，这将以交互方式生成一个文件pyproject.toml。该文件将具有所有包依赖项。这与requirements.txt文件类似。</p><p>当参数 <code>virtualenvs.create</code> 为 <code>true</code> 时，执行 <code>poetry install</code> 或 <code>poetry add</code> 时会检测当前项目是否有虚拟环境，没有就自动创建，默认为 <code>true</code>。</p><p>当参数 <code>virtualenvs.in-project</code> 为 <code>true</code> 时，虚拟环境的依赖将会放置于项目的文件夹内，而不是 poetry 默认的 <code>&#123;cache-dir&#125;/virtualenvs</code>，默认为 <code>false</code>。</p><p>我的配置如下:</p><p><img data-src="https://s2.loli.net/2023/12/04/Z1qGakLnrBwdejx.png" alt="image-20231204164441421"></p><blockquote><p>当Poetry完成安装后，它会将所有包及其下载的确切版本写入Poetry.lock文件，从而将项目锁定到这些特定版本。该锁定文件也应包含在您的项目repo中，以便在项目中工作的每个人都被锁定到相同版本的依赖项。</p></blockquote><p><img data-src="https://s2.loli.net/2023/12/04/9rkoJysmI8dFt5b.png" alt="image-20231204163627134"></p><h4 id="PDM"><a href="#PDM" class="headerlink" title="PDM"></a>PDM</h4><p><a href="https://github.com/pdm-project/pdm">pdm-project/pdm: A modern Python package and dependency manager supporting the latest PEP standards (github.com)</a></p><p>支持最新PEP标准的现代Python包和依赖项管理器. Poetry的<code>pyproject.toml</code>与PEP标准不完全符合.</p><p>PDM可以管理项目和集中位置的虚拟环境（venv），类似于Pipenv。它从标准化的pyproject.toml文件中读取项目元数据，并支持锁定文件。用户可以通过插件添加额外的功能，这些功能可以通过将其作为分发版上传来共享。与Poetry和Hatch不同，PDM不局限于特定的构建后端；用户可以自由选择他们喜欢的任何构建后端。</p><h3 id="Formatter"><a href="#Formatter" class="headerlink" title="Formatter"></a>Formatter</h3><p>代码格式化工具,一般用black就够了.</p><h4 id="Black"><a href="#Black" class="headerlink" title="Black"></a>Black</h4><p>Black是不折不扣的Python代码格式化程序。通过使用它，您同意放弃对手工格式化细节的控制。作为回报，Black为您提供了速度、决定论和自由，使您免受pycode风格对格式的唠叨。你会为更重要的事情节省时间和精力。无论您正在阅读的项目是什么，变黑的代码看起来都是一样的。一段时间后，格式将变得透明，您可以转而关注内容。Black通过产生尽可能小的差异来加快代码审查。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install black</span><br><span class="line">black &#123;source_file_or_directory&#125;</span><br></pre></td></tr></table></figure><h4 id="yapf"><a href="#yapf" class="headerlink" title="yapf"></a>yapf</h4><p>YAPF是一个基于clang格式的Python格式化程序（由Daniel Jasper开发）。本质上，该算法采用代码并计算符合配置样式的最佳格式。它省去了维护代码的许多繁琐工作。最终目标是YAPF生成的代码与程序员在遵循样式指南的情况下编写的代码一样好。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install yapf</span><br></pre></td></tr></table></figure><h4 id="autopep8"><a href="#autopep8" class="headerlink" title="autopep8"></a><strong>autopep8</strong></h4><p>autoep8自动格式化Python代码，以符合PEP8样式指南。它使用pycodestyle实用程序来确定需要格式化代码的哪些部分。autoep8能够修复pycodestyle可能报告的大多数格式问题。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade autopep8</span><br><span class="line">autopep8 --in-place --aggressive --aggressive &lt;filename&gt;</span><br></pre></td></tr></table></figure><h3 id="Linter"><a href="#Linter" class="headerlink" title="Linter"></a>Linter</h3><p>一般用pylint足矣,喜欢尝鲜的可以用用Ruff.</p><h4 id="PyLint"><a href="#PyLint" class="headerlink" title="PyLint"></a>PyLint</h4><p>Pylint是Python 2或3的静态代码分析器。最新版本支持Python 3.8.0及以上版本。Pylint在不实际运行代码的情况下分析代码。它检查错误，强制执行编码标准，寻找代码气味，并可以就如何重构代码提出建议。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pylint</span><br></pre></td></tr></table></figure><h4 id="flake8"><a href="#flake8" class="headerlink" title="flake8"></a>flake8</h4><p>Flake8是这些工具的包装：PyFlakespycode样式Ned Batchelder的McCabe脚本Flake8通过启动单个Flake8命令来运行所有工具。它在每个文件的合并输出中显示警告。<a href="https://github.com/PyCQA/flake8">PyCQA/flake8: flake8 is a python tool that glues together pycodestyle, pyflakes, mccabe, and third-party plugins to check the style and quality of some python code. (github.com)</a></p><h4 id="Ruff"><a href="#Ruff" class="headerlink" title="Ruff"></a>Ruff</h4><p>比较新的工具<a href="https://github.com/astral-sh/ruff">astral-sh/ruff: An extremely fast Python linter and code formatter, written in Rust. (github.com)</a>,不只是语法提示器,也可以用于格式化.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install ruff</span><br><span class="line"></span><br><span class="line">ruff path/to/code/to/check.py</span><br><span class="line">ruff path/to/code/</span><br><span class="line">ruff path/to/code/*.py</span><br></pre></td></tr></table></figure><h3 id="类型检查工具"><a href="#类型检查工具" class="headerlink" title="类型检查工具"></a>类型检查工具</h3><p>在Python中使用typing的检查工具,此外与Pydantic<a href="https://docs.pydantic.dev/latest/">Welcome to Pydantic - Pydantic</a>搭配使用效果更佳</p><blockquote><p>Pydantic是Python中使用最广泛的数据验证库。Pydantic快速且可扩展，可以很好地处理您的linters/IDE/brain。</p><p>定义数据应该如何使用纯规范的Python 3.7+；用Pydantic验证它。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delivery</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    timestamp: datetime</span><br><span class="line">    dimensions: <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">m = Delivery(timestamp=<span class="string">&#x27;2020-01-02T03:04:05Z&#x27;</span>, dimensions=[<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">repr</span>(m.timestamp))</span><br><span class="line"><span class="comment">#&gt; datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))</span></span><br><span class="line"><span class="built_in">print</span>(m.dimensions)</span><br><span class="line"><span class="comment">#&gt; (10, 20)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Mypy"><a href="#Mypy" class="headerlink" title="Mypy"></a>Mypy</h4><p><a href="https://github.com/python/mypy">python/mypy: Optional static typing for Python (github.com)</a></p><p>Mypy是Python的静态类型检查器。类型检查器有助于确保您在代码中正确使用变量和函数。</p><p>使用mypy，将类型提示（PEP484）添加到Python程序中，当您错误地使用这些类型时，mypy会发出警告。Python是一种动态语言，所以通常只有当你试图运行它时，你才会在代码中看到错误。Mypy是一个静态检查器，所以它甚至不用运行就可以发现程序中的错误！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install -U mypy</span><br><span class="line">mypy PROGRAM</span><br></pre></td></tr></table></figure><h4 id="Pyright"><a href="#Pyright" class="headerlink" title="Pyright"></a>Pyright</h4><p><a href="https://github.com/microsoft/pyright">microsoft/pyright: Static Type Checker for Python (github.com)</a></p><p>Pyright是一个功能齐全、基于标准的Python静态类型检查器。它是为高性能而设计的，可以与大型Python源代码库一起使用。</p><h3 id="Git-pre-commit-hook"><a href="#Git-pre-commit-hook" class="headerlink" title="Git pre-commit hook"></a>Git pre-commit hook</h3><p>在<code>git commit</code>之前设置hook进行代码检查</p><h3 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h3><p>测试工具</p><h4 id="Pytest"><a href="#Pytest" class="headerlink" title="Pytest"></a>Pytest</h4><p>pytest框架使编写小型可读测试变得容易，并且可以扩展以支持应用程序和库的复杂功能测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U pytest</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://blog.csdn.net/Dontla/article/details/131538693">python项目结构示例（python代码结构、python目录结构）与python部署结构、python部署目录、flask项目结构、flask目录_python项目结构目录结构-CSDN博客</a></li><li><a href="https://blog.csdn.net/captain5339/article/details/128017400">各类Python项目的项目结构及代码组织最佳实践<em>python项目结构__</em>弯弓__的博客-CSDN博客</a></li><li><a href="https://www.cnblogs.com/cuiyubo/p/11756771.html">Python最佳工程实践，建立一个完美的工程项目 - cuiyubo - 博客园 (cnblogs.com)</a></li><li><a href="https://www.hatica.io/blog/pre-commit-git-hooks/">8 Pre-commit Git Hooks You Must Know for Improved Productivity - Hatica</a></li><li><a href="https://pythonguidecn.readthedocs.io/zh/latest/writing/structure.html">结构化您的工程 — The Hitchhiker’s Guide to Python (pythonguidecn.readthedocs.io)</a></li></ol><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>]]></content>
    
    
    <summary type="html">&lt;p&gt;在工程化上,Python相比于Java,C#这类语言还是差了不少,不过整个生态还是不错的.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
