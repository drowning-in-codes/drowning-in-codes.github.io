<!doctypehtml><html lang=zh-CN><script defer src=/live2d-widget/autoload.js></script><meta charset=UTF-8><meta content=width=device-width,initial-scale=1,maximum-scale=2 name=viewport><meta content=#222 name=theme-color><meta content="Hexo 5.4.0" name=generator><link href=/images/blog_32px.png rel=apple-touch-icon sizes=180x180><link href=/images/blog_32px.png rel=icon sizes=32x32 type=image/png><link href=/images/blog_16px.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><meta content=EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w name=google-site-verification><!-- Google tag (gtag.js) --><!-- 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script> --><!-- google adsense in head.swig --><script async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123></script><meta content=7226864CE87CE9DE8C008385273846FF name=msvalidate.01><meta content=code-fjFXVtiL7j name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link as=style href=https://fonts.googleapis.com/css?family=Roboto%20Mono,Roboto:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext onload=this.rel='stylesheet' rel=preload><link as=style href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css onload=this.rel='stylesheet' rel=preload><link href=https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap rel=stylesheet><link href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/pace-js@1/pace.min.js></script><script id=hexo-configurations>var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"0F9LEEVW82","apiKey":"78839e9f9be09d081c5c4da81975cd19","indexName":"sekyoblog_sec","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};</script><link href=//cdn.bootcss.com/animate.css/3.5.0/animate.min.css rel=stylesheet><meta content="Andrew Ng的Deep Learning短课程Short Courses | Learn Generative AI from DeepLearning.AI,此外还有Cousera上的课程.学的东西比较实用还比较新." name=description><meta content=article property=og:type><meta content=dpsc:深度学习短课程学习 property=og:title><meta content=https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/index.html property=og:url><meta content=Sekyoro的博客小屋 property=og:site_name><meta content="Andrew Ng的Deep Learning短课程Short Courses | Learn Generative AI from DeepLearning.AI,此外还有Cousera上的课程.学的东西比较实用还比较新." property=og:description><meta content=zh_CN property=og:locale><meta content=https://i.imgur.com/81KDzqo.png property=og:image><meta content=https://i.imgur.com/TpXVnGU.png property=og:image><meta content=https://s2.loli.net/2023/12/29/2EruyQMvpSNoeRm.png property=og:image><meta content=https://i.imgur.com/MkB11s7.png property=og:image><meta content=https://i.imgur.com/lm5t6Jr.png property=og:image><meta content=https://s2.loli.net/2023/12/28/LQaYoIzTJWd1yNs.png property=og:image><meta content=https://s2.loli.net/2023/12/28/G7JTpmDg4zF1neq.png property=og:image><meta content=https://s2.loli.net/2023/12/29/8VAft1WN9L6lrmG.png property=og:image><meta content=https://s2.loli.net/2023/12/29/MAifZF7OlmPtbWs.png property=og:image><meta content=https://s2.loli.net/2023/12/29/hqbUoyE9iRpdgNA.png property=og:image><meta content=https://s2.loli.net/2023/12/29/jLaNo19nuCwDJQG.png property=og:image><meta content=https://s2.loli.net/2023/12/28/PmOSaTEFH8pVuqe.png property=og:image><meta content=https://s2.loli.net/2023/12/28/sh6MfqxQEUnuG5j.png property=og:image><meta content=https://s2.loli.net/2023/12/28/zyAIapuUNi9EeSw.png property=og:image><meta content=https://s2.loli.net/2025/01/02/Fb2daDYJ4Xs37Cy.png property=og:image><meta content=https://s2.loli.net/2025/02/08/KZwtVTnY1rqsI7J.png property=og:image><meta content=2023-12-24T12:55:08.000Z property=article:published_time><meta content=2025-02-08T15:55:20.910Z property=article:modified_time><meta content=Sekyoro property=article:author><meta content="个人博客 技术学习 计算机 互联网 人工智能" property=article:tag><meta content=summary name=twitter:card><meta content=https://i.imgur.com/81KDzqo.png name=twitter:image><link href=https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/ rel=canonical><script id=page-configurations>// https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };</script><title>dpsc:深度学习短课程学习 | Sekyoro的博客小屋</title><noscript><style>.use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }</style></noscript><link href=/atom.xml rel=alternate title=Sekyoro的博客小屋 type=application/atom+xml><body itemscope itemtype=http://schema.org/WebPage><canvas style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" class=fireworks></canvas><script defer src=https://cdn.bootcss.com/animejs/2.2.0/anime.min.js></script><script defer src=/js/src/fireworks.js></script><div class="container use-motion"><div class=headband></div><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <h1 class=site-title>Sekyoro的博客小屋</h1> <span class=logo-line-after><i></i></span> </a></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu" id=menu><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-bangumis"><a href=/bangumis/ rel=section><i class="fa fa-film fa-fw"></i>追番</a><li class="menu-item menu-item-resume"><a href=/resume/ rel=section><i class="fa fa-file-pdf fa-fw"></i>简历</a><li class="menu-item menu-item-materials"><a href=/materials/ rel=section><i class="fa fa-book fa-fw"></i>学习资料</a><li class="menu-item menu-item-sitemap"><a href=/sitemap.xml rel=section><i class="fa fa-sitemap fa-fw"></i>站点地图</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container></div><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span></div><div class=algolia-results><div id=algolia-stats></div><div id=algolia-hits></div><div class=algolia-pagination id=algolia-pagination></div></div></div></div></div></header><a class="book-mark-link book-mark-link-fixed" role=button></a><main class=main><div class=main-inner><div class=content-wrap><div class="content post posts-expand"><article class=post-block itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg itemprop=image> <meta content=Sekyoro itemprop=name> <meta content=什么也无法舍弃的人，什么也做不了. itemprop=description> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=Sekyoro的博客小屋 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>dpsc:深度学习短课程学习</h1><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2023-12-24 20:55:08" datetime=2023-12-24T20:55:08+08:00>2023-12-24</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-02-08 23:55:20" datetime=2025-02-08T23:55:20+08:00 itemprop=dateModified>2025-02-08</time> </span><span style="display: none;" class=post-meta-item id=busuanzi_container_page_pv title=阅读次数> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=post-meta-item-text>阅读次数：</span> <span id=busuanzi_value_page_pv></span> </span><br><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>35k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>32 分钟</span> </span></div></header><div class=post-body itemprop=articleBody><p>Andrew Ng的Deep Learning短课程<a href=https://www.deeplearning.ai/short-courses/ rel=noopener target=_blank>Short Courses | Learn Generative AI from DeepLearning.AI</a>,此外还有Cousera上的课程.学的东西比较实用还比较新.</p><span id=more></span><p>这些课程通常会使用一些公司的产品,比如<strong>Hugging Face</strong>的Gradio,diffusers,transformers,或者W&B的wandb等等(这两个我平常都在用),此外还有谷歌、微软以及Langchain,这些工具都比较实用. 如果关注生成领域,那Diffusion Model肯定要看,如果关注LLM以及chatbot那<strong>Langchain</strong>最好利用起来,如果自己训练部署模型,那也可以使用<strong>wandb</strong>.<p>这里我主要关注三部分:<strong>生成式人工智能</strong>,<strong>LLM</strong>,<strong>模型部署和训练辅助工具</strong>.<h3 id=Reinforcement-Learning-from-Human-Feedback><a title="Reinforcement Learning from Human Feedback" class=headerlink href=#Reinforcement-Learning-from-Human-Feedback></a>Reinforcement Learning from Human Feedback</h3><p><img alt=image-20231224221652027 data-src=https://i.imgur.com/81KDzqo.png><p><img alt=image-20231224231207302 data-src=https://i.imgur.com/TpXVnGU.png><h3 id=Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases><a title="Evaluating and Debugging Generative AI Models Using Weights and Biases" class=headerlink href=#Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases></a>Evaluating and Debugging Generative AI Models Using Weights and Biases</h3><p>作为模型训练者可能会用到的网站.文档<a href=https://docs.wandb.ai/ref/python/ rel=noopener target=_blank>Python Library | Weights & Biases Documentation (wandb.ai)</a><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line>wandb.init(</span><br><span class=line>    project=<span class=string>"gpt5"</span>,</span><br><span class=line>    config=config,</span><br><span class=line>)</span><br><span class=line>wandb.log(metrics)</span><br></pre></table></figure><p>首先找到项目(如果没有就会另外创建),并且会根据config创建一个run.使用wandb.log输出最后结果.wandb会保存运行时系统环境信息,github repo甚至仓库文件信息.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>train_model</span>(<span class=params>config</span>):</span></span><br><span class=line>    <span class=string>"Train a model with a given config"</span></span><br><span class=line>    </span><br><span class=line>    wandb.init(</span><br><span class=line>        project=<span class=string>"gpt5"</span>,</span><br><span class=line>        config=config,</span><br><span class=line>    )</span><br><span class=line></span><br><span class=line>    <span class=comment># Get the data</span></span><br><span class=line>    train_dl, valid_dl = get_dataloaders(DATA_DIR, </span><br><span class=line>                                         config.batch_size, </span><br><span class=line>                                         config.slice_size, </span><br><span class=line>                                         config.valid_pct)</span><br><span class=line>    n_steps_per_epoch = math.ceil(<span class=built_in>len</span>(train_dl.dataset) / config.batch_size)</span><br><span class=line></span><br><span class=line>    <span class=comment># A simple MLP model</span></span><br><span class=line>    model = get_model(config.dropout)</span><br><span class=line></span><br><span class=line>    <span class=comment># Make the loss and optimizer</span></span><br><span class=line>    loss_func = nn.CrossEntropyLoss()</span><br><span class=line>    optimizer = Adam(model.parameters(), lr=config.lr)</span><br><span class=line></span><br><span class=line>    example_ct = <span class=number>0</span></span><br><span class=line></span><br><span class=line>    <span class=keyword>for</span> epoch <span class=keyword>in</span> tqdm(<span class=built_in>range</span>(config.epochs), total=config.epochs):</span><br><span class=line>        model.train()</span><br><span class=line></span><br><span class=line>        <span class=keyword>for</span> step, (images, labels) <span class=keyword>in</span> <span class=built_in>enumerate</span>(train_dl):</span><br><span class=line>            images, labels = images.to(DEVICE), labels.to(DEVICE)</span><br><span class=line></span><br><span class=line>            outputs = model(images)</span><br><span class=line>            train_loss = loss_func(outputs, labels)</span><br><span class=line>            optimizer.zero_grad()</span><br><span class=line>            train_loss.backward()</span><br><span class=line>            optimizer.step()</span><br><span class=line></span><br><span class=line>            example_ct += <span class=built_in>len</span>(images)</span><br><span class=line>            metrics = {</span><br><span class=line>                <span class=string>"train/train_loss"</span>: train_loss,</span><br><span class=line>                <span class=string>"train/epoch"</span>: epoch + <span class=number>1</span>,</span><br><span class=line>                <span class=string>"train/example_ct"</span>: example_ct</span><br><span class=line>            }</span><br><span class=line>            wandb.log(metrics)</span><br><span class=line>            </span><br><span class=line>        <span class=comment># Compute validation metrics, log images on last epoch</span></span><br><span class=line>        val_loss, accuracy = validate_model(model, valid_dl, loss_func)</span><br><span class=line>        <span class=comment># Compute train and validation metrics</span></span><br><span class=line>        val_metrics = {</span><br><span class=line>            <span class=string>"val/val_loss"</span>: val_loss,</span><br><span class=line>            <span class=string>"val/val_accuracy"</span>: accuracy</span><br><span class=line>        }</span><br><span class=line>        wandb.log(val_metrics)</span><br><span class=line>    </span><br><span class=line>    wandb.finish()</span><br><span class=line></span><br></pre></table></figure><p>如何在同一个run更改,更新现有运行的配置.下面是我匿名使用wandb跑的一次run<figure class="highlight arduino"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> wandb</span><br><span class=line>api = wandb.<span class=built_in>Api</span>()</span><br><span class=line></span><br><span class=line>run = api.<span class=built_in>run</span>(<span class=string>"anony-mouse-988582345570149472/gpt5/&LTrun_id>"</span>)</span><br><span class=line>run.config[<span class=string>"key"</span>] = updated_value</span><br><span class=line>run.<span class=built_in>update</span>()</span><br></pre></table></figure><p>将单个运行的指标导出到CSV文件<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> wandb</span><br><span class=line>api = wandb.Api()</span><br><span class=line></span><br><span class=line><span class=comment># run is specified by &LTentity>/&LTproject>/&LTrun_id></span></span><br><span class=line>run = api.run(<span class=string>"anony-mouse-946987442323310233/dlai_sprite_diffusion/&LTrun_id>"</span>)</span><br><span class=line></span><br><span class=line><span class=comment># save the metrics for the run to a csv file</span></span><br><span class=line>metrics_dataframe = run.history()</span><br><span class=line>metrics_dataframe.to_csv(<span class=string>"metrics.csv"</span>)</span><br></pre></table></figure><p>读取运行指标<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> wandb</span><br><span class=line>api = wandb.Api()</span><br><span class=line></span><br><span class=line>run = api.run(<span class=string>"anony-mouse-946987442323310233/dlai_sprite_diffusion/&LTrun_id>"</span>)</span><br><span class=line><span class=keyword>if</span> run.state == <span class=string>"finished"</span>:</span><br><span class=line>    <span class=keyword>for</span> i, row <span class=keyword>in</span> run.history().iterrows():</span><br><span class=line>      <span class=built_in>print</span>(row[<span class=string>"_timestamp"</span>], row[<span class=string>"accuracy"</span>])</span><br></pre></table></figure><p>当您从历史中提取数据时，默认情况下会对其采样到500点。使用run.scan_history（）获取所有记录的数据点。下面是下载所有记录在历史中的丢失数据点的示例。<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> wandb</span><br><span class=line>api = wandb.Api()</span><br><span class=line></span><br><span class=line>run = api.run(<span class=string>"anony-mouse-946987442323310233/dlai_sprite_diffusion/&LTrun_id>"</span>)</span><br><span class=line>history = run.scan_history()</span><br><span class=line>losses = [row[<span class=string>"loss"</span>] <span class=keyword>for</span> row <span class=keyword>in</span> history]</span><br></pre></table></figure><h4 id=wandb-Table><a title="wandb Table" class=headerlink href=#wandb-Table></a>wandb Table</h4><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>table = wandb.Table(columns=[<span class=string>"input_noise"</span>, <span class=string>"ddpm"</span>, <span class=string>"ddim"</span>, <span class=string>"class"</span>])</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br></pre><td class=code><pre><span class=line><span class=keyword>for</span> noise, ddpm_s, ddim_s, c <span class=keyword>in</span> <span class=built_in>zip</span>(noises, </span><br><span class=line>                                    ddpm_samples, </span><br><span class=line>                                    ddim_samples, </span><br><span class=line>                                    to_classes(ctx_vector)):</span><br><span class=line>    </span><br><span class=line>    <span class=comment># add data row by row to the Table</span></span><br><span class=line>    table.add_data(wandb.Image(noise),</span><br><span class=line>                   wandb.Image(ddpm_s), </span><br><span class=line>                   wandb.Image(ddim_s),</span><br><span class=line>                   c)</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=keyword>with</span> wandb.init(project=<span class=string>"dlai_sprite_diffusion"</span>, </span><br><span class=line>                job_type=<span class=string>"samplers_battle"</span>, </span><br><span class=line>                config=config):</span><br><span class=line>    </span><br><span class=line>    wandb.log({<span class=string>"samplers_table"</span>:table})</span><br></pre></table></figure><p>先创建<code>wandb.Table</code>,再使用其添加数据,最后使用log推上去<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre><td class=code><pre><span class=line>table = wandb.Table(columns=[<span class=string>"prompt"</span>, <span class=string>"generation"</span>])</span><br><span class=line></span><br><span class=line><span class=keyword>for</span> prompt <span class=keyword>in</span> prompts:</span><br><span class=line>    input_ids = tokenizer.encode(prefix + prompt, return_tensors=<span class=string>"pt"</span>)</span><br><span class=line>    output = model.generate(input_ids, do_sample=<span class=literal>True</span>, max_new_tokens=<span class=number>50</span>, top_p=<span class=number>0.3</span>)</span><br><span class=line>    output_text = tokenizer.decode(output[<span class=number>0</span>], skip_special_tokens=<span class=literal>True</span>)</span><br><span class=line>    table.add_data(prefix + prompt, output_text)</span><br><span class=line>    </span><br><span class=line>wandb.log({<span class=string>'tiny_generations'</span>: table})</span><br></pre></table></figure><h3 id=使用W-amp-B-sweep进行超参搜索调整><a title="使用W&B sweep进行超参搜索调整" class=headerlink href=#使用W-amp-B-sweep进行超参搜索调整></a>使用W&B sweep进行超参搜索调整</h3><blockquote><p>在高维超参数空间中搜索以找到最具性能的模型可能会变得非常困难。超参数扫描提供了一种有组织、高效的方式来进行一系列模型的战斗，并选择最准确的模型。它们通过自动搜索超参数值的组合（例如学习率、批量大小、隐藏层的数量、优化器类型）来找到最优化的值。Sweep结合了一种尝试一堆超参数值的策略和评估代码</blockquote><ol><li>定义sweep：通过创建一个字典或YAML文件来实现这一点，该文件指定了要搜索的参数、搜索策略、优化指标等。</ol><p>首先选择搜索策略,包括网格,随机和贝叶斯.<blockquote><ul><li><strong><code>grid</code> Search</strong> – Iterate over every combination of hyperparameter values. Very effective, but can be computationally costly.<li><strong><code>random</code> Search</strong> – Select each new combination at random according to provided <code>distribution</code>s. Surprisingly effective!<li><strong><code>bayes</code>ian Search</strong> – Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.</ul></blockquote><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre><td class=code><pre><span class=line>sweep_config = {</span><br><span class=line>    <span class=string>'method'</span>: <span class=string>'random'</span></span><br><span class=line>    }</span><br><span class=line>metric = {</span><br><span class=line>    <span class=string>'name'</span>: <span class=string>'loss'</span>,</span><br><span class=line>    <span class=string>'goal'</span>: <span class=string>'minimize'</span>   </span><br><span class=line>    }</span><br><span class=line></span><br><span class=line>sweep_config[<span class=string>'metric'</span>] = metric</span><br></pre></table></figure><p>然后是训练网络的一些超参<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br></pre><td class=code><pre><span class=line>parameters_dict = {</span><br><span class=line>    <span class=string>'optimizer'</span>: {</span><br><span class=line>        <span class=string>'values'</span>: [<span class=string>'adam'</span>, <span class=string>'sgd'</span>]</span><br><span class=line>        },</span><br><span class=line>    <span class=string>'fc_layer_size'</span>: {</span><br><span class=line>        <span class=string>'values'</span>: [<span class=number>128</span>, <span class=number>256</span>, <span class=number>512</span>]</span><br><span class=line>        },</span><br><span class=line>    <span class=string>'dropout'</span>: {</span><br><span class=line>          <span class=string>'values'</span>: [<span class=number>0.3</span>, <span class=number>0.4</span>, <span class=number>0.5</span>]</span><br><span class=line>        },</span><br><span class=line>    }</span><br><span class=line></span><br><span class=line>sweep_config[<span class=string>'parameters'</span>] = parameters_dict</span><br></pre></table></figure><p>通常情况下，有些超参数我们不想在这次扫描中发生变化，但我们仍然想在扫描_配置中设置。<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>parameters_dict.update({</span><br><span class=line>    <span class=string>'epochs'</span>: {</span><br><span class=line>        <span class=string>'value'</span>: <span class=number>1</span>}</span><br><span class=line>    })</span><br></pre></table></figure><p><code>`rand</code>搜索策略可以指定一个正态分布进行选参数,默认是均匀分布.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br></pre><td class=code><pre><span class=line>parameters_dict.update({</span><br><span class=line>    <span class=string>'learning_rate'</span>: {</span><br><span class=line>        <span class=comment># a flat distribution between 0 and 0.1</span></span><br><span class=line>        <span class=string>'distribution'</span>: <span class=string>'uniform'</span>,</span><br><span class=line>        <span class=string>'min'</span>: <span class=number>0</span>,</span><br><span class=line>        <span class=string>'max'</span>: <span class=number>0.1</span></span><br><span class=line>      },</span><br><span class=line>    <span class=string>'batch_size'</span>: {</span><br><span class=line>        <span class=comment># integers between 32 and 256</span></span><br><span class=line>        <span class=comment># with evenly-distributed logarithms </span></span><br><span class=line>        <span class=string>'distribution'</span>: <span class=string>'q_log_uniform_values'</span>,</span><br><span class=line>        <span class=string>'q'</span>: <span class=number>8</span>,</span><br><span class=line>        <span class=string>'min'</span>: <span class=number>32</span>,</span><br><span class=line>        <span class=string>'max'</span>: <span class=number>256</span>,</span><br><span class=line>      }</span><br><span class=line>    })</span><br></pre></table></figure><p>所以参数包括<code>metho</code>,<code>metric</code>和<code>parameter</code>.此外还有一些这里就不介绍了<ol><li>初始化扫描：用一行代码初始化扫描并传入扫描配置字典：sweep_id=wandb.sweep（sweep_config）</ol><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>sweep_id = wandb.sweep(sweep_config, project=<span class=string>"pytorch-sweeps-demo"</span>)</span><br></pre></table></figure><p>创建一个sweep<ol><li>运行扫描代理：也可以用一行代码完成，我们调用wandb.agent（）并传递要运行的sweep_id，以及一个定义模型架构并对其进行训练的函数：wandb.agent（sweep_id，function=train）</ol><p>开始正常的训练.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.optim <span class=keyword>as</span> optim</span><br><span class=line><span class=keyword>import</span> torch.nn.functional <span class=keyword>as</span> F</span><br><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line><span class=keyword>from</span> torchvision <span class=keyword>import</span> datasets, transforms</span><br><span class=line></span><br><span class=line>device = torch.device(<span class=string>"cuda"</span> <span class=keyword>if</span> torch.cuda.is_available() <span class=keyword>else</span> <span class=string>"cpu"</span>)</span><br><span class=line></span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>train</span>(<span class=params>config=<span class=literal>None</span></span>):</span></span><br><span class=line>    <span class=comment># Initialize a new wandb run</span></span><br><span class=line>    <span class=keyword>with</span> wandb.init(config=config):</span><br><span class=line>        <span class=comment># If called by wandb.agent, as below,</span></span><br><span class=line>        <span class=comment># this config will be set by Sweep Controller</span></span><br><span class=line>        config = wandb.config</span><br><span class=line></span><br><span class=line>        loader = build_dataset(config.batch_size)</span><br><span class=line>        network = build_network(config.fc_layer_size, config.dropout)</span><br><span class=line>        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)</span><br><span class=line></span><br><span class=line>        <span class=keyword>for</span> epoch <span class=keyword>in</span> <span class=built_in>range</span>(config.epochs):</span><br><span class=line>            avg_loss = train_epoch(network, loader, optimizer)</span><br><span class=line>            wandb.log({<span class=string>"loss"</span>: avg_loss, <span class=string>"epoch"</span>: epoch})           </span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>wandb.agent(sweep_id, train, count=<span class=number>5</span>)</span><br></pre></table></figure><p>使用Sweep Controller返回的随机生成的超参数值，启动一个运行训练5次的agents<p><img alt=image-20231229183908912 data-src=https://s2.loli.net/2023/12/29/2EruyQMvpSNoeRm.png style=zoom:67%;><p>另外课程还讲了Tracer等,现在我用不上….主要还是上传loss和acc这些结果.<h3 id=How-Diffusion-Models-Work><a title="How Diffusion Models Work" class=headerlink href=#How-Diffusion-Models-Work></a>How Diffusion Models Work</h3><p>Diffusion Models在前段时间非常火,也是现在prompt生成图像的主要模型.<p><img alt=image-20231225195441214 data-src=https://i.imgur.com/MkB11s7.png><p><img alt=image-20231225200851364 data-src=https://i.imgur.com/lm5t6Jr.png><p><img alt=image-20231228224804703 data-src=https://s2.loli.net/2023/12/28/LQaYoIzTJWd1yNs.png><p><img alt=image-20231228232748110 data-src=https://s2.loli.net/2023/12/28/G7JTpmDg4zF1neq.png><p>训练的预测噪声网络是Unet<p><img alt=image-20231229151559530 data-src=https://s2.loli.net/2023/12/29/8VAft1WN9L6lrmG.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>ContextUnet</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_channels, n_feat=<span class=number>256</span>, n_cfeat=<span class=number>10</span>, height=<span class=number>28</span></span>):</span>  <span class=comment># cfeat - context features</span></span><br><span class=line>        <span class=built_in>super</span>(ContextUnet, self).__init__()</span><br><span class=line></span><br><span class=line>        <span class=comment># number of input channels, number of intermediate feature maps and number of classes</span></span><br><span class=line>        self.in_channels = in_channels</span><br><span class=line>        self.n_feat = n_feat</span><br><span class=line>        self.n_cfeat = n_cfeat</span><br><span class=line>        self.h = height  <span class=comment>#assume h == w. must be divisible by 4, so 28,24,20,16...</span></span><br><span class=line></span><br><span class=line>        <span class=comment># Initialize the initial convolutional layer</span></span><br><span class=line>        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=<span class=literal>True</span>)</span><br><span class=line></span><br><span class=line>        <span class=comment># Initialize the down-sampling path of the U-Net with two levels</span></span><br><span class=line>        self.down1 = UnetDown(n_feat, n_feat)        <span class=comment># down1 #[10, 256, 8, 8]</span></span><br><span class=line>        self.down2 = UnetDown(n_feat, <span class=number>2</span> * n_feat)    <span class=comment># down2 #[10, 256, 4,  4]</span></span><br><span class=line>        </span><br><span class=line>         <span class=comment># original: self.to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())</span></span><br><span class=line>        self.to_vec = nn.Sequential(nn.AvgPool2d((<span class=number>4</span>)), nn.GELU())</span><br><span class=line></span><br><span class=line>        <span class=comment># Embed the timestep and context labels with a one-layer fully connected neural network</span></span><br><span class=line>        self.timeembed1 = EmbedFC(<span class=number>1</span>, <span class=number>2</span>*n_feat)</span><br><span class=line>        self.timeembed2 = EmbedFC(<span class=number>1</span>, <span class=number>1</span>*n_feat)</span><br><span class=line>        self.contextembed1 = EmbedFC(n_cfeat, <span class=number>2</span>*n_feat)</span><br><span class=line>        self.contextembed2 = EmbedFC(n_cfeat, <span class=number>1</span>*n_feat)</span><br><span class=line></span><br><span class=line>        <span class=comment># Initialize the up-sampling path of the U-Net with three levels</span></span><br><span class=line>        self.up0 = nn.Sequential(</span><br><span class=line>            nn.ConvTranspose2d(<span class=number>2</span> * n_feat, <span class=number>2</span> * n_feat, self.h//<span class=number>4</span>, self.h//<span class=number>4</span>), <span class=comment># up-sample  </span></span><br><span class=line>            nn.GroupNorm(<span class=number>8</span>, <span class=number>2</span> * n_feat), <span class=comment># normalize                       </span></span><br><span class=line>            nn.ReLU(),</span><br><span class=line>        )</span><br><span class=line>        self.up1 = UnetUp(<span class=number>4</span> * n_feat, n_feat)</span><br><span class=line>        self.up2 = UnetUp(<span class=number>2</span> * n_feat, n_feat)</span><br><span class=line></span><br><span class=line>        <span class=comment># Initialize the final convolutional layers to map to the same number of channels as the input image</span></span><br><span class=line>        self.out = nn.Sequential(</span><br><span class=line>            nn.Conv2d(<span class=number>2</span> * n_feat, n_feat, <span class=number>3</span>, <span class=number>1</span>, <span class=number>1</span>), <span class=comment># reduce number of feature maps   #in_channels, out_channels, kernel_size, stride=1, padding=0</span></span><br><span class=line>            nn.GroupNorm(<span class=number>8</span>, n_feat), <span class=comment># normalize</span></span><br><span class=line>            nn.ReLU(),</span><br><span class=line>            nn.Conv2d(n_feat, self.in_channels, <span class=number>3</span>, <span class=number>1</span>, <span class=number>1</span>), <span class=comment># map to same number of channels as input</span></span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, t, c=<span class=literal>None</span></span>):</span></span><br><span class=line>        <span class=string>"""</span></span><br><span class=line><span class=string>        x : (batch, n_feat, h, w) : input image</span></span><br><span class=line><span class=string>        t : (batch, n_cfeat)      : time step</span></span><br><span class=line><span class=string>        c : (batch, n_classes)    : context label</span></span><br><span class=line><span class=string>        """</span></span><br><span class=line>        <span class=comment># x is the input image, c is the context label, t is the timestep, context_mask says which samples to block the context on</span></span><br><span class=line></span><br><span class=line>        <span class=comment># pass the input image through the initial convolutional layer</span></span><br><span class=line>        x = self.init_conv(x)</span><br><span class=line>        <span class=comment># pass the result through the down-sampling path</span></span><br><span class=line>        down1 = self.down1(x)       <span class=comment>#[10, 256, 8, 8]</span></span><br><span class=line>        down2 = self.down2(down1)   <span class=comment>#[10, 256, 4, 4]</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment># convert the feature maps to a vector and apply an activation</span></span><br><span class=line>        hiddenvec = self.to_vec(down2)</span><br><span class=line>        </span><br><span class=line>        <span class=comment># mask out context if context_mask == 1</span></span><br><span class=line>        <span class=keyword>if</span> c <span class=keyword>is</span> <span class=literal>None</span>:</span><br><span class=line>            c = torch.zeros(x.shape[<span class=number>0</span>], self.n_cfeat).to(x)</span><br><span class=line>            </span><br><span class=line>        <span class=comment># embed context and timestep</span></span><br><span class=line>        cemb1 = self.contextembed1(c).view(-<span class=number>1</span>, self.n_feat * <span class=number>2</span>, <span class=number>1</span>, <span class=number>1</span>)     <span class=comment># (batch, 2*n_feat, 1,1)</span></span><br><span class=line>        temb1 = self.timeembed1(t).view(-<span class=number>1</span>, self.n_feat * <span class=number>2</span>, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        cemb2 = self.contextembed2(c).view(-<span class=number>1</span>, self.n_feat, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        temb2 = self.timeembed2(t).view(-<span class=number>1</span>, self.n_feat, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        <span class=comment>#print(f"uunet forward: cemb1 {cemb1.shape}. temb1 {temb1.shape}, cemb2 {cemb2.shape}. temb2 {temb2.shape}")</span></span><br><span class=line></span><br><span class=line></span><br><span class=line>        up1 = self.up0(hiddenvec)</span><br><span class=line>        up2 = self.up1(cemb1*up1 + temb1, down2)  <span class=comment># add and multiply embeddings</span></span><br><span class=line>        up3 = self.up2(cemb2*up2 + temb2, down1)</span><br><span class=line>        out = self.out(torch.cat((up3, x), <span class=number>1</span>))</span><br><span class=line>        <span class=keyword>return</span> out</span><br><span class=line></span><br></pre></table></figure><p>训练的时候是random一个timestamp得到噪声,sampling的时候是根据步数进行依次sampling<h3 id=control-and-speed-up><a title="control and speed up" class=headerlink href=#control-and-speed-up></a>control and speed up</h3><p>加入context_vector进行控制输出,使用DDIM替换DDPM进行加速samping<p><img alt=image-20231229152240050 data-src=https://s2.loli.net/2023/12/29/MAifZF7OlmPtbWs.png><p><img alt=image-20231229152302772 data-src=https://s2.loli.net/2023/12/29/hqbUoyE9iRpdgNA.png><p><img alt=image-20231229152531542 data-src=https://s2.loli.net/2023/12/29/jLaNo19nuCwDJQG.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br></pre><td class=code><pre><span class=line><span class=comment># define sampling function for DDIM   </span></span><br><span class=line><span class=comment># removes the noise using ddim</span></span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>denoise_ddim</span>(<span class=params>x, t, t_prev, pred_noise</span>):</span></span><br><span class=line>    ab = ab_t[t]</span><br><span class=line>    ab_prev = ab_t[t_prev]</span><br><span class=line>    </span><br><span class=line>    x0_pred = ab_prev.sqrt() / ab.sqrt() * (x - (<span class=number>1</span> - ab).sqrt() * pred_noise)</span><br><span class=line>    dir_xt = (<span class=number>1</span> - ab_prev).sqrt() * pred_noise</span><br><span class=line></span><br><span class=line>    <span class=keyword>return</span> x0_pred + dir_xt</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br></pre><td class=code><pre><span class=line><span class=comment># fast sampling algorithm with context</span></span><br><span class=line><span class=meta>@torch.no_grad()</span></span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>sample_ddim_context</span>(<span class=params>n_sample, context, n=<span class=number>20</span></span>):</span></span><br><span class=line>    <span class=comment># x_T ~ N(0, 1), sample initial noise</span></span><br><span class=line>    samples = torch.randn(n_sample, <span class=number>3</span>, height, height).to(device)  </span><br><span class=line></span><br><span class=line>    <span class=comment># array to keep track of generated steps for plotting</span></span><br><span class=line>    intermediate = [] </span><br><span class=line>    step_size = timesteps // n</span><br><span class=line>    <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(timesteps, <span class=number>0</span>, -step_size):</span><br><span class=line>        <span class=built_in>print</span>(<span class=string>f'sampling timestep <span class=subst>{i:3d}</span>'</span>, end=<span class=string>'\r'</span>)</span><br><span class=line></span><br><span class=line>        <span class=comment># reshape time tensor</span></span><br><span class=line>        t = torch.tensor([i / timesteps])[:, <span class=literal>None</span>, <span class=literal>None</span>, <span class=literal>None</span>].to(device)</span><br><span class=line></span><br><span class=line>        eps = nn_model(samples, t, c=context)    <span class=comment># predict noise e_(x_t,t)</span></span><br><span class=line>        samples = denoise_ddim(samples, i, i - step_size, eps)</span><br><span class=line>        intermediate.append(samples.detach().cpu().numpy())</span><br><span class=line></span><br><span class=line>    intermediate = np.stack(intermediate)</span><br><span class=line>    <span class=keyword>return</span> samples, intermediate</span><br></pre></table></figure><h3 id=ChatGPT-Prompt-Engineering-for-Developers><a title="ChatGPT Prompt Engineering for Developers" class=headerlink href=#ChatGPT-Prompt-Engineering-for-Developers></a>ChatGPT Prompt Engineering for Developers</h3><p>使用ChatGPT辅助,感觉已经成为现代社会一种普通工具了<p><img style="zoom: 67%;" alt=image-20231228232329050 data-src=https://s2.loli.net/2023/12/28/PmOSaTEFH8pVuqe.png><p><img alt=image-20231228232417399 data-src=https://s2.loli.net/2023/12/28/sh6MfqxQEUnuG5j.png><h3 id=Finetuning-Large-Language-Models><a title="Finetuning Large Language Models" class=headerlink href=#Finetuning-Large-Language-Models></a>Finetuning Large Language Models</h3><p>大模型的finetune,了解原理即可<p><img alt=image-20231228232508902 data-src=https://s2.loli.net/2023/12/28/zyAIapuUNi9EeSw.png style=zoom:50%;><h3 id=Opensource-models-with-huggingface><a title="Opensource models with huggingface" class=headerlink href=#Opensource-models-with-huggingface></a>Opensource models with huggingface</h3><p>非常全面的使用hugging face模型的课程,可以用于部署一些接口.<h3 id=Getting-started-with-Mistral><a title="Getting started with Mistral" class=headerlink href=#Getting-started-with-Mistral></a>Getting started with Mistral</h3><p>如果你想玩玩开源模型可以试试这个Mistral.此外也有llama2&&3的玩意<h3 id=Prompt-Engineering-for-Vision-Models><a title="Prompt Engineering for Vision Models" class=headerlink href=#Prompt-Engineering-for-Vision-Models></a>Prompt Engineering for Vision Models</h3><p>使用相应工具对视觉模型的输出使用文本进行调整<h3 id=Building-an-AI-Powered-Game><a title="Building an AI-Powered Game" class=headerlink href=#Building-an-AI-Powered-Game></a>Building an AI-Powered Game</h3><p>AI Dungeon公司与together.ai联合的课程,前者官网有一系列文字游戏,使用体验很好,后者有一系列LLM教程。第一讲就是关于prompt生成游戏中世界、城镇等信息，作者把这个叫做hierarchical content generation,给我的感觉还是有点hype. 比如下面的文本让llm生成按照这个格式的信息<figure class="highlight ini"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br></pre><td class=code><pre><span class=line><span class=attr>kingdom_prompt</span> = f<span class=string>"""</span></span><br><span class=line><span class=string>Create 3 different kingdoms for a fantasy world.</span></span><br><span class=line><span class=string>For each kingdom generate a description based on the world it's in. \</span></span><br><span class=line><span class=string>Describe important leaders, cultures, history of the kingdom.\</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Output content in the form:</span></span><br><span class=line><span class=string>Kingdom 1 Name: &LTKINGDOM NAME></span></span><br><span class=line><span class=string>Kingdom 1 Description: &LTKINGDOM DESCRIPTION></span></span><br><span class=line><span class=string>Kingdom 2 Name: &LTKINGDOM NAME></span></span><br><span class=line><span class=string>Kingdom 2 Description: &LTKINGDOM DESCRIPTION></span></span><br><span class=line><span class=string>Kingdom 3 Name: &LTKINGDOM NAME></span></span><br><span class=line><span class=string>Kingdom 3 Description: &LTKINGDOM DESCRIPTION></span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>World Name: {world['name']}</span></span><br><span class=line><span class=string>World Description: {world['description']}</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Kingdom 1"""</span></span><br></pre></table></figure><p>第二门课使用gradio构建交互式的输入输出,将之前的游戏文本信息再输入给llm,让其生成游戏开始的相关的信息<figure class="highlight ini"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br></pre><td class=code><pre><span class=line><span class=attr>system_prompt</span> = <span class=string>"""You are an AI Game master. Your job is to create a </span></span><br><span class=line><span class=string>start to an adventure based on the world, kingdom, town and character </span></span><br><span class=line><span class=string>a player is playing as. </span></span><br><span class=line><span class=string>Instructions:</span></span><br><span class=line><span class=string>You must only use 2-4 sentences \</span></span><br><span class=line><span class=string>Write in second person. For example: "You are Jack" \</span></span><br><span class=line><span class=string>Write in present tense. For example "You stand at..." \</span></span><br><span class=line><span class=string>First describe the character and their backstory. \</span></span><br><span class=line><span class=string>Then describes where they start and what they see around them."""</span></span><br><span class=line><span class=attr>world_info</span> = f<span class=string>"""</span></span><br><span class=line><span class=string>World: {world}</span></span><br><span class=line><span class=string>Kingdom: {kingdom}</span></span><br><span class=line><span class=string>Town: {town}</span></span><br><span class=line><span class=string>Your Character: {character}</span></span><br><span class=line><span class=string>"""</span></span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line>model_output = client.chat.completions.create(</span><br><span class=line>    model=<span class=string>"meta-llama/Llama-3-70b-chat-hf"</span>,</span><br><span class=line>    temperature=<span class=number>1.0</span>,</span><br><span class=line>    messages=[</span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"system"</span>, <span class=string>"content"</span>: system_prompt},</span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: world_info + <span class=string>'\nYour Start:'</span>}</span><br><span class=line>    ],</span><br><span class=line>)</span><br></pre></table></figure><p>第三节内容是关于生成的文本信息的安全方面,实际上就是通过llm自身检查输出内容的其安全性<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br></pre><td class=code><pre><span class=line><span class=comment># Set the content policy</span></span><br><span class=line>mature_content_policy = {</span><br><span class=line>    <span class=string>"policy"</span>: <span class=string>"""O2: Sexual Content.</span></span><br><span class=line><span class=string>Should not</span></span><br><span class=line><span class=string>- Write about graphic or illegal content.</span></span><br><span class=line><span class=string>Can</span></span><br><span class=line><span class=string>- Write about mature content between adults"""</span></span><br><span class=line>}</span><br><span class=line>check_text = <span class=string>"Kill the troll."</span></span><br><span class=line></span><br><span class=line>prompt = <span class=string>f"""[INST] Task: Check if there is unsafe </span></span><br><span class=line><span class=string>content in 'user' messages in conversations according </span></span><br><span class=line><span class=string>to our safety policy with the below categories.</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>&LTBEGIN UNSAFE CONTENT CATEGORIES></span></span><br><span class=line><span class=string><span class=subst>{mature_content_policy[<span class=string>'policy'</span>]}</span></span></span><br><span class=line><span class=string>&LTEND UNSAFE CONTENT CATEGORIES></span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>&LTBEGIN CONVERSATION></span></span><br><span class=line><span class=string>user: <span class=subst>{check_text}</span></span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Provide your safety assessment for user in the above conversation:</span></span><br><span class=line><span class=string>- First line must read 'safe' or 'unsafe'.</span></span><br><span class=line><span class=string>- If unsafe, a second line must include a comma-separated list of </span></span><br><span class=line><span class=string>violated categories. [/INST]"""</span></span><br><span class=line>response = client.completions.create(</span><br><span class=line>    model=<span class=string>"Meta-Llama/LlamaGuard-2-8b"</span>,</span><br><span class=line>    prompt=prompt,</span><br><span class=line>)</span><br><span class=line><span class=built_in>print</span>(response.choices[<span class=number>0</span>].text)</span><br></pre></table></figure><p>第四节实现游戏机制,主要通过state记住(靠告诉llm)之前的游戏状态<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>detect_inventory_changes</span>(<span class=params>game_state, output</span>):</span></span><br><span class=line>    </span><br><span class=line>    inventory = game_state[<span class=string>'inventory'</span>]</span><br><span class=line>    messages = [</span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"system"</span>, <span class=string>"content"</span>: system_prompt},</span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: </span><br><span class=line>         <span class=string>f'Current Inventory: <span class=subst>{<span class=built_in>str</span>(inventory)}</span>'</span>},</span><br><span class=line>        </span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: <span class=string>f'Recent Story: <span class=subst>{output}</span>'</span>},</span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: <span class=string>'Inventory Updates'</span>}</span><br><span class=line>    ]</span><br><span class=line>    chat_completion = client.chat.completions.create(</span><br><span class=line>        <span class=comment># response_format={"type": "json_object", "schema": InventoryUpdate.model_json_schema()},</span></span><br><span class=line>        model=<span class=string>"meta-llama/Llama-3-70b-chat-hf"</span>,</span><br><span class=line>        temperature=<span class=number>0.0</span>,</span><br><span class=line>        messages=messages</span><br><span class=line>    )</span><br><span class=line>    response = chat_completion.choices[<span class=number>0</span>].message.content</span><br><span class=line>    result = json.loads(response)</span><br><span class=line>    <span class=keyword>return</span> result[<span class=string>'itemUpdates'</span>]</span><br><span class=line>   </span><br><span class=line>   <span class=keyword>from</span> helper <span class=keyword>import</span> get_game_state</span><br><span class=line></span><br><span class=line>game_state = get_game_state()</span><br><span class=line>game_state[<span class=string>'inventory'</span>] = {</span><br><span class=line>    <span class=string>"cloth pants"</span>: <span class=number>1</span>,</span><br><span class=line>    <span class=string>"cloth shirt"</span>: <span class=number>1</span>,</span><br><span class=line>    <span class=string>"gold"</span>: <span class=number>5</span></span><br><span class=line>}</span><br><span class=line></span><br><span class=line>result = detect_inventory_changes(game_state, </span><br><span class=line><span class=string>"You buy a sword from the merchant for 5 gold"</span>)</span><br><span class=line></span><br><span class=line><span class=built_in>print</span>(result)</span><br></pre></table></figure><h3 id=LangChain-for-LLM-Application-Development><a title="LangChain for LLM Application Development" class=headerlink href=#LangChain-for-LLM-Application-Development></a>LangChain for LLM Application Development</h3><p>LangChain的一个优点在于不用去管常见平台提供的模型了,比如OpenAI,HuggingFace,Ollama等. LangChain将一个常见的LLM应用分了多个部分,包括针对输入的PromptTemplate,针对输出的OutputParser以及Memory等<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.chat_models <span class=keyword>import</span> ChatOpenAI</span><br><span class=line><span class=keyword>from</span> langchain.prompts <span class=keyword>import</span> ChatPromptTemplate</span><br><span class=line></span><br><span class=line><span class=comment># To control the randomness and creativity of the generated</span></span><br><span class=line><span class=comment># text by an LLM, use temperature = 0.0</span></span><br><span class=line>chat = ChatOpenAI(temperature=<span class=number>0.0</span>, model=llm_model)</span><br><span class=line>prompt_template = ChatPromptTemplate.from_template(template_string)</span><br><span class=line>customer_style = <span class=string>"""American English \</span></span><br><span class=line><span class=string>in a calm and respectful tone</span></span><br><span class=line><span class=string>"""</span></span><br><span class=line>customer_email = <span class=string>"""</span></span><br><span class=line><span class=string>Arrr, I be fuming that me blender lid \</span></span><br><span class=line><span class=string>flew off and splattered me kitchen walls \</span></span><br><span class=line><span class=string>with smoothie! And to make matters worse, \</span></span><br><span class=line><span class=string>the warranty don't cover the cost of \</span></span><br><span class=line><span class=string>cleaning up me kitchen. I need yer help \</span></span><br><span class=line><span class=string>right now, matey!</span></span><br><span class=line><span class=string>"""</span></span><br><span class=line>customer_messages = prompt_template.format_messages(</span><br><span class=line>                    style=customer_style,</span><br><span class=line>                    text=customer_email)</span><br><span class=line><span class=comment># Call the LLM to translate to the style of the customer message</span></span><br><span class=line>customer_response = chat(customer_messages)</span><br></pre></table></figure><p>可以让LLM输出json格式的输出并通过StructuredOutputParser格式输出. 其实可以简单理解为parser就是通过llm有格式的输出进行爬取的,所以前提是一定要让llm输出按照一定格式的json数据.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.output_parsers <span class=keyword>import</span> ResponseSchema</span><br><span class=line><span class=keyword>from</span> langchain.output_parsers <span class=keyword>import</span> StructuredOutputParser</span><br><span class=line></span><br><span class=line>gift_schema = ResponseSchema(name=<span class=string>"gift"</span>,</span><br><span class=line>                             description=<span class=string>"Was the item purchased\</span></span><br><span class=line><span class=string>                             as a gift for someone else? \</span></span><br><span class=line><span class=string>                             Answer True if yes,\</span></span><br><span class=line><span class=string>                             False if not or unknown."</span>)</span><br><span class=line>delivery_days_schema = ResponseSchema(name=<span class=string>"delivery_days"</span>,</span><br><span class=line>                                      description=<span class=string>"How many days\</span></span><br><span class=line><span class=string>                                      did it take for the product\</span></span><br><span class=line><span class=string>                                      to arrive? If this \</span></span><br><span class=line><span class=string>                                      information is not found,\</span></span><br><span class=line><span class=string>                                      output -1."</span>)</span><br><span class=line>price_value_schema = ResponseSchema(name=<span class=string>"price_value"</span>,</span><br><span class=line>                                    description=<span class=string>"Extract any\</span></span><br><span class=line><span class=string>                                    sentences about the value or \</span></span><br><span class=line><span class=string>                                    price, and output them as a \</span></span><br><span class=line><span class=string>                                    comma separated Python list."</span>)</span><br><span class=line></span><br><span class=line>response_schemas = [gift_schema, </span><br><span class=line>                    delivery_days_schema,</span><br><span class=line>                    price_value_schema]</span><br><span class=line>output_parser = StructuredOutputParser.from_response_schemas(response_schemas)</span><br><span class=line>format_instructions = output_parser.get_format_instructions()</span><br><span class=line>review_template_2 = <span class=string>"""\</span></span><br><span class=line><span class=string>For the following text, extract the following information:</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>gift: Was the item purchased as a gift for someone else? \</span></span><br><span class=line><span class=string>Answer True if yes, False if not or unknown.</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>delivery_days: How many days did it take for the product\</span></span><br><span class=line><span class=string>to arrive? If this information is not found, output -1.</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>price_value: Extract any sentences about the value or price,\</span></span><br><span class=line><span class=string>and output them as a comma separated Python list.</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>text: {text}</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>{format_instructions}</span></span><br><span class=line><span class=string>"""</span></span><br><span class=line></span><br><span class=line>prompt = ChatPromptTemplate.from_template(template=review_template_2)</span><br><span class=line></span><br><span class=line>messages = prompt.format_messages(text=customer_review,                                 format_instructions=format_instructions)</span><br><span class=line>response = chat(messages)</span><br><span class=line><span class=built_in>print</span>(response.content)</span><br><span class=line>output_dict = output_parser.parse(response.content)</span><br><span class=line><span class=built_in>print</span>(output_dict.get(<span class=string>'delivery_days'</span>))</span><br></pre></table></figure><p>使用LangChain的Memory记忆上下文,目前其中的ConversationChain和ConversationBufferMemory已经deprecated了,要么往LangGraph上转要么使用RunnableWithMessageHistory或者BaseChatMessageHistory<p><img alt=image-20250102180828216 data-src=https://s2.loli.net/2025/01/02/Fb2daDYJ4Xs37Cy.png><p>这里还是简单介绍一下之前的用法<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.chat_models <span class=keyword>import</span> ChatOpenAI</span><br><span class=line><span class=keyword>from</span> langchain.chains <span class=keyword>import</span> ConversationChain</span><br><span class=line><span class=keyword>from</span> langchain.memory <span class=keyword>import</span> ConversationBufferMemory</span><br><span class=line></span><br><span class=line>llm = ChatOpenAI(temperature=<span class=number>0.0</span>, model=llm_model)</span><br><span class=line>memory = ConversationBufferMemory()</span><br><span class=line>conversation = ConversationChain(</span><br><span class=line>    llm=llm, </span><br><span class=line>    memory = memory,</span><br><span class=line>    verbose=<span class=literal>True</span></span><br><span class=line>)</span><br><span class=line>conversation.predict(<span class=built_in>input</span>=<span class=string>"Hi, my name is xxx"</span>)</span><br></pre></table></figure><p>由于这种memory相当于额外给llms输入,当对话比较长时就很浪费token了.此外还有ConversationBufferWindowMemory，ConversationTokenBufferMemory以及ConversationSummaryMemory.<p>在LangGraph中使用<code>`InMemoryStore</code>相当于字典<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langgraph.store.memory <span class=keyword>import</span> InMemoryStore</span><br><span class=line>in_memory_store = InMemoryStore()</span><br><span class=line>user_id = <span class=string>"1"</span></span><br><span class=line>namespace_for_memory = (user_id, <span class=string>"memories"</span>)</span><br><span class=line>memory_id = <span class=built_in>str</span>(uuid.uuid4())</span><br><span class=line>memory = {<span class=string>"food_preference"</span> : <span class=string>"I like pizza"</span>}</span><br><span class=line>in_memory_store.put(namespace_for_memory, memory_id, memory)</span><br></pre></table></figure><p>Chains这章使用LLMChain也是deprecated,已经流行使用<code>prompt|llm</code>了.<p>但是其他更复杂的Chain还没有deprecated.<p>SimpleSequentialChain可以将不同的chain连起来,将上一个输出作为下一个输入<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.chains <span class=keyword>import</span> SimpleSequentialChain</span><br><span class=line>llm = ChatOpenAI(temperature=<span class=number>0.9</span>, model=llm_model)</span><br><span class=line></span><br><span class=line><span class=comment># prompt template 1</span></span><br><span class=line>first_prompt = ChatPromptTemplate.from_template(</span><br><span class=line>    <span class=string>"What is the best name to describe \</span></span><br><span class=line><span class=string>    a company that makes {product}?"</span></span><br><span class=line>)</span><br><span class=line></span><br><span class=line><span class=comment># Chain 1</span></span><br><span class=line>chain_one = LLMChain(llm=llm, prompt=first_prompt)</span><br><span class=line><span class=comment># prompt template 2</span></span><br><span class=line>second_prompt = ChatPromptTemplate.from_template(</span><br><span class=line>    <span class=string>"Write a 20 words description for the following \</span></span><br><span class=line><span class=string>    company:{company_name}"</span></span><br><span class=line>)</span><br><span class=line><span class=comment># chain 2</span></span><br><span class=line>chain_two = LLMChain(llm=llm, prompt=second_prompt)</span><br><span class=line>overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],verbose=<span class=literal>True</span>)</span><br><span class=line>overall_simple_chain.run(product)</span><br></pre></table></figure><p>如果不使用LLMChain<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>chain1 = first_prompt | llm</span><br><span class=line>chain2 = second_prompt | llm</span><br><span class=line>overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],verbose=<span class=literal>True</span> )</span><br><span class=line>overall_simple_chain.run(product)</span><br></pre></table></figure><p>SequentialChain可以有多个输入和多个输出<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.chains <span class=keyword>import</span> SequentialChain</span><br><span class=line></span><br><span class=line>llm = ChatOpenAI(temperature=<span class=number>0.9</span>, model=llm_model)</span><br><span class=line></span><br><span class=line><span class=comment># prompt template 1: translate to english</span></span><br><span class=line>first_prompt = ChatPromptTemplate.from_template(</span><br><span class=line>    <span class=string>"Translate the following review to english:"</span></span><br><span class=line>    <span class=string>"\n\n{Review}"</span></span><br><span class=line>)</span><br><span class=line><span class=comment># chain 1: input= Review and output= English_Review</span></span><br><span class=line>chain_one = LLMChain(llm=llm, prompt=first_prompt, </span><br><span class=line>                     output_key=<span class=string>"English_Review"</span></span><br><span class=line>                    )</span><br><span class=line></span><br><span class=line>second_prompt = ChatPromptTemplate.from_template(</span><br><span class=line>    <span class=string>"Can you summarize the following review in 1 sentence:"</span></span><br><span class=line>    <span class=string>"\n\n{English_Review}"</span></span><br><span class=line>)</span><br><span class=line><span class=comment># chain 2: input= English_Review and output= summary</span></span><br><span class=line>chain_two = LLMChain(llm=llm, prompt=second_prompt, </span><br><span class=line>                     output_key=<span class=string>"summary"</span></span><br><span class=line>                    )</span><br><span class=line><span class=comment># prompt template 3: translate to english</span></span><br><span class=line>third_prompt = ChatPromptTemplate.from_template(</span><br><span class=line>    <span class=string>"What language is the following review:\n\n{Review}"</span></span><br><span class=line>)</span><br><span class=line><span class=comment># chain 3: input= Review and output= language</span></span><br><span class=line>chain_three = LLMChain(llm=llm, prompt=third_prompt,</span><br><span class=line>                       output_key=<span class=string>"language"</span></span><br><span class=line>                      )</span><br><span class=line></span><br><span class=line><span class=comment># prompt template 4: follow up message</span></span><br><span class=line>fourth_prompt = ChatPromptTemplate.from_template(</span><br><span class=line>    <span class=string>"Write a follow up response to the following "</span></span><br><span class=line>    <span class=string>"summary in the specified language:"</span></span><br><span class=line>    <span class=string>"\n\nSummary: {summary}\n\nLanguage: {language}"</span></span><br><span class=line>)</span><br><span class=line><span class=comment># chain 4: input= summary, language and output= followup_message</span></span><br><span class=line>chain_four = LLMChain(llm=llm, prompt=fourth_prompt,</span><br><span class=line>                      output_key=<span class=string>"followup_message"</span></span><br><span class=line>                     )</span><br><span class=line><span class=comment># overall_chain: input= Review </span></span><br><span class=line><span class=comment># and output= English_Review,summary, followup_message</span></span><br><span class=line>overall_chain = SequentialChain(</span><br><span class=line>    chains=[chain_one, chain_two, chain_three, chain_four],</span><br><span class=line>    input_variables=[<span class=string>"Review"</span>],</span><br><span class=line>    output_variables=[<span class=string>"English_Review"</span>, <span class=string>"summary"</span>,<span class=string>"followup_message"</span>],</span><br><span class=line>    verbose=<span class=literal>True</span></span><br><span class=line>)</span><br></pre></table></figure><p>RouterChain会根据输出选择接下来不同的chain,简单来说一般会利用outputParser获取诸如json数据中指定key对应的value,根据value选择chain.<figure class="highlight smalltalk"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br><span class=line>84</span><br><span class=line>85</span><br><span class=line>86</span><br><span class=line>87</span><br><span class=line>88</span><br><span class=line>89</span><br><span class=line>90</span><br><span class=line>91</span><br><span class=line>92</span><br><span class=line>93</span><br><span class=line>94</span><br><span class=line>95</span><br><span class=line>96</span><br><span class=line>97</span><br><span class=line>98</span><br><span class=line>99</span><br><span class=line>100</span><br><span class=line>101</span><br><span class=line>102</span><br><span class=line>103</span><br><span class=line>104</span><br><span class=line>105</span><br><span class=line>106</span><br><span class=line>107</span><br><span class=line>108</span><br><span class=line>109</span><br><span class=line>110</span><br><span class=line>111</span><br><span class=line>112</span><br><span class=line>113</span><br><span class=line>114</span><br><span class=line>115</span><br><span class=line>116</span><br><span class=line>117</span><br><span class=line>118</span><br><span class=line>119</span><br><span class=line>120</span><br><span class=line>121</span><br><span class=line>122</span><br><span class=line>123</span><br><span class=line>124</span><br><span class=line>125</span><br><span class=line>126</span><br><span class=line>127</span><br></pre><td class=code><pre><span class=line>physics_template = <span class=comment>""</span><span class=comment>"You are a very smart physics professor. \</span></span><br><span class=line><span class=comment>You are great at answering questions about physics in a concise\</span></span><br><span class=line><span class=comment>and easy to understand manner. \</span></span><br><span class=line><span class=comment>When you don't know the answer to a question you admit\</span></span><br><span class=line><span class=comment>that you don't know.</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment>Here is a question:</span></span><br><span class=line><span class=comment>{input}"</span><span class=comment>""</span></span><br><span class=line></span><br><span class=line></span><br><span class=line>math_template = <span class=comment>""</span><span class=comment>"You are a very good mathematician. \</span></span><br><span class=line><span class=comment>You are great at answering math questions. \</span></span><br><span class=line><span class=comment>You are so good because you are able to break down \</span></span><br><span class=line><span class=comment>hard problems into their component parts, </span></span><br><span class=line><span class=comment>answer the component parts, and then put them together\</span></span><br><span class=line><span class=comment>to answer the broader question.</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment>Here is a question:</span></span><br><span class=line><span class=comment>{input}"</span><span class=comment>""</span></span><br><span class=line></span><br><span class=line>history_template = <span class=comment>""</span><span class=comment>"You are a very good historian. \</span></span><br><span class=line><span class=comment>You have an excellent knowledge of and understanding of people,\</span></span><br><span class=line><span class=comment>events and contexts from a range of historical periods. \</span></span><br><span class=line><span class=comment>You have the ability to think, reflect, debate, discuss and \</span></span><br><span class=line><span class=comment>evaluate the past. You have a respect for historical evidence\</span></span><br><span class=line><span class=comment>and the ability to make use of it to support your explanations \</span></span><br><span class=line><span class=comment>and judgements.</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment>Here is a question:</span></span><br><span class=line><span class=comment>{input}"</span><span class=comment>""</span></span><br><span class=line></span><br><span class=line></span><br><span class=line>computerscience_template = <span class=comment>""</span><span class=comment>" You are a successful computer scientist.\</span></span><br><span class=line><span class=comment>You have a passion for creativity, collaboration,\</span></span><br><span class=line><span class=comment>forward-thinking, confidence, strong problem-solving capabilities,\</span></span><br><span class=line><span class=comment>understanding of theories and algorithms, and excellent communication \</span></span><br><span class=line><span class=comment>skills. You are great at answering coding questions. \</span></span><br><span class=line><span class=comment>You are so good because you know how to solve a problem by \</span></span><br><span class=line><span class=comment>describing the solution in imperative steps \</span></span><br><span class=line><span class=comment>that a machine can easily interpret and you know how to \</span></span><br><span class=line><span class=comment>choose a solution that has a good balance between \</span></span><br><span class=line><span class=comment>time complexity and space complexity. </span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment>Here is a question:</span></span><br><span class=line><span class=comment>{input}"</span><span class=comment>""</span></span><br><span class=line>prompt_infos = [</span><br><span class=line>    {</span><br><span class=line>        <span class=comment>"name"</span>: <span class=comment>"physics"</span>, </span><br><span class=line>        <span class=comment>"description"</span>: <span class=comment>"Good for answering questions about physics"</span>, </span><br><span class=line>        <span class=comment>"prompt_template"</span>: physics_template</span><br><span class=line>    },</span><br><span class=line>    {</span><br><span class=line>        <span class=comment>"name"</span>: <span class=comment>"math"</span>, </span><br><span class=line>        <span class=comment>"description"</span>: <span class=comment>"Good for answering math questions"</span>, </span><br><span class=line>        <span class=comment>"prompt_template"</span>: math_template</span><br><span class=line>    },</span><br><span class=line>    {</span><br><span class=line>        <span class=comment>"name"</span>: <span class=comment>"History"</span>, </span><br><span class=line>        <span class=comment>"description"</span>: <span class=comment>"Good for answering history questions"</span>, </span><br><span class=line>        <span class=comment>"prompt_template"</span>: history_template</span><br><span class=line>    },</span><br><span class=line>    {</span><br><span class=line>        <span class=comment>"name"</span>: <span class=comment>"computer science"</span>, </span><br><span class=line>        <span class=comment>"description"</span>: <span class=comment>"Good for answering computer science questions"</span>, </span><br><span class=line>        <span class=comment>"prompt_template"</span>: computerscience_template</span><br><span class=line>    }</span><br><span class=line>]</span><br><span class=line>from langchain.chains.router import <span class=type>MultiPromptChain</span></span><br><span class=line>from langchain.chains.router.llm_router import <span class=type>LLMRouterChain</span>,<span class=type>RouterOutputParser</span></span><br><span class=line>from langchain.prompts import <span class=type>PromptTemplate</span></span><br><span class=line>llm = <span class=type>ChatOpenAI</span>(temperature=<span class=number>0</span>, model=llm_model)</span><br><span class=line></span><br><span class=line>destination_chains = {}</span><br><span class=line>for p_info in prompt_infos:</span><br><span class=line>    name = p_info[<span class=comment>"name"</span>]</span><br><span class=line>    prompt_template = p_info[<span class=comment>"prompt_template"</span>]</span><br><span class=line>    prompt = <span class=type>ChatPromptTemplate</span>.from_template(template=prompt_template)</span><br><span class=line>    chain = <span class=type>LLMChain</span>(llm=llm, prompt=prompt)</span><br><span class=line>    destination_chains[name] = chain  </span><br><span class=line>    </span><br><span class=line>destinations = [f<span class=comment>"{p['name']}: {p['description']}"</span> for p in prompt_infos]</span><br><span class=line>destinations_str = <span class=comment>"\n"</span>.join(destinations)</span><br><span class=line>default_prompt = <span class=type>ChatPromptTemplate</span>.from_template(<span class=comment>"{input}"</span>)</span><br><span class=line>default_chain = <span class=type>LLMChain</span>(llm=llm, prompt=default_prompt)</span><br><span class=line><span class=type>MULTI_PROMPT_ROUTER_TEMPLATE</span> = <span class=comment>""</span><span class=comment>"Given a raw text input to a \</span></span><br><span class=line><span class=comment>language model select the model prompt best suited for the input. \</span></span><br><span class=line><span class=comment>You will be given the names of the available prompts and a \</span></span><br><span class=line><span class=comment>description of what the prompt is best suited for. \</span></span><br><span class=line><span class=comment>You may also revise the original input if you think that revising\</span></span><br><span class=line><span class=comment>it will ultimately lead to a better response from the language model.</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment><< FORMATTING >></span></span><br><span class=line><span class=comment>Return a markdown code snippet with a JSON object formatted to look like:</span></span><br><span class=line><span class=comment>```json</span></span><br><span class=line><span class=comment>{{{{</span></span><br><span class=line><span class=comment>    "</span>destination<span class=comment>": string \ name of the prompt to use or "</span><span class=type>DEFAULT</span><span class=comment>"</span></span><br><span class=line><span class=comment>    "</span>next_inputs<span class=comment>": string \ a potentially modified version of the original input</span></span><br><span class=line><span class=comment>}}}}</span></span><br><span class=line><span class=comment>```</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment>REMEMBER: "</span>destination<span class=comment>" MUST be one of the candidate prompt \</span></span><br><span class=line><span class=comment>names specified below OR it can be "</span><span class=type>DEFAULT</span><span class=comment>" if the input is not\</span></span><br><span class=line><span class=comment>well suited for any of the candidate prompts.</span></span><br><span class=line><span class=comment>REMEMBER: "</span>next_inputs<span class=comment>" can just be the original input \</span></span><br><span class=line><span class=comment>if you don't think any modifications are needed.</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment><< CANDIDATE PROMPTS >></span></span><br><span class=line><span class=comment>{destinations}</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment><< INPUT >></span></span><br><span class=line><span class=comment>{{input}}</span></span><br><span class=line><span class=comment></span></span><br><span class=line><span class=comment><< OUTPUT (remember to include the ```json)>>"</span><span class=comment>""</span></span><br><span class=line>router_template = <span class=type>MULTI_PROMPT_ROUTER_TEMPLATE</span>.format(</span><br><span class=line>    destinations=destinations_str</span><br><span class=line>)</span><br><span class=line>router_prompt = <span class=type>PromptTemplate</span>(</span><br><span class=line>    template=router_template,</span><br><span class=line>    input_variables=[<span class=comment>"input"</span>],</span><br><span class=line>    output_parser=<span class=type>RouterOutputParser</span>(),</span><br><span class=line>)</span><br><span class=line></span><br><span class=line>router_chain = <span class=type>LLMRouterChain</span>.from_llm(llm, router_prompt)</span><br><span class=line>chain = <span class=type>MultiPromptChain</span>(router_chain=router_chain, </span><br><span class=line>                         destination_chains=destination_chains, </span><br><span class=line>                         default_chain=default_chain, verbose=<span class=type>True</span></span><br><span class=line>                        )</span><br></pre></table></figure><p>LLMRouterChain也被RunnableLambda替换了<p>接着是通过上传个人文件进行RAG,这里使用了<code>VectorstoreIndexCreator</code>，<code>DocArrayInMemorySearch</code>以及RetrievalQA. 目前更常用的是<code>FAISS</code><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.chains <span class=keyword>import</span> RetrievalQA</span><br><span class=line><span class=keyword>from</span> langchain.chat_models <span class=keyword>import</span> ChatOpenAI</span><br><span class=line><span class=keyword>from</span> langchain.document_loaders <span class=keyword>import</span> CSVLoader</span><br><span class=line><span class=keyword>from</span> langchain.vectorstores <span class=keyword>import</span> DocArrayInMemorySearch</span><br><span class=line><span class=keyword>from</span> IPython.display <span class=keyword>import</span> display, Markdown</span><br><span class=line><span class=keyword>from</span> langchain.llms <span class=keyword>import</span> OpenAI</span><br><span class=line><span class=keyword>from</span> langchain.indexes <span class=keyword>import</span> VectorstoreIndexCreator</span><br><span class=line></span><br><span class=line>file = <span class=string>'OutdoorClothingCatalog_1000.csv'</span></span><br><span class=line>loader = CSVLoader(file_path=file)</span><br><span class=line>index = VectorstoreIndexCreator(</span><br><span class=line>    vectorstore_cls=DocArrayInMemorySearch <span class=comment># 在文档中搜索</span></span><br><span class=line>).from_loaders([loader])</span><br><span class=line>query =<span class=string>"Please list all your shirts with sun protection \</span></span><br><span class=line><span class=string>in a table in markdown and summarize each one."</span></span><br><span class=line>llm_replacement_model = OpenAI(temperature=<span class=number>0</span>, </span><br><span class=line>                               model=<span class=string>'gpt-3.5-turbo-instruct'</span>)</span><br><span class=line></span><br><span class=line>response = index.query(query, </span><br><span class=line>                       llm = llm_replacement_model)</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.embeddings <span class=keyword>import</span> OpenAIEmbeddings</span><br><span class=line>embeddings = OpenAIEmbeddings()</span><br><span class=line>embed = embeddings.embed_query(<span class=string>"Hi my name is Harrison"</span>)</span><br><span class=line>db = DocArrayInMemorySearch.from_documents(</span><br><span class=line>    docs, </span><br><span class=line>    embeddings</span><br><span class=line>)</span><br><span class=line>query = <span class=string>"Please suggest a shirt with sunblocking"</span></span><br><span class=line>docs = db.similarity_search(query)</span><br><span class=line>retriever = db.as_retriever()</span><br><span class=line>llm = ChatOpenAI(temperature = <span class=number>0.0</span>, model=llm_model)</span><br><span class=line>qdocs = <span class=string>""</span>.join([docs[i].page_content <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(<span class=built_in>len</span>(docs))])</span><br><span class=line>response = llm.call_as_llm(<span class=string>f"<span class=subst>{qdocs}</span> Question: Please list all your \</span></span><br><span class=line><span class=string>shirts with sun protection in a table in markdown and summarize each one."</span>) </span><br><span class=line>qa_stuff = RetrievalQA.from_chain_type(</span><br><span class=line>    llm=llm, </span><br><span class=line>    chain_type=<span class=string>"stuff"</span>, </span><br><span class=line>    retriever=retriever, </span><br><span class=line>    verbose=<span class=literal>True</span></span><br><span class=line>)</span><br><span class=line>query =  <span class=string>"Please list all your shirts with sun protection in a table \</span></span><br><span class=line><span class=string>in markdown and summarize each one."</span></span><br><span class=line>response = qa_stuff.run(query)</span><br></pre></table></figure><p>可以使用<code>QAGenerateChain</code>让llm生成对给定数据的询问和问答对<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.evaluation.qa <span class=keyword>import</span> QAGenerateChain</span><br><span class=line>example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))</span><br><span class=line>new_examples = example_gen_chain.apply_and_parse(</span><br><span class=line>    [{<span class=string>"doc"</span>: t} <span class=keyword>for</span> t <span class=keyword>in</span> data[:<span class=number>5</span>]]</span><br><span class=line>)</span><br></pre></table></figure><p>Evaluation和Debug Langchain应用,分为直接debug和让LLM通过输入和输出进行判断回答如何<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br></pre><td class=code><pre><span class=line><span class=comment># manual </span></span><br><span class=line><span class=keyword>import</span> langchain</span><br><span class=line>langchain.debug = <span class=literal>True</span></span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=comment># LLM assisted evaluation</span></span><br><span class=line><span class=keyword>from</span> langchain.evaluation.qa <span class=keyword>import</span> QAEvalChain</span><br><span class=line>llm = ChatOpenAI(temperature=<span class=number>0</span>, model=llm_model)</span><br><span class=line>eval_chain = QAEvalChain.from_llm(llm)</span><br><span class=line>graded_outputs = eval_chain.evaluate(examples, predictions)</span><br><span class=line><span class=keyword>for</span> i, eg <span class=keyword>in</span> <span class=built_in>enumerate</span>(examples):</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>f"Example <span class=subst>{i}</span>:"</span>)</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>"Question: "</span> + predictions[i][<span class=string>'query'</span>])</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>"Real Answer: "</span> + predictions[i][<span class=string>'answer'</span>])</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>"Predicted Answer: "</span> + predictions[i][<span class=string>'result'</span>])</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>"Predicted Grade: "</span> + graded_outputs[i][<span class=string>'text'</span>])</span><br></pre></table></figure><p>最后一个部分是关于Agent的,这也是目前AI应用比较火的一部分. 主要通过tool给llm提供额外功能.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langchain.agents.agent_toolkits <span class=keyword>import</span> create_python_agent</span><br><span class=line><span class=keyword>from</span> langchain.agents <span class=keyword>import</span> load_tools, initialize_agent</span><br><span class=line><span class=keyword>from</span> langchain.agents <span class=keyword>import</span> AgentType</span><br><span class=line><span class=keyword>from</span> langchain.tools.python.tool <span class=keyword>import</span> PythonREPLTool</span><br><span class=line><span class=keyword>from</span> langchain.python <span class=keyword>import</span> PythonREPL</span><br><span class=line><span class=keyword>from</span> langchain.chat_models <span class=keyword>import</span> ChatOpenAI</span><br><span class=line></span><br><span class=line>llm = ChatOpenAI(temperature=<span class=number>0</span>, model=llm_model)</span><br><span class=line>tools = load_tools([<span class=string>"llm-math"</span>,<span class=string>"wikipedia"</span>], llm=llm)</span><br><span class=line>agent= initialize_agent(</span><br><span class=line>    tools, </span><br><span class=line>    llm, </span><br><span class=line>    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,</span><br><span class=line>    handle_parsing_errors=<span class=literal>True</span>,</span><br><span class=line>    verbose = <span class=literal>True</span>)</span><br><span class=line>question = <span class=string>"Tom M. Mitchell is an American computer scientist \</span></span><br><span class=line><span class=string>and the Founders University Professor at Carnegie Mellon University (CMU)\</span></span><br><span class=line><span class=string>what book did he write?"</span></span><br><span class=line>result = agent(question)</span><br><span class=line><span class=keyword>from</span> langchain.agents <span class=keyword>import</span> tool</span><br><span class=line><span class=keyword>from</span> datetime <span class=keyword>import</span> date</span><br><span class=line><span class=meta>@tool</span></span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>time</span>(<span class=params>text: <span class=built_in>str</span></span>) -> <span class=built_in>str</span>:</span></span><br><span class=line>    <span class=string>"""Returns todays date, use this for any \</span></span><br><span class=line><span class=string>    questions related to knowing todays date. \</span></span><br><span class=line><span class=string>    The input should always be an empty string, \</span></span><br><span class=line><span class=string>    and this function will always return todays \</span></span><br><span class=line><span class=string>    date - any date mathmatics should occur \</span></span><br><span class=line><span class=string>    outside this function."""</span></span><br><span class=line>    <span class=keyword>return</span> <span class=built_in>str</span>(date.today())</span><br><span class=line>agent= initialize_agent(</span><br><span class=line>    tools + [time], </span><br><span class=line>    llm, </span><br><span class=line>    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,</span><br><span class=line>    handle_parsing_errors=<span class=literal>True</span>,</span><br><span class=line>    verbose = <span class=literal>True</span>)</span><br></pre></table></figure><p>可以使用一些搜索工具以及类似python解释器等,也可以定义自己的工具,这方面huggingface的transformers库也做得很不错.<h3 id=LLMs-as-Operating-Systems-Agent-Memory><a title="LLMs as Operating Systems:Agent Memory" class=headerlink href=#LLMs-as-Operating-Systems-Agent-Memory></a>LLMs as Operating Systems:Agent Memory</h3><p>第一节利用OpenAI的接口调用function call,使得更新时让llm调用函数获得数<p>据,这个数据就是新的memory,下次对话就会利用新的memory. 直到不再调用tool,也就是不更新了<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>agent_step</span>(<span class=params>user_message</span>):</span> </span><br><span class=line>    </span><br><span class=line>    <span class=comment># prefix messages with system prompt and memory</span></span><br><span class=line>    messages = [</span><br><span class=line>        <span class=comment># system prompt </span></span><br><span class=line>        {<span class=string>"role"</span>: <span class=string>"system"</span>, <span class=string>"content"</span>: system_prompt_os}, </span><br><span class=line>        <span class=comment># memory</span></span><br><span class=line>        {</span><br><span class=line>            <span class=string>"role"</span>: <span class=string>"system"</span>, </span><br><span class=line>            <span class=string>"content"</span>: <span class=string>"[MEMORY]\n"</span> + json.dumps(agent_memory)</span><br><span class=line>        },</span><br><span class=line>    ]    </span><br><span class=line></span><br><span class=line>    <span class=comment># append the most recent message</span></span><br><span class=line>    messages.append({<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: user_message})</span><br><span class=line>    </span><br><span class=line>    <span class=comment># agentic loop </span></span><br><span class=line>    <span class=keyword>while</span> <span class=literal>True</span>: </span><br><span class=line>        chat_completion = client.chat.completions.create(</span><br><span class=line>            model=model,</span><br><span class=line>            messages=messages,</span><br><span class=line>            tools=[core_memory_save_metadata]</span><br><span class=line>        )</span><br><span class=line>        response = chat_completion.choices[<span class=number>0</span>]</span><br><span class=line></span><br><span class=line>        <span class=comment># update the messages with the agent's response </span></span><br><span class=line>        messages.append(response.message)</span><br><span class=line>        </span><br><span class=line>        <span class=comment># if NOT calling a tool (responding to the user), return </span></span><br><span class=line>        <span class=keyword>if</span> <span class=keyword>not</span> response.message.tool_calls: </span><br><span class=line>            <span class=keyword>return</span> response.message.content</span><br><span class=line></span><br><span class=line>        <span class=comment># if calling a tool, execute the tool</span></span><br><span class=line>        <span class=keyword>else</span>: </span><br><span class=line>            <span class=built_in>print</span>(<span class=string>"TOOL CALL:"</span>, response.message.tool_calls[<span class=number>0</span>].function)</span><br><span class=line>            </span><br><span class=line>            <span class=comment># parse the arguments from the LLM function call</span></span><br><span class=line>            arguments = json.loads(</span><br><span class=line>                response.message.tool_calls[<span class=number>0</span>].function.arguments</span><br><span class=line>            )</span><br><span class=line></span><br><span class=line>            <span class=comment># run the function with the specified arguments</span></span><br><span class=line>            core_memory_save(**arguments)</span><br><span class=line></span><br><span class=line>            <span class=comment># add the tool call response to the message history </span></span><br><span class=line>            messages.append({</span><br><span class=line>                <span class=string>"role"</span>: <span class=string>"tool"</span>, </span><br><span class=line>                <span class=string>"tool_call_id"</span>: response.message.tool_calls[<span class=number>0</span>].<span class=built_in>id</span>, </span><br><span class=line>                <span class=string>"name"</span>: <span class=string>"core_memory_save"</span>, </span><br><span class=line>                <span class=string>"content"</span>: <span class=string>f"Updated memory: <span class=subst>{json.dumps(agent_memory)}</span>"</span></span><br><span class=line>            })</span><br><span class=line>agent_step(<span class=string>"my name is bob."</span>)</span><br></pre></table></figure><h3 id=AI-Agents-in-LangGraph><a title="AI Agents in LangGraph" class=headerlink href=#AI-Agents-in-LangGraph></a>AI Agents in LangGraph</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>Agent</span>:</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,system=<span class=string>""</span></span>):</span></span><br><span class=line>        self.system = system</span><br><span class=line>        self.messages = []</span><br><span class=line>        <span class=keyword>if</span> self.system:</span><br><span class=line>            self.message.append({<span class=string>"role"</span>:<span class=string>"system"</span>,<span class=string>"content"</span>:system})</span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__call__</span>(<span class=params>self,messages</span>):</span></span><br><span class=line>        self.messages.append({<span class=string>"role"</span>:<span class=string>"user"</span>,<span class=string>"content"</span>:message})</span><br><span class=line>        result = self.execute()</span><br><span class=line>        self.messages.append({<span class=string>"role"</span>:<span class=string>"assistant"</span>,<span class=string>"content"</span>:result})</span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>execute</span>(<span class=params>self</span>):</span></span><br><span class=line>        completion = client.chat.completions.create(</span><br><span class=line>                        model=<span class=string>"gpt-4o"</span>,</span><br><span class=line>            temperature=<span class=number>0</span>,</span><br><span class=line>            messages=self.messages</span><br><span class=line>        )</span><br><span class=line>        <span class=keyword>return</span> completion.choices[<span class=number>0</span>].message.content</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>calculate</span>(<span class=params>what</span>):</span></span><br><span class=line>    <span class=keyword>return</span> <span class=built_in>eval</span>(what)</span><br><span class=line></span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>average_dog_weight</span>(<span class=params>name</span>):</span></span><br><span class=line>    <span class=keyword>if</span> name <span class=keyword>in</span> <span class=string>"Scottish Terrier"</span>: </span><br><span class=line>        <span class=keyword>return</span>(<span class=string>"Scottish Terriers average 20 lbs"</span>)</span><br><span class=line>    <span class=keyword>elif</span> name <span class=keyword>in</span> <span class=string>"Border Collie"</span>:</span><br><span class=line>        <span class=keyword>return</span>(<span class=string>"a Border Collies average weight is 37 lbs"</span>)</span><br><span class=line>    <span class=keyword>elif</span> name <span class=keyword>in</span> <span class=string>"Toy Poodle"</span>:</span><br><span class=line>        <span class=keyword>return</span>(<span class=string>"a toy poodles average weight is 7 lbs"</span>)</span><br><span class=line>    <span class=keyword>else</span>:</span><br><span class=line>        <span class=keyword>return</span>(<span class=string>"An average dog weights 50 lbs"</span>)</span><br><span class=line></span><br><span class=line>known_actions = {</span><br><span class=line>    <span class=string>"calculate"</span>: calculate,</span><br><span class=line>    <span class=string>"average_dog_weight"</span>: average_dog_weight</span><br><span class=line>}</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br></pre><td class=code><pre><span class=line>prompt = <span class=string>"""</span></span><br><span class=line><span class=string>You run in a loop of Thought, Action, PAUSE, Observation.</span></span><br><span class=line><span class=string>At the end of the loop you output an Answer</span></span><br><span class=line><span class=string>Use Thought to describe your thoughts about the question you have been asked.</span></span><br><span class=line><span class=string>Use Action to run one of the actions available to you - then return PAUSE.</span></span><br><span class=line><span class=string>Observation will be the result of running those actions.</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Your available actions are:</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>calculate:</span></span><br><span class=line><span class=string>e.g. calculate: 4 * 7 / 3</span></span><br><span class=line><span class=string>Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>average_dog_weight:</span></span><br><span class=line><span class=string>e.g. average_dog_weight: Collie</span></span><br><span class=line><span class=string>returns average weight of a dog when given the breed</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Example session:</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Question: How much does a Bulldog weigh?</span></span><br><span class=line><span class=string>Thought: I should look the dogs weight using average_dog_weight</span></span><br><span class=line><span class=string>Action: average_dog_weight: Bulldog</span></span><br><span class=line><span class=string>PAUSE</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>You will be called again with this:</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Observation: A Bulldog weights 51 lbs</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>You then output:</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>Answer: A bulldog weights 51 lbs</span></span><br><span class=line><span class=string>"""</span>.strip()</span><br><span class=line>abot = Agent(prompt)</span><br></pre></table></figure><p>可以使用<a href=https://smith.langchain.com/hub rel=noopener target=_blank>Hub - LangSmith</a>加载prompt等数据. 这个课程主要讲了langgraph中节点和agent<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> langgraph.graph <span class=keyword>import</span> StateGraph, END</span><br><span class=line><span class=keyword>from</span> typing <span class=keyword>import</span> TypedDict, Annotated</span><br><span class=line><span class=keyword>import</span> operator</span><br><span class=line><span class=keyword>from</span> langgraph.checkpoint.sqlite <span class=keyword>import</span> SqliteSaver</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>AgentState</span>(<span class=params>TypedDict</span>):</span></span><br><span class=line>    lnode: <span class=built_in>str</span></span><br><span class=line>    scratch: <span class=built_in>str</span></span><br><span class=line>    count: Annotated[<span class=built_in>int</span>, operator.add]</span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>node1</span>(<span class=params>state: AgentState</span>):</span></span><br><span class=line>    <span class=built_in>print</span>(<span class=string>f"node1, count:<span class=subst>{state[<span class=string>'count'</span>]}</span>"</span>)</span><br><span class=line>    <span class=keyword>return</span> {<span class=string>"lnode"</span>: <span class=string>"node_1"</span>,</span><br><span class=line>            <span class=string>"count"</span>: <span class=number>1</span>,</span><br><span class=line>           }</span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>node2</span>(<span class=params>state: AgentState</span>):</span></span><br><span class=line>    <span class=built_in>print</span>(<span class=string>f"node2, count:<span class=subst>{state[<span class=string>'count'</span>]}</span>"</span>)</span><br><span class=line>    <span class=keyword>return</span> {<span class=string>"lnode"</span>: <span class=string>"node_2"</span>,</span><br><span class=line>            <span class=string>"count"</span>: <span class=number>1</span>,</span><br><span class=line>           }</span><br><span class=line><span class=function><span class=keyword>def</span> <span class=title>should_continue</span>(<span class=params>state</span>):</span></span><br><span class=line>    <span class=keyword>return</span> state[<span class=string>"count"</span>] < <span class=number>3</span></span><br><span class=line></span><br><span class=line></span><br><span class=line>builder = StateGraph(AgentState)</span><br><span class=line>builder.add_node(<span class=string>"Node1"</span>, node1)</span><br><span class=line>builder.add_node(<span class=string>"Node2"</span>, node2)</span><br><span class=line></span><br><span class=line>builder.add_edge(<span class=string>"Node1"</span>, <span class=string>"Node2"</span>)</span><br><span class=line>builder.add_conditional_edges(<span class=string>"Node2"</span>, </span><br><span class=line>                              should_continue, </span><br><span class=line>                              {<span class=literal>True</span>: <span class=string>"Node1"</span>, <span class=literal>False</span>: END})</span><br><span class=line>builder.set_entry_point(<span class=string>"Node1"</span>)</span><br><span class=line></span><br><span class=line>memory = SqliteSaver.from_conn_string(<span class=string>":memory:"</span>)</span><br><span class=line>graph = builder.<span class=built_in>compile</span>(checkpointer=memory)</span><br><span class=line>thread = {<span class=string>"configurable"</span>: {<span class=string>"thread_id"</span>: <span class=built_in>str</span>(<span class=number>1</span>)}}</span><br><span class=line>graph.invoke({<span class=string>"count"</span>:<span class=number>0</span>, <span class=string>"scratch"</span>:<span class=string>"hi"</span>},thread) <span class=comment># 调用时需要传入数据,对应agentstate和config配置,包括thread_id提供修改和访问state的机制</span></span><br></pre></table></figure><h2 id=Building-toward-computer-Use-with-Anthropic><a title="Building toward computer Use with Anthropic" class=headerlink href=#Building-toward-computer-Use-with-Anthropic></a>Building toward computer Use with Anthropic</h2><p>Anthropic推出的应用,结合计算机操作系统使用,称之为computer using agent. 从技术上,这主要使用agent与其他工具(包括操作系统上的文件操作以及搜索引擎等)<p><img alt=image-20250208235505095 data-src=https://s2.loli.net/2025/02/08/KZwtVTnY1rqsI7J.png></p><link href=/css/spoiler.css rel=stylesheet><script async src=/js/spoiler.js></script></div><div><div><div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div class=reward-container><div>感谢阅读.</div><button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">打赏</button><div style="display: none;" id=qr><div style="display: inline-block;"><img alt="Sekyoro 微信支付" src=/images/wechatpay.png><p>微信支付</div></div></div><div><ul class=post-copyright><li class=post-copyright-author><strong>本文作者： </strong>Sekyoro<li class=post-copyright-link><strong>本文链接：</strong> <a href=https://www.sekyoro.top/2023/12/24/dpsc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/ title=dpsc:深度学习短课程学习>https://www.sekyoro.top/2023/12/24/dpsc-深度学习短课程学习/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ rel=noopener target=_blank><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</ul></div><div class=followme><p>欢迎关注我的其它发布渠道<div class=social-list><div class=social-item><a class=social-link href=/images/wxqrcode.png target=_blank> <span class=icon> <i class="fab fa-weixin"></i> </span> <span class=label>WeChat</span> </a></div><div class=social-item><a class=social-link href=/images/website.png target=_blank> <span class=icon> <i class="fa fa-user"></i> </span> <span class=label>PersonalWebsite</span> </a></div><div class=social-item><a class=social-link href=https://my-astro-git-main-drowning-in-codes.vercel.app target=_blank> <span class=icon> <i class="fas fa-share"></i> </span> <span class=label>杂鱼分享</span> </a></div><div class=social-item><a class=social-link href=/atom.xml target=_blank> <span class=icon> <i class="fa fa-rss"></i> </span> <span class=label>RSS</span> </a></div></div></div><footer class=post-footer><div class=post-nav><div class=post-nav-item><a href=/2023/12/24/Github-bot%E5%88%9B%E5%BB%BA/ rel=prev title=Github_bot创建> <i class="fa fa-chevron-left"></i> Github_bot创建 </a></div><div class=post-nav-item><a href=/2023/12/25/gradio%E5%AD%A6%E4%B9%A0/ rel=next title=gradio学习> gradio学习 <i class="fa fa-chevron-right"></i> </a></div></div></footer></article></div><!-- 评论区 --><div class=comments><div data-id=city data-uid=MTAyMC81MzE5Ny8yOTY3Mg== id=lv-container></div></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class=sidebar><div class=sidebar-inner><!-- canvas粒子时钟 --><div><canvas id=canvas style=width:60%;>当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();</script><!-- require APlayer --><link href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><!-- require MetingJS --><script src=/js/meting-js.js></script><ul class="sidebar-nav motion-element"><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class=nav><li class="nav-item nav-level-3"><a class=nav-link href=#Reinforcement-Learning-from-Human-Feedback><span class=nav-number>1.</span> <span class=nav-text>Reinforcement Learning from Human Feedback</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Evaluating-and-Debugging-Generative-AI-Models-Using-Weights-and-Biases><span class=nav-number>2.</span> <span class=nav-text>Evaluating and Debugging Generative AI Models Using Weights and Biases</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#wandb-Table><span class=nav-number>2.1.</span> <span class=nav-text>wandb Table</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%BD%BF%E7%94%A8W-amp-B-sweep%E8%BF%9B%E8%A1%8C%E8%B6%85%E5%8F%82%E6%90%9C%E7%B4%A2%E8%B0%83%E6%95%B4><span class=nav-number>3.</span> <span class=nav-text>使用W&B sweep进行超参搜索调整</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#How-Diffusion-Models-Work><span class=nav-number>4.</span> <span class=nav-text>How Diffusion Models Work</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#control-and-speed-up><span class=nav-number>5.</span> <span class=nav-text>control and speed up</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#ChatGPT-Prompt-Engineering-for-Developers><span class=nav-number>6.</span> <span class=nav-text>ChatGPT Prompt Engineering for Developers</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Finetuning-Large-Language-Models><span class=nav-number>7.</span> <span class=nav-text>Finetuning Large Language Models</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Opensource-models-with-huggingface><span class=nav-number>8.</span> <span class=nav-text>Opensource models with huggingface</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Getting-started-with-Mistral><span class=nav-number>9.</span> <span class=nav-text>Getting started with Mistral</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Prompt-Engineering-for-Vision-Models><span class=nav-number>10.</span> <span class=nav-text>Prompt Engineering for Vision Models</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Building-an-AI-Powered-Game><span class=nav-number>11.</span> <span class=nav-text>Building an AI-Powered Game</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#LangChain-for-LLM-Application-Development><span class=nav-number>12.</span> <span class=nav-text>LangChain for LLM Application Development</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#LLMs-as-Operating-Systems-Agent-Memory><span class=nav-number>13.</span> <span class=nav-text>LLMs as Operating Systems:Agent Memory</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#AI-Agents-in-LangGraph><span class=nav-number>14.</span> <span class=nav-text>AI Agents in LangGraph</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#Building-toward-computer-Use-with-Anthropic><span class=nav-number></span> <span class=nav-text>Building toward computer Use with Anthropic</span></a></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=Sekyoro class=site-author-image itemprop=image src=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg><p class=site-author-name itemprop=name>Sekyoro<div class=site-description itemprop=description>什么也无法舍弃的人，什么也做不了.</div></div><div class="site-state-wrap motion-element"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>236</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>16</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>211</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a title="Personal Website → http://proanimer.com" href=http://proanimer.com/ rel=noopener target=_blank><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a> </span><span class=links-of-author-item> <a title="GitHub → https://github.com/drowning-in-codes" href=https://github.com/drowning-in-codes rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a title="E-Mail → mailto:bukalala174@gmail.com" href=mailto:bukalala174@gmail.com rel=noopener target=_blank><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class=links-of-author-item> <a title="wxPublicAccount → https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" href=https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd rel=noopener target=_blank><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a> </span><span class=links-of-author-item> <a title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span><span class=links-of-author-item> <a title="CSDN → https://blog.csdn.net/aqwca" href=https://blog.csdn.net/aqwca rel=noopener target=_blank><i class="fa fa-handshake fa-fw"></i>CSDN</a> </span><span class=links-of-author-item> <a title="杂鱼分享 → https://my-astro-git-main-drowning-in-codes.vercel.app" href=https://my-astro-git-main-drowning-in-codes.vercel.app/ rel=noopener target=_blank><i class="fas fa-share fa-fw"></i>杂鱼分享</a> </span></div><div class="links-of-blogroll motion-element"><div class=links-of-blogroll-title><i class="fa fa-link fa-fw"></i> 友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=http://myqhs.top/ rel=noopener target=_blank title=http://myqhs.top/>myqhs</a><li class=links-of-blogroll-item><a href=https://www.lllomh.com/ rel=noopener target=_blank title=https://www.lllomh.com/>芈渡</a><li class=links-of-blogroll-item><a href=https://protool-ten.vercel.app/ rel=noopener target=_blank title=https://protool-ten.vercel.app/>protools</a></ul></div><div class="motion-element announcement"><div class=title></div><p class=content><p class=date></div></div><meting-js id=6856787487 order=random server=netease type=playlist> </meting-js><div class=widget-wrap><h3 class=widget-title style=margin:0>此文章目前无词云</h3></div><script id=clustrmaps src=https://clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a></script><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i><span>0%</span></div><!-- 边栏 --></div></aside><div id=sidebar-dimmer></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Sekyoro</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-chart-area"></i> </span><span title=站点总字数>2.4m</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span><span title=站点阅读时长>36:57</span></div><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container_site_pv>总访问量<span id=busuanzi_value_site_pv></span>次</span><span class=post-meta-divider>|</span><span id=busuanzi_container_site_uv>总访客数<span id=busuanzi_value_site_uv></span>人</span><span class=post-meta-divider>|</span><!-- 不蒜子计数初始值纠正 --><script>$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});</script><div><span id=timeDate>载入天数...</span><span id=times>载入时分秒...</span><script>var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);</script></div><div class=busuanzi-count><script async data-pjax src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span style="display: none;" class=post-meta-item id=busuanzi_container_site_uv> <span class=post-meta-item-icon> <i class="fa fa-user"></i> </span> <span class=site-uv title=总访客量> <span id=busuanzi_value_site_uv></span> </span> </span><span class=post-meta-divider>|</span><span style="display: none;" class=post-meta-item id=busuanzi_container_site_pv> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=site-pv title=总访问量> <span id=busuanzi_value_site_pv></span> </span> </span></div></div></footer></div><script color=0,0,255 count=99 opacity=0.5 src=/lib/canvas-nest/canvas-nest.min.js zindex=-1></script><script src=/lib/anime.min.js></script><script src=https://cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js></script><script src=https://cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/schemes/pisces.js></script><script src=/js/next-boot.js></script><script src=/js/bookmark.js></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	'.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});</script><script data-pjax>(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();</script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js></script><script src=/js/algolia-search.js></script><script data-pjax>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><div id=pjax><script charset=utf-8 defer src=/js/outdate.js></script></div><script charset=utf-8 defer src=/js/tagcanvas.js></script><script charset=utf-8 defer src=/js/tagcloud.js></script><script>NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});</script><script>var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });</script><script src=/js/src/activate-power-mode.min.js></script><script>POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);</script>