<!doctypehtml><html lang=zh-CN><script defer src=/live2d-widget/autoload.js></script><meta charset=UTF-8><meta content=width=device-width,initial-scale=1,maximum-scale=2 name=viewport><meta content=#222 name=theme-color><meta content="Hexo 5.4.0" name=generator><link href=/images/blog_32px.png rel=apple-touch-icon sizes=180x180><link href=/images/blog_32px.png rel=icon sizes=32x32 type=image/png><link href=/images/blog_16px.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><meta content=EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w name=google-site-verification><!-- Google tag (gtag.js) --><!-- 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script> --><!-- google adsense in head.swig --><script async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123></script><meta content=7226864CE87CE9DE8C008385273846FF name=msvalidate.01><meta content=code-fjFXVtiL7j name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link as=style href=https://fonts.googleapis.com/css?family=Roboto%20Mono,Roboto:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext onload=this.rel='stylesheet' rel=preload><link as=style href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css onload=this.rel='stylesheet' rel=preload><link href=https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap rel=stylesheet><link href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/pace-js@1/pace.min.js></script><script id=hexo-configurations>var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"3G9PZZIKCH","apiKey":"8eb71f5ca3167e9ef3487882f10cfaad","indexName":"SekyoroSearch","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};</script><link href=//cdn.bootcss.com/animate.css/3.5.0/animate.min.css rel=stylesheet><meta content=这种encoder-decoder结构很重要,同时也可以作为学习GAN的前置 name=description><meta content=article property=og:type><meta content=Autoencoder学习 property=og:title><meta content=https://www.sekyoro.top/2023/09/01/Autoencoder%E5%AD%A6%E4%B9%A0/index.html property=og:url><meta content=Sekyoro的博客小屋 property=og:site_name><meta content=这种encoder-decoder结构很重要,同时也可以作为学习GAN的前置 property=og:description><meta content=zh_CN property=og:locale><meta content=https://s2.loli.net/2023/08/31/ABn4DgqX7xWGI6y.png property=og:image><meta content=https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/09-Autoencoders/images/vae.png property=og:image><meta content=https://s2.loli.net/2023/09/03/HURDP5TfoBuVjyC.png property=og:image><meta content=https://s2.loli.net/2023/09/03/mbhaVXe7jrO63D8.png property=og:image><meta content=https://s2.loli.net/2023/09/04/dcLtUFBSzg41rVl.png property=og:image><meta content=https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/aae_super.png property=og:image><meta content=https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/dis_2.png property=og:image><meta content=https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/aae_semi.png property=og:image><meta content=https://cdn.sekyoro.top/imgs/image-20230907105548807.png property=og:image><meta content=https://s2.loli.net/2023/09/04/HCPMwute1Z2LBV7.png property=og:image><meta content=2023-09-01T12:28:30.000Z property=article:published_time><meta content=2023-09-07T07:22:29.266Z property=article:modified_time><meta content=Sekyoro property=article:author><meta content=VAE property=article:tag><meta content=autoencoder property=article:tag><meta content=summary name=twitter:card><meta content=https://s2.loli.net/2023/08/31/ABn4DgqX7xWGI6y.png name=twitter:image><link href=https://www.sekyoro.top/2023/09/01/Autoencoder%E5%AD%A6%E4%B9%A0/ rel=canonical><script id=page-configurations>// https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };</script><title>Autoencoder学习 | Sekyoro的博客小屋</title><noscript><style>.use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }</style></noscript><link href=/atom.xml rel=alternate title=Sekyoro的博客小屋 type=application/atom+xml><body itemscope itemtype=http://schema.org/WebPage><canvas style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" class=fireworks></canvas><script defer src=https://cdn.bootcss.com/animejs/2.2.0/anime.min.js></script><script defer src=/js/src/fireworks.js></script><div class="container use-motion"><div class=headband></div><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <h1 class=site-title>Sekyoro的博客小屋</h1> <span class=logo-line-after><i></i></span> </a></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu" id=menu><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-bangumis"><a href=/bangumis/ rel=section><i class="fa fa-film fa-fw"></i>追番</a><li class="menu-item menu-item-resume"><a href=/resume/ rel=section><i class="fa fa-file-pdf fa-fw"></i>简历</a><li class="menu-item menu-item-materials"><a href=/materials/ rel=section><i class="fa fa-book fa-fw"></i>学习资料</a><li class="menu-item menu-item-sitemap"><a href=/sitemap.xml rel=section><i class="fa fa-sitemap fa-fw"></i>站点地图</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container></div><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span></div><div class=algolia-results><div id=algolia-stats></div><div id=algolia-hits></div><div class=algolia-pagination id=algolia-pagination></div></div></div></div></div></header><a class="book-mark-link book-mark-link-fixed" role=button></a><main class=main><div class=main-inner><div class=content-wrap><div class="content post posts-expand"><article class=post-block itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://www.sekyoro.top/2023/09/01/Autoencoder%E5%AD%A6%E4%B9%A0/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg itemprop=image> <meta content=Sekyoro itemprop=name> <meta content=什么也无法舍弃的人，什么也做不了. itemprop=description> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=Sekyoro的博客小屋 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>Autoencoder学习</h1><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2023-09-01 20:28:30" datetime=2023-09-01T20:28:30+08:00>2023-09-01</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2023-09-07 15:22:29" datetime=2023-09-07T15:22:29+08:00 itemprop=dateModified>2023-09-07</time> </span><span style="display: none;" class=post-meta-item id=busuanzi_container_page_pv title=阅读次数> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=post-meta-item-text>阅读次数：</span> <span id=busuanzi_value_page_pv></span> </span><br><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>8.8k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>8 分钟</span> </span></div></header><div class=post-body itemprop=articleBody><p>这种encoder-decoder结构很重要,同时也可以作为学习GAN的前置<br><span id=more></span><h2 id=Autoencoders><a class=headerlink href=#Autoencoders title=Autoencoders></a>Autoencoders</h2><p>autoencoders是在深度学习经常听到的词,简单来说是基于latent vector,manifold这种概念上的模型,<blockquote><p>利用输入数据 本身作为监督，来指导神经网络尝试学习一个映射关系，从而得到一个重构输出 。在时间序列异常检测场景下，异常对于正常来说是少数，所以我们认为，如果使用自编码器重构出来的输出跟原始输入的差异超出一定阈值（threshold）的话，原始时间序列即存在了异常。<p>An autoencoder is a type of algorithm with the primary purpose of learning an “informative” representation of the data that can be used for different applicationsa by learning to reconstruct a set of input observations well enough.</blockquote><p>latent feature又可以叫做潜在向量,潜在特征,bottleneck等等,叫法很多,不要听见新的说法发怵.简单来说就是encoder-decoder架构,不过进行自监督,使用损失函数比较输入和输出. 使用,重建误差(Reconsrtuction Error)体现,重建误差（RE）是一个指标，它可以指示自动编码器能够重建输入观测x的好坏。相比于全连接网络和卷积网络,AE并不需要labeled data, 我们可以使用图像同时作为输入和输出.<p><strong>The main idea of autoencoder is that we will have an encoder network that converts input image into some latent space (normally it is just a vector of some smaller size), then the decoder network, whose goal would be to reconstruct the original image</strong><p><img alt data-src=https://s2.loli.net/2023/08/31/ABn4DgqX7xWGI6y.png><p>常用于如下用途<ul><li>降低图像的维度以进行可视化或训练图像嵌入。通常，自动编码器比PCA给出更好的结果，因为它考虑了图像的空间性质和层次特征。<li>去噪，即从图像中去除噪声。由于噪声携带了大量无用的信息，自动编码器无法将其全部放入相对较小的潜在空间，因此只能捕获图像的重要部分。在训练去噪器时，我们从原始图像开始，并使用带有人工添加噪声的图像作为自动编码器的输入。<li>超分辨率，提高图像分辨率。我们从高分辨率图像开始，使用分辨率较低的图像作为自动编码器输入。<li>生成模型。一旦我们训练了自动编码器，解码器部分就可以用来从随机潜在向量开始创建新的对象。</ul><p>缺点是 传统的AE(autoencoders)潜在向量往往没有太多的语义含义,换句话说，以MNIST数据集为例，弄清楚哪些数字对应于不同的潜在向量并不是一项容易的任务，因为接近的潜在向量不一定对应于同一个数字<p>尝试改变潜变量大小,看看效果.<p>尝试看看不同图像的潜变量,增加噪声后再查看效果.<h3 id=AE常用去噪和超分><a class=headerlink href=#AE常用去噪和超分 title=AE常用去噪和超分.></a>AE常用去噪和超分.</h3><p>对于去噪来说,将没有噪声的图片人工加噪,训练时使用噪声图片作为输入,正常无噪图片作为输出.<blockquote><p>To train super-resolution network, we will start with high-resolution images, and automatically downscale them to produce network inputs. We will then feed autoencoder with small images as inputs and high-resolution images as outputs.</blockquote><p>对于超分将宽高缩小的图片作为输入,将正常图作为输出.<p>训练<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre><td class=code><pre><span class=line>model = AutoEncoder().to(device)</span><br><span class=line>optimizer = optim.Adam(model.parameters(), lr=lr, eps=eps)</span><br><span class=line>loss_fn = nn.BCELoss()</span><br><span class=line>noisy_tensor = torch.FloatTensor(noisify([<span class=number>256</span>, <span class=number>1</span>, <span class=number>28</span>, <span class=number>28</span>])).to(device)</span><br><span class=line>test_noisy_tensor = torch.FloatTensor(noisify([<span class=number>1</span>, <span class=number>1</span>, <span class=number>28</span>, <span class=number>28</span>])).to(device)</span><br><span class=line>noisy_tensors = (noisy_tensor, test_noisy_tensor)</span><br><span class=line>train(dataloaders, model, loss_fn, optimizer, <span class=number>100</span>, device, noisy=noisy_tensors)</span><br></pre></table></figure><p>预测<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br></pre><td class=code><pre><span class=line>model.<span class=built_in>eval</span>()</span><br><span class=line>predictions = []</span><br><span class=line>noise = []</span><br><span class=line>plots = <span class=number>5</span></span><br><span class=line><span class=keyword>for</span> i, data <span class=keyword>in</span> <span class=built_in>enumerate</span>(test_dataset):</span><br><span class=line>    <span class=keyword>if</span> i == plots:</span><br><span class=line>        <span class=keyword>break</span></span><br><span class=line>    shapes = data[<span class=number>0</span>].shape</span><br><span class=line>    noisy_data = data[<span class=number>0</span>] + test_noisy_tensor[<span class=number>0</span>].detach().cpu()</span><br><span class=line>    noise.append(noisy_data)</span><br><span class=line>    predictions.append(model(noisy_data.to(device).unsqueeze(<span class=number>0</span>)).detach().cpu())</span><br><span class=line>plotn(plots, noise)</span><br><span class=line>plotn(plots, predictions)</span><br></pre></table></figure><p>对于超分,因为输入变化了,考虑潜变量不变,所以encoder需要做一些变化.<h2 id=VAE><a class=headerlink href=#VAE title=VAE></a>VAE</h2><p>对于图像降维来说影响不大,但要训练生成模型，最好对潜在空间有一些了解。这个想法使我们想到了变分自动编码器(VAE)<p>VAE是一种自动编码器，它学习预测潜在参数的统计分布，即所谓的潜在分布。<p><img style="zoom: 50%;" alt=img data-src=https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/09-Autoencoders/images/vae.png><p>VAE是一种自动编码器，它学习预测潜在参数的统计分布，即所谓的潜在分布。例如，我们可能希望潜在向量正态分布，具有一些均值z~mean~和标准差z~sigma~（均值和标准差都是一些维度d的向量）。VAE中的编码器学习预测这些参数，然后解码器从这个分布中提取一个随机向量来重建对象。<p>相比于AE简单的损失函数,变分自动编码器使用由两部分组成的复杂损失函数：<ul><li>重建损失是显示重建图像离目标有多近的损失函数（它可以是均方误差或MSE）。它与普通自动编码器中的损失函数相同。<li>KL损失，确保潜在变量分布保持接近正态分布。它基于Kullback-Leibler散度的概念，这是一个估计两个统计分布相似程度的指标。</ul><p>VAE的一个重要优势是，它们使我们能够相对容易地生成新图像，<strong>因为我们知道从哪个分布对潜在向量进行采样</strong>。例如，如果我们在MNIST上用2D潜在向量训练VAE，那么我们可以改变潜在向量的分量以获得不同的数字<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>vae_loss</span>(<span class=params>preds, targets, z_vals</span>):</span></span><br><span class=line>    mse = nn.MSELoss()</span><br><span class=line>    reconstruction_loss = mse(preds, targets.view(targets.shape[<span class=number>0</span>], -<span class=number>1</span>)) * <span class=number>784.0</span></span><br><span class=line>    temp = <span class=number>1.0</span> + z_vals[<span class=number>1</span>] - torch.square(z_vals[<span class=number>0</span>]) - torch.exp(z_vals[<span class=number>1</span>]) <span class=comment># ?尽可能使得潜变量与期望的分布kl相近</span></span><br><span class=line>    <span class=comment># 期望正态分布 均值0 方差1</span></span><br><span class=line>    kl_loss = -<span class=number>0.5</span> * torch.<span class=built_in>sum</span>(temp, axis=-<span class=number>1</span>)  <span class=comment>#  </span></span><br><span class=line>    <span class=keyword>return</span> torch.mean(reconstruction_loss + kl_loss)</span><br></pre></table></figure><p>关键是这里的KL loss,需要使得潜变量与正态分布kl更小,分布更相似. 当我们通过encoder计算出均值和方差的log之后,需要计算其与正态分布的KL,<p><img style="zoom: 80%;" alt=image-20230903182226844 data-src=https://s2.loli.net/2023/09/03/HURDP5TfoBuVjyC.png><p>计算正态分布之间的KL散度公式如上.关于VAE这里的KL 散度比较好的回答<a href=https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes/370048#370048 rel=noopener target=_blank>kullback leibler - Deriving the KL divergence loss for VAEs - Cross Validated (stackexchange.com)</a><blockquote><p><strong>KL散度</strong>，是指当某分布q (x)被用于近似p (x)时的信息损失。 KL Divergence 也就是说，q (x)能在多大程度上表达p (x)所包含的信息，KL散度越大，表达效果越差。</blockquote><p>所以计算KL时应该是KL(z|n)其中z表示潜变量,n表示正态分布. 目的是利用正态分布描述潜变量的损失.<h3 id=Training-a-VAE-with-The-Reparametrization-Trick><a title="Training a VAE with The Reparametrization Trick" class=headerlink href=#Training-a-VAE-with-The-Reparametrization-Trick></a>Training a VAE with The Reparametrization Trick</h3><p>VAE在反向传播时存在一些计算问题.使用了Reparametrization Trick<p><a href=https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important rel=noopener target=_blank>mathematical statistics - How does the reparameterization trick for VAEs work and why is it important? - Cross Validated (stackexchange.com)</a><h2 id=AAE><a class=headerlink href=#AAE title=AAE></a>AAE</h2><p>结合GAN和VAE的结构<p>对抗性自动编码器是生成对抗性网络和变分自动编码器的组合。编码器将是生成器，鉴别器将学习区分编码器输出的真实图像和生成的图像。编码器的输出是一个分布，从这个输出解码器将尝试解码图像。<p><img style="zoom: 67%;" alt=image-20230903230742551 data-src=https://s2.loli.net/2023/09/03/mbhaVXe7jrO63D8.png><p>众所周知,GAN的生成器在训练时使用噪声作为输入,<p><img alt=image-20230904105728118 data-src=https://s2.loli.net/2023/09/04/dcLtUFBSzg41rVl.png style=zoom:67%;><p><strong>纠正</strong>:是Adversarial. 注意,上面一层的autoencoder的encoder也是一个generator,相当于共用了GAN的generator和autoencoder的encoder.首先encoder使用一张图像作为输入,生成的潜变量在VAE中需要减小其与正态分布之间的相似度,也就是优化KL散度,但由于<strong>KL散度项的积分除了少数分布之外没有闭合形式的解析解</strong>,所以利用GAN的鉴别器,从正态分布中采样的数据与生成的潜变量作为鉴别器的输入进行鉴别,利用这个鉴别器的损失更新鉴别器</p><script type="math/tex; mode=display">
L_D=-\frac1m\sum_{k=1}^mlog(D(z'))+log(1-D(z))</script><p>更新后,再使用encoder(同时也是generator)以原始图像作为输入,生成潜变量,输入给更新后的鉴别器,鉴别器将其判断为真的概率.</p><script type="math/tex; mode=display">
L_G=-\frac1m\sum_{k=1}^mlog(D(z))</script><p>以这种方式定义的损失将迫使鉴别器能够识别假样本，同时推动生成器欺骗鉴别器.<p>首先，由于编码器的输出必须遵循高斯分布，我们在其最后一层不使用任何非线性。解码器的输出具有S形非线性，这是因为我们使用的输入以其值在0和1之间的方式归一化。鉴别器网络的输出只是0和1之间的一个数字，表示输入来自真实先验分布的概率<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br></pre><td class=code><pre><span class=line><span class=comment>#Encoder</span></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>Q_net</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(Q_net, self).__init__()</span><br><span class=line>        self.lin1 = nn.Linear(X_dim, N)</span><br><span class=line>        self.lin2 = nn.Linear(N, N)</span><br><span class=line>        self.lin3gauss = nn.Linear(N, z_dim)</span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        x = F.droppout(self.lin1(x), p=<span class=number>0.25</span>, training=self.training)</span><br><span class=line>        x = F.relu(x)</span><br><span class=line>        x = F.droppout(self.lin2(x), p=<span class=number>0.25</span>, training=self.training)</span><br><span class=line>        x = F.relu(x)</span><br><span class=line>        xgauss = self.lin3gauss(x)</span><br><span class=line>        <span class=keyword>return</span> xgauss</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br></pre><td class=code><pre><span class=line><span class=comment># Decoder</span></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>P_net</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(P_net, self).__init__()</span><br><span class=line>        self.lin1 = nn.Linear(z_dim, N)</span><br><span class=line>        self.lin2 = nn.Linear(N, N)</span><br><span class=line>        self.lin3 = nn.Linear(N, X_dim)</span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        x = self.lin1(x)</span><br><span class=line>        x = F.dropout(x, p=<span class=number>0.25</span>, training=self.training)</span><br><span class=line>        x = F.relu(x)</span><br><span class=line>        x = self.lin2(x)</span><br><span class=line>        x = F.dropout(x, p=<span class=number>0.25</span>, training=self.training)</span><br><span class=line>        x = self.lin3(x)</span><br><span class=line>        <span class=keyword>return</span> F.sigmoid(x)</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br></pre><td class=code><pre><span class=line><span class=comment># Discriminator</span></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>D_net_gauss</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(D_net_gauss, self).__init__()</span><br><span class=line>        self.lin1 = nn.Linear(z_dim, N)</span><br><span class=line>        self.lin2 = nn.Linear(N, N)</span><br><span class=line>        self.lin3 = nn.Linear(N, <span class=number>1</span>)</span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        x = F.dropout(self.lin1(x), p=<span class=number>0.2</span>, training=self.training)</span><br><span class=line>        x = F.relu(x)</span><br><span class=line>        x = F.dropout(self.lin2(x), p=<span class=number>0.2</span>, training=self.training)</span><br><span class=line>        x = F.relu(x)</span><br><span class=line>        <span class=keyword>return</span> F.sigmoid(self.lin3(x))</span><br></pre></table></figure><p>所以这里的损失函数定义为重建损失(一般为BCEloss或者cross-entropy loss)和GAN的损失,而GAN的训练一般都是G和D一个训练一下,而之前autoencoder训练时也是把encoder-decoder作为整个模型训练的loss.而这里为了在编码器（也是对抗性网络的生成器）的优化过程中具有独立性，我们为网络的这一部分定义了两个优化器,<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br></pre><td class=code><pre><span class=line>torch.manual_seed(<span class=number>10</span>)</span><br><span class=line>Q, P = Q_net() = Q_net(), P_net(<span class=number>0</span>)     <span class=comment># Encoder/Decoder</span></span><br><span class=line>D_gauss = D_net_gauss()                <span class=comment># Discriminator adversarial</span></span><br><span class=line><span class=keyword>if</span> torch.cuda.is_available():</span><br><span class=line>    Q = Q.cuda()</span><br><span class=line>    P = P.cuda()</span><br><span class=line>    D_cat = D_gauss.cuda()</span><br><span class=line>    D_gauss = D_net_gauss().cuda()</span><br><span class=line><span class=comment># Set learning rates</span></span><br><span class=line>gen_lr, reg_lr = <span class=number>0.0006</span>, <span class=number>0.0008</span></span><br><span class=line><span class=comment># Set optimizators</span></span><br><span class=line>P_decoder = optim.Adam(P.parameters(), lr=gen_lr)</span><br><span class=line>Q_encoder = optim.Adam(Q.parameters(), lr=gen_lr)</span><br><span class=line>Q_generator = optim.Adam(Q.parameters(), lr=reg_lr)</span><br><span class=line>D_gauss_solver = optim.Adam(D_gauss.parameters(), lr=reg_lr)</span><br></pre></table></figure><p>通过编码器/解码器部分进行正向计算，计算重建损失并更新编码器Q和解码器P网络的参数<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br></pre><td class=code><pre><span class=line>z_sample = Q(X)</span><br><span class=line>X_sample = P(z_sample)</span><br><span class=line>recon_loss = F.binary_cross_entropy(X_sample + TINY, </span><br><span class=line>                                    X.resize(train_batch_size, X_dim) + TINY)</span><br><span class=line>recon_loss.backward()</span><br><span class=line>P_decoder.step()</span><br><span class=line>Q_encoder.step()</span><br></pre></table></figure><p>创建一个潜在表示z=Q（x），并从先前的p（z）中提取样本z’，通过鉴别器运行每个样本，并计算分配给每个样本的分数（D（z）和D（z’））<figure class="highlight reasonml"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=module-access><span class=module><span class=identifier>Q</span>.</span></span>eval<span class=literal>()</span>    </span><br><span class=line>z_real_gauss = <span class=constructor>Variable(<span class=params>torch</span>.<span class=params>randn</span>(<span class=params>train_batch_size</span>, <span class=params>z_dim</span>)</span><span class=operator> * </span><span class=number>5</span>)   # Sample from <span class=constructor>N(0,5)</span></span><br><span class=line><span class=keyword>if</span> torch.cuda.is<span class=constructor>_available()</span>:</span><br><span class=line>    z_real_gauss = z_real_gauss.cuda<span class=literal>()</span></span><br><span class=line>z_fake_gauss = <span class=constructor>Q(X)</span></span><br></pre></table></figure><p>训练过程,首先利用encoder-decoder,得到重建后的输出,这里使用二分类交叉熵,计算梯度后更新encoder和decoder的值.然后使用generator(同时也是encoder)使用从高斯分布采样得到的变量作为输入,注意此时需要设置dropout和normalization模式为测试,因为正则目的是为了防止过拟合、加快拟合过程,所以测试、验证时并不需要正则了. 这里Q.eval目的是只需要得到一个生成的潜变量,而不是进行训练.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=comment># Compute discriminator outputs and loss</span></span><br><span class=line>D_real_gauss, D_fake_gauss = D_gauss(z_real_gauss), D_gauss(z_fake_gauss)</span><br><span class=line>D_loss_gauss = -torch.mean(torch.log(D_real_gauss + TINY) + torch.log(<span class=number>1</span> - D_fake_gauss + TINY))</span><br><span class=line>D_loss_gauss.backward()       <span class=comment># Backpropagate loss</span></span><br><span class=line>D_gauss_solver.step()   <span class=comment># Apply optimization step</span></span><br></pre></table></figure><p>计算Generator的loss，并相应地更新Q网络<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line><span class=comment># Generator</span></span><br><span class=line>Q.train()   <span class=comment># Back to use dropout</span></span><br><span class=line>z_fake_gauss = Q(X)</span><br><span class=line>D_fake_gauss = D_gauss(z_fake_gauss)</span><br><span class=line></span><br><span class=line>G_loss = -torch.mean(torch.log(D_fake_gauss + TINY))</span><br><span class=line>G_loss.backward()</span><br><span class=line>Q_generator.step()</span><br></pre></table></figure><p>由于需要更新Generator,恢复训练模式,<h3 id=Supervised-approach><a title="Supervised approach" class=headerlink href=#Supervised-approach></a>Supervised approach</h3><blockquote><p>特征学习最稳健的方法是尽可能多地分解因素，尽可能少地丢弃有关数据的信息</blockquote><p>通常来说,如果我们能提供更多信息,将其作为一个全监督的模型.<p><code>disentangled representations</code>类似于风格迁移中概念,可以将一张图像中的东西分为<strong>内容</strong>和<strong>风格</strong>,进行解耦表示。<p>我们可以加上类标签的独热码,这其实就是所谓的Conditional GAN<blockquote></blockquote><p><img alt=aae_semi data-src=https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/aae_super.png style=zoom:33%;><p>这样在代码上就会增加两个损失函数和一个鉴别器用于分辨产生的label的独热码和真实的label的独热码.<p><img style="zoom: 33%;" alt=disentanglement1 data-src=https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/dis_2.png><p>这是教程<a href=https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/ rel=noopener target=_blank>Adversarial Autoencoders (with Pytorch) (paperspace.com)</a>的图片,使得每一列潜变量第一部分也就是正态分布一样,但类标签不一样,<h3 id=Semi-supervised-approach><a title="Semi-supervised approach" class=headerlink href=#Semi-supervised-approach></a>Semi-supervised approach</h3><p>下面这种半监督的方式,我们需要将label加入,而这种加入并不是直接把label作为输入给decoder的,而是类似刚才AAE的方式通过GAN使得潜变量分为两个部分,分别是想要的某种分布和label,将class label的one-hot编码,比如说MNIST数据集中,3这个图像的label就是数字三,one-hot编码是0011(因为一共十个数字,需要4位.<p>我们可以修改以前的体系结构，使AAE产生一个由矢量级联组成的潜变量y指示类或标签（使用Softmax）和连续潜在变量z(使用线性层). 使用softmax作为最后一层的激活函数,这样最后一层输出shape就是(Batch_size,4) 每个值在0-1之间,<p>通过这种方法还能通过encoder产生的潜变量中的类标签的独热码进行对图像分类,<p><img style="zoom: 33%;" alt=aae002 data-src=https://raw.githubusercontent.com/fducau/AAE_pytorch/master/img/aae_semi.png><p>希望向量y表现为一个独热码，我们通过使用鉴别器Dcat的对抗性网络来强制它遵循类别分布。<p>编码器现在是q（z，y|x）。解码器使用类标签和连续潜变量来重建图像<h2 id=Conditional-Variational-Autoencoders><a title="Conditional Variational Autoencoders" class=headerlink href=#Conditional-Variational-Autoencoders></a>Conditional Variational Autoencoders</h2><p>条件变分自动编码器对编码器和解码器都有一个额外的输入。<p><img style="zoom: 67%;" alt=image-20230907105548807 data-src=https://cdn.sekyoro.top/imgs/image-20230907105548807.png><p>在训练时，将其图像被馈送的数字提供给编码器和解码器。在这种情况下，它将被表示为一个热向量。<p>要生成特定数字的图像，只需将该数字与从标准正态分布采样的潜在空间中的随机点一起输入解码器即可。即使输入同一点来产生两个不同的数字，这个过程也会正确工作，因为系统不再依赖潜在空间来编码你正在处理的数字。相反，潜在空间对其他信息进行编码，如笔划宽度或数字写入的角度。<p><img alt=image-20230904223354814 data-src=https://s2.loli.net/2023/09/04/HCPMwute1Z2LBV7.png style=zoom:50%;><h2 id=参考资料><a class=headerlink href=#参考资料 title=参考资料></a>参考资料</h2><ol><li><a href=https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/4-ComputerVision/09-Autoencoders/README.md rel=noopener target=_blank>AI-For-Beginners/lessons/4-ComputerVision/09-Autoencoders/README.md at main · microsoft/AI-For-Beginners (github.com)</a><li><a href=https://arxiv.org/pdf/2201.03898.pdf rel=noopener target=_blank>*2201.03898.pdf (arxiv.org)</a><li><a href=https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained rel=noopener target=_blank>Kullback-Leibler Divergence Explained — Count Bayesie</a><li><a href=https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians rel=noopener target=_blank>normal distribution - KL divergence between two univariate Gaussians - Cross Validated (stackexchange.com)</a><li><a href=https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/ rel=noopener target=_blank>Adversarial Autoencoders (with Pytorch) (paperspace.com)</a><li><a href=https://ijdykeman.github.io/ml/2016/12/21/cvae.html rel=noopener target=_blank>Conditional Variational Autoencoders (ijdykeman.github.io)</a><li><a href=https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important rel=noopener target=_blank>mathematical statistics - How does the reparameterization trick for VAEs work and why is it important? - Cross Validated (stackexchange.com)</a></ol><link href=/css/spoiler.css rel=stylesheet><script async src=/js/spoiler.js></script></div><div><div><div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div class=reward-container><div>感谢阅读.</div><button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">打赏</button><div style="display: none;" id=qr><div style="display: inline-block;"><img alt="Sekyoro 微信支付" src=/images/wechatpay.png><p>微信支付</div></div></div><div><ul class=post-copyright><li class=post-copyright-author><strong>本文作者： </strong>Sekyoro<li class=post-copyright-link><strong>本文链接：</strong> <a href=https://www.sekyoro.top/2023/09/01/Autoencoder%E5%AD%A6%E4%B9%A0/ title=Autoencoder学习>https://www.sekyoro.top/2023/09/01/Autoencoder学习/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ rel=noopener target=_blank><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</ul></div><div class=followme><p>欢迎关注我的其它发布渠道<div class=social-list><div class=social-item><a class=social-link href=/images/wxqrcode.png target=_blank> <span class=icon> <i class="fab fa-weixin"></i> </span> <span class=label>WeChat</span> </a></div><div class=social-item><a class=social-link href=/images/website.png target=_blank> <span class=icon> <i class="fa fa-user"></i> </span> <span class=label>PersonalWebsite</span> </a></div><div class=social-item><a class=social-link href=https://my-astro-git-main-drowning-in-codes.vercel.app target=_blank> <span class=icon> <i class="fas fa-share"></i> </span> <span class=label>杂鱼分享</span> </a></div><div class=social-item><a class=social-link href=/atom.xml target=_blank> <span class=icon> <i class="fa fa-rss"></i> </span> <span class=label>RSS</span> </a></div></div></div><footer class=post-footer><div class=post-tags><a href=/tags/VAE/ rel=tag><i class="fa fa-tag"></i> VAE</a><a href=/tags/autoencoder/ rel=tag><i class="fa fa-tag"></i> autoencoder</a></div><div class=post-nav><div class=post-nav-item><a href=/2023/08/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86(%E4%BA%8C)/ rel=prev title=深度学习基础知识(二)> <i class="fa fa-chevron-left"></i> 深度学习基础知识(二) </a></div><div class=post-nav-item><a href=/2023/09/12/pytorch%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%88%9D%E6%8E%A2/ rel=next title=pytorch学习——初探> pytorch学习——初探 <i class="fa fa-chevron-right"></i> </a></div></div></footer></article></div><!-- 评论区 --><div class=comments><div data-id=city data-uid=MTAyMC81MzE5Ny8yOTY3Mg== id=lv-container></div></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class=sidebar><div class=sidebar-inner><!-- canvas粒子时钟 --><div><canvas id=canvas style=width:60%;>当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();</script><!-- require APlayer --><link href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><!-- require MetingJS --><script src=/js/meting-js.js></script><ul class="sidebar-nav motion-element"><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#Autoencoders><span class=nav-number>1.</span> <span class=nav-text>Autoencoders</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#AE%E5%B8%B8%E7%94%A8%E5%8E%BB%E5%99%AA%E5%92%8C%E8%B6%85%E5%88%86><span class=nav-number>1.1.</span> <span class=nav-text>AE常用去噪和超分.</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#VAE><span class=nav-number>2.</span> <span class=nav-text>VAE</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#Training-a-VAE-with-The-Reparametrization-Trick><span class=nav-number>2.1.</span> <span class=nav-text>Training a VAE with The Reparametrization Trick</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#AAE><span class=nav-number>3.</span> <span class=nav-text>AAE</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#Supervised-approach><span class=nav-number>3.1.</span> <span class=nav-text>Supervised approach</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Semi-supervised-approach><span class=nav-number>3.2.</span> <span class=nav-text>Semi-supervised approach</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#Conditional-Variational-Autoencoders><span class=nav-number>4.</span> <span class=nav-text>Conditional Variational Autoencoders</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99><span class=nav-number>5.</span> <span class=nav-text>参考资料</span></a></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=Sekyoro class=site-author-image itemprop=image src=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg><p class=site-author-name itemprop=name>Sekyoro<div class=site-description itemprop=description>什么也无法舍弃的人，什么也做不了.</div></div><div class="site-state-wrap motion-element"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>166</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>17</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>184</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a title="Personal Website → http://proanimer.com" href=http://proanimer.com/ rel=noopener target=_blank><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a> </span><span class=links-of-author-item> <a title="GitHub → https://github.com/drowning-in-codes" href=https://github.com/drowning-in-codes rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a title="E-Mail → mailto:bukalala174@gmail.com" href=mailto:bukalala174@gmail.com rel=noopener target=_blank><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class=links-of-author-item> <a title="wxPublicAccount → https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" href=https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd rel=noopener target=_blank><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a> </span><span class=links-of-author-item> <a title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span><span class=links-of-author-item> <a title="CSDN → https://blog.csdn.net/aqwca" href=https://blog.csdn.net/aqwca rel=noopener target=_blank><i class="fa fa-handshake fa-fw"></i>CSDN</a> </span><span class=links-of-author-item> <a title="杂鱼分享 → https://my-astro-git-main-drowning-in-codes.vercel.app" href=https://my-astro-git-main-drowning-in-codes.vercel.app/ rel=noopener target=_blank><i class="fas fa-share fa-fw"></i>杂鱼分享</a> </span></div><div class="links-of-blogroll motion-element"><div class=links-of-blogroll-title><i class="fa fa-link fa-fw"></i> 友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=http://myqhs.top/ rel=noopener target=_blank title=http://myqhs.top/>myqhs</a></ul></div><div class="motion-element announcement"><div class=title>注意</div><p class=content>由于最近图床更新,可能有些图片显示不了.如果发现了有些图片无法显示影响阅读的,还烦请联系我,我有空补上.<p class=date>2023-10-6</div></div><meting-js id=6856787487 order=random server=netease type=playlist> </meting-js><div class=widget-wrap><h3 class=widget-title style=margin:0>文章词云</h3><div class="widget tagcloud" id=myCanvasContainer><canvas height=250 id=resCanvas style=width:100% width=250><ul class=tag-list itemprop=keywords><li class=tag-list-item><a class=tag-list-link href=/tags/VAE/ rel=tag>VAE</a><span class=tag-list-count>1</span><li class=tag-list-item><a class=tag-list-link href=/tags/autoencoder/ rel=tag>autoencoder</a><span class=tag-list-count>1</span></ul></canvas></div></div><script id=clustrmaps src=https://clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a></script><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i><span>0%</span></div><!-- 边栏 --></div></aside><div id=sidebar-dimmer></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – <span itemprop=copyrightYear>2024</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Sekyoro</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-chart-area"></i> </span><span title=站点总字数>1.2m</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span><span title=站点阅读时长>17:51</span></div><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container_site_pv>总访问量<span id=busuanzi_value_site_pv></span>次</span><span class=post-meta-divider>|</span><span id=busuanzi_container_site_uv>总访客数<span id=busuanzi_value_site_uv></span>人</span><span class=post-meta-divider>|</span><!-- 不蒜子计数初始值纠正 --><script>$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});</script><div><span id=timeDate>载入天数...</span><span id=times>载入时分秒...</span><script>var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);</script></div><div class=busuanzi-count><script async data-pjax src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span style="display: none;" class=post-meta-item id=busuanzi_container_site_uv> <span class=post-meta-item-icon> <i class="fa fa-user"></i> </span> <span class=site-uv title=总访客量> <span id=busuanzi_value_site_uv></span> </span> </span><span class=post-meta-divider>|</span><span style="display: none;" class=post-meta-item id=busuanzi_container_site_pv> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=site-pv title=总访问量> <span id=busuanzi_value_site_pv></span> </span> </span></div></div></footer></div><script color=0,0,255 count=99 opacity=0.5 src=/lib/canvas-nest/canvas-nest.min.js zindex=-1></script><script src=/lib/anime.min.js></script><script src=https://cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js></script><script src=https://cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/schemes/pisces.js></script><script src=/js/next-boot.js></script><script src=/js/bookmark.js></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	'.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});</script><script data-pjax>(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();</script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js></script><script src=/js/algolia-search.js></script><script data-pjax>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><div id=pjax><script charset=utf-8 defer src=/js/outdate.js></script></div><script charset=utf-8 defer src=/js/tagcanvas.js></script><script charset=utf-8 defer src=/js/tagcloud.js></script><script>NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});</script><script>var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });</script><script src=/js/src/activate-power-mode.min.js></script><script>POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);</script>