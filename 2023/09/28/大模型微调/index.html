<!DOCTYPE html>
<html lang="zh-CN">
<head>
<script src="/live2d-widget/autoload.js"></script>

  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/blog_32px.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/blog_32px.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/blog_16px.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script>

<!-- google adsense in head.swig -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123"
     crossorigin="anonymous"></script>
  <meta name="msvalidate.01" content="7226864CE87CE9DE8C008385273846FF">
  <meta name="baidu-site-verification" content="code-fjFXVtiL7j" />

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-corner-indicator.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"3G9PZZIKCH","apiKey":"8eb71f5ca3167e9ef3487882f10cfaad","indexName":"SekyoroSearch","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>
<link href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css" rel="stylesheet">
  <meta name="description" content="这段时间非常火的topic,大模型参数多,占用体积大训练困难,而且一般需要微调技术用于特定任务.">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型微调">
<meta property="og:url" content="https://www.sekyoro.top/2023/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/index.html">
<meta property="og:site_name" content="Sekyoro的博客小屋">
<meta property="og:description" content="这段时间非常火的topic,大模型参数多,占用体积大训练困难,而且一般需要微调技术用于特定任务.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/06/EVg6Y5wI4bORafU.png">
<meta property="og:image" content="https://miro.medium.com/v2/resize:fit:700/1*aeek418WCndtt1491JHK7w.png">
<meta property="og:image" content="https://miro.medium.com/v2/resize:fit:700/1*bYy116KZAanbxXta4PCkjQ.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/06/bJK6SC3Pq5AT7FV.png">
<meta property="og:image" content="https://s2.loli.net/2023/10/06/nGVmIryLvM3AZEY.png">
<meta property="article:published_time" content="2023-09-28T12:15:47.000Z">
<meta property="article:modified_time" content="2023-10-06T09:30:13.202Z">
<meta property="article:author" content="Sekyoro">
<meta property="article:tag" content="llm">
<meta property="article:tag" content="finetune">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/06/EVg6Y5wI4bORafU.png">

<link rel="canonical" href="https://www.sekyoro.top/2023/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>大模型微调 | Sekyoro的博客小屋</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Sekyoro的博客小屋" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
<!-- require JQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<!-- require pjax -->
<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/index.min.js"></script>


   <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
   <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
   <script type="text/javascript" src="/js/src/fireworks.js"></script>


  <div class="container use-motion">
    <div class="headband"></div>
	
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Sekyoro的博客小屋</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-bangumis">

    <a href="/bangumis/" rel="section"><i class="fa fa-film fa-fw"></i>追番</a>

  </li>
        <li class="menu-item menu-item-resume">

    <a href="/resume/" rel="section"><i class="fa fa-file-pdf fa-fw"></i>简历</a>

  </li>
        <li class="menu-item menu-item-materials">

    <a href="/materials/" rel="section"><i class="fa fa-book fa-fw"></i>学习资料</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.sekyoro.top/2023/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg">
      <meta itemprop="name" content="Sekyoro">
      <meta itemprop="description" content="什么也无法舍弃的人，什么也做不了.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sekyoro的博客小屋">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大模型微调
        </h1>

        <div class="post-meta">
		
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-28 20:15:47" itemprop="dateCreated datePublished" datetime="2023-09-28T20:15:47+08:00">2023-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-06 17:30:13" itemprop="dateModified" datetime="2023-10-06T17:30:13+08:00">2023-10-06</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>19k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>18 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>这段时间非常火的topic,大模型参数多,占用体积大训练困难,而且一般需要微调技术用于特定任务.<br><span id="more"></span></p>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/14MCMope8tjZkg5H5mXKSr_g2lYi5woVU#scrollTo=_Gw1sj7sagEE&amp;uniqifier=1">AnimeBot.ipynb - Colaboratory (google.com)</a>我的完整代码</p>
<h2 id="什么是大模型LLM"><a href="#什么是大模型LLM" class="headerlink" title="什么是大模型LLM"></a>什么是大模型LLM</h2><blockquote>
<p>LLM是大型语言模型的缩写，是人工智能和机器学习领域的最新创新。2022年12月，随着ChatGPT的发布，这种强大的新型人工智能在网上疯传。对于那些足够开明的人来说，生活在人工智能的嗡嗡声和科技新闻周期之外，ChatGPT是一个在名为GPT-3的LLM上运行的聊天界面。</p>
</blockquote>
<p>最近的大模型就是Meta的llama2当然还有openai的GPT4,google的PaLM2.国内有清华的ChatGLM等等.</p>
<p>而大模型微调就是在此基础上更改其参数或者一些层使得更好应对一些下游任务.当你想将预先存在的模型适应特定的任务或领域时，微调模型在机器学习中至关重要。微调模型的决定取决于您的目标，这些目标通常是特定于领域或任务的。</p>
<p><img data-src="https://s2.loli.net/2023/10/06/EVg6Y5wI4bORafU.png" alt="image-20231006172946171"></p>
<p>现在关于微调的技术有很多,这些技术都是为了解决自己的specified task,一般需要特定的数据.</p>
<p>一般涉及三种方法。Prompt Engineering,embedding以及finetune也就是微调.</p>
<h3 id="Prompt-Engineering"><a href="#Prompt-Engineering" class="headerlink" title="Prompt Engineering"></a>Prompt Engineering</h3><p>简单来说就是跟模型对话时提前给一些已知的信息.</p>
<p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*aeek418WCndtt1491JHK7w.png" alt="Chat GPT responds to the query using custom data (revenue numbers) provided in the prompt." style="zoom:67%;" /></p>
<p>这种方法简单,但是由于将大文本传递到LLM的提示大小和相关成本的限制，使用大文档集或网页作为LLM的输入不是最佳方式。</p>
<h3 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h3><p>嵌入是一种将信息（无论是文本、图像还是音频）表示为数字形式的方式</p>
<p><img data-src="https://miro.medium.com/v2/resize:fit:700/1*bYy116KZAanbxXta4PCkjQ.png" alt="img"></p>
<p>当需要将大量文档或网页传递给LLM时，嵌入效果很好。例如，当聊天机器人被构建为向用户提供一组策略文档的响应时，这种方法会很好地工作。</p>
<p>使用时需要将文本等内容生成embedding,这就需要seq2seq模型得到嵌入了.当用户想要查询LLM时，嵌入将从向量存储中检索并传递给LLM。LLM使用嵌入从自定义数据生成响应。</p>
<h3 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine tuning"></a>Fine tuning</h3><p><img data-src="https://s2.loli.net/2023/10/06/bJK6SC3Pq5AT7FV.png" alt="image-20231006172959467"></p>
<p>微调是教模型如何处理输入查询以及如何表示响应的一种方式。例如，LLM可以通过提供有关客户评价和相应情绪的数据来进行微调。</p>
<p>微调通常用于为特定任务调整LLM，并在该范围内获得响应。该任务可以是电子邮件分类、情绪分析、实体提取、基于规格生成产品描述等</p>
<p>具体的微调技术有Lora,QLora,Peft等等</p>
<h4 id="Fine-tuning技术"><a href="#Fine-tuning技术" class="headerlink" title="Fine tuning技术"></a>Fine tuning技术</h4><h4 id="old-school"><a href="#old-school" class="headerlink" title="old school"></a>old school</h4><p>在老派的方法中，有各种方法可以微调预先训练的语言模型，每种方法都是根据特定需求和资源限制量身定制的。</p>
<ul>
<li>基于特征：它使用预先训练的LLM作为特征提取器，将输入文本转换为固定大小的数组。一个单独的分类器网络预测NLP任务中文本的分类概率。在训练中，只有分类器的权重会改变，这使得它对资源友好，但可能性能较差。</li>
<li>微调I：微调I通过添加额外的密集层来增强预先训练的LLM。在训练期间，只调整新添加的层的权重，同时保持预先训练的LLM权重冻结。在实验中，<strong>它显示出比基于特征的方法略好的性能</strong>。</li>
<li>微调II：在这种方法中，整个模型，包括预先训练的语言模型（LLM），都被解冻进行训练，允许更新所有模型权重。然而，它可能会导致<strong>灾难性的遗忘</strong>，新的特征会覆盖旧的知识。微调II是资源密集型的，但在需要最大性能时可提供卓越的结果。通用语言模型微调</li>
<li>ULMFiT是一种可应用于NLP任务的迁移学习方法。它涉及一个3层的AWD-LSTM体系结构来进行表示。ULMFiT是一种用于为特定下游任务微调预先训练的语言模型的方法。</li>
<li>基于梯度的参数重要性排序：这些方法用于对模型中特征或参数的重要性进行排序。在基于梯度的排序中，参数的重要性取决于排除参数时精度降低的程度。在基于随机森林的排序中，可以对每个特征的杂质减少进行平均，并根据该度量对特征进行排序。</li>
</ul>
<p><img data-src="https://s2.loli.net/2023/10/06/nGVmIryLvM3AZEY.png" alt="image-20231006173008820"></p>
<h4 id="LLM微调的前沿策略"><a href="#LLM微调的前沿策略" class="headerlink" title="LLM微调的前沿策略"></a>LLM微调的前沿策略</h4><ul>
<li>低秩自适应（LoRA）：LoRA是一种微调大型语言模型的技术。它使用低秩近似方法来降低将具有数十亿参数的模型（如GPT-3）适应特定任务或领域的计算和财务成本。</li>
<li>量化LoRA（QLoRA）：QLoRA是一种适用于大型语言模型（LLM）的高效微调方法，可显著减少内存使用，同时保持完整的16位微调性能。它通过将冻结的4位量化预训练语言模型的梯度反向传播到低秩适配器中来实现这一点。</li>
<li>参数高效微调（PEFT）：PEFT是一种NLP技术，<strong>通过只微调一小组参数</strong>，降低计算和存储成本，使预先训练的语言模型有效地适应各种应用。<strong>它可以消除灾难性的遗忘，为特定任务调整关键参数，并提供与图像分类和稳定扩散dreambooth等模式的全面微调相当的性能。这是一种在最小可训练参数的情况下实现高性能的有价值的方法。</strong></li>
<li>DeepSpeed:DeepSpeed是一个深度学习软件库，用于加速大型语言模型的训练。它包括ZeRO（零冗余优化器），这是一种用于分布式训练的内存高效方法。DeepSpeed可以自动优化使用Hugging Face的Trainer API的微调作业，并提供一个替代脚本来运行现有的微调脚本。</li>
<li>ZeRO：ZeRO是一组内存优化技术，能够有效训练具有数万亿参数的大型模型，如GPT-2和图灵NLG 17B。ZeRO的一个主要吸引力是不需要修改模型代码。这是一种内存高效的数据并行形式，可以让您访问所有可用GPU设备的聚合GPU内存，而不会因数据并行中的数据复制而导致效率低下。</li>
</ul>
<p>现在一般用lora及其衍生方法以及PEFT.</p>
<p>微调用的数据集可以自己做也可以到处找,比如hugging face上或者Google dataset,github上.</p>
<p>至于模型一般使用hugging face或者langchain等工具库直接调用,没有必要手动下载.获取到一般的语言或者其他类型的数据之后,一般都需要embedding等预处理步骤.embedding模型一般要与处理任务的模型有一定对应关系.</p>
<p>下面使用Hugging Face的transformers等库进行大模型微调.常常使用<code>AutoModel</code>,<code>AutoTokenizer</code>以及<code>AutoConfig</code>,通过调用<code>from_pretrained</code>获取相关信息.下面是一般训练流程.</p>
<h4 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Transformers installation</span></span><br><span class="line">pip install transformers datasets</span><br><span class="line"><span class="comment"># To install from source instead of the last release, comment the command above and uncomment the following one.</span></span><br><span class="line">pip install git+https://github.com/huggingface/transformers.git</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;yelp_review_full&quot;</span>)</span><br><span class="line"><span class="comment">#dataset[&quot;train&quot;][100]</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_function</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;text&quot;</span>], padding=<span class="string">&quot;max_length&quot;</span>, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">tokenized_datasets = dataset.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line">small_train_dataset = tokenized_datasets[<span class="string">&quot;train&quot;</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line">small_eval_dataset = tokenized_datasets[<span class="string">&quot;test&quot;</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(output_dir=<span class="string">&quot;test_trainer&quot;</span>)</span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=small_train_dataset,</span><br><span class="line">    eval_dataset=small_eval_dataset,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<p>上面的<code>compute_metrics</code>用于评估模型.<code>training_args</code>是训练时设置参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    logits, labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure>
<p>可以使用<code>trainer.push_to_hub()</code>推送到自己的仓库.这样会自动将训练超参数、训练结果和框架版本添加到您的模型卡中</p>
<h4 id="PEFT训练adapters"><a href="#PEFT训练adapters" class="headerlink" title="PEFT训练adapters"></a>PEFT训练adapters</h4><p>使用PEFT训练的适配器通常也比完整模型小一个数量级，便于共享、存储和加载。通常搭配Lora模型.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">peft_model_id = <span class="string">&quot;ybelkada/opt-350m-lora&quot;</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(peft_model_id)</span><br></pre></td></tr></table></figure>
<p>加载和使用PEFT适配器型,请确保Hub存储库或本地目录包含adapter_config.json文件和adapter weights.</p>
<p>也可以先加载基础model,再使用<code>load_adapter</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&quot;facebook/opt-350m&quot;</span></span><br><span class="line">peft_model_id = <span class="string">&quot;ybelkada/opt-350m-lora&quot;</span></span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_id)</span><br><span class="line">model.load_adapter(peft_model_id)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>load_in_8bit</code>以及<code>device_map</code>涉及到将模型放哪和占用大小.</p>
<p>增加<code>adapter</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftConfig</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&quot;facebook/opt-350m&quot;</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_id)</span><br><span class="line"></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>],</span><br><span class="line">    init_lora_weights=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.add_adapter(lora_config, adapter_name=<span class="string">&quot;adapter_1&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>训练一个adapter</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">    lora_alpha=<span class="number">16</span>,</span><br><span class="line">    lora_dropout=<span class="number">0.1</span>,</span><br><span class="line">    r=<span class="number">64</span>,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">)</span><br><span class="line">model.add_adapter(peft_config)</span><br><span class="line">trainer = Trainer(model=model, ...)</span><br><span class="line">trainer.train()</span><br><span class="line">model.save_pretrained(save_dir)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(save_dir)</span><br></pre></td></tr></table></figure>
<p>每个 PEFT方法由<code>PeftConfig</code>类定义，该类存储用于构建<code>PeftModel</code>的所有重要参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, TaskType</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=<span class="literal">False</span>, r=<span class="number">8</span>, lora_alpha=<span class="number">32</span>, lora_dropout=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">    r=lora_r,</span><br><span class="line">    lora_alpha=lora_alpha,</span><br><span class="line">    lora_dropout=lora_dropout,</span><br><span class="line">    target_modules=lora_target_modules,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用<code>get_peft_model</code>函数包装基本模型和peft_config以创建PeftModel.并使用<code>print_trainable_parameters</code>打印需要更新的参数.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> get_peft_model</span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&quot;bigscience/mt0-large&quot;</span></span><br><span class="line">tokenizer_name_or_path = <span class="string">&quot;bigscience/mt0-large&quot;</span></span><br><span class="line">model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)</span><br><span class="line"></span><br><span class="line">model = get_peft_model(model, peft_config)</span><br><span class="line">model.print_trainable_parameters()</span><br></pre></td></tr></table></figure>
<p><strong>保存并推送模型到仓库</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;output_dir&quot;</span>)</span><br><span class="line">model.push_to_hub(<span class="string">&quot;my_awesome_peft_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这只会保存增量经过训练的PEFT重量，这意味着它在存储、转移和装载方面非常高效。例如，在RAFT数据集的twitter_complaints子集上使用LoRA训练的bigscience/To_3B模型只包含两个文件：adapter_config.json和adapter_model.bin。</p>
</blockquote>
<p><strong>下载模型</strong></p>
<p>下面的方法是逻辑是首先通过PeftConfig得到peft的配置,从中得到基础模型位置,利用基础模型得到其模型和tokenizer,最后利用PeftModel得到model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel, PeftConfig</span><br><span class="line"></span><br><span class="line">peft_model_id = <span class="string">&quot;smangrul/twitter_complaints_bigscience_T0_3B_LORA_SEQ_2_SEQ_LM&quot;</span></span><br><span class="line">config = PeftConfig.from_pretrained(peft_model_id)</span><br><span class="line">  model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)</span><br><span class="line">model = PeftModel.from_pretrained(model, peft_model_id)</span><br><span class="line">  tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)</span><br><span class="line"></span><br><span class="line">  model = model.to(device)</span><br><span class="line">  model.<span class="built_in">eval</span>()</span><br><span class="line">  inputs = tokenizer(<span class="string">&quot;Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. Label :&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">      outputs = model.generate(input_ids=inputs[<span class="string">&quot;input_ids&quot;</span>].to(<span class="string">&quot;cuda&quot;</span>), max_new_tokens=<span class="number">10</span>)</span><br><span class="line">      <span class="built_in">print</span>(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=<span class="literal">True</span>)[<span class="number">0</span>])</span><br><span class="line">  <span class="string">&#x27;complaint&#x27;</span></span><br></pre></td></tr></table></figure>
<p>也可以简单地使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModelForCausalLM</span><br><span class="line">peft_model = AutoPeftModelForCausalLM.from_pretrained(<span class="string">&quot;ybelkada/opt-350m-lora&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModel</span><br><span class="line">model = AutoPeftModel.from_pretrained(peft_model_id)</span><br></pre></td></tr></table></figure>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><h4 id="下载所需包"><a href="#下载所需包" class="headerlink" title="下载所需包"></a>下载所需包</h4><p>一般是hugging face的transformers,datasets以及xformers,accelerate,trl,bitsandbytes,peft等库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">!pip install -Uqqq pip --progress-bar off</span><br><span class="line">!pip install -qqq torch==2.0.1 --progress-bar off</span><br><span class="line">!pip install -qqq transformers==4.32.1 --progress-bar off</span><br><span class="line">!pip install -qqq datasets==2.14.4 --progress-bar off</span><br><span class="line">!pip install -qqq peft==0.5.0 --progress-bar off</span><br><span class="line">!pip install -qqq bitsandbytes==0.41.1 --progress-bar off</span><br><span class="line">!pip install -qqq trl==0.7.1 --progress-bar off</span><br></pre></td></tr></table></figure>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><p>数据处理方式特别多,有很多实现方式.这里主要使用pandas与datasets处理csv数据.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">animes_dataset = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files = <span class="string">&quot;/content/animes.csv&quot;</span>) </span><br><span class="line">reviews_dataset = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files = <span class="string">&quot;/content/reviews.csv&quot;</span>) </span><br><span class="line">animes_df = pd.DataFrame(animes_dataset[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">reviews_df = pd.DataFrame(reviews_dataset[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">merged_df = pd.merge(animes_df,reviews_df,left_on=<span class="string">&quot;uid&quot;</span>,right_on=<span class="string">&quot;anime_uid&quot;</span>)</span><br><span class="line"><span class="comment"># remove /n/r</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_text</span>(<span class="params">x</span>):</span></span><br><span class="line">  <span class="comment">#remove multiple whitespace</span></span><br><span class="line">  new_string = <span class="built_in">str</span>(x).strip()</span><br><span class="line">  pattern = <span class="string">r&quot;\s&#123;3,&#125;&quot;</span></span><br><span class="line">  new_string = re.sub(pattern, <span class="string">&quot; &quot;</span>, new_string)</span><br><span class="line">  <span class="comment">#remove \r \n \t</span></span><br><span class="line">  pattern = <span class="string">r&quot;[\n\r\t]&quot;</span></span><br><span class="line">  new_string  = re.sub(pattern,<span class="string">&quot;&quot;</span>, new_string)</span><br><span class="line">  <span class="keyword">return</span> new_string</span><br><span class="line">merged_df[<span class="string">&quot;synopsis&quot;</span>] = merged_df[<span class="string">&quot;synopsis&quot;</span>].<span class="built_in">map</span>(clean_text)</span><br><span class="line">merged_df[<span class="string">&quot;text&quot;</span>] = merged_df[<span class="string">&quot;text&quot;</span>].<span class="built_in">map</span>(clean_text)</span><br><span class="line"><span class="comment"># split merged_df into train and test</span></span><br><span class="line">train_df, test_df = train_test_split(merged_df, test_size=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">dataset_dict = DatasetDict(&#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: Dataset.from_pandas(train_df),</span><br><span class="line">    <span class="string">&quot;validation&quot;</span>: Dataset.from_pandas(test_df)</span><br><span class="line">&#125;)</span><br><span class="line">DEFAULT_SYSTEM_PROMPT = <span class="string">&quot;Below is a name of an anime,write some intro about it&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">DEFAULT_SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT.strip()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_training_prompt</span>(<span class="params">data_point</span>):</span></span><br><span class="line">  <span class="comment"># 去除字符串中的方括号和空格</span></span><br><span class="line">  genres = data_point[<span class="string">&quot;genre&quot;</span>].strip(<span class="string">&quot;[]&quot;</span>).replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;\&#x27;&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">  synopsis_len = <span class="built_in">len</span>(data_point[<span class="string">&quot;synopsis&quot;</span>])</span><br><span class="line">  split_len = random.randint(<span class="number">1</span>,synopsis_len)</span><br><span class="line">  synopsis_input = data_point[<span class="string">&quot;synopsis&quot;</span>][<span class="number">1</span>:split_len]</span><br><span class="line"></span><br><span class="line">  <span class="built_in">input</span> = data_point[<span class="string">&quot;title&quot;</span>]+genres+synopsis_input</span><br><span class="line">  output = data_point[<span class="string">&quot;synopsis&quot;</span>]+data_point[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">      <span class="string">&quot;text&quot;</span>:<span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;DEFAULT_SYSTEM_PROMPT&#125;</span></span></span><br><span class="line"><span class="string">            ### Input:</span></span><br><span class="line"><span class="string">            <span class="subst">&#123;<span class="built_in">input</span>.strip()&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            ### Response:</span></span><br><span class="line"><span class="string">            <span class="subst">&#123;output.strip()&#125;</span></span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span>.strip()</span><br><span class="line">  &#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_dataset</span>(<span class="params">data: Dataset</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        data.shuffle(seed=<span class="number">42</span>)</span><br><span class="line">        .<span class="built_in">map</span>(generate_training_prompt)</span><br><span class="line">        .remove_columns(</span><br><span class="line">              [</span><br><span class="line">                <span class="string">&quot;uid_x&quot;</span>,</span><br><span class="line">                <span class="string">&quot;aired&quot;</span>,</span><br><span class="line">                <span class="string">&quot;members&quot;</span>,</span><br><span class="line">                <span class="string">&quot;img_url&quot;</span>,</span><br><span class="line">                <span class="string">&quot;uid_y&quot;</span>,</span><br><span class="line">                <span class="string">&quot;profile&quot;</span>,</span><br><span class="line">                <span class="string">&quot;anime_uid&quot;</span>,</span><br><span class="line">                <span class="string">&quot;score_y&quot;</span>,</span><br><span class="line">                <span class="string">&quot;link_y&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">dataset_dict[<span class="string">&quot;train&quot;</span>] = process_dataset(dataset_dict[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">dataset_dict[<span class="string">&quot;validation&quot;</span>] = process_dataset(dataset_dict[<span class="string">&quot;validation&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>这里处理逻辑其实复杂了,只需要使用pandas读取数据,然后分为训练集和测试集然后转为Dataset即可.中间需要对dataframe的数据去除一些空白字符等.</p>
<h4 id="训练设置"><a href="#训练设置" class="headerlink" title="训练设置"></a>训练设置</h4><p>由于使用了PEFT</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">lora_r = <span class="number">16</span></span><br><span class="line">lora_alpha = <span class="number">64</span></span><br><span class="line">lora_dropout = <span class="number">0.1</span></span><br><span class="line">lora_target_modules = [</span><br><span class="line">    <span class="string">&quot;q_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;up_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;k_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;down_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;gate_proj&quot;</span>,</span><br><span class="line">    <span class="string">&quot;v_proj&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">    r=lora_r,</span><br><span class="line">    lora_alpha=lora_alpha,</span><br><span class="line">    lora_dropout=lora_dropout,</span><br><span class="line">    target_modules=lora_target_modules,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>设置trainingArgument,使用trl进行训练.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">OUTPUT_DIR = <span class="string">&quot;experiments&quot;</span></span><br><span class="line">training_arguments = TrainingArguments(</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    gradient_accumulation_steps=<span class="number">4</span>,</span><br><span class="line">    optim=<span class="string">&quot;paged_adamw_32bit&quot;</span>,</span><br><span class="line">    logging_steps=<span class="number">1</span>,</span><br><span class="line">    learning_rate=<span class="number">1e-4</span>,</span><br><span class="line">    fp16=<span class="literal">True</span>,</span><br><span class="line">    max_grad_norm=<span class="number">0.3</span>,</span><br><span class="line">    num_train_epochs=<span class="number">2</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    eval_steps=<span class="number">0.2</span>,</span><br><span class="line">    warmup_ratio=<span class="number">0.05</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    group_by_length=<span class="literal">True</span>,</span><br><span class="line">    output_dir=OUTPUT_DIR,</span><br><span class="line">    report_to=<span class="string">&quot;tensorboard&quot;</span>,</span><br><span class="line">    save_safetensors=<span class="literal">True</span>,</span><br><span class="line">    lr_scheduler_type=<span class="string">&quot;cosine&quot;</span>,</span><br><span class="line">    seed=<span class="number">42</span>,</span><br><span class="line">)</span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model=model,</span><br><span class="line">    train_dataset=dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=dataset[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    peft_config=peft_config,</span><br><span class="line">    dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length=<span class="number">4096</span>,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    args=training_arguments,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="训练与后续评估测试"><a href="#训练与后续评估测试" class="headerlink" title="训练与后续评估测试"></a>训练与后续评估测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModelForCausalLM</span><br><span class="line"><span class="comment"># Load Lora adapter</span></span><br><span class="line"><span class="comment"># model = PeftModel.from_pretrained(</span></span><br><span class="line"><span class="comment">#     base_model,</span></span><br><span class="line"><span class="comment">#     &quot;/content/Finetuned_adapter&quot;,</span></span><br><span class="line"><span class="comment">#     )</span></span><br><span class="line"><span class="comment"># merged_model = model.merge_and_unload()</span></span><br><span class="line">trained_model = AutoPeftModelForCausalLM.from_pretrained(</span><br><span class="line">    OUTPUT_DIR,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">merged_model = base_model.merge_and_unload()</span><br><span class="line">merged_model.save_pretrained(<span class="string">&quot;merged_model&quot;</span>, safe_serialization=<span class="literal">True</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;merged_model&quot;</span>)</span><br><span class="line"><span class="comment"># trainer.push_to_hub(&quot;anime_chatbot&quot;)</span></span><br><span class="line">merged_model.push_to_hub(<span class="string">&quot;anime_chatbot&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Pushed to hub&quot;</span>)</span><br><span class="line"><span class="comment"># @title test fine tune model</span></span><br><span class="line"><span class="comment"># @title test base model</span></span><br><span class="line">DEFAULT_SYSTEM_PROMPT = <span class="string">&quot;Below is a name of an anime,write some intro about it&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">DEFAULT_SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT.strip()</span><br><span class="line">user_prompt = <span class="keyword">lambda</span> <span class="built_in">input</span>:<span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;DEFAULT_SYSTEM_PROMPT&#125;</span></span></span><br><span class="line"><span class="string">            ### Input:</span></span><br><span class="line"><span class="string">            <span class="subst">&#123;<span class="built_in">input</span>.strip()&#125;</span></span></span><br><span class="line"><span class="string">            ### Response:</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span>.strip()</span><br><span class="line">pipe = pipeline(<span class="string">&#x27;text-generation&#x27;</span>,model=merged_model,tokenizer=tokenizer,max_length=<span class="number">150</span>)</span><br><span class="line"></span><br><span class="line">result = pipe(user_prompt(<span class="string">&quot;please introduce shingekinokyojin&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(result[<span class="number">0</span>][<span class="string">&#x27;generated_text&#x27;</span>])</span><br></pre></td></tr></table></figure>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSeq2SeqLM</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">model_base = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;facebook/opt-350m&quot;</span>, torch_dtype=torch.bfloat16)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;facebook/opt-350m&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这里model_base是</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">OPTForCausalLM(</span><br><span class="line">  (model): OPTModel(</span><br><span class="line">    (decoder): OPTDecoder(</span><br><span class="line">      (embed_tokens): Embedding(50272, 512, <span class="attribute">padding_idx</span>=1)</span><br><span class="line">      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)</span><br><span class="line">      (project_out): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (project_in): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (layers): ModuleList(</span><br><span class="line">        (0-23): 24 x OPTDecoderLayer(</span><br><span class="line">          (self_attn): OPTAttention(</span><br><span class="line">            (k_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (v_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (q_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (out_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          (activation_fn): ReLU()</span><br><span class="line">          (self_attn_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc1): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc2): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (final_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (lm_head): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=50272, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> get_peft_model</span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>],</span><br><span class="line">    init_lora_weights=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line">peft_model = get_peft_model(peft_model_base, lora_config)</span><br><span class="line">peft_model.print_trainable_parameters()</span><br></pre></td></tr></table></figure>
<p>使用lora_config获取到peft_model</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">PeftModel(</span><br><span class="line">  (base_model): LoraModel(</span><br><span class="line">    (model): OPTForCausalLM(</span><br><span class="line">      (model): OPTModel(</span><br><span class="line">        (decoder): OPTDecoder(</span><br><span class="line">          (embed_tokens): Embedding(50272, 512, <span class="attribute">padding_idx</span>=1)</span><br><span class="line">          (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)</span><br><span class="line">          (project_out): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">          (project_in): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">          (layers): ModuleList(</span><br><span class="line">            (0-23): 24 x OPTDecoderLayer(</span><br><span class="line">              (self_attn): OPTAttention(</span><br><span class="line">                (k_proj): Linear(</span><br><span class="line">                  <span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span></span><br><span class="line">                  (lora_dropout): ModuleDict(</span><br><span class="line">                    (default): Identity()</span><br><span class="line">                  )</span><br><span class="line">                  (lora_A): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=8, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_B): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=8, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_embedding_A): ParameterDict()</span><br><span class="line">                  (lora_embedding_B): ParameterDict()</span><br><span class="line">                )</span><br><span class="line">                (v_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">                (q_proj): Linear(</span><br><span class="line">                  <span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span></span><br><span class="line">                  (lora_dropout): ModuleDict(</span><br><span class="line">                    (default): Identity()</span><br><span class="line">                  )</span><br><span class="line">                  (lora_A): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=8, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_B): ModuleDict(</span><br><span class="line">                    (default): Linear(<span class="attribute">in_features</span>=8, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">                  )</span><br><span class="line">                  (lora_embedding_A): ParameterDict()</span><br><span class="line">                  (lora_embedding_B): ParameterDict()</span><br><span class="line">                )</span><br><span class="line">                (out_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">              )</span><br><span class="line">              (activation_fn): ReLU()</span><br><span class="line">              (self_attn_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">              (fc1): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">              (fc2): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">              (final_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (lm_head): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=50272, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用<code>peft_model.merge_and_unload()</code>得到融合后的model</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">OPTForCausalLM(</span><br><span class="line">  (model): OPTModel(</span><br><span class="line">    (decoder): OPTDecoder(</span><br><span class="line">      (embed_tokens): Embedding(50272, 512, <span class="attribute">padding_idx</span>=1)</span><br><span class="line">      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)</span><br><span class="line">      (project_out): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (project_in): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (layers): ModuleList(</span><br><span class="line">        (0-23): 24 x OPTDecoderLayer(</span><br><span class="line">          (self_attn): OPTAttention(</span><br><span class="line">            (k_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (v_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (q_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">            (out_proj): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          (activation_fn): ReLU()</span><br><span class="line">          (self_attn_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc1): Linear(<span class="attribute">in_features</span>=1024, <span class="attribute">out_features</span>=4096, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (fc2): Linear(<span class="attribute">in_features</span>=4096, <span class="attribute">out_features</span>=1024, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">          (final_layer_norm): LayerNorm((1024,), <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (lm_head): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=50272, <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="遇到的一些问题"><a href="#遇到的一些问题" class="headerlink" title="遇到的一些问题"></a>遇到的一些问题</h4><ol>
<li>数据集的处理,微调的template该如何写</li>
</ol>
<p>找到的例子</p>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/curiousily/Get-Things-Done-with-Prompt-Engineering-and-LangChain/blob/master/14.fine-tuning-llama-2-7b-on-custom-dataset.ipynb#scrollTo=eRbskn48QNfW">14.fine-tuning-llama-2-7b-on-custom-dataset.ipynb - Colaboratory (google.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1Ud2vVdjxs18qPCXG334E5rZfvo9b3nUN?usp=sharing#scrollTo=KfPuoMSrDD5-">Fine_tuned_Llama_PEFT_QLora.ipynb - Colaboratory (google.com)</a></p>
<p>在训练时使用一个template</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DEFAULT_SYSTEM_PROMPT = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Below is a conversation between a human and an AI agent. Write a summary of the conversation.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>.strip()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_training_prompt</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    conversation: <span class="built_in">str</span>, summary: <span class="built_in">str</span>, system_prompt: <span class="built_in">str</span> = DEFAULT_SYSTEM_PROMPT</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;system_prompt&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;conversation.strip()&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;summary&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>.strip()</span><br></pre></td></tr></table></figure>
<p>测试时</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_prompt</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    conversation: <span class="built_in">str</span>, system_prompt: <span class="built_in">str</span> = DEFAULT_SYSTEM_PROMPT</span></span></span><br><span class="line"><span class="params"><span class="function"></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;### Instruction: <span class="subst">&#123;system_prompt&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;conversation.strip()&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>.strip()</span><br></pre></td></tr></table></figure>
<ol>
<li><p>训练后得到的model是peftmodel还是什么类型的模型</p>
<p>一种方法是</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">repo_id = <span class="string">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span></span><br><span class="line">use_ram_optimized_load=<span class="literal">False</span></span><br><span class="line"></span><br><span class="line">base_model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    repo_id,</span><br><span class="line">    device_map=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">    trust_remote_code=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">base_model.config.use_cache = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p><code>base_model</code>是一个<code>LlamaForCausalLM</code>类,训练完后使用</p>
<p><code>trainer.save_model(&quot;Finetuned_adapter&quot;)</code>保存模型,然后使用<code>PeftModel.from_pretrained</code>得到PeftModel</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = PeftModel.from_pretrained(</span><br><span class="line">    base_model,</span><br><span class="line">    <span class="string">&quot;/content/Finetuned_adapter&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">merged_model = model.merge_and_unload()</span><br></pre></td></tr></table></figure>
<p>然后保存模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">merged_model.save_pretrained(<span class="string">&quot;/content/Merged_model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;/content/Merged_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>另一种是使用<code>AutoPeftModelForCausalLM</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AutoPeftModelForCausalLM</span><br><span class="line"></span><br><span class="line">trained_model = AutoPeftModelForCausalLM.from_pretrained(</span><br><span class="line">    OUTPUT_DIR,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">merged_model = model.merge_and_unload()</span><br><span class="line">merged_model.save_pretrained(<span class="string">&quot;merged_model&quot;</span>, safe_serialization=<span class="literal">True</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;merged_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://medium.com/walmartglobaltech/training-large-language-model-llm-on-your-data-2139eaad5f4f">Training Large Language Model (LLM) on your data | by Mohit Soni | Walmart Global Tech Blog | Aug, 2023 | Medium</a></li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148">A Practical Introduction to LLMs | By: Shawhin Talebi | Towards Data Science</a></li>
<li><a target="_blank" rel="noopener" href="https://www.lakera.ai/insights/llm-fine-tuning-guide">The Ultimate Guide to LLM Fine Tuning: Best Practices &amp; Tools | Lakera – Protecting AI teams that disrupt the world.</a></li>
<li>tutorial <a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/finetuning-large-language-models">https://learn.deeplearning.ai/finetuning-large-language-models</a></li>
</ol>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    
    <div>
	
     <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
     
   </div>
      

        <div class="reward-container">
  <div>感谢阅读.</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="Sekyoro 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Sekyoro
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www.sekyoro.top/2023/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/" title="大模型微调">https://www.sekyoro.top/2023/09/28/大模型微调/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wxqrcode.png">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/website.png">
            <span class="icon">
              <i class="fa fa-user"></i>
            </span>

            <span class="label">PersonalWebsite</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://my-astro-git-main-drowning-in-codes.vercel.app">
            <span class="icon">
              <i class="fas fa-share"></i>
            </span>

            <span class="label">杂鱼分享</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/llm/" rel="tag"><i class="fa fa-tag"></i> llm</a>
              <a href="/tags/finetune/" rel="tag"><i class="fa fa-tag"></i> finetune</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/09/26/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" rel="prev" title="风格迁移">
      <i class="fa fa-chevron-left"></i> 风格迁移
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/09/29/HFNLP%E5%AD%A6%E4%B9%A0/" rel="next" title="HFNLP学习">
      HFNLP学习 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
		  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123"
     crossorigin="anonymous"></script>
<!-- 评论区 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4034523802263123"
     data-ad-slot="6333657257"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81MzE5Ny8yOTY3Mg=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>
	
  <aside class="sidebar">
    <div class="sidebar-inner">
      	   
          <!-- canvas粒子时钟 -->
          <div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>
        

<!-- require APlayer -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
<!-- require MetingJS -->

<script src="/js/meting-js.js"></script>
	  
      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>
	  
      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%A8%A1%E5%9E%8BLLM"><span class="nav-number">1.</span> <span class="nav-text">什么是大模型LLM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Prompt-Engineering"><span class="nav-number">1.1.</span> <span class="nav-text">Prompt Engineering</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Embeddings"><span class="nav-number">1.2.</span> <span class="nav-text">Embeddings</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fine-tuning"><span class="nav-number">1.3.</span> <span class="nav-text">Fine tuning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Fine-tuning%E6%8A%80%E6%9C%AF"><span class="nav-number">1.3.1.</span> <span class="nav-text">Fine tuning技术</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#old-school"><span class="nav-number">1.3.2.</span> <span class="nav-text">old school</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LLM%E5%BE%AE%E8%B0%83%E7%9A%84%E5%89%8D%E6%B2%BF%E7%AD%96%E7%95%A5"><span class="nav-number">1.3.3.</span> <span class="nav-text">LLM微调的前沿策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="nav-number">1.3.4.</span> <span class="nav-text">训练流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PEFT%E8%AE%AD%E7%BB%83adapters"><span class="nav-number">1.3.5.</span> <span class="nav-text">PEFT训练adapters</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E6%88%98"><span class="nav-number">1.4.</span> <span class="nav-text">实战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E6%89%80%E9%9C%80%E5%8C%85"><span class="nav-number">1.4.1.</span> <span class="nav-text">下载所需包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">1.4.2.</span> <span class="nav-text">数据处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.4.3.</span> <span class="nav-text">训练设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E7%BB%AD%E8%AF%84%E4%BC%B0%E6%B5%8B%E8%AF%95"><span class="nav-number">1.4.4.</span> <span class="nav-text">训练与后续评估测试</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F"><span class="nav-number">1.4.5.</span> <span class="nav-text">注意</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="nav-number">1.4.6.</span> <span class="nav-text">遇到的一些问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">2.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
      </div>
      <!--/noindex-->
      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sekyoro"
      src="https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg">
  <p class="site-author-name" itemprop="name">Sekyoro</p>
  <div class="site-description" itemprop="description">什么也无法舍弃的人，什么也做不了.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">145</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">176</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="http://proanimer.com/" title="Personal Website → http:&#x2F;&#x2F;proanimer.com" rel="noopener" target="_blank"><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/drowning-in-codes" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;drowning-in-codes" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:bukalala174@gmail.com" title="E-Mail → mailto:bukalala174@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" title="wxPublicAccount → https:&#x2F;&#x2F;mp.weixin.qq.com&#x2F;s?__biz&#x3D;Mzg3ODY1MDkzMg&#x3D;&#x3D;&amp;mid&#x3D;2247483770&amp;idx&#x3D;1&amp;sn&#x3D;fdf88faab01d5c219ac609570a21c9d6&amp;chksm&#x3D;cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&amp;token&#x3D;1096259873&amp;lang&#x3D;zh_CN#rd" rel="noopener" target="_blank"><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/aqwca" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;aqwca" rel="noopener" target="_blank"><i class="fa fa-handshake fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://my-astro-git-main-drowning-in-codes.vercel.app/" title="杂鱼分享 → https:&#x2F;&#x2F;my-astro-git-main-drowning-in-codes.vercel.app" rel="noopener" target="_blank"><i class="fas fa-share fa-fw"></i>杂鱼分享</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://myqhs.top/" title="http:&#x2F;&#x2F;myqhs.top&#x2F;" rel="noopener" target="_blank">myqhs</a>
        </li>
    </ul>
  </div>


  <div class="motion-element announcement">
   <div class="title">注意</div>
   <p class="content">由于最近图床更新,可能有些图片显示不了.如果发现了有些图片无法显示影响阅读的,还烦请联系我,我有空补上. </p>
   <p class="date"> 2023-10-6 </p>
  </div>
      </div>
<meting-js
	id="6856787487"
	server="netease"
	type="playlist"
	order="random"
	>
</meting-js>
			<div class="widget-wrap">
    <h3 class="widget-title" style="margin:0">文章词云</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width:100%">
		  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/finetune/" rel="tag">finetune</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/llm/" rel="tag">llm</a><span class="tag-list-count">1</span></li></ul>	
        </canvas>
    </div>
</div>
		<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a"></script>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
	 
	 <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123"
     crossorigin="anonymous"></script>
<!-- 边栏 -->

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4034523802263123"
     data-ad-slot="6549565089"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
	 
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
	 
	
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>
  


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sekyoro</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">857k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">12:59</span>
</div>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

<div>
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	'.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script data-pjax>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>










<script data-pjax>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




    <div id="pjax">
  

  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>
 

<script>
  var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });
</script>



  <script src="/js/src/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>


    </div>  
  
  <script  type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script  type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>

<!-- hexo injector body_end start --><script src='/js/outdate.js'></script><!-- hexo injector body_end end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>