<!doctypehtml><html lang=zh-CN><script defer src=/live2d-widget/autoload.js></script><meta charset=UTF-8><meta content=width=device-width,initial-scale=1,maximum-scale=2 name=viewport><meta content=#222 name=theme-color><meta content="Hexo 5.4.0" name=generator><link href=/images/blog_32px.png rel=apple-touch-icon sizes=180x180><link href=/images/blog_32px.png rel=icon sizes=32x32 type=image/png><link href=/images/blog_16px.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><meta content=EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w name=google-site-verification><!-- Google tag (gtag.js) --><!-- 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script> --><!-- google adsense in head.swig --><script async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123></script><meta content=7226864CE87CE9DE8C008385273846FF name=msvalidate.01><meta content=code-fjFXVtiL7j name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link as=style href=https://fonts.googleapis.com/css?family=Roboto%20Mono,Roboto:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext onload=this.rel='stylesheet' rel=preload><link as=style href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css onload=this.rel='stylesheet' rel=preload><link href=https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap rel=stylesheet><link href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/pace-js@1/pace.min.js></script><script id=hexo-configurations>var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"0F9LEEVW82","apiKey":"78839e9f9be09d081c5c4da81975cd19","indexName":"sekyoblog_sec","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};</script><link href=//cdn.bootcss.com/animate.css/3.5.0/animate.min.css rel=stylesheet><meta content=因为redis与mysql经常搭配使用,也是面试常问,这里记录一些常见基础题. name=description><meta content=article property=og:type><meta content=redis核心技术 property=og:title><meta content=https://www.sekyoro.top/2025/07/10/redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/index.html property=og:url><meta content=Sekyoro的博客小屋 property=og:site_name><meta content=因为redis与mysql经常搭配使用,也是面试常问,这里记录一些常见基础题. property=og:description><meta content=zh_CN property=og:locale><meta content=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752755991314-2f20e3b3-9aa3-4494-bf49-48ea529daaf7.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752735691205-f5e95d48-30b5-4f75-886b-d321246a6a77.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752740565844-5373d0d1-51aa-4572-9842-2c0ad7416c15.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752740956433-3ffaded7-66fa-450f-8960-cf5cfdfe2094.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752742351171-8abf2081-55b0-42d1-80ad-3692cbbbc49a.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752742682775-a2f8b405-48fa-4fa5-9c48-93b8ca085971.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752743224388-30fd1e2a-362e-4f23-84e1-2498b98e8850.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752736677683-1a2ca974-682c-4d81-a4e8-3b866ab460bb.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752739931411-abef6f94-f5c5-4f97-a7b6-8d82e679ae31.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752739974643-1ab9714e-98ee-4688-8413-43b85fdb889a.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752744992659-b6fc6e10-806b-4e27-a53d-6f6996678a18.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752745139855-32e93a45-508f-403c-802f-e2e1802b4db5.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752745172030-d6a56f19-6bcf-4fbd-84ae-5764a208ee72.png property=og:image><meta content=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752745179378-a96e1d60-a238-4212-bf17-70cac9a3259d.png property=og:image><meta content=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/454a8228a6549176ad7e0484fba3c92b.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/cc208c2931b4e889d1a58cb655537767.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/1cc7401143e79383ead96582ac11b615.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/c34a9d1f58d602ff1fe8601f7270baa7-20230309232304226.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/4eeef4dd1bedd2ffe0b84d4eaa0dbdea-20230309232249413.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/98987d9417b2bab43087f45fc959d32a-20230309232253633.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/723d6c580c05400b3841bc69566dd61b-20230309232257343.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309232301042.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/2b7231b6aabb9a9a2e2390ab3a280b2d.png property=og:image><meta content=https://cdn.xiaolincoding.com//mysql/other/26f88373d8454682b9e0c1d4fd1611b4.png property=og:image><meta content=https://cdn.xiaolincoding.com//picgo/1d4685f1f19d72aff8412498c05bed4a.png property=og:image><meta content=https://cdn.xiaolincoding.com//picgo/fe3703c3d045462a12b41a628ff26825.png property=og:image><meta content=https://cdn.xiaolincoding.com//picgo/cd36f67141ebab2e43b2371a7fd51c8c.png property=og:image><meta content=https://cdn.xiaolincoding.com//picgo/9ca67fa36a0c084e315e843e6ef46197.png property=og:image><meta content=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.jpg property=og:image><meta content=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97.png property=og:image><meta content=2025-07-10T05:47:30.000Z property=article:published_time><meta content=2025-08-05T12:01:51.172Z property=article:modified_time><meta content=Sekyoro property=article:author><meta content=Redis property=article:tag><meta content=summary name=twitter:card><meta content=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png name=twitter:image><link href=https://www.sekyoro.top/2025/07/10/redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/ rel=canonical><script id=page-configurations>// https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };</script><title>redis核心技术 | Sekyoro的博客小屋</title><noscript><style>.use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }</style></noscript><link href=/atom.xml rel=alternate title=Sekyoro的博客小屋 type=application/atom+xml><body itemscope itemtype=http://schema.org/WebPage><canvas style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" class=fireworks></canvas><script defer src=https://cdn.bootcss.com/animejs/2.2.0/anime.min.js></script><script defer src=/js/src/fireworks.js></script><div class="container use-motion"><div class=headband></div><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <h1 class=site-title>Sekyoro的博客小屋</h1> <span class=logo-line-after><i></i></span> </a></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu" id=menu><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-bangumis"><a href=/bangumis/ rel=section><i class="fa fa-film fa-fw"></i>追番</a><li class="menu-item menu-item-resume"><a href=/resume/ rel=section><i class="fa fa-file-pdf fa-fw"></i>简历</a><li class="menu-item menu-item-materials"><a href=/materials/ rel=section><i class="fa fa-book fa-fw"></i>学习资料</a><li class="menu-item menu-item-sitemap"><a href=/sitemap.xml rel=section><i class="fa fa-sitemap fa-fw"></i>站点地图</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container></div><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span></div><div class=algolia-results><div id=algolia-stats></div><div id=algolia-hits></div><div class=algolia-pagination id=algolia-pagination></div></div></div></div></div></header><a class="book-mark-link book-mark-link-fixed" role=button></a><main class=main><div class=main-inner><div class=content-wrap><div class="content post posts-expand"><article class=post-block itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://www.sekyoro.top/2025/07/10/redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg itemprop=image> <meta content=Sekyoro itemprop=name> <meta content=什么也无法舍弃的人，什么也做不了. itemprop=description> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=Sekyoro的博客小屋 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>redis核心技术</h1><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-07-10 13:47:30" datetime=2025-07-10T13:47:30+08:00>2025-07-10</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-08-05 20:01:51" datetime=2025-08-05T20:01:51+08:00 itemprop=dateModified>2025-08-05</time> </span><span style="display: none;" class=post-meta-item id=busuanzi_container_page_pv title=阅读次数> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=post-meta-item-text>阅读次数：</span> <span id=busuanzi_value_page_pv></span> </span><br><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>36k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>33 分钟</span> </span></div></header><div class=post-body itemprop=articleBody><p>因为redis与mysql经常搭配使用,也是面试常问,这里记录一些常见基础题.<br><span id=more></span><h1 id=数据类型与单线程模型><a class=headerlink href=#数据类型与单线程模型 title=数据类型与单线程模型></a>数据类型与单线程模型</h1><h2 id=常用数据类型实现以及使用场景><a class=headerlink href=#常用数据类型实现以及使用场景 title=常用数据类型实现以及使用场景></a>常用数据类型实现以及使用场景</h2><p><img alt=img data-src=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png><h4 id=String><a class=headerlink href=#String title=String></a>String</h4><p>实现:简单动态字符串<p>Redis 的字符串是<strong>二进制安全的</strong>，这意味着它们可以存储任何类型的数据，例如文本、图片或序列化的对象。<ul><li><strong>短字符串：</strong> 当字符串较短时（小于 44 字节），Redis 会使用 <code>embstr</code> 编码，将 <code>redisObject</code> 结构和字符串本身一起分配在一块连续的内存区域，从而减少内存碎片和提高存取效率。<li><strong>长字符串：</strong> 当字符串较长时，会使用 <code>raw</code> 编码，<code>redisObject</code> 指向一个单独分配的 SDS (Simple Dynamic String) 结构。SDS 不仅存储字符串内容，还包含长度信息和可用空间，使得字符串操作（如追加）更高效，并避免 C 语言字符串常见的缓冲区溢出问题。<li>如果存储的是整数值,并且大小在LONG_MAX范围则会采用INT编码,直接保存在redisObject的ptr位置,不再需要SDS</ul><p><strong>使用场景：</strong><ul><li><strong>缓存：</strong> 最常见的用途，存储用户会话、商品信息、HTML 片段等。<li><strong>计数器：</strong> 使用 <code>INCR</code>、<code>DECR</code> 命令实现网站访问量、点赞数、商品库存等。<li><strong>分布式锁：</strong> 利用 <code>SETNX</code> (SET if Not eXists) 命令实现分布式锁。<li><strong>限流：</strong> 结合过期时间对某个操作进行限流。</ul><h4 id=List><a class=headerlink href=#List title=List></a>List</h4><p>Redis 列表是<strong>有序的字符串列表</strong>，底层实现随着版本和元素数量、大小的变化而变化，目的是优化内存和性能。<ul><li><strong><code>ziplist</code> (压缩列表)：</strong> 当列表元素较少且每个元素较小时，Redis 会使用 <code>ziplist</code> 编码。<code>ziplist</code> 是一块连续的内存，元素紧凑存储，内存效率很高。<li><strong><code>quicklist</code> (快速列表)：</strong> Redis 3.2 之后，<code>quicklist</code> 成为了列表的主要底层实现。<code>quicklist</code> 是一个由多个 <code>ziplist</code> 组成的双向链表。每个 <code>quicklist</code> 节点内部是一个 <code>ziplist</code>，存储少量元素，这样既利用了 <code>ziplist</code> 的内存效率，又保留了链表的快速增删和两端操作的特性。<li><strong><code>linkedlist</code> (双向链表)：</strong> 在很旧的版本中，当元素较多或较大时，会使用 <code>linkedlist</code>。但现在 <code>quicklist</code> 已经取代了它的地位。</ul><p><strong>使用场景：</strong><ul><li><strong>消息队列：</strong> <code>LPUSH</code> (左边入队) 和 <code>RPOP</code> (右边出队) 实现先进先出 (FIFO) 队列。<li><strong>任务队列：</strong> <code>BRPOP</code> (阻塞右边出队) 实现消费者阻塞等待任务。<li><strong>最新消息/动态：</strong> <code>LPUSH</code> 添加新消息，<code>LRANGE</code> 获取最新消息列表（如微博时间线、文章评论）。<li><strong>栈：</strong> <code>LPUSH</code> (入栈) 和 <code>LPOP</code> (出栈) 实现后进先出 (LIFO) 栈。</ul><h4 id=Hash><a class=headerlink href=#Hash title=Hash></a>Hash</h4><p>Redis 哈希表用于存储<strong>字段-值对</strong>的集合，类似于 Java 的 <code>HashMap</code> 或 Python 的字典。<ul><li><strong><code>ziplist</code> (压缩列表)：</strong> 当哈希表的字段数量较少且字段值较小时，Redis 会使用 <code>ziplist</code> 编码。<li><strong><code>hashtable</code> (哈希表)：</strong> 当哈希表的字段数量或字段值较大时，Redis 会使用 <code>hashtable</code> 编码，这是一个真正的哈希表，基于数组和链表实现，支持动态扩容和缩容。</ul><p><strong>使用场景：</strong><ul><li><strong>存储对象：</strong> 存储用户资料、商品信息等，可以将一个对象的所有字段存储为一个哈希表的字段。<li><strong>购物车：</strong> 用户 ID 作为键，商品 ID 和数量作为哈希表的字段和值。<li><strong>计数器：</strong> 存储多个相关联的计数器，例如文章的点赞数、评论数和阅读数。</ul><h4 id=Set><a class=headerlink href=#Set title=Set></a>Set</h4><p>Redis 集合是<strong>无序的、不重复的字符串集合</strong>。<ul><li><strong><code>intset</code> (整数集合)：</strong> 当集合中只包含整数值，且元素数量较少时，Redis 会使用 <code>intset</code> 编码，它将整数有序地存储在一块连续的内存区域中，内存效率高。<li><strong><code>hashtable</code> (哈希表)：</strong> 当集合中包含非整数值，或者元素数量较多时，Redis 会使用 <code>hashtable</code> 编码。哈希表的键用于存储集合元素，值则被设置为 <code>NULL</code>，表示只有键有意义。</ul><p><strong>使用场景：</strong><ul><li><strong>标签系统：</strong> 存储文章的标签、用户的兴趣爱好。<li><strong>共同好友/关注：</strong> 使用 <code>SINTER</code> 命令计算共同好友。<li><strong>随机抽取：</strong> <code>SRANDMEMBER</code> 随机抽取集合中的元素（如抽奖）。<li><strong>判断某个元素是否存在：</strong> <code>SISMEMBER</code> 复杂度为 O(1)。<li><strong>去重：</strong> 自动去重。</ul><h4 id=ZSet><a class=headerlink href=#ZSet title=ZSet></a>ZSet</h4><p>Redis 有序集合是<strong>字符串集合，每个成员都会关联一个分数 (score)</strong>。集合中的成员是唯一的，但分数可以重复。元素总是按照分数进行升序排列，如果分数相同，则按字典序排列。<ul><li><strong><code>ziplist</code> (压缩列表)：</strong> 当有序集合的成员数量较少且成员和分数较小时，Redis 会使用 <code>ziplist</code> 编码。<li><strong><code>skiplist</code> (跳跃表) 和 <code>hashtable</code> (哈希表)：</strong> 当有序集合的成员数量或大小超出 <code>ziplist</code> 限制时，Redis 会同时使用 <code>skiplist</code> 和 <code>hashtable</code>。<ul><li><strong><code>skiplist</code>：</strong> 用于按分数范围或成员排名快速查找，高效支持范围查询和排名操作。<li><strong><code>hashtable</code>：</strong> 用于存储成员到分数的映射，实现 O(1) 复杂度的按成员查找分数。</ul></ul><p><strong>使用场景：</strong><ul><li><strong>排行榜：</strong> 游戏积分榜、商品销量榜、点赞数排行榜等。<li><strong>带权重的任务队列：</strong> 优先级队列，分数代表任务优先级或执行时间。<li><strong>范围查询：</strong> 获取分数在某个范围内的成员列表。<li><strong>按距离排序：</strong> 例如地理位置附近的人（结合地理哈希）。</ul><h3 id=使用的底层数据结构><a class=headerlink href=#使用的底层数据结构 title=使用的底层数据结构></a>使用的底层数据结构</h3><h4 id=简单动态字符串><a class=headerlink href=#简单动态字符串 title=简单动态字符串></a>简单动态字符串</h4><p>编码类型:RAW,EMBSTR,INT<p>相比于普通c语言字符数组优点:<p>不仅可以保存文本数据还可以保存二进制数据. 使用len属性表示长度,不以’\0’结尾,二进制安全<p>获取字符串长度O(1),拼接字符串等操作不会造成内存溢出,因为会进行预先分配空间.<p>基本编码方式是RAW,存储上限512MB,如果存储的SDS长度小于44字节，则会采用EMBSTR编码,内存变为连续的(而不是通过redisObject的ptr指向). 原因是redis底层分配内存以2^n使得redisObject小于64字节,减少了内存分配.<p>如果存储的是整数值,并且大小在LONG_MAX范围则会采用INT编码,直接保存在redisObject的ptr位置,不再需要SDS.<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752755991314-2f20e3b3-9aa3-4494-bf49-48ea529daaf7.png><h4 id=intset><a class=headerlink href=#intset title=intset></a>intset</h4><p>intset中元素唯一有序,具备类型升级机制,节省内存空间,底层采用二分查找<p>intset包含编码类型，元素个数与整数数组. 编码类型指定包含元素的类型<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752735691205-f5e95d48-30b5-4f75-886b-d321246a6a77.png><h4 id=ziplist><a class=headerlink href=#ziplist title=ziplist></a>ziplist</h4><p>特殊的双端链表,<strong>由一系列特殊编码的连续内存块组成</strong>. 可以在任意一端进行压入/弹出操作O(1)<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752740565844-5373d0d1-51aa-4572-9842-2c0ad7416c15.png><p>ntry每个节点也包含三个结构<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752740956433-3ffaded7-66fa-450f-8960-cf5cfdfe2094.png><p>包含上一个节点长度,编码属性,实际数据<p>编码属性记录了content的数据类型以及该entry内容的总长度.<p>如果是字符串<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752742351171-8abf2081-55b0-42d1-80ad-3692cbbbc49a.png><p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752742682775-a2f8b405-48fa-4fa5-9c48-93b8ca085971.png><p>ziplist连锁更新问题,注意到其中每个节点有个previous_entry_length包含前一个节点占用字节数,而且是动态变化的,也就是说如果一个节点存储数据增加,导致占用字节数增加,当达到previous_entry_length一个阈值时导致后续节点字节数也增加,又恰好导致后续的节点占用字节数增加…<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752743224388-30fd1e2a-362e-4f23-84e1-2498b98e8850.png><p>listpack引入为 Redis 设计的<strong>紧凑型（compact）数据结构</strong>，用于高效地存储小型的列表（List）、哈希（Hash）、有序集合（Sorted Set）和集合（Set）的元素。它的主要目标是<strong>减少内存开销</strong>，特别是当这些数据结构包含少量、小尺寸的元素时<h4 id=quicklist><a class=headerlink href=#quicklist title=quicklist></a>quicklist</h4><h4 id=dict><a class=headerlink href=#dict title=dict></a>dict</h4><p>dict包括字典,哈希表以及哈希节点.<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752736677683-1a2ca974-682c-4d81-a4e8-3b866ab460bb.png><p>dict的渐进式rehash<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752739931411-abef6f94-f5c5-4f97-a7b6-8d82e679ae31.png><p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752739974643-1ab9714e-98ee-4688-8413-43b85fdb889a.png><p>Dict内存不连续,使用指针过多,造成内存浪费<h4 id=skiplist><a class=headerlink href=#skiplist title=skiplist></a>skiplist</h4><p>ziplist与quicklist都需要不断遍历查询,跳表目的是提高查询效率<p>其元素按序排列存储,节点可能包含多个指针,指针跨度不同.<p>相当于分层的指针,一级指针包含所有元素,从最高级出发,如果没找到就跳到下一级<p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752744992659-b6fc6e10-806b-4e27-a53d-6f6996678a18.png><p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752745139855-32e93a45-508f-403c-802f-e2e1802b4db5.png><p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752745172030-d6a56f19-6bcf-4fbd-84ae-5764a208ee72.png><p><img alt=img data-src=https://cdn.nlark.com/yuque/0/2025/png/25410833/1752745179378-a96e1d60-a238-4212-bf17-70cac9a3259d.png><h4 id=listpack><a class=headerlink href=#listpack title=listpack></a>listpack</h4><p>在 Redis 5.0 中，<code>listpack</code> 是一种全新的、更高效的编码方式，它被设计用来完全取代 <code>ziplist</code>，成为 <strong>Hash、List 和 Sorted Set</strong> 等数据结构在元素数量较少且元素值较小时的底层优化存储。<p><code>ziplist</code> 存在一个著名的缺陷叫做<strong>连锁更新 (Cascade Update)</strong>。<ul><li><code>ziplist</code> 中的每个元素在存储时，除了自身内容，还会存储<strong>前一个元素的长度</strong>。<li>如果前一个元素的长度发生变化，导致其存储的“前一个元素的长度”字段本身的编码长度也需要变化，就会引起一系列的连锁反应，导致后面所有元素的“前一个元素长度”字段都需要更新，可能带来 O(N) 的性能开销。<li>尽管 Redis 会尽量避免这种情况，但在特定场景下（例如大量小元素紧密排列，然后头部元素长度变化），连锁更新依然可能发生，影响性能。</ul><p>为了解决 <code>ziplist</code> 的这个根本性问题，Redis 5.0 引入了 <code>listpack</code>。<p><code>listpack</code> 的设计目标是：<strong>保持 <code>ziplist</code> 的紧凑内存布局，同时彻底避免连锁更新问题。</strong><ol><li><strong>连续内存块：</strong> 类似于 <code>ziplist</code>，<code>listpack</code> 也是将所有元素存储在<strong>一块连续的内存区域</strong>中，没有指针开销，内存效率极高。<li><strong>独立的元素编码：</strong> 这是 <code>listpack</code> 与 <code>ziplist</code> 最根本的区别。<ul><li>在 <code>listpack</code> 中，每个元素不再存储前一个元素的长度。<li>每个元素在编码时，会先记录<strong>自身内容的长度</strong>，然后才是实际内容。这意味着每个元素都是<strong>独立编码</strong>的，修改一个元素的长度不会影响到它前后的元素。</ul><li><strong>支持向前和向后遍历：</strong> 虽然不存储前一个元素的长度，但 <code>listpack</code> 仍然支持双向遍历。<ul><li>每个元素在编码自身长度时，会使用一种特殊的编码方式，使得可以从当前位置快速地计算出下一个元素的起始位置，以及从当前位置快速地找到前一个元素的起始位置。这通过在元素的末尾额外存储一个小的“反向跳跃”信息来实现（通常是元素总长度）。</ul><li><strong>变长编码：</strong> 元素内容和长度信息都采用变长编码，根据实际大小动态调整，进一步节省空间。</ol><p>Listpack 的优缺点<p><strong>优点：</strong><ul><li><strong>彻底解决连锁更新问题：</strong> 这是 <code>listpack</code> 最核心的优势。因为它移除了对前一个元素长度的依赖，修改一个元素不会引起连锁反应，从而保证了 O(1) 的插入和删除复杂度（在不考虑内存重新分配和数据移动的情况下）。<li><strong>内存效率高：</strong> 依然保持了紧凑的内存布局，没有指针开销，与 <code>ziplist</code> 相似。<li><strong>支持双向遍历：</strong> 虽然没有前驱长度信息，但巧妙的编码方式使其依然支持从两端高效地遍历。<li><strong>实现和维护相对简单：</strong> 相较于 <code>ziplist</code> 处理连锁更新的复杂逻辑，<code>listpack</code> 的内部逻辑更清晰。</ul><p><strong>缺点：</strong><ul><li><strong>插入和删除的内存移动：</strong> 尽管避免了连锁更新，但由于是连续内存，在中间位置进行插入或删除操作时，仍然需要对后续元素进行<strong>内存拷贝和移动</strong>，最坏情况下是 O(N) 复杂度。因此，<code>listpack</code> 仍然不适合存储大量元素或频繁在中间位置变动的场景。</ul><h4 id=BitMap><a class=headerlink href=#BitMap title=BitMap></a>BitMap</h4><p>Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行的设置，表示某个元素的值或者状态，时间复杂度为O(1)。<p>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。<p>Bitmap 实际上就是普通的 Redis 字符串。一个字节有 8 位，所以 Redis 会将你设置的位映射到字符串的相应字节和位上。例如，设置第 0 位会影响第一个字节的第一个位，设置第 8 位会影响第二个字节的第一个位。<h4 id=Hyperloglog><a class=headerlink href=#Hyperloglog title=Hyperloglog></a>Hyperloglog</h4><p>HyperLogLog 是一种用于<strong>基数估算</strong>（即统计一个集合中不重复元素的数量，例如独立访客 UV）的概率型数据结构。它不是精确计数，而是以<strong>极小的内存开销</strong>（Redis 中每个 HyperLogLog 键固定占用 12KB 内存）来<strong>估算</strong>海量数据的基数，标准误差通常在 0.81% 左右。<p><strong>底层实现：</strong> HyperLogLog 基于 LogLog 算法的改进版，通过对输入元素进行哈希处理，并观察哈希值中前导零的数量来估算基数。它内部维护一个稀疏或密集表示的寄存器数组。<h4 id=geo><a class=headerlink href=#geo title=geo></a>geo</h4><p>Geo 是 Redis 3.2 引入的数据结构，用于存储地理空间信息（经度、纬度），并能够执行基于距离的查询。它实际上是<strong>有序集合 (Sorted Set) 的一个特化</strong>，利用 GeoHash 算法将二维的经纬度数据转换为一维的字符串，并存储在 Sorted Set 中。<h4 id=stream><a class=headerlink href=#stream title=stream></a>stream</h4><p>消息队列,相比于基于list实现的消息队列,支持:生成全局唯一id以及以消费者组形式消费数据.<p>Stream 是 Redis 5.0 引入的全新数据结构，它是一个<strong>只追加的（append-only）\</strong>数据结构，主要用于实现*<em>消息队列<strong>、</strong>事件日志<strong>和</strong>时间序列数据存储*</em>。它支持多消费者组模式，能够持久化消息，并允许消费者从指定位置开始读取。<h3 id=常用操作><a class=headerlink href=#常用操作 title=常用操作></a>常用操作</h3><h4 id=bitmaps><a class=headerlink href=#bitmaps title=bitmaps></a>bitmaps</h4><p>BITFILED key GET u[dayOfMonth] 0<p>获得这个月截止到今天的签到情况<p>BITCOUNT key start end<p>获取从start到end范围为1的值<h4 id=stream消息队列><a class=headerlink href=#stream消息队列 title=stream消息队列></a>stream消息队列</h4><p>XADD key id field value<p>XREAD<p>XGROUP CREATE key groupname ID<p>XREADGROUP GROUP groupname<p>XACK key groupname ID 确认处理<p>XPENDING 查看待处理的(未ACK)的消息<h2 id=单线程模型><a class=headerlink href=#单线程模型 title=单线程模型></a>单线程模型</h2><p>Redis 的“单线程”指的是其<strong>核心命令执行引擎是单线程的</strong><h3 id=Redis-为什么选择单线程？><a title="Redis 为什么选择单线程？" class=headerlink href=#Redis-为什么选择单线程？></a>Redis 为什么选择单线程？</h3><p>在多线程并发编程中，为了保证数据的一致性，通常需要引入锁（互斥锁、读写锁等）来同步对共享资源的访问。锁会带来以下问题：<ul><li><strong>性能开销：</strong> 锁的获取和释放会消耗 CPU 资源，并且可能导致上下文切换。<li><strong>死锁和活锁：</strong> 多线程编程中常见的复杂并发问题。<li><strong>代码复杂性：</strong> 编写和维护正确的并发代码非常困难，容易出错。</ul><p>Redis 的作者认为，<strong>CPU 并不是 Redis 的主要瓶颈</strong>。对于内存数据库来说，瓶颈通常在于：<ul><li><strong>内存访问：</strong> Redis 是内存数据库，数据操作主要在内存中进行，速度非常快。<li><strong>网络 I/O：</strong> 客户端与 Redis 服务器之间的网络传输。</ul><p>因此，如果能避免多线程带来的复杂性和开销，而将主要精力放在优化内存操作和网络 I/O 上，反而能实现更高的性能和更简洁的设计。<p>Redis 的单线程模型主要基于 <strong>I/O 多路复用 (I/O Multiplexing)</strong> 技术，例如 Linux 上的 <code>epoll</code>、macOS 上的 <code>kqueue</code> 等。<p>其工作流程可以概括为：<ol><li><strong>I/O 多路复用器：</strong> Redis 的主线程使用 I/O 多路复用器来监听多个套接字（客户端连接）上的事件，例如连接建立、数据可读、数据可写等。<li><strong>事件循环 (Event Loop)：</strong> 主线程在一个无限循环中，不断地从 I/O 多路复用器中获取已经就绪的事件。<li><strong>串行执行：</strong> 每当一个事件就绪时（例如某个客户端发送了命令），Redis 主线程会将其对应的命令从事件队列中取出，<strong>串行地执行</strong>该命令。<li><strong>返回结果：</strong> 命令执行完成后，结果会被放入响应缓冲区，并等待网络 I/O 就绪后发送给客户端。</ol><p><strong>核心优势：</strong><ul><li><strong>无锁竞争：</strong> 因为所有命令都在一个线程中串行执行，Redis 内部的数据结构（如哈希表、跳跃表等）无需加锁，避免了锁带来的性能损耗和复杂性。<li><strong>简单高效：</strong> 避免了多线程并发控制的复杂性，使得代码更简洁，更容易维护和优化。<li><strong>高吞吐量：</strong> 内存操作速度快，I/O 多路复用使得单个线程能够同时处理大量并发连接，充分利用 CPU 的等待时间。</ul><p>虽然核心命令执行是单线程的，但为了进一步提升性能和处理一些耗时的后台任务，Redis 引入了少量其他线程：<p><img alt=img data-src=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg><p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。<p>关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：<ul><li>BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；<li>BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘.<li><p>BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象</p><li><p><strong>Redis 6.0 引入多线程 I/O (可选)：</strong></p> <ul><li>这是 Redis 单线程模型在<strong>网络 I/O 层面</strong>的重大突破。<li>在 Redis 6.0 之后，你可以选择开启多线程 I/O。这意味着在<strong>解析客户端请求数据</strong>和<strong>向客户端回写响应数据</strong>这两个阶段，Redis 可以使用多个 I/O 线程并行处理。<li><strong>关键点：</strong> 即使开启了多线程 I/O，<strong>核心的命令执行（读写内存数据）仍然是单线程的</strong>。多线程 I/O 只是将网络数据的读取、协议解析以及响应的序列化、发送等任务并行化，从而减少了主线程在这些 I/O 上的耗时。<li>这对于处理大量小请求的场景，可以显著提高吞吐量。</ul></ul><p><strong>核心命令执行：</strong> 单线程，保证数据一致性，避免锁开销。<p><strong>I/O 多路复用：</strong> 单线程也能高效处理大量并发连接。<p><strong>后台任务：</strong> 部分耗时任务（如大键删除）或通过 <code>fork</code> 子进程（AOF 重写、RDB 持久化）或通过少量后台线程异步执行，避免阻塞主线程。<p><strong>Redis 6.0+ 的网络 I/O：</strong> 可以选择性地开启多线程，用于<strong>网络数据的读写和协议解析</strong>，但命令执行仍然单线程。<h1 id=缓存><a class=headerlink href=#缓存 title=缓存></a>缓存</h1><h2 id=缓存更新策略><a class=headerlink href=#缓存更新策略 title=缓存更新策略></a>缓存更新策略</h2><p>常见的缓存更新策略共有3种：<ul><li>Cache Aside（旁路缓存）策略；<li>Read/Write Through（读穿 / 写穿）策略；<li>Write Back（写回）策略；</ul><p>Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。<p><strong>写策略的步骤：</strong><ul><li>先更新数据库中的数据，再删除缓存中的数据。</ul><p><strong>读策略的步骤：</strong><ul><li>如果读取的数据命中了缓存，则直接返回数据；<li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</ul><p>注意，写策略的步骤的顺序不能倒过来，即<strong>不能先删除缓存再更新数据库</strong>，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。<p><strong>Read/Write Through（读穿 / 写穿）策略</strong><p>Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。<p><strong><em>1、Read Through 策略</em></strong><p>先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。<p><strong><em>2、Write Through 策略</em></strong><p>当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：<ul><li>如果缓存中数据已经存在，<strong>则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成</strong>。<li>如果缓存中数据不存在，直接更新数据库，然后返回；</ul><p>Read Through/Write Through 策略的特点是由缓存节点而非应用程序来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 <strong>Redis 都不提供写入数据库和自动加载数据库中的数据的功能</strong>。而在使用本地缓存的时候可以考虑使用这种策略。<p><strong>Write Back（写回）策略</strong><p>Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。<p>实际上，Write Back（写回）策略也不能应用到我们常用的数据库和缓存的场景中，因为 Redis 并没有异步更新数据库的功能。<p>Write Back 是计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存都采用了 Write Back（写回）策略。<p><strong>Write Back 策略特别适合写多的场景</strong>，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。<p><strong>但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险</strong>，因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的。<h2 id=缓存雪崩、穿透、击穿><a class=headerlink href=#缓存雪崩、穿透、击穿 title=缓存雪崩、穿透、击穿></a>缓存雪崩、穿透、击穿</h2><h3 id=缓存穿透><a class=headerlink href=#缓存穿透 title=缓存穿透></a>缓存穿透</h3><p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。<p>应对缓存穿透的方案，常见的方案有三种。<ul><li><strong>非法请求的限制</strong>：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。<li><strong>设置空值或者默认值</strong>：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。<li><strong>使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在</strong>：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</ul><h3 id=缓存击穿><a class=headerlink href=#缓存击穿 title=缓存击穿></a>缓存击穿</h3><p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。<p>应对缓存击穿可以采取前面说到两种方案：<ul><li>互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</ul><h3 id=缓存雪崩><a class=headerlink href=#缓存雪崩 title=缓存雪崩></a>缓存雪崩</h3><p>当<strong>大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机</strong>时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是<strong>缓存雪崩</strong>的问题。<p>可以看到，发生缓存雪崩有两个原因：<ul><li>大量数据同时过期；<li>Redis 故障宕机；</ul><p>不同的诱因，应对的策略也会不同。<p><strong>大量数据同时过期</strong><p>针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法有下面这几种：<ul><li>均匀设置过期时间；<li>互斥锁；<li>后台更新缓存；</ul><ol><li>均匀设置过期时间</ol><p>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。<ol><li>互斥锁</ol><p>当业务线程在处理用户请求时，<strong>如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</strong>（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。<p>实现互斥锁的时候，最好设置<strong>超时时间</strong>，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。<ol><li>后台更新缓存</ol><p>业务线程不再负责更新缓存，缓存也不设置有效期，而是<strong>让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</strong>。<p>事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为<strong>当系统内存紧张的时候，有些缓存数据会被“淘汰”</strong>，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。<p>解决上面的问题的方式有两种。<p>第一种方式，后台线程不仅负责定时更新缓存，而且也负责<strong>频繁地检测缓存是否有效</strong>，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。<p>这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。<p>第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），<strong>通过消息队列发送一条消息通知后台线程更新缓存</strong>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。<p>在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的<strong>缓存预热</strong>，后台更新缓存的机制刚好也适合干这个事情。<p><strong>故障宕机</strong><p>针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种：<ul><li>服务熔断或请求限流机制；<li>构建 Redis 缓存高可靠集群；</ul><ol><li>服务熔断或请求限流机制</ol><p>因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动<strong>服务熔断</strong>机制，<strong>暂停业务应用对缓存服务的访问，直接返回错误</strong>，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。<p>服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作<p>为了减少对业务的影响，我们可以启用<strong>请求限流</strong>机制，<strong>只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务</strong>，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。<ol><li>构建 Redis 缓存高可靠集群</ol><p>服务熔断或请求限流机制是缓存雪崩发生后的应对方案，我们最好通过<strong>主从节点的方式构建 Redis 缓存高可靠集群</strong>。<p>如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。<h2 id=数据库与缓存如何保证一致性><a class=headerlink href=#数据库与缓存如何保证一致性 title=数据库与缓存如何保证一致性></a>数据库与缓存如何保证一致性</h2><p>由于引入了缓存，那么在数据更新时，不仅要更新数据库，而且要更新缓存，这两个更新操作存在前后的问题<h3 id=删除缓存还是更新缓存><a class=headerlink href=#删除缓存还是更新缓存 title=删除缓存还是更新缓存></a>删除缓存还是更新缓存</h3><p>如果是更新缓存,不管是先更新数据库还是先更新缓存都可能存在并发问题导致后执行操作的缓存被覆盖<p><img alt=图片 data-src=https://cdn.xiaolincoding.com//mysql/other/454a8228a6549176ad7e0484fba3c92b.png style=zoom:50%;><p>使用旁路缓存策略,<strong>写策略的步骤：</strong><ul><li>更新数据库中的数据；<li>删除缓存中的数据。</ul><p><strong>读策略的步骤：</strong><ul><li>如果读取的数据命中了缓存，则直接返回数据；<li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</ul><h2 id=先更新数据库还是先删除缓存><a class=headerlink href=#先更新数据库还是先删除缓存 title=先更新数据库还是先删除缓存></a>先更新数据库还是先删除缓存</h2><p>如果是先删除缓存,当一个写请求到来,删除缓存后并更新数据库,若还没更新数据时另一个读请求读到了空缓存然后读取数据库内容并写入缓存,之后写请求才更新数据库.<p><img alt=图片 data-src=https://cdn.xiaolincoding.com//mysql/other/cc208c2931b4e889d1a58cb655537767.png style=zoom:50%;><p><strong>先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题</strong>。<p>如果是先更新数据库再删除缓存,也可能出现问题. 例如一个写请求到来,而此时另一个读请求读到了空缓存然后读取数据库内容,这时写请求更新数据库并删除缓存,然后读请求更新缓存.<p><img alt=图片 data-src=https://cdn.xiaolincoding.com//mysql/other/1cc7401143e79383ead96582ac11b615.png style=zoom:50%;><p>先更新数据库，再删除缓存也是会出现数据不一致性的问题，<strong>但是在实际中，这个问题出现的概率并不高</strong>。<p><strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。<p>而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。<p>所以，<strong>「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的</strong>。<p>但是仍然可能存在问题，可以采用两种做法：<ul><li>在更新缓存前先加个<strong>分布式锁</strong>，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。<li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</ul><p>针对”先删除缓存，再更新数据库”方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「<strong>延迟双删</strong>」<p>延迟双删实现的伪代码如下：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line>#删除缓存</span><br><span class=line>redis.delKey(X)</span><br><span class=line>#更新数据库</span><br><span class=line>db.update(X)</span><br><span class=line>#睡眠</span><br><span class=line>Thread.sleep(N)</span><br><span class=line>#再删除缓存</span><br><span class=line>redis.delKey(X)</span><br></pre></table></figure><p>加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。<p>所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。<p>但是具体睡眠多久其实是个<strong>玄学</strong>，很难评估出来，所以这个方案也只是<strong>尽可能</strong>保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。<p>因此，还是比较建议用「先更新数据库，再删除缓存」的方案。<h2 id=如何保证先更新数据库-，再删除缓存这两个操作能执行成功><a title="如何保证先更新数据库 ，再删除缓存这两个操作能执行成功" class=headerlink href=#如何保证先更新数据库-，再删除缓存这两个操作能执行成功></a>如何保证先更新数据库 ，再删除缓存这两个操作能执行成功</h2><p>“先更新数据库， 再删除缓存”其实是两个操作，问题在于，<strong>在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值</strong>。<p>有两种方法：<ul><li>消息队列重试机制。<li>订阅 MySQL binlog，再操作缓存。</ul><p>可以引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。<ul><li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。<li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</ul><p><strong>订阅 MySQL binlog,再删除缓存</strong><p><strong>先更新数据库，再删缓存</strong>的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。<p>于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。<p>Canal 模拟 MySQL 主从复制的交互协议，<strong>把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据</strong>，供下游程序订阅使用。<p>将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性.<p><strong>必须是删除缓存成功，再回 ack 机制给消息队列</strong>，否则可能会造成消息丢失的问题，比如消费服务从消息队列拿到事件之后，直接回了 ack，然后再执行删除缓存操作的话，如果删除缓存的操作还是失败了，那么因为提前给消息队列回 ack了，就没办重试了。<p>所以，如果要想保证”先更新数据库，再删缓存”策略第二个操作能执行成功，我们可以使用：<ul><li>消息队列来重试缓存的删除，优点是保证缓存一致性的问题，缺点会对业务代码入侵<li>订阅 MySQL binlog + 消息队列 + 重试缓存的删除，优点是规避了代码入侵问题，也很好的保证缓存一致性的问题，缺点就是引入的组件比较多，对团队的运维能力比较有高要求。</ul><p>这两种方法有一个共同的特点，都是采用<strong>异步操作缓存</strong><h1 id=持久化机制><a class=headerlink href=#持久化机制 title=持久化机制></a>持久化机制</h1><blockquote><p>Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。</blockquote><p>Redis的三种持久化机制:RDB AOF以及混合持久化<h2 id=RDB><a class=headerlink href=#RDB title=RDB></a>RDB</h2><p>将某一时刻的内存数据以二进制的方式写入磁盘.<p>Redis 的 RDB (Redis Database) 快照是一种<strong>二进制格式的紧凑存储</strong>，它记录了 Redis 在某个时间点上的<strong>全量数据</strong>。<p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据.<p>RDB 快照的生成可以由以下几种方式触发：<ol><li><p><strong>手动触发：</strong></p> <ul><li><strong><code>SAVE</code> 命令：</strong> 阻塞 Redis 主进程。在 RDB 文件生成期间，Redis 不会响应任何客户端请求。这在生产环境几乎不使用。<li><strong><code>BGSAVE</code> 命令：</strong> <strong>非阻塞</strong>。Redis 会 <code>fork</code> 一个子进程来执行 RDB 文件生成任务。这是生产环境推荐的方式。</ul><li><p><strong>自动触发：</strong></p> <ul><li>通过配置 <code>redis.conf</code> 中的 <code>save</code> 规则。例如：<ul><li><code>save 900 1</code>：表示 900 秒内至少 1 个键被修改，则自动执行 <code>BGSAVE</code>。<li><code>save 300 10</code>：表示 300 秒内至少 10 个键被修改，则自动执行 <code>BGSAVE</code>。<li><code>save 60 10000</code>：表示 60 秒内至少 10000 个键被修改，则自动执行 <code>BGSAVE</code>。</ul><li>每次自动触发时，都会执行一次 <code>BGSAVE</code>。<li>主从复制时，主节点向从节点同步数据也会触发 <code>BGSAVE</code>。<li>执行 <code>SHUTDOWN</code> 命令且配置了 RDB 持久化时，也会执行 <code>SAVE</code>。</ul> <p>Redis+的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对+Redis+性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多</p></ol><p>其中重要的是BGSAVE命令,使用fork创建新进程利用os提供的写时复制(COW),<p><code>BGSAVE</code> 命令的执行流程充分利用了操作系统的特性，以达到非阻塞持久化的目的：<ol><li><strong>客户端发送 <code>BGSAVE</code> 命令或自动触发条件满足。</strong><li><strong>主进程判断是否可以执行：</strong><ul><li>如果当前已经有一个 <code>BGSAVE</code> 或 <code>BGREWRITEAOF</code> 子进程正在运行，主进程会拒绝新的 <code>BGSAVE</code> 请求，以避免同时产生多个快照进程。</ul><li><strong>主进程 <code>fork()</code> 子进程：</strong><ul><li>Redis 主进程会调用操作系统提供的 <code>fork()</code> 系统调用，创建一个<strong>子进程</strong>。<li><code>fork()</code> 操作会复制父进程的<strong>页表</strong>，并创建一个与父进程几乎完全相同的子进程。这个子进程继承了父进程的所有内存副本、文件描述符等。<li><strong><code>fork()</code> 是唯一的可能导致主进程短暂阻塞的阶段</strong>。阻塞时间取决于服务器的 CPU 性能和 Redis 实例的内存大小。对于几十 GB 的实例，<code>fork</code> 阻塞通常在几十到几百毫秒。</ul><li><strong>写时复制 (Copy-on-Write, COW) 机制：</strong><ul><li>在 <code>fork()</code> 完成后，主进程和子进程会<strong>共享相同的物理内存页面</strong>。这些页面在此时被操作系统标记为<strong>只读</strong>。<li><strong>子进程：</strong> 子进程会遍历它所“看到”的内存数据（即 <code>fork</code> 瞬间的内存快照），并将其以 RDB 格式写入到磁盘上的一个临时文件 (<code>temp-XXXX.rdb</code>)。子进程只负责读取这些共享的内存页面，它不会修改它们。<li><strong>主进程：</strong> 主进程继续处理客户端的请求。<ul><li>如果主进程执行<strong>读操作</strong>，它会直接访问这些共享的、未被修改的内存页面。<li>如果主进程执行<strong>写操作</strong>（例如 <code>SET</code>、<code>DEL</code>），当它尝试修改某个共享的内存页面时，操作系统会触发 <strong>COW</strong> 机制：<ul><li>操作系统会为这个即将被修改的内存页面<strong>创建一个私有的副本</strong>。<li>主进程的内存地址映射会被更新，使其指向这个新复制出来的页面。<li>主进程的写操作会在这个新复制的页面上完成。<li><strong>子进程仍然读取原始的、未被修改的共享内存页面</strong>。</ul></ul></ul><li><strong>子进程完成写入并通知主进程：</strong><ul><li>子进程完成 RDB 文件的写入后，会向主进程发送一个信号。<li>在子进程写入完成之前，即使子进程崩溃，也不会影响主进程的正常运行和数据。</ul><li><strong>主进程替换 RDB 文件：</strong><ul><li>主进程收到子进程的成功信号后，会<strong>原子地用新生成的临时 RDB 文件替换掉旧的 RDB 文件</strong>（通常是重命名操作）。<li>这个替换操作是极快的，不会造成服务阻塞</ul></ol><p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/c34a9d1f58d602ff1fe8601f7270baa7-20230309232304226.png><p>也就是利用写时复制技术实现了在子进程进行读取内存写入新RDB文件时,主线程能够修改数据.<p>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。<p>如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。<p><strong>优点：</strong><ul><li><strong>恢复速度快：</strong> RDB 文件是经过压缩的二进制格式，恢复时直接加载到内存即可，速度远快于 AOF 重放命令。<li><strong>文件紧凑：</strong> RDB 文件比 AOF 文件小得多，适合做备份和传输。<li><strong>更适合灾难恢复：</strong> 对数据的恢复点清晰。</ul><p><strong>缺点：</strong><ul><li><strong>数据丢失风险：</strong> 无法做到实时持久化。如果在两次 RDB 快照之间 Redis 发生崩溃，最后一次快照之后的所有数据都将丢失。丢失的数据量取决于 <code>save</code> 配置的间隔时间。<li><strong><code>fork()</code> 阻塞：</strong> <code>BGSAVE</code> 命令在 <code>fork()</code> 阶段会短暂阻塞主进程，对于内存非常大的实例，这个阻塞可能比较明显。<li><strong>频繁 <code>fork()</code> 的开销：</strong> 如果配置的 <code>save</code> 规则过于频繁，或者写操作过于集中，可能导致频繁的 <code>fork()</code> 操作，增加系统开销。</ul><h2 id=AOF><a class=headerlink href=#AOF title=AOF></a>AOF</h2><p>Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。<p>Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。<ul><li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。<li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</ul><p>当然，这样做也会带来风险：<ul><li><strong>数据可能会丢失：</strong> 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。<li><strong>可能阻塞其他操作：</strong> 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。</ul><h3 id=AOF回写策略><a class=headerlink href=#AOF回写策略 title=AOF回写策略></a>AOF回写策略</h3><p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/4eeef4dd1bedd2ffe0b84d4eaa0dbdea-20230309232249413.png style=zoom:67%;><ol><li>Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；<li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；<li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</ol><p>Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：<ul><li><strong>Always</strong>，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘； <strong>每次</strong>有新的写命令追加到 AOF 缓冲区时，都会立即执行 <code>fsync()</code> 操作，将缓冲区中的所有数据同步到磁盘。<li><strong>Everysec</strong>，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；Redis 会将 AOF 缓冲区的数据写入操作系统内存缓冲区，然后启动一个<strong>后台线程</strong>，<strong>每秒</strong>将这些数据同步到磁盘一次。<li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。Redis 只负责将 AOF 缓冲区的数据写入操作系统内存缓冲区，<strong>不主动进行 <code>fsync()</code> 操作</strong>。数据何时同步到磁盘完全由操作系统决定（通常是每 30 秒或当缓冲区满时）。</ul><p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/98987d9417b2bab43087f45fc959d32a-20230309232253633.png><h3 id=AOF日志过大会触发什么机制><a class=headerlink href=#AOF日志过大会触发什么机制 title=AOF日志过大会触发什么机制></a>AOF日志过大会触发什么机制</h3><p>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。<p>所以，Redis 为了避免 AOF 文件越写越大，提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。<h3 id=AOF重写><a class=headerlink href=#AOF重写 title=AOF重写></a>AOF重写</h3><p>AOF 重写机制是在重写时，<strong>读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</strong><p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/723d6c580c05400b3841bc69566dd61b-20230309232257343.png><p>Redis 的<strong>重写 AOF 过程是由子进程 *bgrewriteaof* 来完成的</strong>，这么做可以达到两个好处:<ul><li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；<li>子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</ul><p>触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。<p><strong>但是重写过程中，主进程依然可以正常处理命令</strong>，那问题来了，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，那么会发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？<p>为了解决这种数据不一致问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。<p>在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 AOF 缓冲区和 AOF 重写缓冲区</strong>。<p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309232301042.png><p>在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:<ul><li>执行客户端发来的命令；<li>将执行后的写命令追加到 「AOF 缓冲区」；这是为了确保即使 AOF 重写失败，旧的 AOF 文件仍然是完整且最新的，不会丢失任何数据。<li>将执行后的写命令追加到 「AOF 重写缓冲区」；所有在重写期间新发生的写命令都会被缓存到这个独立的缓冲区中。</ul><p>当子进程完成 AOF 重写工作（<em>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。<p>主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：<ul><li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；<li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</ul><h3 id=混合持久化><a class=headerlink href=#混合持久化 title=混合持久化></a>混合持久化</h3><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。<p>AOF 优点是丢失数据少，但是数据恢复不快。<p>为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。<p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。<p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。<p>重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。<p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。<p><strong>混合持久化优点：</strong><ul><li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</ul><p><strong>混合持久化缺点：</strong><ul><li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；<li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了</ul><h2 id=大-Key-对持久化影响><a title="大 Key 对持久化影响" class=headerlink href=#大-Key-对持久化影响></a>大 Key 对持久化影响</h2><h3 id=对AOF日志影响><a class=headerlink href=#对AOF日志影响 title=对AOF日志影响></a>对AOF日志影响</h3><p>AOF有三种写回磁盘策略,分别是：<ul><li>Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；<li>Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；<li>No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</ul><p>这三种策略只是在控制 fsync() 函数的调用时机。<p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。<p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。<ul><li>Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；<li>Everysec 策略就会创建一个异步任务来执行 fsync() 函数；<li>No 策略就是永不执行 fsync() 函数;</ul><p>在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。<p><strong>当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</strong>。<p>当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程。<p>当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。<h3 id=AOF重写和RDB影响><a class=headerlink href=#AOF重写和RDB影响 title=AOF重写和RDB影响></a>AOF重写和RDB影响</h3><p>当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 <strong>AOF 重写机制</strong>。<p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。<p>在创建子进程的过程中，<strong>操作系统会把父进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系</strong>，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。<p>子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。<p>随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。<p>在通过 <code>fork()</code> 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是<strong>内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象</strong>。<strong>fork 函数是由 Redis 主线程调用的，如果 fork 函数发生阻塞，那么意味着就会阻塞 Redis 主线程</strong>。由于 Redis 执行命令是在主线程处理的，所以当 Redis 主线程发生阻塞，就无法处理后续客户端发来的命令。<p>当父进程或者子进程在向共享内存发起写操作时，CPU 就会触发<strong>写保护中断</strong>，这个「写保护中断」是由于违反权限导致的，<strong>然后操作系统会在「写保护中断处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写</strong>，最后才会对内存进行写操作，这个过程被称为「<strong>写时复制(Copy On Write)</strong>」。<p>写时复制顾名思义，在发生写操作的时候，操作系统才会去复制物理内存，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。<p>如果创建完子进程后，<strong>父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞</strong>。<p>所以，有两个阶段会导致阻塞父进程：<ul><li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；<li>创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；</ul><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。<p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：<ul><li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；<li>创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</ul><blockquote><p>大 key 除了会影响持久化之外，还会有以下的影响：</blockquote><ul><li>客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。<li>引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。<li>阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。<li>内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多。</ul><blockquote><p>如何避免大 Key 呢？</blockquote><p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。<h1 id=高可用><a class=headerlink href=#高可用 title=高可用></a>高可用</h1><h2 id=Redis集群><a class=headerlink href=#Redis集群 title=Redis集群></a>Redis集群</h2><blockquote><p>主从如何进行同步<p>哨兵的节点故障转移<p>cluster集群的哈希槽<p>脑裂产生以及解决</blockquote><h3 id=主从复制><a class=headerlink href=#主从复制 title=主从复制></a>主从复制</h3><p>主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。<p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/2b7231b6aabb9a9a2e2390ab3a280b2d.png style=zoom:50%;><p>主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。<p>具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。所以无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。<h3 id=哨兵模式><a class=headerlink href=#哨兵模式 title=哨兵模式></a>哨兵模式</h3><p>在使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。<p>兵模式做到了可以监控主从服务器，并且提供<strong>主从节点故障转移的功能。</strong><p><img alt=img data-src=https://cdn.xiaolincoding.com//mysql/other/26f88373d8454682b9e0c1d4fd1611b4.png style=zoom:67%;><h3 id=cluster分片集群><a class=headerlink href=#cluster分片集群 title=cluster分片集群></a>cluster分片集群</h3><p>当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 <strong>Redis 切片集群</strong>（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。<p>使用哈希槽来处理数据和节点之间的映射,<strong>一个切片集群共有 16384 个哈希槽</strong>，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：<ul><li>根据键值对的 key，按照 CRC16计算一个 16 bit 的值。<li>再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</ul><p>这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：<ul><li><strong>平均分配：</strong> 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。<li><strong>手动分配：</strong> 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。</ul><p>当读取或设置key时的流程.在Redis cluster模式下，节点对请求的处理过程如下：<ul><li>通过哈希槽映射，检查当前Redis key是否存在当前节点<li>若哈希槽不是由自身节点负责，就返回MOVED重定向<li>若哈希槽确实由自身负责，且key在slot中，则返回该key对应结果<li>若Redis key不存在此哈希槽中，检查该哈希槽是否正在迁出（MIGRATING）？<li>若Redis key正在迁出，返回ASK错误重定向客户端到迁移的目的服务器上<li>若哈希槽未迁出，检查哈希槽是否导入中？<li>若哈希槽导入中且有ASKING标记，则直接操作，否则返回MOVED重定向</ul><p>cluster集群管理重要命令<figure class="highlight sh"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br></pre><td class=code><pre><span class=line>redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 \</span><br><span class=line>127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \</span><br><span class=line>--cluster-replicas 1</span><br><span class=line>redis-cli --cluster check 127.0.0.1:7000</span><br><span class=line>redis-cli --cluster reshard 127.0.0.1:7000</span><br><span class=line>redis-cli --cluster rebalance 127.0.0.1:7000</span><br></pre></table></figure><p>CLUSTER命令是redis-cli —cluster分片集群管理的底层指令,在要移除一个节点时,<figure class="highlight sh"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>redis-cli --cluster reshard &LTany_existing_node_ip>:&LTany_existing_node_port></span><br><span class=line>redis-cli --cluster del-node &LTany_existing_node_ip>:&LTany_existing_node_port> &LTnode_id_to_delete></span><br></pre></table></figure><p>客户端给一个Redis实例发送数据读写操作时，如果这个实例上并没有相应的数据，会怎么样呢？<p>在Redis cluster模式下，节点对请求的处理过程如下：<ul><li>通过哈希槽映射，检查当前Redis key是否存在当前节点<li>若哈希槽<strong>不是由自身节点负责</strong>，就返回MOVED重定向<li>若哈希槽确实由自身负责，且key在slot中，则返回该key对应结果<li>若Redis key不存在此哈希槽中，检查该哈希槽是否正在迁出（MIGRATING）？<li>若Redis key正在迁出，返回ASK错误重定向客户端到迁移的目的服务器上<li>若哈希槽未迁出，检查哈希槽是否导入中？<li>若哈希槽导入中且有ASKING标记，则直接操作，否则返回MOVED重定向</ul><h4 id=MOVED重定向><a class=headerlink href=#MOVED重定向 title=MOVED重定向></a>MOVED重定向</h4><p>其中MOVED重定向<code>MOVED</code> 重定向表示<strong>某个哈希槽（及其包含的数据）已经永久性地从当前节点迁移到了另一个节点</strong>。这意味着集群的拓扑结构已经发生了变化。<ul><li><strong>哈希槽迁移完成：</strong> 当一个哈希槽的迁移过程（通过 <code>CLUSTER SETSLOT &LTslot> NODE &LTnode_id></code> 命令）完全结束，该槽位被正式分配给新的目标节点时。<li><strong>客户端请求不属于当前节点的键：</strong> 客户端向一个节点发送了对某个键的请求，但计算得出该键所属的哈希槽不属于当前节点，而是由集群中的另一个节点负责。这通常发生在客户端的哈希槽映射缓存过期或不准确时。</ul><p>客户端给一个Redis实例发送数据读写操作时，如果计算出来的槽不是在该节点上，这时候它会返回MOVED重定向错误，MOVED重定向错误中，会将哈希槽所在的新实例的IP和port端口带回去。这就是Redis Cluster的MOVED重定向机制。<p><img alt=img data-src=https://cdn.xiaolincoding.com//picgo/1d4685f1f19d72aff8412498c05bed4a.png style=zoom:67%;><h4 id=ASK重定向><a class=headerlink href=#ASK重定向 title=ASK重定向></a>ASK重定向</h4><p>Ask重定向一般发生于集群伸缩的时候。集群伸缩会导致槽迁移，当去源节点访问时，此时数据已经可能已经迁移到了目标节点，使用Ask重定向可以解决此种情况<p><code>ASK</code> 重定向表示<strong>某个哈希槽正在进行迁移（resharding）操作，当前键可能已经迁移到目标节点，或者在源节点上不存在（新写入的键）</strong>。这是一个<strong>临时性</strong>的重定向，发生在哈希槽迁移过程中，当源节点处于 <code>MIGRATING</code> 状态，而目标节点处于 <code>IMPORTING</code> 状态时。<p>在哈希槽迁移（例如 <code>reshard</code> 命令执行期间）的过程中，当客户端向<strong>源节点</strong>（<code>MIGRATING</code> 状态）发送对一个键的请求时：<ol><li>如果该键在源节点上<strong>不存在</strong>（可能是新创建的键，或者该键已经迁移到了目标节点，但客户端仍然向源节点请求），源节点会返回 <code>ASK &LThash_slot> &LTtarget_node_ip>:&LTtarget_node_port></code> 错误。<li>如果该键在源节点上<strong>存在且尚未被迁移</strong>，源节点会直接处理该命令，不会进行 <code>ASK</code> 重定向。</ol><p><img alt=img data-src=https://cdn.xiaolincoding.com//picgo/fe3703c3d045462a12b41a628ff26825.png><p>各个节点之间通过gossip协议互相通信,一个节点想要分享一些信息给网络中的其他的一些节点。于是，<strong>它周期性的随机选择一些节点，并把信息传递给这些节点</strong>。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。一般而言，信息会周期性的传递给N个目标节点，而不只是一个。这个N被称为fanout<p>节点之前不断交换信息，交换的信息内容包括节点出现故障、新节点加入、主从节点变更信息、slot信息等等。gossip协议包含多种消息类型，包括ping，pong，meet，fail等等<p><img alt=img data-src=https://cdn.xiaolincoding.com//picgo/cd36f67141ebab2e43b2371a7fd51c8c.png style=zoom:67%;><ul><li>meet消息：通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。<li>ping消息：节点每秒会向集群中其他节点发送 ping 消息，消息中带有自己已知的两个节点的地址、槽、状态信息、最后一次通信时间等<li>pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。消息中同样带有自己已知的两个节点信息。<li>fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。</ul><h4 id=故障转移><a class=headerlink href=#故障转移 title=故障转移></a>故障转移</h4><p>Redis集群实现了高可用，当集群内节点出现故障时，通过<strong>故障转移</strong>，以保证集群正常对外提供服务。<p>redis集群通过ping/pong消息，实现故障发现。这个环境包括<strong>主观下线和客观下线。</strong><ul><li><p><strong>主观下线</strong>：某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。</p><li><p><strong>客观下线</strong>：指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。</p><li><p>假如节点A标记节点B为主观下线，一段时间后，节点A通过消息把节点B的状态发到其它节点，当节点C接受到消息并解析出消息体时，如果发现节点B的pfail状态时，会触发客观下线流程；</p><li><p>当下线为主节点时，此时Redis Cluster集群为统计持有槽的主节点投票，看投票数是否达到一半，当下线报告统计数大于一半时，被标记为客观下线状态。</p><li><p>故障恢复：故障发现后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，以保证集群的高可用。流程如下：</p></ul><p><img alt=img data-src=https://cdn.xiaolincoding.com//picgo/9ca67fa36a0c084e315e843e6ef46197.png><ul><li>资格检查：检查从节点是否具备替换故障主节点的条件。<li>准备选举时间：资格检查通过后，更新触发故障选举时间。<li>发起选举：到了故障选举时间，进行选举。<li>选举投票：只有持有槽的主节点才有票，从节点收集到足够的选票（大于一半），触发替换主节点</ul><h2 id=Redis-Cluster的Hash-Slot-是16384><a title="Redis Cluster的Hash Slot 是16384" class=headerlink href=#Redis-Cluster的Hash-Slot-是16384></a>Redis Cluster的Hash Slot 是16384</h2><p>减少节点之间传递哈希槽的数据量<p>减少哈希碰撞概率<p>哨兵模式已经实现了故障自动转移的能力，但业务规模的不断扩展，用户量膨胀，并发量持续提升，会出现了 Redis 响应慢的情况。<p>使用 Redis Cluster 集群，主要解决了大数据量存储导致的各种慢问题，同时也便于横向拓展。在面对千万级甚至亿级别的流量的时候，很多大厂的做法是在千百台的实例节点组成的集群上进行流量调度、服务治理的。<p>整个Redis数据库划分为16384个哈希槽，Redis集群可能有n个实例节点，每个节点可以处理0个 到至多 16384 个槽点，这些节点把 16384个槽位瓜分完成。<p>Cluster 是具备Master 和 Slave模式，Redis 集群中的每个实例节点都负责一些槽位，节点之间保持TCP通信，当Master发生了宕机， Redis Cluster自动会将对应的Slave节点选为Master，来继续提供服务。<p>客户端能够快捷的连接到服务端，主要是将slots与实例节点的映射关系存储在本地，当需要访问的时候，对key进行CRC16计算后，再对16384 取模得到对应的 Slot 索引，再定位到相应的实例上。实现高效的连接。<h3 id=集群脑裂导致的数据丢失><a class=headerlink href=#集群脑裂导致的数据丢失 title=集群脑裂导致的数据丢失></a>集群脑裂导致的数据丢失</h3><p>导致集群脑裂的原因:主节点与集群中其他节点出现网络问题失去连接.<p>在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果<strong>主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的</strong>。<p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。<p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。<blockquote><p>由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</blockquote><p><strong>解决方案</strong><p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。<p>在 Redis 的配置文件中有两个参数我们可以设置：<ul><li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。<li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</ul><p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。<p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。<p>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。<p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong><h2 id=如何判断Redis某个节点是否正常><a class=headerlink href=#如何判断Redis某个节点是否正常 title=如何判断Redis某个节点是否正常></a>如何判断Redis某个节点是否正常</h2><p>判断 Redis 某个节点是否正常工作是一个常见的运维和开发需求。接下来我会详细讲述判断 Redis 节点正常工作五种常见方式。<p>第一种是采用 PING 命令，它是 Redis 内置命令，用于测试 Redis 服务是否可用。如果 Redis 节点正常工作，执行 PING 命令会返回 PONG。如果未收到 PONG 或连接超时，则说明节点可能存在问题。<p>第二种是采用 INFO 命令，它也是 Redis 内置命令，INFO 命令可以返回 Redis 节点的详细运行信息，包括内存使用、连接数、持久化状态等。通过解析这些信息，可以判断节点是否处于正常状态。例如，检查 role 字段可以确认节点是主节点还是从节点，检查 connected_clients 可以确认是否有过多的客户端连接。<p>第三种是采用 CLUSTER INFO 命令（集群模式），它还是 Redis 内置命令，如果 Redis 运行在集群模式下，可以使用 CLUSTER INFO 命令查看集群的状态。重点关注 cluster_state 字段，如果值为 ok，则表示集群正常；如果是 fail，则说明集群中有节点不可用。<p>第四种是采用 Telnet 或 Netcat，它们属于外部工具，用于测试 Redis 节点的端口是否可达。例如，尝试连接到 Redis 的默认端口 6379，如果连接失败，说明节点可能宕机或网络有问题。<p>第五种是采用监控系统，配置 Prometheus、Grafana 等监控工具，实时监控 Redis 的性能指标（如内存使用率、QPS、延迟等）。如果某些指标超出阈值或出现异常波动，可能是节点出现问题<h1 id=过期删除与内存淘汰策略><a class=headerlink href=#过期删除与内存淘汰策略 title=过期删除与内存淘汰策略></a>过期删除与内存淘汰策略</h1><p>Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。<p>通过expire以及setex, set key \<ex>等设置过期时间,ttl查看剩余时间. <h2 id=如何判定过期><a class=headerlink href=#如何判定过期 title=如何判定过期></a>如何判定过期</h2><p>当对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。</p> <figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span> <span class=title>redisDb</span> {</span></span><br><span class=line>    dict *dict;    <span class=comment>/* 数据库键空间，存放着所有的键值对 */</span></span><br><span class=line>    dict *expires; <span class=comment>/* 键的过期时间 */</span></span><br><span class=line>    ....</span><br><span class=line>} redisDb;</span><br></pre></table></figure> <p>过期字典数据结构结构如下：</p> <ul><li>过期字典的 key 是一个指针，指向某个键对象；<li>过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；</ul> <p>字典实际上是哈希表，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找。当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p> <ul><li>如果不在，则正常读取键值；<li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</ul> <h2 id=过期删除策略><a class=headerlink href=#过期删除策略 title=过期删除策略></a>过期删除策略</h2><p><strong>Redis 选择「惰性删除+定期删除」这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。</p> <p>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p> <p>定期删除策略的<strong>优点</strong>：</p> <ul><li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</ul> <p>定期删除策略的<strong>缺点</strong>：</p> <ul><li>内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。<li>难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放</ul> <p>定期删除策略的做法：<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p> <p><em>1、这个间隔检查的时间是多长呢？</em></p> <p>在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。</p> <p>特别强调下，每次检查数据库并不是遍历过期字典中的所有 key，而是从数据库中随机抽取一定数量的 key 进行过期检查。</p> <p><em>2、随机抽查的数量是多少呢？</em></p> <p>我查了下源码，定期删除的实现在 expire.c 文件下的 <code>activeExpireCycle</code> 函数中，其中随机抽查的数量由 <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> 定义的，它是写死在代码中的，数值是 20。</p> <p>也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。</p> <p>接下来，详细说说 Redis 的定期删除的流程：</p> <ol><li>从过期字典中随机抽取 20 个 key；<li>检查这 20 个 key 是否过期，并删除已过期的 key；<li>如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</ol> <p>可以看到，定期删除是一个循环的流程。</p> <p>那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</p> <p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></p> <p>惰性删除策略的<strong>优点</strong>：</p> <ul><li>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</ul> <p>惰性删除策略的<strong>缺点</strong>：</p> <ul><li>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友</ul> <h2 id=内存淘汰策略><a class=headerlink href=#内存淘汰策略 title=内存淘汰策略></a>内存淘汰策略</h2><p>当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。在配置文件 redis.conf 中，可以通过参数 <code>maxmemory &LTbytes></code> 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。 不同位数的操作系统，maxmemory 的默认值是不同的：</p> <ul><li>在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。<li>在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。</ul> <p>Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。</p> <p><em>1、不进行数据淘汰的策略</em></p> <p><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。</p> <p><em>2、进行数据淘汰的策略</em></p> <p>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。</p> <p>在设置了过期时间的数据中进行淘汰：</p> <ul><li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；<li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。<li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；<li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</ul> <p>在所有数据范围内进行淘汰：</p> <ul><li><strong>allkeys-random</strong>：随机淘汰任意键值;<li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；<li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</ul> <blockquote><p>什么是 LRU 算法？</blockquote> <p><strong>LRU</strong> 全称是 Least Recently Used 翻译为<strong>最近最少使用</strong>，会选择淘汰最近最少使用的数据。</p> <p>传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。</p> <p>Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题：</p> <ul><li>需要用链表管理所有的缓存数据，这会带来额外的空间开销；<li>当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。</ul> <blockquote><p>Redis 是如何实现 LRU 算法的？</blockquote> <p>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。</p> <p>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>。</p> <p>Redis 实现的 LRU 算法的优点：</p> <ul><li>不用为所有的数据维护一个大链表，节省了空间占用；<li><p>不用在每次数据访问时都移动链表项，提升了缓存的性能；</p> <p>LRU 算法有一个问题，<strong>无法解决缓存污染问题</strong>，比如<strong>应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间</strong>，造成缓存污染。</p></ul> <p>所以引入了LFU 算法,根据数据访问次数来淘汰数据，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。</p> <p>所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。LFU 算法相比于 LRU 算法的实现，多记录了<strong>“数据的访问频次</strong>”的信息</p> <p><strong>在 LRU 算法中</strong>，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。</p> <p><strong>在 LFU 算法中</strong>，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。</p> <p>在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据<strong>访问频率</strong>来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。</p> <ul><li>ldt 是用来<strong>记录 key 的访问时间戳</strong>；<li>logc 是用来<strong>记录 key 的访问频次</strong>，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。</ul> <p>注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 <strong>logc 会随时间推移而衰减的</strong></p> <p>对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。</p> <p>所以，Redis 在访问 key 时，对于 logc 是这样变化的：</p> <ol><li>先按照上次访问距离当前的时长，来对 logc 进行衰减；<li>然后，再按照一定概率增加 logc 的值</ol> <p>redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减：</p> <ul><li><code>lfu-decay-time</code> 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢；<li><code>lfu-log-factor</code> 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢</ul> <h1 id=Redis在项目中应用><a class=headerlink href=#Redis在项目中应用 title=Redis在项目中应用></a>Redis在项目中应用</h1><h2 id=如何设计缓存策略动态缓存热点数据><a class=headerlink href=#如何设计缓存策略动态缓存热点数据 title=如何设计缓存策略动态缓存热点数据></a>如何设计缓存策略动态缓存热点数据</h2><p>由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而<strong>只是将其中一部分热点数据缓存起来</strong>，所以我们要设计一个热点数据动态缓存的策略。</p> <p>热点数据动态缓存的策略总体思路：<strong>通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据</strong>。</p> <p>以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：</p> <ul><li>先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；<li>同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；<li>这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。</ul> <p>在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操</p> <h2 id=实现分布锁><a class=headerlink href=#实现分布锁 title=实现分布锁></a>实现分布锁</h2><p><img alt=img data-src=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.jpg style=zoom:67%;></p> <p>Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。</p> <p>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p> <ul><li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</ul> <p>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p> <ul><li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；<li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；</ul> <p>满足这三个条件的分布式命令如下：</p> <figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>SET lock_key unique_value NX PX <span class=number>10000</span> </span><br></pre></table></figure> <ul><li>lock_key 就是 key 键；<li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；<li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；<li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。</ul> <p>而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。</p> <p>可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。</p> <figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br></pre><td class=code><pre><span class=line><span class=comment>// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span></span><br><span class=line><span class=keyword>if</span> redis.call(<span class=string>"get"</span>,KEYS[<span class=number>1</span>]) == ARGV[<span class=number>1</span>] then</span><br><span class=line>    <span class=keyword>return</span> redis.call(<span class=string>"del"</span>,KEYS[<span class=number>1</span>])</span><br><span class=line><span class=keyword>else</span></span><br><span class=line>    <span class=keyword>return</span> <span class=number>0</span></span><br><span class=line>end</span><br></pre></table></figure> <p>这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。</p> <blockquote><p>基于 Redis 实现分布式锁有什么优缺点？</blockquote> <p>基于 Redis 实现分布式锁的<strong>优点</strong>：</p> <ol><li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。<li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。<li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</ol> <p>基于 Redis 实现分布式锁的<strong>缺点</strong>：</p> <ul><li><p>超时时间不好设置</p> <p>。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。</p> <ul><li><strong>那么如何合理设置超时时间呢？</strong> 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</ul><li><p><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</p></ul> <h3 id=Redis如何解决集群情况下锁的可靠性><a class=headerlink href=#Redis如何解决集群情况下锁的可靠性 title=Redis如何解决集群情况下锁的可靠性></a>Redis如何解决集群情况下锁的可靠性</h3><p>为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock</p> <p>它是基于<strong>多个 Redis 节点</strong>的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。</p> <p>Redlock 算法的基本思路，<strong>是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败</strong>。</p> <p>这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。</p> <p>Redlock 算法加锁三个过程：</p> <ul><li>第一步是，客户端获取当前时间（t1）。<li>第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：<ul><li>加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。<li>如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。</ul><li>第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</ul> <p>可以看到，加锁成功要同时满足两个条件（<em>简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功</em>）：</p> <ul><li>条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁；<li>条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。</ul> <p>加<strong>锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」</strong>。如果计算的结果已经来不及完成共享数据的操作了，可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。</p> <p>加锁失败后，客户端向<strong>所有 Redis 节点发起释放锁的操作</strong>，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。</p> <h2 id=stream实现延迟队列><a class=headerlink href=#stream实现延迟队列 title=stream实现延迟队列></a>stream实现延迟队列</h2><p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：</p> <ul><li>在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；<li>打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；<li>点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；</ul> <p>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。</p> <p><img alt=img data-src=https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97.png></p> <h2 id=数据库与缓存的一致性><a class=headerlink href=#数据库与缓存的一致性 title=数据库与缓存的一致性></a>数据库与缓存的一致性</h2><p>更新缓存还是删缓存</p> <p>先更新数据库还是先删缓存</p> <p>延迟双删解决并发读写请求下的缓存不一致问题</p> <p>如何保证先更新数据库再删除缓存操作能执行成功.</p> <p>订阅mysql binlog,消息队列</p> <p>订阅 MySQL Binlog 来解决缓存删除失败导致的数据不一致问题，是一种<strong>最终一致性</strong>的解决方案，也是目前业界公认的<strong>最可靠</strong>和<strong>最推荐</strong>的方式之一。它通过将数据变更的事件流作为驱动，确保数据库和缓存之间的数据保持同步。</p> <h3 id=为什么会出现缓存删除失败问题？><a class=headerlink href=#为什么会出现缓存删除失败问题？ title=为什么会出现缓存删除失败问题？></a>为什么会出现缓存删除失败问题？</h3><p>在“先更新数据库再删除缓存”的策略中，最常见的失败场景是：</p> <ul><li><strong>数据库更新成功，但删除缓存操作失败。</strong> 这可能是由于网络问题、缓存服务宕机、Redis 连接超时等原因造成的。<li>一旦缓存删除失败，缓存中就会保留旧数据，而数据库中已经是新数据，导致<strong>数据不一致</strong>，用户可能会读取到脏数据。</ul> <h3 id=订阅-Binlog-的解决方案原理><a title="订阅 Binlog 的解决方案原理" class=headerlink href=#订阅-Binlog-的解决方案原理></a>订阅 Binlog 的解决方案原理</h3><p>这种方案的核心思想是：应用程序只负责更新数据库，而<strong>缓存的更新或删除则由一个独立的、专门的服务来完成，该服务通过监听 MySQL 的 Binlog 来感知数据库的变化</strong>。</p> <p>Binlog（Binary Log）是 MySQL 的二进制日志，它记录了所有对数据库进行更改的事件，包括数据插入、更新、删除等操作的详细信息。</p> <p>具体流程如下：</p> <ol><li><strong>应用程序操作数据库：</strong><ul><li>业务应用层只进行数据库操作（<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>）。<li><strong>应用程序不再直接负责删除缓存。</strong></ul><li><strong>Binlog 实时同步到中间件：</strong><ul><li><strong>变更数据捕获 (Change Data Capture, CDC) 工具</strong>（例如 <strong>Canal</strong>、<strong>Debezium</strong> 等）作为 Binlog 的消费者，连接到 MySQL 数据库，并模拟成一个 MySQL 从库。<li>它会实时地读取 MySQL 的 Binlog，捕获所有的数据变更事件。<li>捕获到的变更事件会被发送到一个<strong>消息队列</strong>（例如 <strong>Kafka</strong>、<strong>RabbitMQ</strong> 等）。消息队列在这里起到了缓冲、解耦和削峰的作用，确保事件不会丢失，并且能够异步处理。</ul><li><strong>缓存同步服务消费消息：</strong><ul><li>一个独立的<strong>缓存同步服务</strong>（或称为“数据同步服务”）作为消息队列的消费者，订阅 Binlog 变更事件对应的消息主题。<li>当该服务收到数据库变更事件时，它会解析事件内容，知道是哪个表、哪条记录发生了什么变化。</ul><li><strong>根据事件类型操作缓存：</strong><ul><li><strong>对于更新 (UPDATE) 或删除 (DELETE) 事件：</strong> 缓存同步服务根据事件中的主键或唯一标识符，找到对应的缓存键，并执行<strong>缓存删除操作</strong>。<li><strong>对于插入 (INSERT) 事件：</strong> 如果业务需要，也可以选择预热缓存，将新数据插入到缓存中。但通常删除旧缓存是更常见的操作。</ul><li><strong>失败重试与告警：</strong><ul><li>如果缓存同步服务在删除缓存时遇到问题（例如，Redis 服务不可用），它会将该操作标记为失败，并利用消息队列的<strong>重试机制</strong>（如 Kafka 的死信队列、Spring Cloud Stream 的重试策略等）进行重试。<li>如果多次重试仍然失败，可以触发告警通知运维人员介入</ul></ol> <h3 id=其他方法><a class=headerlink href=#其他方法 title=其他方法></a>其他方法</h3><p>使用<strong>Redis + Kafka实现缓存与数据库的一致性</strong>，在写入数据时，可以将操作信息发送到Kafka等消息队列，然后由消费者（可以是一个专门的服务）来处理数据库和缓存的同步。这种方案通过消息队列解耦了数据库和缓存的操作，确保两者的一致性。Kafka的可靠性保证了消息不丢失，因此可以保障一致性，但需要额外的基础设施来管理消息队列。</p> <p>其次是使用<strong>Redis + TCC事务管理</strong>，TCC（Try-Confirm-Cancel）事务模型适用于分布式事务管理。在写入Redis和MySQL时，可以先在Redis进行预写操作（Try），然后确认MySQL的数据更新（Confirm），如果遇到失败，可以取消Redis的操作（Cancel）。这种方式通过分布式事务的处理，能够确保两者一致性，但需要额外的事务管理中间件，增加系统复杂度。</p> <p>最后是使用<strong>分布式数据库中间件（如Sentinel, Canal等）</strong>，Redis的高可用架构可以借助Sentinel实现主从复制，保证缓存的高可用性和一致性。与此同时，Canal可以作为MySQL的增量数据订阅工具，实时同步数据库变更到Redis缓存。通过这种方式，可以实现高效的数据一致性保障，但配置和维护较为复杂。</p> <h2 id=相关资料><a class=headerlink href=#相关资料 title=相关资料></a>相关资料</h2><ol><li><a href=https://xiaolincoding.com/redis/base/redis_interview.html rel=noopener target=_blank>Redis 常见面试题 | 小林coding</a><li><a href=https://www.bilibili.com/video/BV1cr4y1671t/?spm_id_from=333.337.search-card.all.click&vd_source=177ef88aa6608bc3652c72d71b0aa098 rel=noopener target=_blank>黑马程序员Redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目_哔哩哔哩_bilibili</a></ol> <link href=/css/spoiler.css rel=stylesheet><script async src=/js/spoiler.js></script> <div><div><div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div> <div class=reward-container><div>感谢阅读.</div><button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">打赏</button><div style="display: none;" id=qr><div style="display: inline-block;"><img alt="Sekyoro 微信支付" src=/images/wechatpay.png><p>微信支付</div></div></div> <div><ul class=post-copyright><li class=post-copyright-author><strong>本文作者： </strong>Sekyoro<li class=post-copyright-link><strong>本文链接：</strong> <a href=https://www.sekyoro.top/2025/07/10/redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/ title=redis核心技术>https://www.sekyoro.top/2025/07/10/redis核心技术/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ rel=noopener target=_blank><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</ul></div> <div class=followme><p>欢迎关注我的其它发布渠道<div class=social-list><div class=social-item><a class=social-link href=/images/wxqrcode.png target=_blank> <span class=icon> <i class="fab fa-weixin"></i> </span> <span class=label>WeChat</span> </a></div><div class=social-item><a class=social-link href=/images/website.png target=_blank> <span class=icon> <i class="fa fa-user"></i> </span> <span class=label>PersonalWebsite</span> </a></div><div class=social-item><a class=social-link href=https://my-astro-git-main-drowning-in-codes.vercel.app target=_blank> <span class=icon> <i class="fas fa-share"></i> </span> <span class=label>杂鱼分享</span> </a></div><div class=social-item><a class=social-link href=/atom.xml target=_blank> <span class=icon> <i class="fa fa-rss"></i> </span> <span class=label>RSS</span> </a></div></div></div> <footer class=post-footer><div class=post-tags><a href=/tags/Redis/ rel=tag><i class="fa fa-tag"></i> Redis</a></div><div class=post-nav><div class=post-nav-item><a title="coding agent in real world" href=/2025/07/01/coding-agent-in-real-world/ rel=prev> <i class="fa fa-chevron-left"></i> coding agent in real world </a></div><div class=post-nav-item><a href=/2025/07/21/rabbit-mq%E5%88%9D%E6%8E%A2/ rel=next title=rabbit-mq初探> rabbit-mq初探 <i class="fa fa-chevron-right"></i> </a></div></div></footer> <!-- 评论区 --> <div class=comments><div data-id=city data-uid=MTAyMC81MzE5Ny8yOTY3Mg== id=lv-container></div></div> <script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script> <div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div> <aside class=sidebar><div class=sidebar-inner><!-- canvas粒子时钟 --><div><canvas id=canvas style=width:60%;>当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();</script><!-- require APlayer --><link href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><!-- require MetingJS --><script src=/js/meting-js.js></script><ul class="sidebar-nav motion-element"><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class=nav><li class="nav-item nav-level-1"><a class=nav-link href=#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B><span class=nav-number>1.</span> <span class=nav-text>数据类型与单线程模型</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF><span class=nav-number>1.1.</span> <span class=nav-text>常用数据类型实现以及使用场景</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#String><span class=nav-number>1.1.0.1.</span> <span class=nav-text>String</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#List><span class=nav-number>1.1.0.2.</span> <span class=nav-text>List</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#Hash><span class=nav-number>1.1.0.3.</span> <span class=nav-text>Hash</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#Set><span class=nav-number>1.1.0.4.</span> <span class=nav-text>Set</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#ZSet><span class=nav-number>1.1.0.5.</span> <span class=nav-text>ZSet</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%BD%BF%E7%94%A8%E7%9A%84%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84><span class=nav-number>1.1.1.</span> <span class=nav-text>使用的底层数据结构</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2><span class=nav-number>1.1.1.1.</span> <span class=nav-text>简单动态字符串</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#intset><span class=nav-number>1.1.1.2.</span> <span class=nav-text>intset</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#ziplist><span class=nav-number>1.1.1.3.</span> <span class=nav-text>ziplist</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#quicklist><span class=nav-number>1.1.1.4.</span> <span class=nav-text>quicklist</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#dict><span class=nav-number>1.1.1.5.</span> <span class=nav-text>dict</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#skiplist><span class=nav-number>1.1.1.6.</span> <span class=nav-text>skiplist</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#listpack><span class=nav-number>1.1.1.7.</span> <span class=nav-text>listpack</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#BitMap><span class=nav-number>1.1.1.8.</span> <span class=nav-text>BitMap</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#Hyperloglog><span class=nav-number>1.1.1.9.</span> <span class=nav-text>Hyperloglog</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#geo><span class=nav-number>1.1.1.10.</span> <span class=nav-text>geo</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#stream><span class=nav-number>1.1.1.11.</span> <span class=nav-text>stream</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C><span class=nav-number>1.1.2.</span> <span class=nav-text>常用操作</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#bitmaps><span class=nav-number>1.1.2.1.</span> <span class=nav-text>bitmaps</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#stream%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97><span class=nav-number>1.1.2.2.</span> <span class=nav-text>stream消息队列</span></a></ol></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B><span class=nav-number>1.2.</span> <span class=nav-text>单线程模型</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#Redis-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9%E5%8D%95%E7%BA%BF%E7%A8%8B%EF%BC%9F><span class=nav-number>1.2.1.</span> <span class=nav-text>Redis 为什么选择单线程？</span></a></ol></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E7%BC%93%E5%AD%98><span class=nav-number>2.</span> <span class=nav-text>缓存</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5><span class=nav-number>2.1.</span> <span class=nav-text>缓存更新策略</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF><span class=nav-number>2.2.</span> <span class=nav-text>缓存雪崩、穿透、击穿</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F><span class=nav-number>2.2.1.</span> <span class=nav-text>缓存穿透</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF><span class=nav-number>2.2.2.</span> <span class=nav-text>缓存击穿</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9><span class=nav-number>2.2.3.</span> <span class=nav-text>缓存雪崩</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E7%BC%93%E5%AD%98%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%80%E8%87%B4%E6%80%A7><span class=nav-number>2.3.</span> <span class=nav-text>数据库与缓存如何保证一致性</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E8%BF%98%E6%98%AF%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98><span class=nav-number>2.3.1.</span> <span class=nav-text>删除缓存还是更新缓存</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E5%85%88%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98><span class=nav-number>2.4.</span> <span class=nav-text>先更新数据库还是先删除缓存</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93-%EF%BC%8C%E5%86%8D%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E8%BF%99%E4%B8%A4%E4%B8%AA%E6%93%8D%E4%BD%9C%E8%83%BD%E6%89%A7%E8%A1%8C%E6%88%90%E5%8A%9F><span class=nav-number>2.5.</span> <span class=nav-text>如何保证先更新数据库 ，再删除缓存这两个操作能执行成功</span></a></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6><span class=nav-number>3.</span> <span class=nav-text>持久化机制</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#RDB><span class=nav-number>3.1.</span> <span class=nav-text>RDB</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#AOF><span class=nav-number>3.2.</span> <span class=nav-text>AOF</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#AOF%E5%9B%9E%E5%86%99%E7%AD%96%E7%95%A5><span class=nav-number>3.2.1.</span> <span class=nav-text>AOF回写策略</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#AOF%E6%97%A5%E5%BF%97%E8%BF%87%E5%A4%A7%E4%BC%9A%E8%A7%A6%E5%8F%91%E4%BB%80%E4%B9%88%E6%9C%BA%E5%88%B6><span class=nav-number>3.2.2.</span> <span class=nav-text>AOF日志过大会触发什么机制</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#AOF%E9%87%8D%E5%86%99><span class=nav-number>3.2.3.</span> <span class=nav-text>AOF重写</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96><span class=nav-number>3.2.4.</span> <span class=nav-text>混合持久化</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%A4%A7-Key-%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E5%BD%B1%E5%93%8D><span class=nav-number>3.3.</span> <span class=nav-text>大 Key 对持久化影响</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%AF%B9AOF%E6%97%A5%E5%BF%97%E5%BD%B1%E5%93%8D><span class=nav-number>3.3.1.</span> <span class=nav-text>对AOF日志影响</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#AOF%E9%87%8D%E5%86%99%E5%92%8CRDB%E5%BD%B1%E5%93%8D><span class=nav-number>3.3.2.</span> <span class=nav-text>AOF重写和RDB影响</span></a></ol></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E9%AB%98%E5%8F%AF%E7%94%A8><span class=nav-number>4.</span> <span class=nav-text>高可用</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#Redis%E9%9B%86%E7%BE%A4><span class=nav-number>4.1.</span> <span class=nav-text>Redis集群</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6><span class=nav-number>4.1.1.</span> <span class=nav-text>主从复制</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F><span class=nav-number>4.1.2.</span> <span class=nav-text>哨兵模式</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#cluster%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4><span class=nav-number>4.1.3.</span> <span class=nav-text>cluster分片集群</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#MOVED%E9%87%8D%E5%AE%9A%E5%90%91><span class=nav-number>4.1.3.1.</span> <span class=nav-text>MOVED重定向</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#ASK%E9%87%8D%E5%AE%9A%E5%90%91><span class=nav-number>4.1.3.2.</span> <span class=nav-text>ASK重定向</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB><span class=nav-number>4.1.3.3.</span> <span class=nav-text>故障转移</span></a></ol></ol><li class="nav-item nav-level-2"><a class=nav-link href=#Redis-Cluster%E7%9A%84Hash-Slot-%E6%98%AF16384><span class=nav-number>4.2.</span> <span class=nav-text>Redis Cluster的Hash Slot 是16384</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E9%9B%86%E7%BE%A4%E8%84%91%E8%A3%82%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1><span class=nav-number>4.2.1.</span> <span class=nav-text>集群脑裂导致的数据丢失</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%ADRedis%E6%9F%90%E4%B8%AA%E8%8A%82%E7%82%B9%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8><span class=nav-number>4.3.</span> <span class=nav-text>如何判断Redis某个节点是否正常</span></a></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5><span class=nav-number>5.</span> <span class=nav-text>过期删除与内存淘汰策略</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%A6%82%E4%BD%95%E5%88%A4%E5%AE%9A%E8%BF%87%E6%9C%9F><span class=nav-number>5.1.</span> <span class=nav-text>如何判定过期</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5><span class=nav-number>5.2.</span> <span class=nav-text>过期删除策略</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5><span class=nav-number>5.3.</span> <span class=nav-text>内存淘汰策略</span></a></ol><li class="nav-item nav-level-1"><a class=nav-link href=#Redis%E5%9C%A8%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%BA%94%E7%94%A8><span class=nav-number>6.</span> <span class=nav-text>Redis在项目中应用</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E5%8A%A8%E6%80%81%E7%BC%93%E5%AD%98%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE><span class=nav-number>6.1.</span> <span class=nav-text>如何设计缓存策略动态缓存热点数据</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E9%94%81><span class=nav-number>6.2.</span> <span class=nav-text>实现分布锁</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#Redis%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%9B%86%E7%BE%A4%E6%83%85%E5%86%B5%E4%B8%8B%E9%94%81%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7><span class=nav-number>6.2.1.</span> <span class=nav-text>Redis如何解决集群情况下锁的可靠性</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#stream%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97><span class=nav-number>6.3.</span> <span class=nav-text>stream实现延迟队列</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E7%BC%93%E5%AD%98%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7><span class=nav-number>6.4.</span> <span class=nav-text>数据库与缓存的一致性</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%87%BA%E7%8E%B0%E7%BC%93%E5%AD%98%E5%88%A0%E9%99%A4%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%EF%BC%9F><span class=nav-number>6.4.1.</span> <span class=nav-text>为什么会出现缓存删除失败问题？</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E8%AE%A2%E9%98%85-Binlog-%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86><span class=nav-number>6.4.2.</span> <span class=nav-text>订阅 Binlog 的解决方案原理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95><span class=nav-number>6.4.3.</span> <span class=nav-text>其他方法</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99><span class=nav-number>6.5.</span> <span class=nav-text>相关资料</span></a></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=Sekyoro class=site-author-image itemprop=image src=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg><p class=site-author-name itemprop=name>Sekyoro<div class=site-description itemprop=description>什么也无法舍弃的人，什么也做不了.</div></div><div class="site-state-wrap motion-element"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>245</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>16</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>215</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a title="Personal Website → http://proanimer.com" href=http://proanimer.com/ rel=noopener target=_blank><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a> </span><span class=links-of-author-item> <a title="GitHub → https://github.com/drowning-in-codes" href=https://github.com/drowning-in-codes rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a title="E-Mail → mailto:bukalala174@gmail.com" href=mailto:bukalala174@gmail.com rel=noopener target=_blank><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class=links-of-author-item> <a title="wxPublicAccount → https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" href=https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd rel=noopener target=_blank><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a> </span><span class=links-of-author-item> <a title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span><span class=links-of-author-item> <a title="CSDN → https://blog.csdn.net/aqwca" href=https://blog.csdn.net/aqwca rel=noopener target=_blank><i class="fa fa-handshake fa-fw"></i>CSDN</a> </span><span class=links-of-author-item> <a title="杂鱼分享 → https://my-astro-git-main-drowning-in-codes.vercel.app" href=https://my-astro-git-main-drowning-in-codes.vercel.app/ rel=noopener target=_blank><i class="fas fa-share fa-fw"></i>杂鱼分享</a> </span></div><div class="links-of-blogroll motion-element"><div class=links-of-blogroll-title><i class="fa fa-link fa-fw"></i> 友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=http://myqhs.top/ rel=noopener target=_blank title=http://myqhs.top/>myqhs</a><li class=links-of-blogroll-item><a href=https://www.lllomh.com/ rel=noopener target=_blank title=https://www.lllomh.com/>芈渡</a><li class=links-of-blogroll-item><a href=https://protool-ten.vercel.app/ rel=noopener target=_blank title=https://protool-ten.vercel.app/>protools</a></ul></div><div class="motion-element announcement"><div class=title></div><p class=content><p class=date></div></div><meting-js id=6856787487 order=random server=netease type=playlist> </meting-js><div class=widget-wrap><h3 class=widget-title style=margin:0>文章词云</h3><div class="widget tagcloud" id=myCanvasContainer><canvas height=250 id=resCanvas style=width:100% width=250><ul class=tag-list itemprop=keywords><li class=tag-list-item><a class=tag-list-link href=/tags/Redis/ rel=tag>Redis</a><span class=tag-list-count>1</span></ul></canvas></div></div><script id=clustrmaps src=https://clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a></script><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i><span>0%</span></div><!-- 边栏 --></div></aside> <div id=sidebar-dimmer></div> <footer class=footer><div class=footer-inner><div class=copyright>© Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Sekyoro</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-chart-area"></i> </span><span title=站点总字数>3m</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span><span title=站点阅读时长>45:40</span></div><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container_site_pv>总访问量<span id=busuanzi_value_site_pv></span>次</span><span class=post-meta-divider>|</span><span id=busuanzi_container_site_uv>总访客数<span id=busuanzi_value_site_uv></span>人</span><span class=post-meta-divider>|</span><!-- 不蒜子计数初始值纠正 --><script>$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});</script><div><span id=timeDate>载入天数...</span><span id=times>载入时分秒...</span><script>var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);</script></div><div class=busuanzi-count><script async data-pjax src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span style="display: none;" class=post-meta-item id=busuanzi_container_site_uv> <span class=post-meta-item-icon> <i class="fa fa-user"></i> </span> <span class=site-uv title=总访客量> <span id=busuanzi_value_site_uv></span> </span> </span><span class=post-meta-divider>|</span><span style="display: none;" class=post-meta-item id=busuanzi_container_site_pv> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=site-pv title=总访问量> <span id=busuanzi_value_site_pv></span> </span> </span></div></div></footer> <script color=0,0,255 count=99 opacity=0.5 src=/lib/canvas-nest/canvas-nest.min.js zindex=-1></script> <script src=/lib/anime.min.js></script> <script src=https://cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js></script> <script src=https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js></script> <script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js></script> <script src=https://cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js></script> <script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js></script> <script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js></script> <script src=/js/utils.js></script> <script src=/js/motion.js></script> <script src=/js/schemes/pisces.js></script> <script src=/js/next-boot.js></script> <script src=/js/bookmark.js></script> <script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	'.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});</script> <script data-pjax>(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();</script> <script src=https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js></script> <script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js></script> <script src=/js/algolia-search.js></script> <script data-pjax>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script> <div id=pjax><script charset=utf-8 defer src=/js/outdate.js></script></div> <script charset=utf-8 defer src=/js/tagcanvas.js></script> <script charset=utf-8 defer src=/js/tagcloud.js></script> <script>NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});</script> <script>var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });</script> <script src=/js/src/activate-power-mode.min.js></script> <script>POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);</script> 