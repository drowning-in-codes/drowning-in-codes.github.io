<!doctypehtml><html lang=zh-CN><script defer src=/live2d-widget/autoload.js></script><meta charset=UTF-8><meta content=width=device-width,initial-scale=1,maximum-scale=2 name=viewport><meta content=#222 name=theme-color><meta content="Hexo 5.4.0" name=generator><link href=/images/blog_32px.png rel=apple-touch-icon sizes=180x180><link href=/images/blog_32px.png rel=icon sizes=32x32 type=image/png><link href=/images/blog_16px.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><meta content=EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w name=google-site-verification><!-- Google tag (gtag.js) --><!-- 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script> --><!-- google adsense in head.swig --><script async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123></script><meta content=7226864CE87CE9DE8C008385273846FF name=msvalidate.01><meta content=code-fjFXVtiL7j name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link as=style href=https://fonts.googleapis.com/css?family=Roboto%20Mono,Roboto:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext onload=this.rel='stylesheet' rel=preload><link as=style href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css onload=this.rel='stylesheet' rel=preload><link href=https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap rel=stylesheet><link href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/pace-js@1/pace.min.js></script><script id=hexo-configurations>var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"0F9LEEVW82","apiKey":"78839e9f9be09d081c5c4da81975cd19","indexName":"sekyoblog_sec","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};</script><link href=//cdn.bootcss.com/animate.css/3.5.0/animate.min.css rel=stylesheet><meta content="周志明老师的几本业内享誉的书，包括凤凰架构：构建可靠的大型分布式系统 | 凤凰架构，深入理解Java虚拟机，智慧的疆界等。都是很好的学习资料，这里对凤凰架构做一些简单读后感" name=description><meta content=article property=og:type><meta content=凤凰架构学习 property=og:title><meta content=https://www.sekyoro.top/2025/12/30/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0/index.html property=og:url><meta content=Sekyoro的博客小屋 property=og:site_name><meta content="周志明老师的几本业内享誉的书，包括凤凰架构：构建可靠的大型分布式系统 | 凤凰架构，深入理解Java虚拟机，智慧的疆界等。都是很好的学习资料，这里对凤凰架构做一些简单读后感" property=og:description><meta content=zh_CN property=og:locale><meta content=https://s2.loli.net/2026/01/10/3QUgkEYsd4D5yMo.png property=og:image><meta content=https://s2.loli.net/2026/01/17/JfPC83GImLAUs6t.png property=og:image><meta content=https://s2.loli.net/2026/01/17/P1bSpYD6inHEd9x.png property=og:image><meta content=https://s2.loli.net/2026/01/19/GpVQTCvBPqK36My.png property=og:image><meta content=https://s2.loli.net/2026/01/19/nPuZdlfx81b5WTv.png property=og:image><meta content=https://s2.loli.net/2026/01/19/5buzEGCsU2qrHKj.png property=og:image><meta content=https://s2.loli.net/2026/01/30/LBoqCrxwlPWINUc.png property=og:image><meta content=https://s2.loli.net/2026/01/30/mGsoYJ61XguTDCx.png property=og:image><meta content=https://s2.loli.net/2026/01/30/7n1Va5YByC8wGcr.png property=og:image><meta content=https://s2.loli.net/2026/01/30/qHVznybSg71lxUo.png property=og:image><meta content=https://s2.loli.net/2026/01/30/s8HMFphjYQb1aGJ.png property=og:image><meta content=https://s2.loli.net/2026/01/30/2mrEXG8VcCxd9eT.png property=og:image><meta content=https://s2.loli.net/2026/01/30/UdWMCisZSTaYE2h.png property=og:image><meta content=https://s2.loli.net/2026/01/30/851eJUml9VXnKTG.png property=og:image><meta content=https://s2.loli.net/2026/01/30/PpsHoeAr2Utycv3.png property=og:image><meta content=2025-12-30T10:00:43.000Z property=article:published_time><meta content=2026-01-30T15:18:16.740Z property=article:modified_time><meta content=Sekyoro property=article:author><meta content="个人博客 技术学习 计算机 互联网 人工智能" property=article:tag><meta content=summary name=twitter:card><meta content=https://s2.loli.net/2026/01/10/3QUgkEYsd4D5yMo.png name=twitter:image><link href=https://www.sekyoro.top/2025/12/30/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0/ rel=canonical><script id=page-configurations>// https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };</script><title>凤凰架构学习 | Sekyoro的博客小屋</title><noscript><style>.use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }</style></noscript><link href=/atom.xml rel=alternate title=Sekyoro的博客小屋 type=application/atom+xml><body itemscope itemtype=http://schema.org/WebPage><canvas style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" class=fireworks></canvas><script defer src=https://cdn.bootcss.com/animejs/2.2.0/anime.min.js></script><script defer src=/js/src/fireworks.js></script><div class="container use-motion"><div class=headband></div><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <h1 class=site-title>Sekyoro的博客小屋</h1> <span class=logo-line-after><i></i></span> </a></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu" id=menu><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-bangumis"><a href=/bangumis/ rel=section><i class="fa fa-film fa-fw"></i>追番</a><li class="menu-item menu-item-resume"><a href=/resume/ rel=section><i class="fa fa-file-pdf fa-fw"></i>简历</a><li class="menu-item menu-item-materials"><a href=/materials/ rel=section><i class="fa fa-book fa-fw"></i>学习资料</a><li class="menu-item menu-item-sitemap"><a href=/sitemap.xml rel=section><i class="fa fa-sitemap fa-fw"></i>站点地图</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container></div><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span></div><div class=algolia-results><div id=algolia-stats></div><div id=algolia-hits></div><div class=algolia-pagination id=algolia-pagination></div></div></div></div></div></header><a class="book-mark-link book-mark-link-fixed" role=button></a><main class=main><div class=main-inner><div class=content-wrap><div class="content post posts-expand"><article class=post-block itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://www.sekyoro.top/2025/12/30/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg itemprop=image> <meta content=Sekyoro itemprop=name> <meta content=什么也无法舍弃的人，什么也做不了. itemprop=description> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=Sekyoro的博客小屋 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>凤凰架构学习</h1><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-12-30 18:00:43" datetime=2025-12-30T18:00:43+08:00>2025-12-30</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-30 23:18:16" datetime=2026-01-30T23:18:16+08:00 itemprop=dateModified>2026-01-30</time> </span><span style="display: none;" class=post-meta-item id=busuanzi_container_page_pv title=阅读次数> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=post-meta-item-text>阅读次数：</span> <span id=busuanzi_value_page_pv></span> </span><br><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>74k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>1:07</span> </span></div></header><div class=post-body itemprop=articleBody><p>周志明老师的几本业内享誉的书，包括<a href=https://icyfenix.cn/ rel=noopener target=_blank>凤凰架构：构建可靠的大型分布式系统 | 凤凰架构</a>，深入理解Java虚拟机，智慧的疆界等。都是很好的学习资料，这里对凤凰架构做一些简单读后感<br><span id=more></span><h2 id=早期的分布式探索><a class=headerlink href=#早期的分布式探索 title=早期的分布式探索></a>早期的分布式探索</h2><blockquote><p>可能与绝大多数人心中的认知会有差异，“使用多个独立的分布式服务共同构建一个更大型系统”的设想与实际尝试，反而要比今天大家所了解的大型单体系统出现的时间更早。</blockquote><p>由于早期单个计算机硬件处理能力优先，不同机构开始寻找<strong>使用多台计算机共同协作来支撑同一套软件系统运行的可行方案</strong><p>其中最为重要的是OSF组织制定的<strong>DCE标准</strong>(分布式运算环境),DCE 包含一套相对完整的分布式服务组件规范与参考实现，譬如源自 NCA 的远程服务调用规范（Remote Procedure Call，RPC）,而NCA是早期惠普公司提出的网络运算架构。 还有基于通用 TCP/IP 协议的远程服务标准ONC RPC被认为是现代 RPC 的共同鼻祖；源自 AFS 的分布式文件系统（Distributed File System，DFS）规范，当时被称为<a href=https://en.wikipedia.org/wiki/DCE_Distributed_File_System rel=noopener target=_blank>DCE/DFS</a>；源自 Kerberos 的服务认证规范；还有时间服务、命名与目录服务，就连现在程序中很常用的通用唯一识别符 UUID 也是在 DCE 中发明出来的。<p><img alt=image-20260110120637940 data-src=https://s2.loli.net/2026/01/10/3QUgkEYsd4D5yMo.png><blockquote><p>这次尝试最大的收获就是对 RPC、DFS 等概念的开创，以及得到了一个价值千金的教训：<strong>某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果。</strong>”</blockquote><p>由于当时微型计算机的性能以每两年即增长一倍的惊人速度提升，信息系统进入了以单台或少量几台计算机即可作为服务器来支撑大型信息系统运作的单体时代，且在很长的一段时间内，单体都将是软件架构的绝对主流。<h2 id=单体系统><a class=headerlink href=#单体系统 title=单体系统></a>单体系统</h2><p>“单体”只是表明系统中主要的过程调用都是进程内调用，不会发生进程间通信。<blockquote><p>单体系统的不足，必须基于软件的性能需求超过了单机，软件的开发人员规模明显超过了“<a href=https://wiki.mbalib.com/wiki/两个披萨原则 rel=noopener target=_blank>2 Pizza Team</a>”范畴的前提下才有讨论的价值</blockquote><p>在“拆分”这方面，单体系统的真正缺陷不在如何拆分，而在<strong>拆分之后的隔离与自治能力上的欠缺。由于所有代码都运行在同一个进程空间之内，所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事和性能损失</strong>。获得了进程内调用的简单、高效等好处的同时，也意味着<strong>如果任何一部分代码出现了缺陷，过度消耗了进程空间内的资源，所造成的影响也是全局性的、难以隔离的</strong>。譬如内存泄漏、线程爆炸、阻塞、死循环等问题，都将会影响整个程序，而不仅仅是影响某一个功能、模块本身的正常运作。如果消耗的是某些更高层次的公共资源，譬如端口号或者数据库连接池泄漏，影响还将会波及整台机器，甚至是集群中其他单体副本的正常工作。<h2 id=面向服务架构SOA><a class=headerlink href=#面向服务架构SOA title=面向服务架构SOA></a>面向服务架构SOA</h2><p>SOA 的核心理念是<strong>将大型的业务系统拆解成一个个独立的、可复用的“服务”，</strong>这些服务就像积木一样，可以通过标准协议组合成更复杂的业务流程。<p>面向服务的架构是一次具体地、系统性地成功<strong>解决分布式服务主要问题的架构模式</strong>。<p>为了<strong>对大型的单体系统进行拆分，让每一个子系统都能独立地部署、运行、更新</strong>，开发者们曾经尝试过多种方案，这里列举以下三种较有代表性的架构模式，具体如下。<h3 id=烟囱式架构><a class=headerlink href=#烟囱式架构 title=烟囱式架构></a>烟囱式架构</h3><p>信息烟囱又名信息孤岛（Information Island），使用这种架构的系统也被称为孤岛式信息系统或者烟囱式信息系统。它<strong>指的是一种完全不与其他相关信息系统进行互操作或者协调工作的设计模式。</strong>这样的系统其实并没有什么“架构设计”可言。<strong>两个不发生交互的信息系统，让它们使用独立的数据库和服务器即可实现拆分</strong>，而唯一的问题，也是致命的问题是，对于两个信息系统来说，哪怕真的毫无业务往来关系，但系统的人员、组织、权限等主数据，会是完全独立、没有任何重叠的吗？这样“独立拆分”“老死不相往来”的系统，显然不可能是企业所希望见到的。<h3 id=微内核架构><a class=headerlink href=#微内核架构 title=微内核架构></a>微内核架构</h3><p>微内核架构也被称为插件式架构（Plug-in Architecture）。既然在烟囱式架构中，没有业务往来关系的系统也可能需要共享人员、组织、权限等一些的公共的主数据，那不妨就<strong>将这些主数据，连同其他可能被各子系统使用到的公共服务、数据、资源集中到一块，成为一个被所有业务系统共同依赖的核心</strong>（Kernel，也称为 Core System），<strong>具体的业务系统以插件模块</strong>（Plug-in Modules）的形式存在，这样也可提供可扩展的、灵活的、天然隔离的功能特性，即微内核架构<p>这种模式很适合桌面应用程序，也经常在 Web 应用程序中使用。任何计算机系统都是由各种软件互相配合工作来实现具体功能的，本节列举的不同架构实现的软件，都可视作整个系统的某种插件。对于平台型应用来说，如果我们希望将新特性或者新功能及时加入系统，微内核架构会是一种不错的方案。微内核架构也可以嵌入到其他的架构模式之中，通过插件的方式来提供新功能的定制开发能力，如果你准备实现一个能够支持二次开发的软件系统，微内核也会是一种良好的选择。<br>不过，微内核架构也有它的局限和使用前提，它<strong>假设系统中各个插件模块之间是互不认识，不可预知系统将安装哪些模块，因此这些插件可以访问内核中一些公共的资源，但不会直接交互。</strong>可是，无论是企业信息系统还是互联网应用，这一前提假设在许多场景中都并不成立，我们必须找到办法，既能拆分出独立的系统，也能让拆分后的子系统之间顺畅地互相调用通信。<h3 id=事件驱动架构><a class=headerlink href=#事件驱动架构 title=事件驱动架构></a>事件驱动架构</h3><p>为了能让子系统互相通信，一种可行的方案是<strong>在子系统之间建立一套事件队列管道</strong>（Event Queues），<strong>来自系统外部的消息将以事件的形式发送至管道中，各个子系统从管道里获取自己感兴趣、能够处理的事件消息，也可以为事件新增或者修改其中的附加信息，甚至可以自己发布一些新的事件到管道队列中去</strong>，如此，每一个消息的处理者都是独立的，高度解耦的，但又能与其他处理者（如果存在该消息处理者的话）通过事件管道进行互动<p><img alt=image-20260117161811392 data-src=https://s2.loli.net/2026/01/17/JfPC83GImLAUs6t.png style=zoom:67%;><h2 id=微服务时代><a class=headerlink href=#微服务时代 title=微服务时代></a>微服务时代</h2><p>微服务是一种<strong>通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建</strong>。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。<p>SOA 旨在实现企业内部异构系统的“集成”与“重用”，而微服务旨在实现单个复杂应用的“解耦”与“敏捷”。<div class=table-container><table><thead><tr><th><strong>特性</strong><th><strong>SOA (面向服务架构)</strong><th><strong>微服务 (Microservices)</strong><tbody><tr><td><strong>颗粒度</strong><td><strong>粗粒度</strong>：如“财务系统”、“库存管理”。<td><strong>细粒度</strong>：如“库存查询”、“订单支付”。<tr><td><strong>通信机制</strong><td><strong>重量级总线</strong>：依赖 ESB（企业服务总线）进行路由和协议转换。<td><strong>轻量级通信</strong>：使用 REST API、gRPC 或消息队列。<tr><td><strong>数据管理</strong><td><strong>共享数据库</strong>：多个服务通常共用一个中心数据库。<td><strong>独立数据库</strong>：每个微服务拥有自己的数据库，实现数据隔离。<tr><td><strong>治理方式</strong><td><strong>集中式治理</strong>：统一的标准、统一的技术栈。<td><strong>去中心化治理</strong>：团队可根据需要选择不同的技术栈（Polyglot）。<tr><td><strong>部署方式</strong><td>通常是<strong>整体部署</strong>或大块部署，变更影响范围大。<td><strong>独立部署</strong>：每个微服务都可以独立于其他服务进行更新。<tr><td><strong>架构重心</strong><td><strong>重用性</strong>：如何让旧系统重新发挥价值。<td><strong>解耦性</strong>：如何让系统更易于扩展和快速迭代。</table></div><h2 id=后微服务时代><a class=headerlink href=#后微服务时代 title=后微服务时代></a>后微服务时代</h2><p>从软件层面独力应对微服务架构问题，发展到软、硬一体，合力应对架构问题的时代，此即为“后微服务时代”。<p>分布式架构中出现的问题，如注册发现、跟踪治理、负载均衡、传输通信等，其实在 SOA 时代甚至可以说从原始分布式时代起就已经存在了，只要是分布式架构的系统，就无法完全避免，但我们不妨换个思路来想一下，这些问题一定要由软件系统自己来解决吗？<p><strong>如果不局限于采用软件的方式，这些问题几乎都有对应的硬件解决方案</strong>。譬如，某个系统需要伸缩扩容，通常会购买新的服务器，部署若干副本实例来分担压力；如果某个系统需要解决负载均衡问题，通常会布置负载均衡器，选择恰当的均衡算法来分流；如果需要解决传输安全问题，通常会布置 TLS 传输链路，配置好 CA 证书以保证通信不被窃听篡改；如果需要解决服务发现问题，通常会设置 DNS 服务器，让服务访问依赖稳定的记录名而不是易变的 IP 地址，等等。经过计算机科学多年的发展，这些问题大多有了专职化的基础设施去解决，而之所以微服务时代，人们选择在软件的代码层面而不是硬件的基础设施层面去解决这些分布式问题，很大程度上是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举。软件可以只使用键盘命令就能拆分出不同的服务，只通过拷贝、启动就能够伸缩扩容服务，硬件难道就不可以通过敲键盘就变出相应的应用服务器、负载均衡器、DNS 服务器、网络链路这些设施吗？<blockquote><p>微服务时代所取得的成就，本身就离不开以 Docker 为代表的早期容器化技术的巨大贡献。在此之前，笔者从来没有提起过“容器”二字，这并不是刻意冷落，而是早期的容器只被简单地视为一种可快速启动的服务运行环境，目的是方便程序的分发部署，这个阶段针对单个应用进行封装的容器并未真正参与到分布式问题的解决之中。</blockquote><p>被业界广泛认可、普遍采用的<strong>通过虚拟化基础设施去解决分布式架构问题的开端</strong>，应该要从 2017 年 Kubernetes 赢得容器战争的胜利开始算起。<div class=table-container><table><thead><tr><th>Kubernetes<th>Spring Cloud<th><tbody><tr><td>弹性伸缩<td>Autoscaling<td>N/A<tr><td>服务发现<td>KubeDNS / CoreDNS<td>Spring Cloud Eureka<tr><td>配置中心<td><strong>ConfigMap</strong> / <strong>Secret</strong><td>Spring Cloud Config<tr><td>服务网关<td><strong>Ingress Controller</strong><td>Spring Cloud Zuul<tr><td>负载均衡<td><strong>Load Balancer</strong><td>Spring Cloud Ribbon<tr><td>服务安全<td>RBAC API<td>Spring Cloud Security<tr><td>跟踪监控<td>Metrics API / Dashboard<td>Spring Cloud Turbine<tr><td>降级熔断<td>N/A<td>Spring Cloud Hystrix</table></div><p>当虚拟化的基础设施从单个服务的容器扩展至由多个容器构成的服务集群、通信网络和存储设施时，软件与硬件的界限便已经模糊。一旦虚拟化的硬件能够跟上软件的灵活性，<strong>那些与业务无关的技术性问题便有可能从软件层面剥离，悄无声息地解决于硬件基础设施之内，让软件得以只专注业务</strong>，真正“围绕业务能力构建”团队与产品。<h4 id=服务网格><a class=headerlink href=#服务网格 title=服务网格></a>服务网格</h4><p>Kubernetes 成为容器战争胜利者标志着后微服务时代的开端，但 Kubernetes 仍然没有能够完美解决全部的分布式问题。 有一些问题处于应用系统与基础设施的边缘，使得完全在基础设施层面中确实很难精细化地处理。<p>举个例子，微服务 A 调用了微服务 B 的两个服务，称为 B1和 B2，假设 B1表现正常但 B2出现了持续的 500 错，那在达到一定阈值之后就应该对 B2进行熔断，以避免产生雪崩效应。<strong>如果仅在基础设施层面来处理，这会遇到一个两难问题，切断 A 到 B 的网络通路则会影响到 B1的正常调用，不切断的话则持续受 B2的错误影响。</strong><p>为了解决这一类问题，虚拟化的基础设施很快完成了第二次进化，引入了今天被称为“服务网格”（Service Mesh）的“边车代理模式”（Sidecar Proxy）<p>这个场景里指的具体含义是<strong>由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器</strong>，以类似网络安全里中间人攻击的方式进行流量劫持，<strong>在应用毫无感知的情况下，悄然接管应用所有对外通信。这个代理除了实现正常的服务间通信外（称为数据平面通信），还接收来自控制器的指令（称为控制平面通信）</strong>，<strong>根据控制平面中的配置，对数据平面通信的内容进行分析处理，以实现熔断、认证、度量、监控、负载均衡等各种附加功能。</strong>这样便实现了<strong>既不需要在应用层面加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理</strong>能力。<p>服务网格将会成为微服务之间通信交互的主流模式，把“选择什么通信协议”、“怎样调度流量”、“如何认证授权”之类的技术问题隔离于程序代码之外，取代今天 Spring Cloud 全家桶中大部分组件的功能，微服务只需要考虑业务本身的逻辑<p><img alt=image-20260117175734501 data-src=https://s2.loli.net/2026/01/17/P1bSpYD6inHEd9x.png style=zoom:67%;><h2 id=无服务时代Serverless><a class=headerlink href=#无服务时代Serverless title=无服务时代Serverless></a>无服务时代Serverless</h2><blockquote><p>如果说微服务架构是分布式系统这条路的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。<p><strong>无服务</strong>（Serverless Computing）并不是指真的不需要服务器，而是指<strong>开发者不再需要关心服务器的运维和管理</strong>。在无服务架构中，云服务商（如 AWS、阿里云、腾讯云）负责处理所有的底层资源管理，包括服务器的采购、配置、维护、更新以及根据流量进行的自动扩缩容。开发者只需要编写业务逻辑代码并上传即可</blockquote><p>无服务现在还没有一个特别权威的“官方”定义，但它的概念并没有前面各种架构那么复杂，本来无服务也是以“简单”为主要卖点的，它只涉及两块内容：后端设施（Backend）和函数（Function）。<ul><li><strong>后端设施</strong>是指<strong>数据库</strong>、<strong>消息队列</strong>、<strong>日志</strong>、<strong>存储</strong>，等等这一类<strong>用于支撑业务逻辑运行，但本身无业务含义的技术组件</strong>，这些后端设施都运行在云中，无服务中称其为“后端即服务”（Backend as a Service，BaaS）。<li><strong>函数</strong>是指业务逻辑代码，这里函数的概念与粒度，都已经很接近于程序编码角度的函数了，其区别是无服务中的函数运行在云端，不必考虑算力问题，不必考虑容量规划（从技术角度可以不考虑，从计费的角度你的钱包够不够用还是要掂量一下的），无服务中称其为“函数即服务”（Function as a Service，FaaS）。</ul><p>无服务的愿景是<strong>让开发者只需要纯粹地关注业务，不需要考虑技术组件，后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼</strong>；不需要考虑如何部署，<strong>部署过程完全是托管到云端的，工作由云端自动完成；不需要考虑算力，有整个数据中心支撑，算力可以认为是无限的；也不需要操心运维，维护系统持续平稳运行是云计算服务商的责任而不再是开发者的责任</strong>。<h2 id=远程服务调用><a class=headerlink href=#远程服务调用 title=远程服务调用></a>远程服务调用</h2><p>它允许程序调用位于另一台计算机（或另一进程）上的子程序，而程序员<strong>不需要显式地编写网络通信相关的代码</strong>。<p>RPC 的工作原理<p>为了实现“透明”的远程调用，RPC 引入了几个核心组件。<ol><li><strong>客户端（Client）：</strong> 服务调用方。<li><strong>客户端存根（Client Stub）：</strong> 存放服务端的地址信息，负责将函数调用打包成网络消息（序列化）。<li><strong>网络传输（Transport）：</strong> 负责将消息从客户端发送到服务端。<li><strong>服务端存根（Server Stub/Skeleton）：</strong> 接收网络消息，将其解包（反序列化）并调用本地的实际函数。<li><strong>服务端（Server）：</strong> 服务提供方，执行真正的业务逻辑。</ol><p>RPC 的核心步骤<p>一个完整的 RPC 调用过程通常包含以下五个阶段：<ol><li><strong>调用：</strong> 客户端程序像调用本地方法一样调用 Client Stub。<li><strong>序列化（Marshaling）：</strong> Client Stub 将参数转换成字节流，以便在网络上传输。<li><strong>传输：</strong> 消息通过 TCP/UDP 等协议发送到远程服务器。<li><strong>反序列化（Unmarshaling）：</strong> Server Stub 接收到消息，将字节流还原为函数参数。<li><strong>返回：</strong> 服务端处理完逻辑后，将结果通过同样的步骤返回给客户端。</ol><p>在现代分布式架构（尤其是微服务）中，开发者通常使用现成的 RPC 框架：<ul><li><strong>gRPC：</strong> Google 开发的高性能框架，使用 <strong>Protocol Buffers</strong> 作为序列化协议，基于 HTTP/2。<li><strong>Dubbo：</strong> 阿里巴巴开源的高性能 Java RPC 框架，在国内企业中应用广泛。<li><strong>Thrift：</strong> Facebook 开发的跨语言 RPC 框架。<li><strong>Spring Cloud OpenFeign：</strong> 虽然底层通常走 HTTP，但在 Spring 生态中实现了类似 RPC 的开发体验。</ul><h3 id=进程间通信><a class=headerlink href=#进程间通信 title=进程间通信></a>进程间通信</h3><p>调用一个本地方法时，进程，确切的说是进程中的一个线程，会在自己的地址空间创建栈帧。<p>在完全不考虑编译器优化的前提下，程序运行至调用<code>println()</code>方法输出<code>hello world</code>这行时，计算机（物理机或者虚拟机）要完成以下几项工作。<ol><li><strong>传递方法参数</strong>：将字符串<code>helloworld</code>的引用地址压栈。<li><strong>确定方法版本</strong>：根据<code>println()</code>方法的签名，确定其执行版本。这其实并不是一个简单的过程，不论是编译时静态解析也好，是运行时动态分派也好，总之必须根据某些语言规范中明确定义原则，找到明确的<code>Callee</code>，“明确”是指唯一的一个<code>Callee</code>，或者有严格优先级的多个<code>Callee</code>，譬如不同的重载版本。笔者曾在《<a href=https://book.douban.com/subject/34907497/ rel=noopener target=_blank>深入理解 Java 虚拟机</a>》中用一整章篇幅介绍该过程，有兴趣的读者可以参考，这里就不赘述了。<li><strong>执行被调方法</strong>：从栈中弹出<code>Parameter</code>的值或引用，以此为输入，执行<code>Callee</code>内部的逻辑；这里我们只关心方法如何调用的，不关心方法内部具体是如何执行的。<li><strong>返回执行结果</strong>：将<code>Callee</code>的执行结果压栈，并将程序的指令流恢复到<code>Call Site</code>的下一条指令，继续向下执行。</ol><p>如果caller和callee不在同一进程，此时至少面临两个直接的障碍：<p>首先<strong>，第一步和第四步所做的传递参数、传回结果都依赖于栈内存的帮助</strong>，如果<code>Caller</code>与<code>Callee</code>分属不同的进程，<strong>就不会拥有相同的栈内存，将参数在<code>Caller</code>进程的内存中压栈</strong>，对于 Callee 进程的执行毫无意义。<p>其次，第二步的<strong>方法版本选择依赖于语言规则的定义</strong>，如果<code>Caller</code>与<code>Callee</code>不是同一种语言实现的程序，方法版本选择就将是一项模糊的不可知行为。<blockquote><p><strong>Caller (调用者)：</strong> 发起函数调用的代码块。它负责准备执行环境，将必要的参数传递给目标函数，并等待（或异步接收）执行结果。<p><strong>Callee (被调用者)：</strong> 被执行的函数或过程。它接收来自调用者的参数，执行其内部定义的逻辑，并在完成后将控制权（以及可能的返回值）交还给调用者。</blockquote><p>假设<code>Caller</code>与<code>Callee</code>是使用同一种语言实现的，先来解决两个进程之间如何交换数据的问题，这件事情在计算机科学中被称为“进程间通信”（Inter-Process Communication，IPC）。可以考虑的办法有管道，信号，消息队列，共享内存以及socket网络编程。<p>管道是内核维护的一块缓冲区，用于<strong>在进程之间进行“单向字节流”通信</strong>。匿名管道能用于 <strong>有亲缘关系的进程</strong>，如父子进程。例如fork后父子进程通过pipe(fd);通信,以及shell中的<code>|</code>. 命名管道有文件路径可用于 <strong>无亲缘关系的进程</strong>，持久存在于文件系统,通过<code>mkfifo</code>创建文件<p>管道是最简单的 IPC，本质是内核中的 FIFO 字节流缓冲区； 匿名管道用于亲缘进程，命名管道用于任意进程； 单向、阻塞、容量有限，正确 close 是使用成败的关键。<p><strong>信号</strong>（Signal）：信号用于通知目标进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程自身。信号的典型应用是<code>kill</code>命令:<p><strong>消息队列</strong>是<strong>内核</strong>中的一个链表（或优先队列），<strong>进程可以按“消息”为单位发送和接收数据</strong>，而不是字节流。消息队列克服了信号承载信息量少，管道只能用于无格式字节流以及缓冲区大小受限等缺点，但实时性相对受限。<p><strong>共享内存</strong>（Shared Memory）：允许多个进程访问同一块公共的内存空间，这是效率最高的进程间通信形式。原本每个进程的内存地址空间都是相互隔离的，但<strong>操作系统提供了让进程主动创建、映射、分离、控制某一块内存的程序接口</strong>。当一块内存被多进程共享时，各个进程往往会与其它通信机制，譬如信号量结合使用，来达到进程间同步及互斥的协调操作。<p><strong>套接字接口</strong>（Socket）：消息队列和共享内存只适合单机多进程间的通信，套接字接口是更为普适的进程间通信机制，可用于不同机器之间的进程通信。套接字（Socket）起初是由 UNIX 系统的 BSD 分支开发出来的，现在已经移植到所有主流的操作系统上。出于效率考虑，当仅限于本机进程间通信时，套接字接口是被优化过的，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等操作，只是简单地将应用层数据从一个进程拷贝到另一个进程，这种进程间通信方式有个专名的名称：UNIX Domain Socket，又叫做 IPC Socket。<h4 id=Beyond-IPC-通信的成本><a title="Beyond IPC 通信的成本" class=headerlink href=#Beyond-IPC-通信的成本></a>Beyond IPC 通信的成本</h4><p>在跨机器的通信上有三个关键问题<p><strong>如何表示数据</strong>：这里数据包括了传递给方法的参数，以及方法执行后的返回值。无论是将参数传递给另外一个进程，还是从另外一个进程中取回执行结果，都涉及到它们应该如何表示。进程内的方法调用，<strong>使用程序语言预置的和程序员自定义的数据类型，就很容易解决数据表示问题</strong>，<strong>远程方法调用则完全可能面临交互双方各自使用不同程序语言的情况；即使只支持一种程序语言的 RPC 协议，在不同硬件指令集、不同操作系统下，同样的数据类型也完全可能有不一样表现细节</strong>，譬如数据宽度、字节序的差异等等。<strong>有效的做法是将交互双方所涉及的数据转换为某种事先约定好的中立数据流格式来进行传输，将数据流转换回不同语言中对应的数据类型来进行使用，</strong>这个过程说起来拗口，但相信大家一定很熟悉，就是序列化与反序列化。每种 RPC 协议都应该要有对应的序列化协议<p><strong>如何传递数据</strong>：准确地说，是指<strong>如何通过网络，在两个服务的 Endpoint 之间相互操作、交换数据。这里“交换数据”通常指的是应用层协议</strong>，实际传输一般是基于标准的 TCP、UDP 等标准的传输层协议来完成的。两个服务交互不是只扔个序列化数据流来表示参数和结果就行的，<strong>许多在此之外信息，譬如异常、超时、安全、认证、授权、事务，等等</strong>，都可能产生双方需要交换信息的需求。<p><strong>如何确定方法</strong>：这在本地方法调用中并不是太大的问题，<strong>编译器或者解释器会根据语言规范，将调用的方法签名转换为进程空间中子过程入口位置的指针</strong>。不过一旦要考虑不同语言，事情又立刻麻烦起来，每门语言的方法签名都可能有所差别，所以“如何表示同一个方法”，“如何找到对应的方法”还是得弄个跨语言的统一的标准才行。这个标准做起来可以非常简单，譬如直接给程序的每个方法都规定一个唯一的、在任何机器上都绝不重复的编号，调用时压根不管它什么方法签名是如何定义的，直接传这个编号就能找到对应的方法。这种听起既粗鲁又寒碜的办法，还真的就是 DCE/RPC 当初准备的解决方案。虽然最终 DCE 还是弄出了一套<strong>语言无关的接口描述语言</strong>（Interface Description Language，IDL），成为此后许多 RPC 参考或依赖的基础（如 CORBA 的 OMG IDL）<p>由于一直没有一个同时满足以上三点的“完美 RPC 协议”出现，所以远程服务器调用这个小小的领域里，逐渐进入了群雄混战、百家争鸣的战国时代，距离“统一”是越来越远，并一直延续至今。现在，已经相继出现过 RMI（Sun/Oracle）、Thrift（Facebook/Apache）、Dubbo（阿里巴巴/Apache）、gRPC（Google）、Motan1/2（新浪）、Finagle（Twitter）、brpc（百度/Apache）、.NET Remoting（微软）、Arvo（Hadoop）、JSON-RPC 2.0（公开规范，JSON-RPC 工作组）……等等难以穷举的协议和框架。这些 RPC 功能、特点不尽相同，有的是某种语言私有，有的能支持跨越多门语言，有的运行在应用层 HTTP 协议之上，有的能直接运行于传输层 TCP/UDP 协议之上，但肯定不存在哪一款是“最完美的 RPC”。今时今日，任何一款具有生命力的 RPC 框架，都不再去追求大而全的“完美”，而是有自己的针对性特点作为主要的发展方向<h3 id=REST与RPC><a class=headerlink href=#REST与RPC title=REST与RPC></a>REST与RPC</h3><p>REST 与 RPC 在思想上差异的核心是<strong>抽象的目标不一样</strong>，即<strong>面向资源的编程思想</strong>与<strong>面向过程的编程思想</strong>两者之间的区别。面向过程编程、面向对象编程大家想必听说过，但什么是面向资源编程？这个问题等介绍完 REST 的特征之后我们再回头细说。<p>概念上的不同是指 REST 并不是一种远程服务调用协议，甚至可以把定语也去掉，它就不是一种协议。协议都带有一定的规范性和强制性，最起码也该有个规约文档，譬如 JSON-RPC，它哪怕再简单，也要有个《JSON-RPC Specification》来规定协议的格式细节、异常、响应码等信息，但是 REST 并没有定义这些内容，尽管有一些指导原则，但实际上并不受任何强制的约束。<h4 id=如何理解REST><a class=headerlink href=#如何理解REST title=如何理解REST></a>如何理解REST</h4><ul><li><strong>资源</strong>（Resource）：譬如你现在正在阅读一篇名为《REST 设计风格》的文章，这篇文章的内容本身（你可以将其理解为其蕴含的信息、数据）我们称之为“资源”。无论你是购买的书籍、是在浏览器看的网页、是打印出来看的文稿、是在电脑屏幕上阅读抑或是手机上浏览，尽管呈现的样子各不相同，但其中的信息是不变的，你所阅读的仍是同一份“资源”。<li><strong>表征</strong>（Representation）：当你通过电脑浏览器阅读此文章时，浏览器向服务端发出请求“我需要这个资源的 HTML 格式”，服务端向浏览器返回的这个 HTML 就被称之为“表征”，你可能通过其他方式拿到本文的 PDF、Markdown、RSS 等其他形式的版本，它们也同样是一个资源的多种表征。可见“表征”这个概念是指信息与用户交互时的表示形式，这与我们软件分层架构中常说的“表示层”（Presentation Layer）的语义其实是一致的。<li><strong>状态</strong>（State）：当你读完了这篇文章，想看后面是什么内容时，你向服务器发出请求“给我下一篇文章”。但是“下一篇”是个相对概念，必须依赖“当前你正在阅读的文章是哪一篇”才能正确回应，这类在特定语境中才能产生的上下文信息即被称为“状态”。我们所说的有状态（Stateful）抑或是无状态（Stateless），都是只相对于服务端来说的，服务器要完成“取下一篇”的请求，要么自己记住用户的状态：这个用户现在阅读的是哪一篇文章，这称为有状态；要么客户端来记住状态，在请求的时候明确告诉服务器：我正在阅读某某文章，现在要读它的下一篇，这称为无状态。<li><strong>转移</strong>（Transfer）：无论状态是由服务端还是客户端来提供的，“取下一篇文章”这个行为逻辑必然只能由服务端来提供，因为只有服务端拥有该资源及其表征形式。服务器通过某种方式，把“用户当前阅读的文章”转变成“下一篇文章”，这就被称为“表征状态转移”。</ul><p>什么是RESTful的系统<p>Fielding 认为，一套理想的、完全满足 REST 风格的系统应该满足以下六大原则。<ol><li><strong>服务端与客户端分离</strong>（Client-Server）<br>将用户界面所关注的逻辑和数据存储所关注的逻辑分离开来，有助于提高用户界面的跨平台的可移植性，这一点正越来越受到广大开发者所认可，以前完全基于服务端控制和渲染（如 JSF 这类）框架实际用户已甚少，而在服务端进行界面控制（Controller），通过服务端或者客户端的模版渲染引擎来进行界面渲染的框架（如 Struts、SpringMVC 这类）也受到了颇大的冲击。这一点主要推动力量与 REST 可能关系并不大，前端技术（从 ES 规范，到语言实现，到前端框架等）的近年来的高速发展，使得前端表达能力大幅度加强才是真正的幕后推手。由于前端的日渐强势，现在还流行起由前端代码反过来驱动服务端进行渲染的 SSR（Server-Side Rendering）技术，在 Serverless、SEO 等场景中已经占领了一块领地。<li><strong>无状态</strong>（Stateless）<br>无状态是 REST 的一条核心原则，部分开发者在做服务接口规划时，觉得 REST 风格的服务怎么设计都感觉别扭，很有可能的一种原因是在服务端持有着比较重的状态。REST 希望服务器不要去负责维护状态，每一次从客户端发送的请求中，应包括所有的必要的上下文信息，会话信息也由客户端负责保存维护，服务端依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。客户端承担状态维护职责以后，会产生一些新的问题，譬如身份认证、授权等可信问题，它们都应有针对性的解决方案<br>但必须承认的现状是，目前大多数的系统都达不到这个要求，往往越复杂、越大型的系统越是如此。服务端无状态可以在分布式计算中获得非常高价值的好处，但大型系统的上下文状态数量完全可能膨胀到让客户端在每次请求时提供变得不切实际的程度，在服务端的内存、会话、数据库或者缓存等地方持有一定的状态成为一种是事实上存在，并将长期存在、被广泛使用的主流的方案。<li><strong>可缓存</strong>（Cacheability）<br>无状态服务虽然提升了系统的可见性、可靠性和可伸缩性，但降低了系统的网络性。“降低网络性”的通俗解释是某个功能如果使用有状态的设计只需要一次（或少量）请求就能完成，使用无状态的设计则可能会需要多次请求，或者在请求中带有额外冗余的信息。为了缓解这个矛盾，REST 希望软件系统能够如同万维网一样，允许客户端和中间的通讯传递者（譬如代理）将部分服务端的应答缓存起来。当然，为了缓存能够正确地运作，服务端的应答中必须明确地或者间接地表明本身是否可以进行缓存、可以缓存多长时间，以避免客户端在将来进行请求的时候得到过时的数据。运作良好的缓存机制可以减少客户端、服务器之间的交互，甚至有些场景中可以完全避免交互，这就进一步提高了性能。<li><strong>分层系统</strong>（Layered System）<br>这里所指的并不是表示层、服务层、持久层这种意义上的分层。而是指客户端一般不需要知道是否直接连接到了最终的服务器，抑或连接到路径上的中间服务器。中间服务器可以通过负载均衡和共享缓存的机制提高系统的可扩展性，这样也便于缓存、伸缩和安全策略的部署。该原则的典型的应用是内容分发网络（Content Distribution Network，CDN）。如果你是通过网站浏览到这篇文章的话，你所发出的请求一般（假设你在中国国境内的话）并不是直接访问位于 GitHub Pages 的源服务器，而是访问了位于国内的 CDN 服务器，但作为用户，你完全不需要感知到这一点。<li><strong>统一接口</strong>（Uniform Interface）<br>这是 REST 的另一条核心原则，REST 希望开发者面向资源编程，希望软件系统设计的重点放在抽象系统该有哪些资源上，而不是抽象系统该有哪些行为（服务）上。这条原则你可以类比计算机中对文件管理的操作来理解，管理文件可能会进行创建、修改、删除、移动等操作，这些操作数量是可数的，而且对所有文件都是固定的、统一的。如果面向资源来设计系统，同样会具有类似的操作特征，由于 REST 并没有设计新的协议，所以这些操作都借用了 HTTP 协议中固有的操作命令来完成。<li><strong>按需代码</strong>（Code-On-Demand）<br>按需代码被 Fielding 列为一条可选原则。它是指任何按照客户端（譬如浏览器）的请求，将可执行的软件程序从服务器发送到客户端的技术，按需代码赋予了客户端无需事先知道所有来自服务端的信息应该如何处理、如何运行的宽容度。</ol><h2 id=事务处理><a class=headerlink href=#事务处理 title=事务处理></a>事务处理</h2><p>事务处理几乎在每一个信息系统中都会涉及，它存在的意义是<strong>为了保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾</strong>，即数据状态的<strong>一致性</strong><p>按照数据库的经典理论，要达成这个目标，需要三方面共同努力来保障。<ul><li><strong>原子性</strong>（<strong>A</strong>tomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。<li><strong>隔离性</strong>（<strong>I</strong>solation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。<li><strong>持久性</strong>（<strong>D</strong>urability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。</ul><p>以上四种属性即事务的“ACID”特性，这四种特性并不正交，A、I、D 是手段，C 是目的，前者是因，后者是果，弄到一块去完全是为了拼凑个单词缩写。<p>事务的概念虽然最初起源于数据库系统，但今天已经有所延伸，而不再局限于数据库本身了，所有需要保证数据一致性的应用场景<strong>，包括但不限于数据库、事务内存、缓存、消息队列、分布式存储</strong>，等等，都有可能会用到事务<ul><li>当一个服务只使用一个数据源时，通过 A、I、D 来获得一致性是最经典的做法，也是相对容易的。此时，多个并发事务所读写的数据能够被数据源感知是否存在冲突，并发事务的读写在时间线上的最终顺序是由数据源来确定的，这种事务间一致性被称为“内部一致性”。<li>当一个服务使用到多个不同的数据源，甚至多个不同服务同时涉及多个不同的数据源时，问题就变得相对困难了许多。此时，并发执行甚至是先后执行的多个事务，在时间线上的顺序并不由任何一个数据源来决定，这种涉及多个数据源的事务间一致性被称为“外部一致性”。</ul><p>外部一致性问题通常很难再使用 A、I、D 来解决，因为这样需要付出很大乃至不切实际的代价；但是外<strong>部一致性又是分布式系统中必然会遇到且必须要解决的问题</strong>，为此我们要转变观念，将一致性从“是或否”的二元属性转变为可以<strong>按不同强度分开讨论的多元属性，在确保代价可承受的前提下获得强度尽可能高的一致性保障</strong>，也正因如此，事务处理才从一个具体操作上的“编程问题”上升成一个需要全局权衡的“架构问题”。<h3 id=本地事务><a class=headerlink href=#本地事务 title=本地事务></a>本地事务</h3><p>本地事务是指<strong>仅操作单一事务资源的、不需要全局事务管理器进行协调的事务</strong>。<p>本地事务是最基础的一种事务解决方案<strong>，只适用于单个服务使用单个数据源的场景</strong>。从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并不能深入参与到事务的运作过程当中，<strong>事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作</strong>，这一点与后续的 XA、TCC、SAGA 等主要靠应用程序代码来实现的事务有着十分明显的区别。<blockquote><p>ARIES 是现代数据库的基础理论。在 20 世纪 90 年代，<a href=http://www.research.ibm.com/labs/almaden/ rel=noopener target=_blank>IBM Almaden 研究院</a>总结了研发原型数据库系统“IBM System R”的经验，发表了 ARIES 理论中最主要的三篇论文，其中《<a href=https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf rel=noopener target=_blank>ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging</a>》着重解决了 ACID 的其中两个属性：原子性（A）和持久性（D）在算法层面上应当如何实现。而另一篇《<a href=http://vldb.org/conf/1990/P392.PDF rel=noopener target=_blank>ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes</a>》则是现代数据库隔离性（I）奠基式的文章，</blockquote><h4 id=如何实现原子性和持久性><a class=headerlink href=#如何实现原子性和持久性 title=如何实现原子性和持久性></a>如何实现原子性和持久性</h4><p>原子性和持久性在事务里是密切相关的两个属性，<strong>原子性保证了事务的多个操作要么都生效要么都不生效，不会存在中间状态</strong>；<strong>持久性保证了一旦事务生效，就不会再因为任何原因而导致其修改的内容被撤销或丢失。</strong><p>众所周知，数据必须要成功写入磁盘、磁带等持久化存储器后才能拥有持久性，只存储在内存中的数据，一旦遇到应用程序忽然崩溃，或者数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等情况就会丢失，后文我们将这些意外情况都统称为“崩溃”（Crash）。<p>实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观地存在着“正在写”的中间状态。正因为写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。下面通过具体事例来说明。<p>购买一本书需要修改三个数据：在用户账户中减去货款、在商家账户中增加货款、在商品仓库中标记一本书为配送状态。由于写入存在中间状态，所以可能发生以下情形。<ul><li><strong>未提交事务，写入后崩溃</strong>：程序还没修改完三个数据，但数据库已经将其中一个或两个数据的变动写入磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。<li><strong>已提交事务，写入前崩溃</strong>：程序已经修改完三个数据，但数据库还未将全部三个数据的变动都写入到磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。</ul><p>由于<strong>写入中间状态</strong>与<strong>崩溃</strong>都是无法避免的，为了保证原子性和持久性，就只能在崩溃后采取恢复的补救措施，这种数据恢复操作被称为“崩溃恢复”（Crash Recovery，也有资料称作 Failure Recovery 或 Transaction Recovery）。<p>为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。<p>只有在日志记录全部都安全落盘，<strong>数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改</strong>，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“Commit Logging”（提交日志）<p><strong>Commit Logging 保障数据持久性、原子性的原理</strong><p>首先，日志一旦成功写入 Commit Record，那整个事务就是成功的，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场、继续修改数据即可，这保证了持久性；其次，如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态即可，整个事务就像完全没好有发生过一样，这保证了原子性。<p>Commit Logging 的原理很清晰，也确实有一些数据库就是直接采用 Commit Logging 机制来实现事务的，譬如较具代表性的是阿里的OceanBase。但是，Commit Logging 存在一个巨大的先天缺陷：所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后。在此之前，即使磁盘 I/O 有足够空闲、<strong>即使某个事务修改的数据量非常庞大</strong>，<strong>占用了大量的内存缓冲区</strong>，<strong>无论有何种理由，都决不允许在事务提交之前就修改磁盘上的数据，这一点是 Commit Logging 成立的前提</strong>，却对提升数据库的性能十分不利。为了解决这个问题，前面提到的 ARIES 理论终于可以登场。<p>ARIES 提出了“Write-Ahead Logging”的日志改进方案，所谓“提前写入”（Write-Ahead），就是允许在事务提交之前，提前写入变动数据的意思。<p>Write-Ahead Logging 先将何时写入变动数据，按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。<ul><li><strong>FORCE</strong>：<strong>当事务提交后，要求变动数据必须同时完成写入则称为 FORCE</strong>，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，<strong>因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行</strong>。<li><strong>STEAL</strong>：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。<strong>从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源</strong>，也有利于<strong>节省数据库缓存区的内存。</strong></ul><p>Commit Logging 允许 NO-FORCE，但不允许 STEAL。因为假如事务提交前就有部分变动数据写入磁盘，那一旦事务要回滚，或者发生了崩溃，这些提前写入的变动数据就都成了错误。<p><strong>Write-Ahead Logging 允许 NO-FORCE，也允许 STEAL，它给出的解决办法是增加了另一种被称为 Undo Log 的日志类型，当变动数据写入磁盘前，必须先记录 Undo Log，注明修改了哪个位置的数据、从什么值改成什么值，等等。</strong>以便在事务回滚或者崩溃恢复时根据 Undo Log 对提前写入的数据变动进行擦除。Undo Log 现在一般被翻译为“回滚日志”，此前记录的用于崩溃恢复时重演数据变动的日志就相应被命名为 Redo Log，一般翻译为“重做日志”。<p>由于 Undo Log 的加入，Write-Ahead Logging 在崩溃恢复时会执行以下三个阶段的操作。<ul><li><strong>分析阶段</strong>（Analysis）：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合，这个集合至少会包括 Transaction Table 和 Dirty Page Table 两个组成部分。<li><strong>重做阶段</strong>（Redo）：该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作为：找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。<li><strong>回滚阶段</strong>（Undo）：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。</ul><p>重做阶段和回滚阶段的操作都应该设计为幂等的.数据库按照是否允许 FORCE 和 STEAL 可以产生共计四种组合，从优化磁盘 I/O 的角度看，NO-FORCE 加 STEAL 组合的性能无疑是最高的；从算法实现与日志的角度看 NO-FORCE 加 STEAL 组合的复杂度无疑也是最高的。<blockquote><p>此外还有shaow paing,SQLite Version 3 采用的事务机制就是 Shadow Paging<p>Shadow Paging 的大体思路是对数据的变动会写到硬盘的数据中，但并不是直接就地修改原先的数据，而是先将数据复制一份副本，保留原数据，修改副本数据。在事务过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。<strong>当事务成功提交，所有数据的修改都成功持久化之后，最后一步是去修改数据的引用指针</strong>，将引用从原数据改为新复制出来修改后的副本，<strong>最后的“修改指针”这个操作将被认为是原子操作</strong>，现代磁盘的写操作可以认为在硬件上保证了不会出现“改了半个值”的现象。所以 Shadow Paging 也可以保证原子性和持久性。Shadow Paging 实现事务要比 Commit Logging 更加简单，但涉及隔离性与并发锁时，Shadow Paging 实现的事务并发能力就相对有限，因此在高性能的数据库中应用不多。</blockquote><h4 id=实现隔离性><a class=headerlink href=#实现隔离性 title=实现隔离性></a>实现隔离性</h4><p>隔离性保证了每个事务各自读、写的数据互相独立，不会彼此影响。只从定义上就能嗅出隔离性肯定与并发密切相关，因为如果没有并发，所有事务全都是串行的，那就不需要任何隔离，或者说这样的访问具备了天然的隔离性。<p>如何保证并发下实现串行操作？现代数据库均提供了以下三种锁。<ul><li><strong>写锁</strong>（Write Lock，也叫作排他锁，eXclusive Lock，简写为 X-Lock）：如果<strong>数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据</strong>，也不能施加读锁。<li><strong>读锁</strong>（Read Lock，也叫作共享锁，Shared Lock，简写为 S-Lock）：<strong>多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入</strong>，但仍然可以读取。对于持有读锁的事务，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。<li><strong>范围锁</strong>（Range Lock）：对于某个范围直接加排他锁，在这个范围内的数据不能被写入</ul><p>事务隔离的不同等级，可串行化，可重复读，读已提交以及读未提交。<p>串行化访问提供了强度最高的隔离性，ANSI/ISO SQL-92中定义的最高等级的隔离级别便是<code>可串行化</code>（Serializable）。<code>可串行化</code>完全符合普通程序员对数据竞争加锁的理解。如果不考虑性能优化的话，对事务所有读、写的数据全都加上读锁、写锁和范围锁即可做到<code>可串行化</code>（实际还是很复杂的，<strong>要分成 Expanding 和 Shrinking 两阶段去处理读锁、写锁与数据间的关系</strong>，称为<a href=https://en.wikipedia.org/wiki/Two-phase_locking rel=noopener target=_blank>Two-Phase Lock</a>，2PL）。<p>但数据库不考虑性能肯定是不行的，<a href=https://en.wikipedia.org/wiki/Concurrency_control rel=noopener target=_blank>并发控制理论</a>（Concurrency Control）决定了<strong>隔离程度与并发能力是相互抵触的，隔离程度越高，并发访问时的吞吐量就越低</strong>。<p>现代数据库一定会提供除<code>可串行化</code>以外的其他隔离级别供用户使用，让用户调节隔离级别的选项，根本目的是让用户可以调节数据库的加锁方式，取得隔离性与吞吐量之间的平衡。<p><code>可重复读</code>对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，<strong>但不再加范围锁</strong>。<code>可重复读</code>比<code>可串行化</code>弱化的地方<strong>在于幻读问题，它是指在事务执行过程中，两个完全相同的范围查询得到了不同的结果集。</strong><blockquote><p>这里的介绍是以 ARIES 理论为讨论目标的，具体的数据库并不一定要完全遵照着理论去实现。一个例子是 MySQL/InnoDB 的默认隔离级别为<code>可重复读</code>，但它在只读事务中可以完全避免幻读问题，譬如上面例子中事务 T1 只有查询语句，是一个只读事务，所以例子中的问题在 MySQL 中并不会出现。但在读写事务中，MySQL 仍然会出现幻读问题，譬如例子中事务 T1 如果在其他事务插入新书后，不是重新查询一次数量，而是要将所有小于 100 元的书改名，那就依然会受到新插入书籍的影响</blockquote><p><code>读已提交</code>对事务涉及的数据加的写锁会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。<strong><code>读已提交</code>比<code>可重复读</code>弱化的地方在于不可重复读问题（Non-Repeatable Reads），它是指在事务执行过程中，对同一行数据的两次查询得到了不同的结果。</strong><p>原因是<code>读已提交</code>的隔离级别缺乏贯穿整个事务周期的读锁，无法禁止读取过的数据发生变化，此时事务 T2 中的更新语句可以马上提交成功，这也是一个事务受到其他事务影响，隔离性被破坏的表现。假如隔离级别是<code>可重复读</code>的话，由于数据已被事务 T1 施加了读锁且读取后不会马上释放，所以事务 T2 无法获取到写锁，更新就会被阻塞，直至事务 T1 被提交或回滚后才能提交。<p><code>读未提交</code>对事务涉及的数据只加写锁，会一直持续到事务结束，但完全不加读锁。<code>读未提交</code>比<code>读已提交</code>弱化的地方在于脏读问题（Dirty Reads），它是指<strong>在事务执行过程中，一个事务读取到了另一个事务未提交的数据。</strong><p>除了都以锁来实现外，以上四种隔离级别还有另一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性，针对这种“一个事务读+另一个事务写”的隔离问题，近年来有一种名为“<strong>多版本并发控制</strong>”（Multi-Version Concurrency Control，MVCC）的<strong>无锁优化方案</strong>被主流的商业数据库广泛采用。<p><strong>MVCC 是一种读取优化策略，它的“无锁”是特指读取时不需要加锁。MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的</strong>。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION 和 DELETE_VERSION，这两个字段记录的值都是事务 ID，事务 ID 是一个全局严格递增的数值，然后根据以下规则写入数据。<ul><li>插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。<li>删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。<li>修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。</ul><p>此时，如有另外一个事务要读取这些发生了变化的数据，将根据隔离级别来决定到底应该读取哪个版本的数据。<ul><li>隔离级别是<code>可重复读</code>：<strong>总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录</strong>，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。<li>隔离级别是<code>读已提交</code>：<strong>总是取最新的版本即可</strong>，即最近被 Commit 的那个版本的数据记录。</ul><p>另外两个隔离级别都没有必要用到 MVCC，因为<strong><code>读未提交</code>直接修改原始数据即可，其他事务查看数据的时候立刻可以看到</strong>，根本无须版本字段。<code>可串行化</code>本来的语义就是要阻塞其他事务的读取操作，而 <strong>MVCC 是做读取时无锁优化的，自然就不会放到一起用</strong>。<p>MVCC 是<strong>只针对“读+写”场景的优化</strong>，<strong>如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案</strong>，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）。<p>前面介绍的加锁都属于悲观加锁策略，<strong>即认为如果不先做加锁再访问数据，就肯定会出现问题</strong>。相对地，<strong>乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施</strong>。这种思路被称为“乐观并发控制”（Optimistic Concurrency Control，OCC）没有必要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看竞争的剧烈程度，<strong>如果竞争剧烈的话，乐观锁反而更慢。</strong><h3 id=全局事务><a class=headerlink href=#全局事务 title=全局事务></a>全局事务</h3><p>与本地事务相对的是全局事务（Global Transaction），有一些资料中也将其称为外部事务（External Transaction），在这里<strong>全局事务被限定为一种适用于单个服务使用多个数据源场景的事务解决方案</strong>。<p>为了解决分布式事务的一致性问题，X/Open组织提出了一套名为X/Open XA]（XA 是 eXtended Architecture 的缩写）的处理事务架构，其<strong>核心内容是定义了全局的事务管理器（Transaction Manager，用于协调全局事务）和局部的资源管理器（Resource Manager，用于驱动本地事务）之间的通信接口</strong>。<p>XA 接口是双向的，<strong>能在一个事务管理器和多个资源管理器（Resource Manager）之间形成通信桥梁，通过协调多个数据源的一致动作</strong>，<strong>实现全局事务的统一提交或者统一回滚</strong><p>基于 XA 模式在 Java 语言中的实现了全局事务处理的标准，这也就是我们现在所熟知的 JTA。JTA 最主要的两个接口是：<ul><li>事务管理器的接口：<code>javax.transaction.TransactionManager</code>。这套接口是给 Java EE 服务器提供容器事务（由容器自动负责事务管理）使用的，还提供了另外一套<code>javax.transaction.UserTransaction</code>接口，用于通过程序代码手动开启、提交和回滚事务。<li>满足 XA 规范的资源定义接口：<code>javax.transaction.xa.XAResource</code>，任何资源（JDBC、JMS 等等）如果想要支持 JTA，只要实现 XAResource 接口中的方法即可</ul><p>XA 将事务提交拆分成为两阶段过程：<ul><li><strong>准备阶段</strong>：又叫作投票阶段，在这一阶段，<strong>协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared</strong>。这里所说的准备操作跟人类语言中通常理解的准备并不相同，对于数据库来说，准备操作是<strong>在重做日志中记录全部事务提交操作所要做的内容</strong>，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。<li><strong>提交阶段</strong>：又叫作执行阶段，<strong>协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit</strong>，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，<strong>协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作</strong>。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。</ul><p>以上这两个过程被称为“<a href=https://zh.wikipedia.org/wiki/二阶段提交 rel=noopener target=_blank>两段式提交</a>”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。<ul><li><strong>必须假设网络在提交阶段的短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差</strong>，即可以丢失消息，但不会传递错误的消息。两段式提交中<strong>投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救</strong>（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。<li><strong>必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态</strong>。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。</ul><p>上面所说的协调者、参与者都是可以由数据库自己来扮演的，不需要应用程序介入。协调者一般是在参与者之间选举产生的，而应用程序相对于数据库来说只扮演客户端的角色。<p><img alt=image-20260119134801487 data-src=https://s2.loli.net/2026/01/19/GpVQTCvBPqK36My.png><p>两段式提交原理简单，并不难实现，但有几个非常显著的缺点：<ul><li><p><strong>单点问题</strong>：协调者在两段提交中具有举足轻重的作用，<strong>协调者等待参与者回复时可以有超时机制，允许参与者宕机</strong>，但参与者等待协调者指令时无法做超时处理。<strong>一旦宕机的不是其中某个参与者，而是协调者的话，所有参与者都会受到影响</strong>。<strong>如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。</strong></p><li><p><strong>性能问题</strong>：两段提交过程中，所有参与者相当于被绑定成为一个统一调度的整体，期<strong>间要经过两次远程服务调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record），整个过程将持续到参与者集群中最慢的那一个处理操作结束为止</strong>，这决定了两段式提交的性能通常都较差。</p><li><p><strong>一致性风险</strong>：前面已经提到，两段式提交的成立是有前提条件的，当网络稳定性和宕机恢复能力的假设不成立时，仍可能出现一致性问题。宕机恢复能力这一点不必多谈，1985 年 Fischer、Lynch、Paterson 提出了“FLP 不可能原理”，<strong>证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。</strong>该原理在分布式中是与“CAP 不可兼得原理“齐名的理论。</p> <p>而网络稳定性带来的一致性风险是指：尽管提交阶段时间很短，但这仍是一段明确存在的危险期，如果协调者在发出准备指令后，根据收到各个参与者发回的信息确定事务状态是可以提交的，协调者会先持久化事务状态，并提交自己的事务，如果这时候网络忽然被断开，<strong>无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交，也没有办法回滚，产生了数据不一致的问题。</strong></p></ul><p>为了缓解两段式提交协议的一部分缺陷，具体地说是协调者的单点问题和准备阶段的性能问题，后续又发展出了“<a href=https://zh.wikipedia.org/wiki/三阶段提交 rel=noopener target=_blank>三段式提交</a>”（3 Phase Commit，3PC）协议。<p>三段式提交把原本的两段式提交的准备阶段再细分为两个阶段，<strong>分别称为 CanCommit、PreCommit，把提交阶段改称为 DoCommit 阶段</strong>。其中，<strong>新增的 CanCommit 是一个询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成</strong>。将准备阶段一分为二的理由是这个阶段是重负载的操作，<strong>一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，它们所涉及的数据资源即被锁住，如果此时某一个参与者宣告无法完成提交，相当于大家都白做了一轮无用功</strong>。所以，<strong>增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，这也意味着因某个参与者提交时发生崩溃而导致大家全部回滚的风险相对变小</strong>。因此，在事务需要回滚的场景中，三段式的性能通常是要比两段式好很多的，但在事务能够正常提交的场景中，<strong>两者的性能都依然很差，甚至三段式因为多了一次询问，还要稍微更差一些</strong>。<p>同样,由于事务失败回滚概率变小的原因，在三段式提交中，<strong>如果在 PreCommit 阶段之后发生了协调者宕机，即参与者没有能等到 DoCommit 的消息的话，默认的操作策略将是提交事务而不是回滚事务或者持续等待</strong>，这就相当于避免了协调者单点问题的风险。<p><img alt=image-20260119141444338 data-src=https://s2.loli.net/2026/01/19/nPuZdlfx81b5WTv.png><p>三段式提交对单点问题和回滚时的性能问题有所改善，<strong>但是它对一致性风险问题并未有任何改进</strong>，在这方面它面临的风险甚至反而是略有增加了的。譬如，进入 PreCommit 阶段之后，<strong>协调者发出的指令不是 Ack 而是 Abort，而此时因网络问题，有部分参与者直至超时都未能收到协调者的 Abort 指令的话，这些参与者将会错误地提交事务，这就产生了不同参与者之间数据不一致的问题。</strong><h3 id=共享事务><a class=headerlink href=#共享事务 title=共享事务></a>共享事务</h3><p>与全局事务里讨论的单个服务使用多个数据源正好相反，共享事务（Share Transaction）是指<strong>多个服务共用同一个数据源。</strong><blockquote><p><strong>数据源是指提供数据的逻辑设备，不必与物理设备</strong>一一对应。在部署应用集群时最常采用的模式是将同一套程序部署到多个中间件服务器上，构成多个副本实例来分担流量压力。<strong>它们虽然连接了同一个数据库，但每个节点配有自己的专属的数据源，通常是中间件以 JNDI 的形式开放给程序代码使用。</strong></blockquote><p>假设一个购物场景，一个数据库中存储了用户账户，商家账户以及商品信息。但用<strong>户、商户和仓库每个领域都部署了独立的微服务</strong>，此时一次购书的业务操作将贯穿三个微服务，它们都要在数据库中修改数据。<p>为了实现共享事务，就必须新增一个“交易服务器”的中间角色，无论是用户服务、商家服务还是仓库服务，它们都通过同一台交易服务器来与数据库打交道。如果将交易服务器的对外接口按照 JDBC 规范来实现的话，那它完全可以视为是一个独立于各个服务的远程数据库连接池，或者直接作为数据库代理来看待。此时三个服务所发出的交易请求就有可能做到交由交易服务器上的同一个数据库连接，通过本地事务的方式完成。<p><img alt=image-20260119142742825 data-src=https://s2.loli.net/2026/01/19/5buzEGCsU2qrHKj.png><p>但该方案是与实际生产系统中的压力方向相悖的，<strong>一个服务集群里数据库才是压力最大而又最不容易伸缩拓展的重灾区</strong>，所以现实中只有类似<a href=https://www.proxysql.com/ rel=noopener target=_blank>ProxySQL</a>、<a href=https://mariadb.com/kb/en/maxscale/ rel=noopener target=_blank>MaxScale</a>这样用于对多个数据库实例做负载均衡的数据库代理（其实用 ProxySQL 代理单个数据库，再启用 Connection Multiplexing，已经接近于前面所提及的交易服务器方案了），而<strong>几乎没有反过来代理一个数据库为多个应用提供事务协调的交易服务代理</strong>。这也是说它更有可能是个伪需求的原因。<h3 id=分布式事务><a class=headerlink href=#分布式事务 title=分布式事务></a>分布式事务</h3><p>所说的分布式事务（Distributed Transaction）特指<strong>多个服务同时访问多个数据源的事务处理机制</strong>。<blockquote><p>人们曾经寄希望于 XA 的事务机制可以在本节所说的分布式环境中也能良好地应用，但这个美好的愿望今天已经被 CAP 理论彻底地击碎了</blockquote><h3 id=CAP理论与ACID><a class=headerlink href=#CAP理论与ACID title=CAP理论与ACID></a>CAP理论与ACID</h3><p>CAP是分布式计算领域所公认的著名定理。这个定理里描述了一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个：<ul><li><strong>一致性</strong>（<strong>C</strong>onsistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。一致性在分布式研究中是有严肃定义、有多种细分类型的概念，<li><strong>可用性</strong>（<strong>A</strong>vailability）：代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标：可靠性（Reliability）和可维护性（Serviceability）。可靠性使用平均无故障时间（Mean Time Between Failure，MTBF）来度量；可维护性使用平均可修复时间（Mean Time To Repair，MTTR）来度量。可用性衡量系统可以正常使用的时间与总时间之比，其表征为：A=MTBF/（MTBF+MTTR），即可用性是由可靠性和可维护性计算得出的比例值，譬如 99.9999%可用，即代表平均年故障修复时间为 32 秒。<li><strong>分区容忍性</strong>（<strong>P</strong>artition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。</ul><p>在这套系统中，每一个单独的服务节点都有自己的数据库，假设某次交易请求分别由“账号节点 1”、“商家节点 2”、“仓库节点 N”联合进行响应。当用户购买一件价值 100 元的商品后，账号节点 1 首先应给该用户账号扣减 100 元货款，<strong>它在自己数据库扣减 100 元很容易，但它还要把这次交易变动告知本集群的节点 2 到节点 N</strong>，并要确保能正确变更商家和仓库集群其他账号节点中的关联数据，此时将<strong>面临以下可能的情况。</strong><ul><li>如果该变动信息没有及时同步给其他账号节点，将导致有可能发生用户购买另一商品时，被分配给到另一个节点处理，由于看到账号上有不正确的余额而错误地发生了原本无法进行的交易，此为一致性问题。 (一致性)<li>如果由于要把该变动信息同步给其他账号节点，必须暂时停止对该用户的交易服务，直至数据同步一致后再重新恢复，将可能导致用户在下一次购买商品时，因系统暂时无法提供服务而被拒绝交易，此为可用性问题。(可用性)<li>如果由于账号服务集群中某一部分节点，因出现网络问题，无法正常与另一部分节点交换账号变动信息，此时服务集群中无论哪一部分节点对外提供的服务都可能是不正确的，整个集群能否承受由于部分节点之间的连接中断而仍然能够正确地提供服务，此为分区容忍性。 (网络分区容错性)</ul><p>如果舍弃 C、A、P 时所带来的不同影响。<ul><li><strong>如果放弃分区容忍性</strong>（CA without P），意味着我们将假设节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的，这不是你想不想的问题，而是只要用到网络来共享数据，分区现象就会始终存在。在现实中，最容易找到放弃分区容忍性的例子便是传统的关系数据库集群，这样的集群虽然依然采用由网络连接的多个节点来协同工作，但数据却不是通过网络来实现共享的。以 Oracle 的 RAC 集群为例，它的每一个节点均有自己独立的 SGA、重做日志、回滚日志等部件，但各个节点是通过共享存储中的同一份数据文件和控制文件来获取数据的，通过共享磁盘的方式来避免出现网络分区。因而 Oracle RAC 虽然也是由多个实例组成的数据库，但它并不能称作是分布式数据库。<li><strong>如果放弃可用性</strong>（CP without A），意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长，此时，问题相当于退化到前面“全局事务”中讨论的一个系统使用多个数据源的场景之中，我们可以通过 2PC/3PC 等手段，同时获得分区容忍性和一致性。在现实中，选择放弃可用性的 CP 系统情况一般<strong>用于对数据质量要求很高的场合中</strong>，除了 DTP 模型的分布式数据库事务外，著名的 HBase 也是属于 CP 系统，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。<li><strong>如果放弃一致性</strong>（AP without C），意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值，除非银行、证券这些涉及金钱交易的服务，宁可中断也不能出错，否则多数系统是不能容忍节点越多可用性反而越低的。目前大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，以 Redis 集群为例，<strong>如果某个 Redis 节点出现网络分区，那仍不妨碍各个节点以自己本地存储的数据对外提供缓存服务，但这时有可能出现请求分配到不同节点时返回给客户端的是不一致的数据。</strong></ul><p>将前面我们在 CAP、ACID 中讨论的一致性称为“强一致性”（Strong Consistency），而把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求“弱一致性”。在弱一致性里，人们又总结出了一种稍微强一点的特例，被称为“最终一致性”（Eventual Consistency），它是指：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，有时候面向最终一致性的算法也被称为“乐观复制算法”。<h4 id=可靠事务队列><a class=headerlink href=#可靠事务队列 title=可靠事务队列></a>可靠事务队列</h4><p>最终一致性的概念是 eBay 的系统架构师 Dan Pritchett 在 2008 年在 ACM 发表的论文《Base: An Acid Alternative》中提出的，<strong>该论文总结了一种独立于 ACID 获得的强一致性之外的、使用 BASE 来达成一致性目的的途径。</strong><p>BASE 分别是基本可用性（<strong>B</strong>asically <strong>A</strong>vailable）、柔性事务（<strong>S</strong>oft State）和最终一致性（<strong>E</strong>ventually Consistent）的缩写。有 ACID vs BASE（酸 vs 碱）这个梗，这篇论文本身作为最终一致性的概念起源，并<strong>系统性地总结了一种针对分布式事务的技术手段</strong>，是非常有价值的。<p>以购买商品为例，<ol><li>用户向 Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。<li>Bookstore <strong>首先应对用户账号扣款、商家账号收款、库存商品出库这三个操作有一个出错概率的先验评估</strong>，根据出错概率的大小来安排它们的操作顺序，<strong>这种评估一般直接体现在程序代码中，有一些大型系统也可能会实现动态排序</strong>。譬如，根据统计，<strong>最有可能的出现的交易异常是用户购买了商品，但是不同意扣款，或者账号余额不足；其次是仓库发现商品库存不够，无法发货；风险最低的是收款，如果到了商家收款环节，一般就不会出什么意外了</strong>。那顺序就应该<strong>安排成最容易出错的最先进行</strong>，即：账号扣款 → 仓库出库 → 商家收款。<li>账号服务进行扣款业务，<strong>如扣款成功，则在自己的数据库建立一张消息表，里面存入一条消息</strong>：“事务 ID：某 UUID，扣款：100 元（状态：已完成），仓库出库《深入理解 Java 虚拟机》：1 本（状态：进行中），某商家收款：100 元（状态：进行中）”，注意，这个步骤中<strong>“扣款业务”和“写入消息”是使用同一个本地事务写入账号服务自己的数据库的</strong>。<li>在系统中建立一个消息服务，定时轮询消息表，将状态是“进行中”的消息同时发送到库存和商家服务节点中去（也可以串行地发，即一个成功后再发送另一个，但在我们讨论的场景中没必要）。这时候可能产生以下几种情况。<ol><li>商家和仓库服务<strong>都成功完成了收款和出库工作</strong>，向用户账号服务器返回执行结果，用户账号服务把消息状态从“进行中”更新为“已完成”。整个事务宣告顺利结束，达到最终一致性的状态。<li>商家或仓库服务中至少一个因网络原因，未能收到来自用户账号服务的消息。此时，由于用户账号服务器中存储的消息状态一直处于“进行中”，所以消息服务器将在每次轮询的时候持续地向未响应的服务重复发送消息。这个步骤的可重复性决定了所有被消息服务器发送的消息都必须具备幂等性，通常的设计是让消息带上一个唯一的事务 ID，以保证一个事务中的出库、收款动作会且只会被处理一次。<li>商家或仓库服务有某个或全部无法完成工作，譬如仓库发现《深入理解 Java 虚拟机》没有库存了，此时，仍然是持续自动重发消息，直至操作成功（譬如补充了新库存），或者被人工介入为止。由此可见，可靠事件队列只要第一步业务完成了，后续就没有失败回滚的概念，只许成功，不许失败。<li>商家和仓库服务<strong>成功完成了收款和出库工作，但回复的应答消息因网络原因丢失，此时，用户账号服务仍会重新发出下一条消息，但因操作具备幂等性，所以不会导致重复出库和收款</strong>，只会导致商家、仓库服务器重新发送一条应答消息，此过程重复直至双方网络通信恢复正常。<li>也有一些支持分布式事务的消息框架，如 <strong>RocketMQ，原生就支持分布式事务操作</strong>，这时候上述情况 2、4 也可以交由消息框架来保障</ol></ol><p>以上这种靠着持续重试来保证可靠性的解决方案谈不上是 Dan Pritchett 的首创或者独创，它在计算机的其他领域中已被频繁使用，也有了专门的名字叫作“最大努力交付”（Best-Effort Delivery），譬如 TCP 协议中未收到 ACK 应答自动重新发包的可靠性保障就属于最大努力交付。而<strong>可靠事件队列还有一种更普通的形式，被称为“最大努力一次提交”（Best-Effort 1PC），指的就是将最有可能出错的业务以本地事务的方式完成后，采用不断重试的方式（不限于消息系统）来促使同一个分布式事务中的其他关联业务全部完成</strong><h4 id=TCC事务><a class=headerlink href=#TCC事务 title=TCC事务></a>TCC事务</h4><p>TCC 是另一种常见的分布式事务机制，它是“Try-Confirm-Cancel”三个单词的缩写<p>可靠消息队列虽然能保证最终的结果是相对可靠的，过程也足够简单（相对于 TCC 来说），但整个过程完全没有任何隔离性可言，有一些业务中隔离性是无关紧要的，但有一些业务中缺乏隔离性就会带来许多麻烦。譬如在本章的场景事例中，缺乏隔离性会带来的一个显而易见的问题便是“超售”：完全有可能两个客户在短时间内都成功购买了同一件商品，而且他们各自购买的数量都不超过目前的库存，但他们购买的数量之和却超过了库存。如果这件事情处于刚性事务，且隔离级别足够的情况下是可以完全避免的，譬如，<strong>以上场景就需要“可重复读”（Repeatable Read）的隔离级别</strong>，以保证后面提交的事务会因为无法获得锁而导致失败，但<strong>用可靠消息队列就无法保证这一点</strong>，这部分属于数据库本地事务方面的知识，可以参考前面的讲解。<strong>如果业务需要隔离，那架构师通常就应该重点考虑 TCC 方案</strong>，该方案天生<strong>适合用于需要强隔离性的分布式事务</strong>中。<p>在具体实现上，TCC 较为烦琐，它是一种<strong>业务侵入式较强的事务方案</strong>，要求业务处理过程必须拆分为“预留业务资源”和“确认/释放消费资源”两个子过程。如同 TCC 的名字所示，它分为以下三个阶段。<ul><li><strong>Try</strong>：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），并且预留好全部需用到的业务资源（保障隔离性）。<li><strong>Confirm</strong>：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。<li><strong>Cancel</strong>：取消执行阶段，释放 Try 阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。</ul><ol><li>最终用户向 Fenix’s Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。<li>创建事务，生成事务 ID，记录在活动日志中，进入 Try 阶段：<ul><li>用户服务：检查业务可行性，可行的话，将该用户的 100 元设置为“冻结”状态，通知下一步进入 Confirm 阶段；不可行的话，通知下一步进入 Cancel 阶段。<li>仓库服务：检查业务可行性，可行的话，将该仓库的 1 本《深入理解 Java 虚拟机》设置为“冻结”状态，通知下一步进入 Confirm 阶段；不可行的话，通知下一步进入 Cancel 阶段。<li>商家服务：检查业务可行性，不需要冻结资源。</ul><li>如果第 2 步所有业务均反馈业务可行，将活动日志中的状态记录为 Confirm，进入 Confirm 阶段：<ul><li>用户服务：完成业务操作（扣减那被冻结的 100 元）。<li>仓库服务：完成业务操作（标记那 1 本冻结的书为出库状态，扣减相应库存）。<li>商家服务：完成业务操作（收款 100 元）。</ul><li>第 3 步如果全部完成，事务宣告正常结束，如果第 3 步中任何一方出现异常，不论是业务异常或者网络异常，都将根据活动日志中的记录，重复执行该服务的 Confirm 操作，即进行最大努力交付。<li>如果第 2 步有任意一方反馈业务不可行，或任意一方超时，将活动日志的状态记录为 Cancel，进入 Cancel 阶段：<ul><li>用户服务：取消业务操作（释放被冻结的 100 元）。<li>仓库服务：取消业务操作（释放被冻结的 1 本书）。<li>商家服务：取消业务操作（大哭一场后安慰商家谋生不易）。</ul><li>第 5 步如果全部完成，事务宣告以失败回滚结束，如果第 5 步中任何一方出现异常，不论是业务异常或者网络异常，都将根据活动日志中的记录，重复执行该服务的 Cancel 操作，即进行最大努力交付。</ol><p>TCC 其实有点类似 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面，这为它的实现带来了较高的灵活性，可以根据需要设计资源锁定的粒度。TCC 在业务执行时只操作预留资源，几乎不会涉及锁和资源的争用，具有很高的性能潜力。但是 TCC 并非纯粹只有好处，它也带来了更高的开发成本和业务侵入性，意味着有更高的开发成本和更换事务实现方案的替换成本，所以，通常我们并不会完全靠裸编码来实现 TCC，而是基于某些分布式事务中间件（譬如阿里开源的<a href=https://seata.io/zh-cn/ rel=noopener target=_blank>Seata</a>）去完成，尽量减轻一些编码工作量。<h4 id=SAGA事务><a class=headerlink href=#SAGA事务 title=SAGA事务></a>SAGA事务</h4><p>TCC 的最主要限制是它的业务侵入性很强，这里并不是重复上一节提到的它需要开发编码配合所带来的工作量，而更多的是指它所要求的技术可控性上的约束。<p>大致思路是把一个大事务分解为可以交错运行的一系列子事务集合。原本 SAGA 的目的是避免大事务长时间锁定数据库的资源，后来才发展成将一个分布式环境中的大事务分解为一系列本地事务的设计模式。SAGA 由两部分操作组成。<ul><li>大事务拆分若干个小事务，将整个分布式事务 T 分解为 n 个子事务，命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该是或者能被视为是原子行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。<li>为每一个子事务设计对应的补偿动作，命名为 C1，C2，…，Ci，…，Cn。Ti与 Ci必须满足以下条件：<ul><li>Ti与 Ci都具备幂等性。<li>Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。<li>Ci必须能成功提交，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须持续重试直至成功，或者要人工介入。</ul></ul><p>如果 T1到 Tn均成功提交，那事务顺利完成，否则，要采取以下两种恢复策略之一：<ul><li><strong>正向恢复</strong>（Forward Recovery）：如果 Ti事务提交失败，则一直对 Ti进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。<li><strong>反向恢复</strong>（Backward Recovery）：如果 Ti事务提交失败，则一直执行 Ci对 Ti进行补偿，直至成功为止（最大努力交付）。这里要求 Ci必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。</ul><p>与 TCC 相比，SAGA 不需要为资源设计冻结状态和撤销冻结的操作，<strong>补偿操作往往要比冻结操作容易实现得多</strong>。<p>SAGA 必须保证所有子事务都得以提交或者补偿，但 SAGA 系统本身也有可能会崩溃，所以它必须设计成与数据库类似的日志机制（被称为 SAGA Log）以保证系统恢复后可以追踪到子事务的执行情况，譬如执行至哪一步或者补偿至哪一步了。另外，尽管补偿操作通常比冻结/撤销容易实现，但保证正向、反向恢复过程的能严谨地进行也需要花费不少的工夫，譬如通过服务编排、可靠事件队列等方式完成，所以，SAGA 事务通常也不会直接靠裸编码来实现，一般也是在事务中间件的基础上完成，前面提到的 Seata 就同样支持 SAGA 事务模式。<p>基于数据补偿来代替回滚的思路，还可以应用在其他事务方案上，例如Seata的AT事务模式。<p>AT 事务是参照了 XA 两段提交协议实现的，但<strong>针对 XA 2PC 的缺陷，即在准备阶段必须等待所有数据源都返回成功后，协调者才能统一发出 Commit 命令</strong>而导致的木桶效应（所有涉及的锁和资源都需要等待到最慢的事务完成后才能统一释放），设计了针对性的解决方案。大致的做法是<strong>在业务数据提交时自动拦截所有 SQL，将 SQL 对数据修改前、修改后的结果分别保存快照，生成行锁，通过本地事务一起提交到操作的数据源中，相当于自动记录了重做和回滚日志。</strong>如果<strong>分布式事务成功提交，那后续清理每个数据源中对应的日志数据即可；如果分布式事务需要回滚，就根据日志数据自动产生用于补偿的“逆向 SQL”。</strong>基于这种补偿方式，分布式事务中所涉及的<strong>每一个数据源都可以单独提交，然后立刻释放锁和资源。这种异步提交的模式，相比起 2PC 极大地提升了系统的吞吐量水平</strong>。而代价就是大幅度地牺牲了隔离性，甚至直接影响到了原子性。因为在缺乏隔离性的前提下，以补偿代替回滚并不一定是总能成功的。譬如，<strong>当本地事务提交之后、分布式事务完成之前，该数据被补偿之前又被其他操作修改过，即出现了脏写（Dirty Write），这时候一旦出现分布式事务需要回滚</strong>，就不可能再通过自动的逆向 SQL 来实现补偿，只能由人工介入处理了。<p>通常来说，<strong>脏写是一定要避免的，所有传统关系数据库在最低的隔离级别上都仍然要加锁以避免脏写，</strong>因为脏写情况一旦发生，人工其实也很难进行有效处理。所以 <strong>GTS(seata前身)增加了一个“全局锁”（Global Lock）的机制来实现写隔离，要求本地事务提交之前，一定要先拿到针对修改记录的全局锁后才允许提交，没有获得全局锁之前就必须一直等待</strong>，这种设计以牺牲一定性能为代价，避免了有两个分布式事务中包含的本地事务修改了同一个数据，从而避免脏写。在读隔离方面，AT 事务默认的隔离级别是读未提交（Read Uncommitted），这意味着可能产生脏读（Dirty Read）。也可以采用全局锁的方案解决读隔离问题，但直接阻塞读取的话，代价就非常大了，一般不会这样做。<h2 id=透明多级分流系统><a class=headerlink href=#透明多级分流系统 title=透明多级分流系统></a>透明多级分流系统</h2><h3 id=客户端缓存><a class=headerlink href=#客户端缓存 title=客户端缓存></a>客户端缓存</h3><p>在 HTTP 协议设计之初，便确定了服务端与客户端之间“无状态”（Stateless）的交互原则，<strong>即要求每次请求是独立的</strong>，每次请求无法感知也不能依赖另一个请求的存在，这既简化了 HTTP 服务器的设计，也为其水平扩展能力留下了广袤的空间.<p>由于每次请求都是独立的，服务端不保存此前请求的状态和资源，所以也不可避免地导致其携带有重复的数据，造成网络性能降低。<p>HTTP 协议对此问题的解决方案便是客户端缓存，在 HTTP 从 1.0 到 1.1，再到 2.0 版本的每次演进中，逐步形成了现在被称为“状态缓存”、“强制缓存”和“协商缓存”的 HTTP 缓存机制。<p>HTTP 缓存中，<strong>状态缓存是指不经过服务器，客户端直接根据缓存信息对目标网站的状态判断</strong>，以前只有 301/Moved Permanently（永久重定向）这一种。后来后HSTS避免301跳转到HTTPS的降级中间人攻击。<h4 id=强制缓存><a class=headerlink href=#强制缓存 title=强制缓存></a>强制缓存</h4><p>HTTP 的强制缓存对一致性处理的策略就如它的名字一样，十分直接：<strong>假设在某个时点到来以前，譬如收到响应后的 10 分钟内，资源的内容和状态一定不会被改变，因此客户端可以无须经过任何请求，在该时点前一直持有和使用该资源的本地缓存副本</strong>。<p>根据约定，<strong>强制缓存在浏览器的地址输入、页面链接跳转、新开窗口、前进和后退中均可生效</strong>，但<strong>在用户主动刷新页面时应当自动失效</strong>。HTTP 协议中设有以下两类 Header 实现强制缓存。<p><strong>Expires</strong>：Expires 是 HTTP/1.0 协议中开始提供的 Header，后面跟随一个截至时间参数。<strong>当服务器返回某个资源时带有该 Header 的话，意味着服务器承诺截止时间之前资源不会发生变动，浏览器可直接缓存该数据</strong>，不再重新发请求，示例<p>Expires 是 HTTP 协议最初版本中提供的缓存机制，设计非常直观易懂，但考虑得并不够周全，它至少存在以下显而易见的问题：<ul><li>受限于客户端的本地时间。譬如，在收到响应后，客户端修改了本地时间，将时间前后调整几分钟，就可能会造成缓存提前失效或超期持有。<li>无法处理涉及到用户身份的私有资源，譬如，某些资源被登录用户缓存在自己的浏览器上是合理的，但如果被代理服务器或者内容分发网络缓存起来，则可能被其他未认证的用户所获取。<li><p>无法描述“<strong>不</strong>缓存”的语义。譬如，浏览器为了提高性能，往往会自动在当次会话中缓存某些 MIME 类型的资源，在 HTTP/1.0 的服务器中就缺乏手段强制浏览器不允许缓存某个资源。以前为了实现这类功能，通常不得不使用脚本，或者手工在资源后面增加时间戳（譬如如“xx.js?t=1586359920”、“xx.jpg?t=1586359350”）来保证每次资源都会重新获取。<br>关于“不缓存”的语义，在 HTTP/1.0 中其实预留了“Pragma: no-cache”来表达，但 Pragma 参数在 HTTP/1.0 中并没有确切描述其具体行为，随后就被 HTTP/1.1 中出现过的 Cache-Control 所替代，现在，尽管主流浏览器通常都会支持 Pragma，但行为仍然是不确定的，实际并没有什么使用价值。</p><li><p><strong>Cache-Control</strong>：Cache-Control 是 <strong>HTTP/1.1 协议中定义的强制缓存 Header</strong>，它的语义比起 Expires 来说就丰富了很多，如果 Cache-Control 和 Expires 同时存在，并且语义存在冲突（譬如 Expires 与 max-age / s-maxage 冲突）的话，规定必须以 Cache-Control 为准。Cache-Control 的使用示例如下：</p> <figure class="highlight http"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line><span class=meta>HTTP/1.1</span> <span class=number>200</span> OK</span><br><span class=line><span class=attribute>Cache-Control</span><span class=punctuation>: </span>max-age=600</span><br></pre></table></figure> <p>Cache-Control 在客户端的请求 Header 或服务器的响应 Header 中都可以存在，它定义了一系列的参数，且允许自行扩展（即不在标准 RFC 协议中，由浏览器自行支持的参数），其标准的参数主要包括有：</p> <ul><li><strong>max-age</strong>和<strong>s-maxage</strong>：max-age 后面跟随一个以秒为单位的数字，表明相对于请求时间（在 Date Header 中会注明请求时间）多少秒以内缓存是有效的，资源不需要重新从服务器中获取。<strong>相对时间避免了 Expires 中采用的绝对时间可能受客户端时钟影响的问题。s-maxage 中的“s”是“Share”的缩写，意味“共享缓存”的有效时间，即允许被 CDN、代理等持有的缓存有效时间，用于提示 CDN 这类服务器应在何时让缓存失效。</strong><li><strong>public</strong>和<strong>private</strong>：指明是否涉及到用户身份的私有资源，如果是 public，则可以被代理、CDN 等缓存，如果是 private，则只能由用户的客户端进行私有缓存。<li><strong>no-cache</strong>和<strong>no-store</strong>：no-cache 指明该资源不应该被缓存，哪怕是同一个会话中对同一个 URL 地址的请求，也必须从服务端获取，令强制缓存完全失效，但此时下一节中的协商缓存机制依然是生效的；no-store 不强制会话中相同 URL 资源的重复获取，但禁止浏览器、CDN 等以任何形式保存该资源。<li><strong>no-transform</strong>：禁止资源被任何形式地修改。譬如，某些 CDN、透明代理支持自动 GZip 压缩图片或文本，以提升网络性能，而 no-transform 就禁止了这样的行为，它要求 Content-Encoding、Content-Range、Content-Type 均不允许进行任何形式的修改。<li><strong>min-fresh</strong>和<strong>only-if-cached</strong>：这两个参数是仅用于客户端的请求 Header。min-fresh 后续跟随一个以秒为单位的数字，用于建议服务器能返回一个不少于该时间的缓存资源（即包含 max-age 且不少于 min-fresh 的数字）。only-if-cached 表示客户端要求不必给它发送资源的具体内容，此时客户端就仅能使用事先缓存的资源来进行响应，若缓存不能命中，就直接返回 503/Service Unavailable 错误。<li><strong>must-revalidate</strong>和<strong>proxy-revalidate</strong>：must-revalidate 表示在资源过期后，一定需要从服务器中进行获取，即超过了 max-age 的时间后，就等同于 no-cache 的行为，proxy-revalidate 用于提示代理、CDN 等设备资源过期后的缓存行为，除对象不同外，语义与 must-revalidate 完全一致。</ul></ul><h4 id=协商缓存><a class=headerlink href=#协商缓存 title=协商缓存></a>协商缓存</h4><p>强制缓存是基于时效性的，但无论是人还是服务器，其实多数情况下都并没有什么把握去承诺某项资源多久不会发生变化。<strong>另外一种基于变化检测的缓存机制，在一致性上会有比强制缓存更好的表现，但需要一次变化检测的交互开销，性能上就会略差一些，这种基于检测的缓存机制，通常被称为“协商缓存”。</strong>另外，应注意在 HTTP 中协商缓存与强制缓存并没有互斥性，这两套机制是并行工作的，譬如，当强制缓存存在时，直接从强制缓存中返回资源，无须进行变动检查；而当强制缓存超过时效，或者被禁止（no-cache / must-revalidate），协商缓存仍可以正常地工作。<p>协商缓存有两种变动检查机制，分别是根据资源的修改时间进行检查，以及根据资源唯一标识是否发生变化来进行检查，它们都是靠一组成对出现的请求、响应 Header 来实现的：<p><strong>Last-Modified 和 If-Modified-Since</strong>：Last-Modified 是服务器的响应 Header，用于告诉客户端这个资源的最后修改时间。对于带有这个 Header 的资源，<strong>当客户端需要再次请求时，会通过 If-Modified-Since 把之前收到的资源最后修改时间发送回服务端</strong>。如果此时服务端发现资源在该时间后没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无须附带消息体，达到节省流量的目的。<p>如果此时服务端发现资源在该时间之后有变动，就会返回 200/OK 的完整响应，在消息体中包含最新的资源。<p><strong>Etag 和 If-None-Match</strong>：Etag 是服务器的响应 Header，用于告诉客户端这个资源的唯一标识。HTTP 服务器可以根据自己的意愿来选择如何生成这个标识，譬如 Apache 服务器的 Etag 值默认是对文件的索引节点（INode），大小和最后修改时间进行哈希计算后得到的。<strong>对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-None-Match 把之前收到的资源唯一标识发送回服务端</strong>。<p>如果此时服务端计算后发现资源的唯一标识与上传回来的一致，说明资源没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无须附带消息体，达到节省流量的目的。如果此时服务端发现资源的唯一标识有变动，就会返回 200/OK 的完整响应，在消息体中包含最新的资源<p>Etag 是 HTTP 中一致性最强的缓存机制，譬如，Last-Modified 标注的最后修改只能精确到秒级，如果某些文件在 1 秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间；又或者如果某些文件会被定期生成，可能内容并没有任何变化，但 Last-Modified 却改变了，导致文件无法有效使用缓存，这些情况 Last-Modified 都有可能产生资源一致性问题，只能使用 Etag 解决。<p>Etag 却又是 HTTP 中性能最差的缓存机制，体现在每次请求时，服务端都必须对资源进行哈希计算，这比起简单获取一下修改时间，开销要大了很多。Etag 和 Last-Modified 是允许一起使用的，服务器会优先验证 Etag，在 Etag 一致的情况下，再去对比 Last-Modified，这是为了防止有一些 HTTP 服务器未将文件修改日期纳入哈希范围内。<p>根据约定，协商缓存不仅在浏览器的地址输入、页面链接跳转、新开窗口、前进、后退中生效，<strong>而且在用户主动刷新页面（F5）时也同样是生效的</strong>，只有用户强制刷新（Ctrl+F5）或者明确禁用缓存（譬如在 DevTools 中设定）时才会失效，此时客户端向服务端发出的请求会自动带有“Cache-Control: no-cache”。<h3 id=域名解析><a class=headerlink href=#域名解析 title=域名解析></a>域名解析</h3><p>DNS解析流程<p>无论是使用浏览器抑或是在程序代码中访问某个网址域名，譬如以<code>www.icyfenix.com.cn</code>为例，如果没有缓存的话，都会先经过 DNS 服务器的解析翻译，找到域名对应的 IP 地址才能开始通信，这项操作是操作系统自动完成的，一般不需要用户程序的介入。<p>不过，DNS 服务器并不是一次性地将“<code>www.icyfenix.com.cn</code>”直接解析成 IP 地址，需要经历一个递归的过程。首先 DNS 会将域名还原为“<code>www.icyfenix.com.cn.</code>”，注意最后多了一个点“<code>.</code>”，它是“<code>.root</code>”的含义。早期的域名必须带有这个点才能被 DNS 正确解析，如今几乎所有的操作系统、DNS 服务器都可以自动补上结尾的点号，然后开始如下解析步骤。<p>无论是使用浏览器抑或是在程序代码中访问某个网址域名，譬如以<code>www.icyfenix.com.cn</code>为例，如果没有缓存的话，都会先经过 DNS 服务器的解析翻译，找到域名对应的 IP 地址才能开始通信，这项操作是操作系统自动完成的，一般不需要用户程序的介入。不过，DNS 服务器并不是一次性地将“<code>www.icyfenix.com.cn</code>”直接解析成 IP 地址，需要经历一个递归的过程。首先 DNS 会将域名还原为“<code>www.icyfenix.com.cn.</code>”，注意最后多了一个点“<code>.</code>”，它是“<code>.root</code>”的含义。早期的域名必须带有这个点才能被 DNS 正确解析，如今几乎所有的操作系统、DNS 服务器都可以自动补上结尾的点号，然后开始如下解析步骤：<ol><li>客户端先检查本地的 DNS 缓存，查看是否存在并且是存活着的该域名的地址记录。DNS 是以<a href=https://en.wikipedia.org/wiki/Time_to_live rel=noopener target=_blank>存活时间</a>（Time to Live，TTL）来衡量缓存的有效情况的，所以，如果某个域名改变了 IP 地址，DNS 服务器并没有任何机制去通知缓存了该地址的机器去更新或者失效掉缓存，只能依靠 TTL 超期后的重新获取来保证一致性。后续每一级 DNS 查询的过程都会有类似的缓存查询操作，再遇到时笔者就不重复叙述了。<li>客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS），这个本地 DNS 服务器可以由用户手工设置，也可以在 DHCP 分配时或者在拨号时从 PPP 服务器中自动获取到。<li>本地 DNS 收到查询请求后，会按照“是否有<code>www.icyfenix.com.cn</code>的权威服务器”→“是否有<code>icyfenix.com.cn</code>的权威服务器”→“是否有<code>com.cn</code>的权威服务器”→“是否有<code>cn</code>的权威服务器”的顺序，依次查询自己的地址记录，如果都没有查询到，就会一直找到最后点号代表的根域名服务器为止。这个步骤里涉及了两个重要名词：<ul><li><strong>权威域名服务器</strong>（Authoritative DNS）：是指负责翻译特定域名的 DNS 服务器，“权威”意味着这个域名应该翻译出怎样的结果是由它来决定的。DNS 翻译域名时无需像查电话本一样刻板地一对一翻译，根据来访机器、网络链路、服务内容等各种信息，可以玩出很多花样，权威 DNS 的灵活应用，在后面的内容分发网络、服务发现等章节都还会有所涉及。<li><strong>根域名服务器</strong>（Root DNS）是指固定的、无需查询的顶级域名（Top-Level Domain）服务器，可以默认为它们已内置在操作系统代码之中。全世界一共有 13 组根域名服务器（注意并不是 13 台，每一组根域名都通过<a href=https://en.wikipedia.org/wiki/Anycast rel=noopener target=_blank>任播</a>的方式建立了一大群镜像，根据维基百科的数据，迄今已经超过 1000 台根域名服务器的镜像了）。13 这个数字是由于 <strong>DNS 主要采用 UDP 传输协议（在需要稳定性保证的时候也可以采用 TCP）</strong>来进行数据交换，未分片的 UDP 数据包在 IPv4 下最大有效值为 512 字节，最多可以存放 13 组地址记录，由此而来的限制。</ul><li>现在假设本地 DNS 是全新的，上面不存在任何域名的权威服务器记录，所以当 DNS 查询请求按步骤 3 的顺序一直查到根域名服务器之后，它将会得到“<code>cn</code>的权威服务器”的地址记录，然后通过“<code>cn</code>的权威服务器”，得到“<code>com.cn</code>的权威服务器”的地址记录，以此类推，最后找到能够解释<code>www.icyfenix.com.cn</code>的权威服务器地址。<li>通过“<code>www.icyfenix.com.cn</code>的权威服务器”，查询<code>www.icyfenix.com.cn</code>的地址记录，地址记录并不一定就是指 IP 地址，在 RFC 规范中有定义的地址记录类型多达十几种，譬如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。</ol><p>每种记录类型中还可以包括多条记录，以一个域名下配置多条不同的 A 记录为例，此时权威服务器可以根据自己的策略来进行选择，典型的应用是智能线路：根据访问者所处的不同地区（譬如华北、华南、东北）、不同服务商（譬如电信、联通、移动）等因素来确定返回最合适的 A 记录，将访问者路由到最合适的数据中心，达到智能加速的目的。<p>DNS 系统多级分流的设计使得 DNS 系统能够经受住全球网络流量不间断的冲击，但也并非全无缺点。典<strong>型的问题是响应速度，当极端情况（各级服务器均无缓存）下的域名解析可能导致每个域名都必须递归多次才能查询到结果，显著影响传输的响应速度</strong><p>DNS的一个缺陷是<strong>位于递归链底层或者来自本地运营商的 Local DNS 服务器的安全防护则相对松懈，甚至不少地区的运营商自己就会主动进行劫持，专门返回一个错的 IP，通过在这个 IP 上代理用户请求</strong>，以便给特定类型的资源（主要是 HTML）注入广告，以此牟利<h3 id=传输链路><a class=headerlink href=#传输链路 title=传输链路></a>传输链路</h3><p>经过<strong>客户端缓存的节流</strong>、经过 <strong>DNS 服务的解析指引</strong>，程序发出的请求流量便正式离开客户端，踏上以服务器为目的地的旅途了，这个过程就是本节的主角：传输链路。<h4 id=连接数优化><a class=headerlink href=#连接数优化 title=连接数优化></a>连接数优化</h4><p>分析一下浏览网络的特点，上网平均每个页面停留的时间，以及每个页面中包含的资源（HTML、JS、CSS、图片等）数量，可以总结出 <strong>HTTP 传输对象的主要特征是数量多、时间短、资源小、切换快</strong>。<p>另一方面，TCP 协议要求必须在三次握手完成之后才能开始数据传输，这是一个可能高达“百毫秒”为计时尺度的事件；另外，TCP 还有慢启动的特性，使得刚刚建立连接时传输速度是最低的，后面再逐步加速直至稳定。由于 TCP 协议本身是面向于长时间、大数据传输来设计的，在长时间尺度下，它连接建立的高昂成本才不至于成为瓶颈，它的稳定性和可靠性的优势才能展现出来。<p><strong>HTTP over TCP 这种搭配在目标特征上确实是有矛盾的</strong>，以至于 HTTP/1.x 时代，<strong>大量短而小的 TCP 连接导致了网络性能的瓶颈</strong>。为了缓解 HTTP 与 TCP 之间的矛盾，聪明的程序员们一面致力于<strong>减少发出的请求数量，另外一方面也致力于增加客户端到服务端的连接数量</strong><p><strong>HTTP1.0的Tricks</strong>:<strong>减少请求数量</strong>：请求每次都需要建立通信链路进行数据传输，这些开销很昂贵，减少请求的数量可有效的提高访问性能:雪碧图，CSS,JS文件合并,分段文档,媒体内联,合并Ajax请求。<strong>扩大并发请求数</strong>：现代浏览器（Chrome、Firefox）一般对每个域名支持 6 个（IE 为 8-13 个）并发请求。压缩传输。<strong>避免页面重定向</strong>。<strong>按重要性调节资源优先级</strong><p>但是，通过开发人员的 Tricks 来节省 TCP 连接，这样的优化措施并非只有好处，它们同时也带来了诸多不良的副作用：<ul><li>如果你用 CSS Sprites 将多张图片合并，意味着任何场景下哪怕只用到其中一张小图，也必须完整加载整个大图片；任何场景下哪怕一张小图要进行修改，都会导致整个缓存失效，类似地，样式、脚本等其他文件的合并也会造成同样的问题。<li>如果你使用了媒体内嵌，除了要承受 Base64 编码导致传输容量膨胀 1/3 的代价外（Base64 以 8 bit 表示 6 bit 数据），也将无法有效利用缓存。<li>如果你合并了异步请求，这就会导致所有请求返回时间都受最慢的那个请求的拖累，整体响应速度下降.<li>如果你把图片放到不同子域下面，将会导致更大的 DNS 解析负担，而且浏览器对两个不同子域下的同一图片必须持有两份缓存，也使得缓存效率的下降。</ul><p>由此可见，一旦在技术根基上出现问题，依赖使用者通过各种 Tricks 去解决，无论如何都难以摆脱“两害相权取其轻”的权衡困境，否则这就不是 Tricks 而是会成为一种标准的设计模式了<p>HTTP1.1中Keep-Alive机制默认开启，持久连接的原理是<strong>让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接</strong>。典型做法是<strong>在客户端维护一个 FIFO 队列，每次取完数据之后一段时间内不自动断开连接</strong>，<strong>以便获取下一个资源时直接复用</strong>，避免创建 TCP 连接的成本。<p>但是，连接复用技术依然是不完美的，最明显的副作用是“队首阻塞”（Head-of-Line Blocking）问题。请设想以下场景：浏览器有 10 个资源需要从服务器中获取，此时它将 10 个资源放入队列，入列顺序只能按照浏览器遇见这些资源的先后顺序来决定的。但如果这 10 个资源中的第 1 个就让服务器陷入长时间运算状态会怎样呢？当它的请求被发送到服务端之后，服务端开始计算，<strong>而运算结果出来之前 TCP 连接中并没有任何数据返回，此时后面 9 个资源都必须阻塞等待</strong>。因为服务端虽然可以并行处理另外 9 个请求（譬如第 1 个是复杂运算请求，消耗 CPU 资源，第 2 个是数据库访问，消耗数据库资源，第 3 个是访问某张图片，消耗磁盘 I/O 资源，这就很适合并行），但问题是处理结果无法及时返回客户端，服务端不能哪个请求先完成就返回哪个，更不可能将所有要返回的资源混杂到一起交叉传输，原因是只使用一个 TCP 连接来传输多个资源的话，如果顺序乱了，客户端就很难区分哪个数据包归属哪个资源了。<p><strong>管道优化</strong>：为“HTTP 管道”（HTTP Pipelining）复用技术，试图在 HTTP 服务器中也建立类似客户端的 FIFO 队列，让客户端一次将所有要请求的资源名单全部发给服务端，由服务端来安排返回顺序，管理传输队列。无论队列维护在服务端还是客户端，其实都无法完全避免队首阻塞的问题，但由于服务端能够较为准确地评估资源消耗情况，进而能够更紧凑地安排资源传输，保证队列中两项工作之间尽量减少空隙，甚至做到并行化传输，从而提升链路传输的效率。可是，由于 HTTP 管道需要多方共同支持，协调起来相当复杂，推广得并不算成功。<p>队首阻塞问题一直持续到第二代的 HTTP 协议，即 HTTP/2 发布后才算是被比较完美地解决。在 HTTP/1.x 中，<strong>HTTP 请求就是传输过程中最小粒度的信息单位了，所以如果将多个请求切碎，再混杂在一块传输，客户端势必难以分辨重组出有效信息</strong>。而<strong>在 HTTP/2 中，帧（Frame）才是最小粒度的信息单位，它可以用来描述各种数据，譬如请求的 Headers、Body，或者用来做控制标识，譬如打开流、关闭流。这里说的流（Stream）是一个逻辑上的数据通道概念，每个帧都附带一个流 ID 以标识这个帧属于哪个流</strong>。这样，在同一个 TCP 连接中传输的多个数据帧就可以根据流 ID 轻易区分出开来，在客户端毫不费力地将不同流中的数据重组出不同 HTTP 请求和响应报文来。这项设计是 HTTP/2 的最重要的技术特征一，被称为 HTTP/2 多路复用HTTP/2 Multiplexing）技术<p><img alt=image-20260130123741191 data-src=https://s2.loli.net/2026/01/30/LBoqCrxwlPWINUc.png><p>有了多路复用的支持，<strong>HTTP/2 就可以对每个域名只维持一个 TCP 连接（One Connection Per Origin）来以任意顺序传输任意数量的资源</strong>，既减轻了服务器的连接压力，开发者也不用去考虑域名分片这种事情来突破浏览器对每个域名最多 6 个连接数限制了。而更重要的是，没有了 TCP 连接数的压力，就无须刻意压缩 HTTP 请求了，所有通过合并、内联文件（无论是图片、样式、脚本）以减少请求数的需求都不再成立，甚至反而是徒增副作用的反模式。 HTTP/2的设计使得其更适合小资源多并发传输了。<ul><li>Header 的传输成本在 Ajax（尤其是只返回少量数据的请求）请求中可能是比重很大的开销，但在图片、样式、脚本这些静态资源的请求中，通常并不占主要。<li>在 HTTP/2 中 Header 压缩的原理是基于字典编码的信息复用，简而言之是同一个连接上产生的请求和响应越多，动态字典积累得越全，头部压缩效果也就越好。<strong>所以 HTTP/2 是单域名单连接的机制，合并资源和域名分片反而对性能提升不利。</strong><li>与 HTTP/1.x 相反，HTTP/2 本身反而变得更适合传输小资源了，譬如传输 1000 张 10K 的小图，HTTP/2 要比 HTTP/1.x 快，但传输 10 张 1000K 的大图，则应该 HTTP/1.x 会更快。这一方面是 TCP 连接数量（相当于多点下载）的影响，更多的是由于 TCP 协议<a href=https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Reliable_transmission rel=noopener target=_blank>可靠传输机制</a>导致的，一个错误的 TCP 包会导致所有的流都必须等待这个包重传成功，这个问题就是 HTTP/3 要解决的目标了。因此，把小文件合并成大文件，在 HTTP/2 下是毫无好处的</ul><h4 id=传输压缩><a class=headerlink href=#传输压缩 title=传输压缩></a>传输压缩</h4><p>如何不以断开 TCP 连接为标志来判断资源已传输完毕。<p>HTTP 很早就支持了<a href=https://en.wikipedia.org/wiki/Gzip rel=noopener target=_blank>GZip</a>压缩，由于 HTTP 传输的主要内容，譬如 HTML、CSS、Script 等，主要是文本数据，对于文本数据启用压缩的收益是非常高的，传输数据量一般会降至原有的 20%左右。而对于那些不适合压缩的资源，Web 服务器则能根据 MIME 类型来自动判断是否对响应进行压缩，这样，已经采用过压缩算法存储的资源，如 JPEG、PNG 图片，便不会被二次压缩，空耗性能。<p>静态预压缩：在网络时代的早期，服务器处理能力还很薄弱，为了启用压缩，会是把静态资源先预先压缩为.gz 文件的形式存放起来，当客户端可以接受压缩版本的资源时（请求的 Header 中包含 Accept-Encoding: gzip）就返回压缩后的版本，否则就返回未压缩的原版<p>即时压缩：整个压缩过程全部在内存的数据流中完成，不必等资源压缩完成再返回响应，这样可以显著提高“<a href=https://en.wikipedia.org/wiki/Time_to_first_byte rel=noopener target=_blank>首字节时间</a>”（Time To First Byte，TTFB），改善 Web 性能体验。而这个过程中唯一不好的地方就是服务器再也没有办法给出 Content-Length 这个响应 Header 了，因为输出 Header 时服务器还不知道压缩后资源的确切大小。<p>因此，HTTP/1.0在即时压缩下，持久连接和即时传输存在冲突，因为HTTP/1.0的持久连接是依靠 Content-Length 来判断传输结束的。<p>HTTP/1.1 版本中修复了这个缺陷，增加了另一种“<a href=https://en.wikipedia.org/wiki/Chunked_transfer_encoding rel=noopener target=_blank>分块传输编码</a>”（Chunked Transfer Encoding）的资源结束判断机制，彻底解决了 Content-Length 与持久链接的冲突问题。分块编码原理相当简单：<strong>在响应 Header 中加入“Transfer-Encoding: chunked”之后，就代表这个响应报文将采用分块编码</strong>。此时，报文中的 Body 需要改为用一系列“分块”来传输。每个分块包含十六进制的长度值和对应长度的数据内容，长度值独占一行，数据从下一行开始。最后以一个长度值为 0 的分块来表示资源结束<p>HTTP/1.1 通过分块传输解决了即时压缩与持久连接并存的问题<strong>，到了 HTTP/2，由于多路复用和单域名单连接的设计，已经无须再刻意去提持久链接机制了，但数据压缩仍然有节约传输带宽的重要价值</strong>。<h4 id=快速UDP连接><a class=headerlink href=#快速UDP连接 title=快速UDP连接></a>快速UDP连接</h4><p>HTTP 是应用层协议而不是传输层协议，它的设计原本并不应该过多地考虑底层的传输细节，从职责上讲，持久连接、多路复用、分块编码这些能力，已经或多或少超过了应用层的范畴。要从根本上改进 HTTP，必须直接替换掉 HTTP over TCP 的根基，即 TCP 传输协议，这便最新一代 HTTP/3 协议的设计重点。<p>Google 在它的服务器（如 Google.com、YouTube.com 等）及 Chrome 浏览器上同时启用了名为“<a href=https://en.wikipedia.org/wiki/QUIC rel=noopener target=_blank>快速 UDP 网络连接</a>”（Quick UDP Internet Connections，QUIC）的全新传输协议<p>从名字上就能看出 QUIC 会以 UDP 协议为基础，而 <strong>UDP 协议没有丢包自动重传的特性，因此 QUIC 的可靠传输能力并不是由底层协议提供，而是完全由自己来实现</strong>。由 QUIC 自己实现的好处是能<strong>对每个流能做单独的控制，如果在一个流中发生错误，协议栈仍然可以独立地继续为其他流提供服务</strong>。这对提高易出错链路的性能非常有用，因为在大多数情况下，TCP 协议接到数据包丢失或损坏通知之前，可能已经收到了大量的正确数据，但是在纠正错误之前，其他的正常请求都会等待甚至被重发，这也是在连接数优化一节中， HTTP/2 未能解决传输大文件慢的根本原因。（TCP队头阻塞）<p>QUIC 的另一个设计目标是<strong>面向移动设备的专门支持</strong>，由于以前 TCP、UDP 传输协议在设计时根本不可能设想到今天移动设备盛行的场景，因此肯定不会有任何专门的支持<strong>。QUIC 在移动设备上的优势体现在网络切换时的响应速度上，譬如当移动设备在不同 WiFi 热点之间切换，或者从 WiFi 切换到移动网络</strong>时，如果使用 TCP 协议，现存的所有连接都必定会超时、中断，然后根据需要重新创建。这个过程会带来很高的延迟，因为超时和重新握手都需要大量时间。为此，<strong>QUIC 提出了连接标识符的概念，该标识符可以唯一地标识客户端与服务器之间的连接，而无须依靠 IP 地址。这样，切换网络后，只需向服务端发送一个包含此标识符的数据包即可重用既有的连接，因为即使用户的 IP 地址发生变化，原始连接连接标识符依然是有效的。</strong><h3 id=内容分发网络><a class=headerlink href=#内容分发网络 title=内容分发网络></a>内容分发网络</h3><p>如果抛却其他影响服务质量的因素，仅从网络传输的角度看，一个互联网系统的速度取决于以下四点因素：<ol><li>网站服务器接入网络运营商的链路所能提供的出口带宽。<li>用户客户端接入网络运营商的链路所能提供的入口带宽。<li>从网站到用户之间经过的不同运营商之间互联节点的带宽，一般来说两个运营商之间只有固定的若干个点是互通的，所有跨运营商之间的交互都要经过这些点。<li>从网站到用户之间的物理链路传输时延。</ol><p>以上四个网络问题，除了第二个只能通过换一个更好的宽带才能解决之外，其余三个都能通过内容分发网络来显著改善。<h4 id=路由解析><a class=headerlink href=#路由解析 title=路由解析></a>路由解析</h4><p>翻译域名无须像查电话本一样刻板地一对一翻译，根据来访机器、网络链路、服务内容等各种信息，可以玩出很多花样，内容分发网络将用户请求路由到它的资源服务器上就是依靠 DNS 服务器来实现的。<p>CDN 路由解析的具体工作过程是：<ol><li>架设好“<code>icyfenix.cn</code>”的服务器后，将服务器的 IP 地址在你的 CDN 服务商上注册为“源站”，注册后你会得到一个 CNAME，即本例中的“<code>icyfenix.cn.cdn.dnsv1.com.</code>”。<li>将得到的 CNAME 在你购买域名的 DNS 服务商上注册为一条 CNAME 记录。<li>当第一位用户来访你的站点时，将首先发生一次未命中缓存的 DNS 查询，域名服务商解析出 CNAME 后，返回给本地 DNS，至此之后链路解析的主导权就开始由内容分发网络的调度服务接管了。<li>本地 DNS 查询 CNAME 时，由于能解析该 CNAME 的权威服务器只有 CDN 服务商所架设的权威 DNS，这个 DNS 服务将根据一定的均衡策略和参数，如拓扑结构、容量、时延等，在全国各地能提供服务的 CDN 缓存节点中挑选一个最适合的，将它的 IP 代替源站的 IP 地址，返回给本地 DNS。<li>浏览器从本地 DNS 拿到 IP 地址，将该 IP 当作源站服务器来进行访问，此时该 IP 的 CDN 节点上可能有，也可能没有缓存过源站的资源。<li>经过内容分发后的 CDN 节点，就有能力代替源站向用户提供所请求的资源。</ol><p><img alt=image-20260130133535991 data-src=https://s2.loli.net/2026/01/30/mGsoYJ61XguTDCx.png><h4 id=内容分发><a class=headerlink href=#内容分发 title=内容分发></a>内容分发</h4><p><strong>CDN 获取源站资源的过程被</strong>称为“内容分发”，“内容分发网络”的名字正是由此而来<p>在 DNS 服务器的协助下，无论是对用户还是服务器，内容分发网络都可以是完全透明的，在两者都不知情的情况下，由 <strong>CDN 的缓存节点接管了用户向服务器发出的资源请求</strong>。后面随之而来的问题是缓存节点中必须有用户想要请求的资源副本，才可能代替源站来响应用户请求<ul><li><strong>主动分发</strong>（Push）：分发由<strong>源站主动发起，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上</strong>。这个推送的操作没有什么业界标准可循，可以采用任何传输方式（HTTP、FTP、P2P，等等）、任何推送策略（满足特定条件、定时、人工，等等）、任何推送时间，只要与后面说的更新策略相匹配即可。由于主动分发通常需要源站、CDN 服务双方提供程序 API 接口层面的配合，所以它对源站并不是透明的，只对用户一侧单向透明。<strong>主动分发一般用于网站要预载大量资源的场景。譬如双十一之前一段时间内，淘宝、京东等各个网络商城就会开始把未来活动中所需用到的资源推送到 CDN 缓存节点中</strong>，特别常用的资源甚至会直接缓存到你的手机 APP 的存储空间或者浏览器的<a href=https://en.wikipedia.org/wiki/Web_storage#localStorage rel=noopener target=_blank>localStorage</a>上。<li><strong>被动回源</strong>（Pull）：<strong>被动回源由用户访问所触发全自动、双向透明的资源缓存过程。当某个资源首次被用户请求的时候，CDN 缓存节点发现自己没有该资源，就会实时从源站中获取，这时资源的响应时间可粗略认为是资源从源站到 CDN 缓存节点的时间，再加上资源从 CDN 发送到用户的时间之和。因此，被动回源的首次访问通常是比较慢的</strong>（但由于 CDN 的网络条件一般远高于普通用户，并不一定就会比用户直接访问源站更慢），不适合应用于数据量较大的资源。被动回源的优点是可以做到完全的双向透明，不需要源站在程序上做任何的配合，使用起来非常方便。这种分发方式是小型站点使用 CDN 服务的主流选择，如果不是自建 CDN，而是购买阿里云、腾讯云的 CDN 服务的站点，多数采用的就是这种方式。</ul><p>DN 如何管理（更新）资源”这个问题，同样没有统一的标准可言，尽管在 HTTP 协议中，关于缓存的 Header 定义中确实是有对 CDN 这类共享缓存的一些指引性参数，譬如Cache-Control的 s-maxage，但是否要遵循，完全取决于 CDN 本身的实现策略。<strong>最常见的做法是超时被动失效与手工主动失效相结合。超时失效是指给予缓存资源一定的生存期，超过了生存期就在下次请求时重新被动回源一次</strong>。而手工失效是指 CDN 服务商一般会提供给程序调用来失效缓存的接口，<strong>在网站更新时，由持续集成的流水线自动调用该接口来实现缓存更新</strong><h3 id=负载均衡><a class=headerlink href=#负载均衡 title=负载均衡></a>负载均衡</h3><p>一般实际用于生产的系统，几乎都离不开集群部署了。<strong>信息系统不论是采用单体架构多副本部署还是微服务架构，不论是为了实现高可用还是为了获得高性能，都需要利用到多台机器来扩展服务能力</strong>，希望用户的请求不管连接到哪台机器上，都能得到相同的处理。另一方面，<strong>如何构建和调度服务集群这事情，又必须对用户一侧保持足够的透明，即使请求背后是由一千台、一万台机器来共同响应的，也绝非用户所关心的事情，用户需记住的只有一个域名地址而已。调度后方的多台机器，以统一的接口对外提供服务，承担此职责的技术组件被称为“负载均衡”</strong>（Load Balancing）。<p>无论在网关内部建立了多少级的负载均衡，从形式上来说都可以分为两种：四层负载均衡和七层负载均衡。<ul><li>四层负载均衡的优势是性能高，七层负载均衡的优势是功能强。<li>做多级混合负载均衡，通常应是低层的负载均衡在前，高层的负载均衡在后</ul><div class=table-container><table><thead><tr><th><strong> 层</strong><th><strong>数据单元</strong><th><strong>功能</strong><th><tbody><tr><td>7<td>应用层 Application Layer<td>数据 Data<td>提供为应用软件提供服务的接口，用于与其他应用软件之间的通信。典型协议：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 等<tr><td>6<td>表达层 Presentation Layer<td>数据 Data<td>把数据转换为能与接收者的系统格式兼容并适合传输的格式。<tr><td>5<td>会话层 Session Layer<td>数据 Data<td>负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。<tr><td>4<td>传输层 Transport Layer<td>数据段 Segments<td>把传输表头加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。典型协议：TCP、UDP、RDP、SCTP、FCP 等<tr><td>3<td>网络层 Network Layer<td>数据包 Packets<td>决定数据的传输路径选择和转发，将网络表头附加至数据段后以形成报文（即数据包）。典型协议：IPv4/IPv6、IGMP、ICMP、EGP、RIP 等<tr><td>2<td>数据链路层 Data Link Layer<td>数据帧 Frame<td>负责点对点的网络寻址、错误侦测和纠错。当表头和表尾被附加至数据包后，就形成数据帧（Frame）。典型协议：WiFi（802.11）、Ethernet（802.3）、PPP 等。<tr><td>1<td>物理层 Physical Layer<td>比特流 Bit<td>在物理网络上传送数据帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机接口卡等。</table></div><p>“四层”的意思是说这些工作模式的共同特点是<strong>维持着同一个 TCP 连接</strong>，而不是说它只工作在第四层。事实上，这些模式主要都是工作在二层（数据链路层，改写 MAC 地址）和三层（网络层，改写 IP 地址）上<h4 id=数据链路层的负载均衡><a class=headerlink href=#数据链路层的负载均衡 title=数据链路层的负载均衡></a>数据链路层的负载均衡</h4><p>数据链路层传输的内容是数据帧（Frame），譬如常见的以太网帧、ADSL 宽带的 PPP 帧等。<p>数据链路层负载均衡所做的工作，是修改请求的数据帧中的 MAC 目标地址，让用户原本是发送给负载均衡器的请求的数据帧，被二层交换机根据新的 MAC 目标地址转发到服务器集群中对应的服务器（后文称为“真实服务器”，Real Server）的网卡上，这样真实服务器就获得了一个原本目标并不是发送给它的数据帧。<p>由于二层负载均衡器在转发请求过程中只修改了帧的 MAC 目标地址，不涉及更上层协议（没有修改 Payload 的数据），所以在更上层（第三层）看来，所有数据都是未曾被改变过的。由于第三层的数据包，即 IP 数据包中包含了源（客户端）和目标（均衡器）的 IP 地址，只有真实服务器保证自己的 IP 地址与数据包中的目标 IP 地址一致，这个数据包才能被正确处理。因此，使用这种负载均衡模式时，需要把真实物理服务器集群所有机器的虚拟IP地址（Virtual IP Address，VIP）配置成与负载均衡器的虚拟 IP 一样，这样经均衡器转发后的数据包就能在真实服务器中顺利地使用。也正是因为实际处理请求的真实物理服务器 IP 和数据请求中的目的 IP 是一致的，所以响应结果就不再需要通过负载均衡服务器进行地址交换，可将响应结果的数据包直接从真实服务器返回给用户的客户端，避免负载均衡器网卡带宽成为瓶颈.<p><img alt=image-20260130135809188 data-src=https://s2.loli.net/2026/01/30/7n1Va5YByC8wGcr.png><p>只有请求经过负载均衡器，而服务的响应无须从负载均衡器原路返回的工作模式，整个请求、转发、响应的链路形成一个“三角关系”，所以这种负载均衡模式也常被很形象地称为“三角传输模式”或”直接路由模式”.<p>数据链路层负载均衡效率很高，但它并不能适用于所有的场合，除了那些<strong>需要感知应用层协议信息的负载均衡场景它无法胜任外</strong>，它在网络一侧受到的约束也很大。二层负载均衡器直接改写目标 MAC 地址的工作原理决定了它与真实的服务器的通信必须是二层可达的，通俗地说就是必须位于同一个子网当中，无法跨 VLAN<h4 id=网络层负载均衡><a class=headerlink href=#网络层负载均衡 title=网络层负载均衡></a>网络层负载均衡</h4><p>一个 IP 数据包由 Headers 和 Payload 两部分组成， Headers 长度最大为 60 Bytes，其中包括了 20 Bytes 的固定数据和最长不超过 40 Bytes 的可选的额外设置组成。<p>只要知道在 IP 分组数据包的 Headers 带有源和目标的 IP 地址即可。源和目标 IP 地址代表了数据是从分组交换网络中哪台机器发送到哪台机器的，我们可以沿用与二层改写 MAC 地址相似的思路，<strong>通过改变这里面的 IP 地址来实现数据包的转发</strong>。具体有两种常见的修改方式。<p>第一种是保持原来的数据包不变，<strong>新创建一个数据包，把原来数据包的 Headers 和 Payload 整体作为另一个新的数据包的 Payload，在这个新数据包的 Headers 中写入真实服务器的 IP 作为目标地址</strong>，然后把它发送出去。经过三层交换机的转发，<strong>真实服务器收到数据包后，必须在接收入口处设计一个针对性的拆包机制，把由负载均衡器自动添加的那层 Headers 扔掉，还原出原来的数据包来进行使用</strong>。这样，真实服务器就同样拿到了一个原本不是发给它（目标 IP 不是它）的数据包，达到了流量转发的目的。(IP隧道)<p>因为要封装新的数据包，IP 隧道的转发模式比起直接路由模式效率会有所下降，但由于并没有修改原有数据包中的任何信息，所以 IP 隧道的转发模式仍然具备三角传输的特性，即负载均衡器转发来的请求，可以由真实服务器去直接应答，无须在经过均衡器原路返回。<strong>而且由于 IP 隧道工作在网络层，所以可以跨越 VLAN，因此摆脱了直接路由模式中网络侧的约束。</strong><p><img alt=image-20260130143930455 data-src=https://s2.loli.net/2026/01/30/qHVznybSg71lxUo.png style=zoom:67%;><p>第一个缺点是它要求真实服务器必须支持“IP 隧道协议”（IP Encapsulation），就是它得学会自己拆包扔掉一层 Headers，这个其实并不是什么大问题，现在几乎所有的 Linux 系统都支持 IP 隧道协议。另外一个缺点是这种模式仍必须通过专门的配置，必须保证所有的真实服务器与均衡器有着相同的虚拟 IP 地址，因为回复该数据包时，需要使用这个虚拟 IP 作为响应数据包的源地址，这样客户端收到这个数据包时才能正确解析。这个限制就相对麻烦一些，它与“透明”的原则冲突，需由系统管理员介入。<p>对服务器进<strong>行虚拟 IP 的配置并不是在任何情况下都可行的，尤其是当有好几个服务共用一台物理服务器的时候，此时就必须考虑第二种修改方式</strong>——改变目标数据包：直接把数据包 Headers 中的目标地址改掉。<p>但问题是这种模式是通过修改目标 IP 地址才到达真实服务器的，如果真实服务器直接将应答包返回客户端的话，这个应答数据包的源 IP 是真实服务器的 IP，也即均衡器修改以后的 IP 地址，客户端不可能认识该 IP，自然就无法再正常处理这个应答了。因此，只能让应答流量继续回到负载均衡，由负载均衡把应答包的源 IP 改回自己的 IP，再发给客户端，这样才能保证客户端与真实服务器之间的正常通信。这类似NAT技术。<p><img alt=image-20260130144957103 data-src=https://s2.loli.net/2026/01/30/s8HMFphjYQb1aGJ.png><p>在流量压力比较大的时候，NAT 模式的负载均衡会带来较大的性能损失，比起直接路由和 IP 隧道模式，甚至会出现数量级上的下降。这点是显而易见的，由负载均衡器代表整个服务集群来进行应答，各个服务器的响应数据都会互相挣抢均衡器的出口带宽，这就好比在家里用 NAT 上网的话，如果有人在下载，你打游戏可能就会觉得卡顿是一个道理，此时整个系统的瓶颈很容易就出现在负载均衡器上。<h4 id=应用层负载均衡><a class=headerlink href=#应用层负载均衡 title=应用层负载均衡></a>应用层负载均衡</h4><p>四层负载均衡工作模式都属于“转发”，即直接将<strong>承载着 TCP 报文的底层数据格式</strong>（IP 数据包或以太网帧）转发到真实服务器上，此时<strong>客户端到响应请求的真实服务器维持着同一条 TCP 通道</strong>。但工作在四层之后的负载均衡模式就无法再进行转发了，只能进行代理，此时真实服务器、负载均衡器、客户端三者之间由两条独立的 TCP 通道来维持通信。<p><img alt=image-20260130145203522 data-src=https://s2.loli.net/2026/01/30/2mrEXG8VcCxd9eT.png style=zoom:80%;><p>“代理”这个词，根据“哪一方能感知到”的原则，可以分为“正向代理”、“反向代理”和“透明代理”三类。正向代理就是通常简称的代理，<strong>指在客户端设置的、代表客户端与服务器通信的代理服务，它是客户端可知，而对服务器透明的</strong>。反向代理是指在设置在服务器这一侧，代表真实服务器来与客户端通信的代理服务，此时它对客户端来说是透明的。至于透明代理是指对双方都透明的，配置在网络中间设备上的代理服务，譬如，架设在路由器上的透明翻墙代理。<p>七层负载均衡器它就属于反向代理中的一种，如果只论网络性能，七层均衡器肯定是无论如何比不过四层均衡器的，它比四层均衡器至少多一轮 TCP 握手，有着跟 NAT 转发模式一样的带宽问题，而且通常要耗费更多的 CPU，因为可用的解析规则远比四层丰富。所以<strong>如果用七层均衡器去做下载站、视频站这种流量应用是不合适的，起码不能作为第一级均衡器</strong>。但是，如果网站的性能瓶颈并不在于网络性能，要论整个服务集群对外所体现出来的服务性能，七层均衡器就有它的用武之地了。这里面<strong>七层均衡器的底气就是来源于它工作在应用层，可以感知应用层通信的具体内容</strong>。<p>代理的工作模式相信大家应该是比较熟悉的，这里不再展开，只是简单列举了一些七层代理可以实现的功能，以便读者对它“功能强大”有个直观的感受。<ul><li>前面介绍 CDN 应用时，所有 CDN 可以做的缓存方面的工作（就是除去 CDN 根据物理位置就近返回这种优化链路的工作外），七层均衡器全都可以实现，譬如静态资源缓存、协议升级、安全防护、访问控制，等等。<li>七层均衡器可以实现更智能化的路由。譬如，根据 Session 路由，以实现亲和性的集群；根据 URL 路由，实现专职化服务（此时就相当于网关的职责）；甚至根据用户身份路由，实现对部分用户的特殊服务（如某些站点的贵宾服务器），等等。<li>某些安全攻击可以由七层均衡器来抵御，譬如一种常见的 DDoS 手段是 SYN Flood 攻击，即攻击者控制众多客户端，使用虚假 IP 地址对同一目标大量发送 SYN 报文。从技术原理上看，由于四层均衡器无法感知上层协议的内容，这些 SYN 攻击都会被转发到后端的真实服务器上；而七层均衡器下这些 SYN 攻击自然在负载均衡设备上就被过滤掉，不会影响到后面服务器的正常运行。类似地，可以在七层均衡器上设定多种策略，譬如过滤特定报文，以防御如 SQL 注入等应用层面的特定攻击手段。<li>很多微服务架构的系统中，链路治理措施都需要在七层中进行，譬如服务降级、熔断、异常注入，等等。譬如，一台服务器只有出现物理层面或者系统层面的故障，导致无法应答 TCP 请求才能被四层均衡器所感知，进而剔除出服务集群，如果一台服务器能够应答，只是一直在报 500 错，那四层均衡器对此是完全无能为力的，只能由七层均衡器来解决。</ul><div class=table-container><table><thead><tr><th><strong>特性</strong><th><strong>四层负载均衡 (L4)</strong><th><strong>七层负载均衡 (L7)</strong><tbody><tr><td><strong>所属层级</strong><td>传输层 (TCP/UDP)<td>应用层 (HTTP/HTTPS/DNS)<tr><td><strong>分配依据</strong><td>IP 地址 + 端口<td>URL、Header、Cookie、Query 参数<tr><td><strong>连接方式</strong><td>直接透传，不拆包<td>代理模式，先拦截再转发<tr><td><strong>性能</strong><td><strong>极高</strong>（消耗资源少）<td><strong>中等</strong>（解析报文消耗 CPU）<tr><td><strong>灵活性</strong><td>较低，无法识别具体业务<td><strong>极高</strong>，可实现复杂的业务逻辑<tr><td><strong>常见代表</strong><td>LVS, F5, Nginx (Stream 模块)<td>Nginx, HAProxy, Envoy, Ingress Controller</table></div><h4 id=均衡策略实现><a class=headerlink href=#均衡策略实现 title=均衡策略实现></a>均衡策略实现</h4><p>负载均衡的两大职责是“<strong>选择谁来处理用户请求</strong>”和“<strong>将用户请求转发过去</strong>”。后者即请求的转发或代理过程。前者是指均衡器所采取的均衡策略，包括如下：<ul><li><strong>轮循均衡</strong>（Round Robin）：每一次来自网络的请求轮流分配给内部中的服务器，从 1 至 N 然后重新开始。此种均衡算法适合于集群中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。<li><strong>权重轮循均衡</strong>（Weighted Round Robin）：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。譬如：服务器 A 的权值被设计成 1，B 的权值是 3，C 的权值是 6，则服务器 A、B、C 将分别接收到 10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。<li><strong>随机均衡</strong>（Random）：把来自客户端的请求随机分配给内部中的多个服务器，在数据足够大的场景下能达到相对均衡的分布。<li><strong>权重随机均衡</strong>（Weighted Random）：此种均衡算法类似于权重轮循算法，不过在分配处理请求时是个随机选择的过程。<li><strong>一致性哈希均衡</strong>（Consistency Hash）：根据请求中某一些数据（可以是 MAC、IP 地址，也可以是更上层协议中的某些参数信息）作为特征值来计算需要落在的节点上，算法一般会保证同一个特征值每次都一定落在相同的服务器上。一致性的意思是保证当服务集群某个真实服务器出现故障，只影响该服务器的哈希，而不会导致整个服务集群的哈希键值重新分布。<li><strong>响应速度均衡</strong>（Response Time）：负载均衡设备对内部各服务器发出一个探测请求（例如 Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间。<li><strong>最少连接数均衡</strong>（Least Connection）：客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不平衡，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡策略适合长时处理的请求服务，如 FTP 传输。</ul><p>从实现角度来看，负载均衡器的实现分为“软件均衡器”和“硬件均衡器”两类。<p><strong>在软件均衡器方面，又分为直接建设在操作系统内核的均衡器和应用程序形式的均衡器两种</strong>。前者的代表是 LVS（Linux Virtual Server），后者的代表有 Nginx、HAProxy、KeepAlived 等，前者性能会更好，因为无须在内核空间和应用空间中来回复制数据包；而后者的优势是选择广泛，使用方便，功能不受限于内核版本。<p>在硬件均衡器方面，往往会直接采用应用专用集成电路（Application Specific Integrated Circuit，ASIC）来实现，有专用处理芯片的支持，避免操作系统层面的损耗，得以达到最高的性能。这类的代表就是著名的 F5 和 A10 公司的负载均衡产品。<h3 id=服务端缓存><a class=headerlink href=#服务端缓存 title=服务端缓存></a>服务端缓存</h3><p>为系统引入缓存之前，第一件事情是确认你的系统是否真的需要缓存。在软件开发中引入缓存的负面作用要明显大于硬件的缓存：从开发角度来说，引入缓存会提高系统复杂度，因为你要考虑缓存的失效、更新、一致性等问题（硬件缓存也有这些问题，只是不需要由你去考虑，主流的 ISA 也都没有提供任何直接操作缓存的指令）；从运维角度来说，缓存会掩盖掉一些缺陷，让问题在更久的时间以后，出现在距离发生现场更远的位置上；从安全角度来说，缓存可能泄漏某些保密数据，也是容易受到攻击的薄弱点。冒着上述种种风险，仍能说服你引入缓存的理由，总结起来无外乎以下两种<ul><li>为缓解 CPU 压力而做缓存：<strong>譬如把方法运行结果存储起来、把原本要实时计算的内容提前算好、把一些公用的数据进行复用</strong>，这可以节省 CPU 算力，顺带提升响应性能。<li>为缓解 I/O 压力而做缓存：<strong>譬如把原本对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问</strong>，将原本对单点部件（如数据库）的读写访问变为到可扩缩部件（如缓存中间件）的访问，顺带提升响应性能。</ul><p>缓存虽然是典型以<strong>空间换时间来提升性能的手段</strong>，但它的<strong>出发点是缓解 CPU 和 I/O 资源在峰值流量下的压力</strong>，“顺带”而非“专门”地提升响应性能。这里的言外之意是如果可以通过增强 CPU、I/O 本身的性能（譬如扩展服务器的数量）来满足需要的话，那升级硬件往往是更好的解决方案<h4 id=缓存属性><a class=headerlink href=#缓存属性 title=缓存属性></a>缓存属性</h4><p>通常，我们设计或者选择缓存至少会考虑以下四个维度的属性：<ul><li><strong>吞吐量</strong>：缓存的吞吐量使用 OPS 值（每秒操作数，Operations per Second，ops/s）来衡量，反映了对缓存进行<strong>并发</strong>读、写操作的效率，即缓存本身的工作效率高低。<li><strong>命中率</strong>：缓存的命中率即成功从缓存中返回结果次数与总请求次数的比值，反映了引入缓存的价值高低，命中率越低，引入缓存的收益越小，价值越低。<li><strong>扩展功能</strong>：缓存除了基本读写功能外，还提供哪些额外的管理功能，譬如最大容量、失效时间、失效事件、命中率统计，等等。<li><strong>分布式支持</strong>：缓存可分为“进程内缓存”和“分布式缓存”两大类，前者只为节点本身提供服务，无网络访问操作，速度快但缓存的数据不能在各个服务节点中共享，后者则相反。</ul><p><strong>吞吐量</strong><p><strong>缓存的吞吐量只在并发场景中才有统计的意义</strong>，因为不考虑并发的话，即使是最原始的、以 HashMap 实现的缓存，访问效率也已经是常量时间复杂度，即 O(1)，其中涉及到碰撞、扩容等场景的处理属于数据结构基础，这里不展开。但 HashMap 并不是线程安全的容器，如果要让它在多线程并发下能正确地工作，就要用 Collections.synchronizedMap 进行包装，这相当于给 Map 接口的所有访问方法都自动加全局锁；或者改用 ConcurrentHashMap 来实现，<strong>这相当于给 Map 的访问分段加锁</strong>（从 JDK 8 起已取消分段加锁，改为 <strong>CAS+Synchronized 锁单个元素</strong>）。无论采用怎样的实现方法，线程安全措施都会带来一定的吞吐量损失<p>并发读写的场景中，吞吐量受多方面因素的共同影响，譬如，怎样设计数据结构以尽可能避免数据竞争，存在竞争风险时怎样处理同步（主要有使用锁实现的悲观同步和使用<a href=https://en.wikipedia.org/wiki/Compare-and-swap rel=noopener target=_blank>CAS</a>实现的乐观同步）、如何避免<a href=https://en.wikipedia.org/wiki/False_sharing rel=noopener target=_blank>伪共享现象</a>（False Sharing，这也算是典型缓存提升开发复杂度的例子）发生，等等。其中第一点尽可能避免竞争是最关键的，无论如何实现同步都不会比直接无须同步更快.<p>缓存中最主要的数据竞争源于读取数据的同时，也会伴随着对数据状态的写入操作，写入数据的同时，也会伴随着数据状态的读取操作。譬如，读取时要同时更新数据的最近访问时间和访问计数器的状态，以实现缓存的淘汰策略；又或者读取时要同时判断数据的超期时间等信息，以实现失效重加载等其他扩展功能。<p>对以上伴随读写操作而来的状态维护，有两种可选择的处理思路，<strong>一种是以 Guava Cache 为代表的同步处理机制，即在访问数据时一并完成缓存淘汰、统计、失效等状态变更操作，通过分段加锁等优化手段来尽量减少竞争。</strong>另一种是以 <strong>Caffeine 为代表的异步日志提交机制，这种机制参考了经典的数据库设计理论，将对数据的读、写过程看作是日志（即对数据的操作指令）的提交过程。尽管日志也涉及到写入操作，有并发的数据变更就必然面临锁竞争，但异步提交的日志已经将原本在 Map 内的锁转移到日志的追加写操作上</strong>，日志里腾挪优化的余地就比在 Map 中要大得多。<p>在 Caffeine 的实现中，设有<strong>专门的环形缓存区</strong>（Ring Buffer，也常称作 Circular Buffer）来记录由于数据读取而产生的状态变动日志。为进一步减少竞争，<strong>Caffeine 给每条线程（对线程取 Hash，哈希值相同的使用同一个缓冲区）都设置一个专用的环形缓冲</strong>。<p>从 Caffeine <strong>读取数据时，数据本身会在其内部的 ConcurrentHashMap 中直接返回</strong>，而<strong>数据的状态信息变更就存入环形缓冲中，由后台线程异步处理。如果异步处理的速度跟不上状态变更的速度，导致缓冲区满了，那此后接收的状态的变更信息就会直接被丢弃掉，直至缓冲区重新富余</strong>。通过环形缓冲和容忍有损失的状态变更，Caffeine 大幅降低了由于数据读取而导致的垃圾收集和锁竞争，因此 Caffeine 的读取性能几乎能与 ConcurrentHashMap 的读取性能相同。 因为缓存除了维护数据也要淘汰数据，Caffeine通过频率决定数据去留，而在 Caffeine 之前的缓存（如 Guava Cache）中，每次读取都会尝试更新 LRU 链表（把节点移到头部）。更新链表需要<strong>加锁</strong>。在高并发场景下，成千上万个线程同时读数据，却要为了更新同一个链表头而排队。这导致“读操作”由于竞争锁而变得极其缓慢。Caffeine 为了解决读操作的并发瓶颈，引入了类似 <strong>日志结构（Log-structured）</strong> 的思路，将“同步维护”改为“异步批处理”。<blockquote><p>当发生读取时，Caffeine 会执行以下逻辑：<ol><li><strong>直接取值</strong>：从内部的 <code>ConcurrentHashMap</code> 中读取数据并立即返回给用户（极快）。<li><strong>记录足迹</strong>：将这次“读取事件”丢进一个 <strong>Striped Ring Buffer</strong>（条带化环形缓冲）中。<ul><li><strong>为什么是 Striped（条带化）？</strong> 它内部由多个 Ring Buffer 组成，根据线程 ID 散列。这样不同线程写不同的 Buffer，进一步减少了竞争。<li><strong>为什么是 Ring Buffer？</strong> 它是无锁的、高性能的，且如果缓冲区满了，Caffeine 会直接<strong>丢弃</strong>新的读取事件，优先保证读性能（即使丢掉一两次读取记录，对频率统计的准确性影响也微乎其微）。</ul></ol></blockquote><p><strong>向 Caffeine 写入数据时，将使用传统的有界队列（ArrayQueue）来存放状态变更信息，写入带来的状态变更是无损的，不允许丢失任何状态</strong>，这是考虑到许多状态的默认值必须通过写入操作来完成初始化，因此写入会有一定的性能损失。根据 Caffeine 官方给出的数据，相比 ConcurrentHashMap，Caffeine 在写入时大约会慢 10%左右。<p><strong>命中率和淘汰策略</strong><p>有限的物理存储决定了任何缓存的容量都不可能是无限的，所以缓存需要在消耗空间与节约时间之间取得平衡，这要求缓存必须能够自动或者由人工淘汰掉缓存中的低价值数据<p>目前，最基础的淘汰策略实现方案有以下三种：<ul><li><strong>FIFO</strong>（First In First Out）：优先淘汰最早进入被缓存的数据。FIFO 实现十分简单，但一般来说它并不是优秀的淘汰策略，越是频繁被用到的数据，往往会越早被存入缓存之中。如果采用这种淘汰策略，很可能会大幅降低缓存的命中率。<li><strong>LRU</strong>（Least Recent Used）：优先淘汰最久未被使用访问过的数据。LRU 通常会采用 HashMap 加 LinkedList 双重结构（如 LinkedHashMap）来实现，以 HashMap 来提供访问接口，保证常量时间复杂度的读取性能，以 LinkedList 的链表元素顺序来表示数据的时间顺序，每次缓存命中时把返回对象调整到 LinkedList 开头，每次缓存淘汰时从链表末端开始清理数据。对大多数的缓存场景来说，LRU 都明显要比 FIFO 策略合理，尤其适合用来处理短时间内频繁访问的热点对象。但相反，<strong>它的问题是如果一些热点数据在系统中经常被频繁访问，但最近一段时间因为某种原因未被访问过，此时这些热点数据依然要面临淘汰的命运</strong>，LRU 依然可能错误淘汰价值更高的数据。<li><strong>LFU</strong>（Least Frequently Used）：优先淘汰最不经常使用的数据。LFU 会给每个数据添加一个访问计数器，每访问一次就加 1，需要淘汰时就清理计数器数值最小的那批数据。LFU 可以解决上面 LRU 中热点数据间隔一段时间不访问就被淘汰的问题，但同时它又引入了两个新的问题，首先是需要对每个缓存的数据专门去维护一个计数器，每次访问都要更新，这样做会带来高昂的维护开销；另一个问题是不便于处理随时间变化的热度变化，譬如某个曾经频繁访问的数据现在不需要了，它也很难自动被清理出缓存。</ul><p>缓存淘汰策略直接影响缓存的命中率，没有一种策略是完美的、能够满足全部系统所需的。不过，随着淘汰算法的发展，近年来的确出现了许多相对性能要更好的，也更为复杂的新算法。以 LFU 分支为例，针对它存在的两个问题，近年来提出的 TinyLFU 和 W-TinyLFU 算法就往往会有更好的效果。<ul><li><strong>TinyLFU</strong>（Tiny Least Frequently Used）：TinyLFU 是 LFU 的改进版本。为了缓解 LFU 每次访问都要修改计数器所带来的性能负担，TinyLFU 会首先采用 Sketch 对访问数据进行分析，所谓 Sketch 是统计学上的概念，指<strong>用少量的样本数据来估计全体数据的特征</strong>，这种做法显然牺牲了一定程度的准确性，但是只要样本数据与全体数据具有相同的概率分布，Sketch 得出的结论仍不失为一种高效与准确之间权衡的有效结论。借助<a href=https://en.wikipedia.org/wiki/Count–min_sketch rel=noopener target=_blank>Count–Min Sketch</a>算法（可视为<a href=https://en.wikipedia.org/wiki/Bloom_filter rel=noopener target=_blank>布隆过滤器</a>的一种等价变种结构），TinyLFU 可以用相对小得多的记录频率和空间来近似地找出缓存中的低价值数据。为了解决 LFU 不便于处理随时间变化的热度变化问题，TinyLFU 采用了基于“滑动时间窗”的热度衰减算法，<strong>简单理解就是每隔一段时间，便会把计数器的数值减半，以此解决“旧热点”数据难以清除的问题。</strong><li><strong><a href=https://arxiv.org/pdf/1512.00727.pdf rel=noopener target=_blank>W-TinyLFU</a></strong>（Windows-TinyLFU）：W-TinyLFU 又是 TinyLFU 的改进版本。<strong>TinyLFU 在实现减少计数器维护频率的同时，也带来了无法很好地应对稀疏突发访问的问题</strong>，所谓稀疏突发访问是指有一些绝对频率较小，但突发访问频率很高的数据，譬如某些运维性质的任务，也许一天、一周只会在特定时间运行一次，其余时间都不会用到，此时 TinyLFU 就很难让这类元素通过 Sketch 的过滤，因为它们无法在运行期间积累到足够高的频率。应对短时间的突发访问是 LRU 的强项，W-TinyLFU 就结合了 LRU 和 LFU 两者的优点，从整体上看是 LFU 策略，从局部实现上看又是 LRU 策略。<strong>具体做法是将新记录暂时放入一个名为 Window Cache 的前端 LRU 缓存里面，让这些对象可以在 Window Cache 中累积热度，如果能通过 TinyLFU 的过滤器，再进入名为 Main Cache 的主缓存中存储</strong>，主缓存根据数据的访问频繁程度分为不同的段（LFU 策略，实际上 W-TinyLFU 只分了两段），但单独某一段局部来看又是基于 LRU 策略去实现的（称为 Segmented LRU）。每当前一段缓存满了之后，会将低价值数据淘汰到后一段中去存储，直至最后一段也满了之后，该数据就彻底清理出缓存。</ul><p><strong>扩展功能</strong><p>在“访问”之外，专业的缓存往往还会提供很多额外的功能。笔者简要列举如下：<ul><li><strong>加载器</strong>：许多缓存都有“CacheLoader”之类的设计，加载器可以让缓存从只能被动存储外部放入的数据，变为能够主动通过加载器去加载指定 Key 值的数据，加载器也是实现自动刷新功能的基础前提。<li><strong>淘汰策略</strong>：有的缓存淘汰策略是固定的，也有一些缓存能够支持用户自己根据需要选择不同的淘汰策略。<li><strong>失效策略</strong>：要求缓存的数据在一定时间后自动失效（移除出缓存）或者自动刷新（使用加载器重新加载）。<li><strong>事件通知</strong>：缓存可能会提供一些事件监听器，让你在数据状态变动（如失效、刷新、移除）时进行一些额外操作。有的缓存还提供了对缓存数据本身的监视能力（Watch 功能）。<li><strong>并发级别</strong>：对于通过分段加锁来实现的缓存（以 Guava Cache 为代表），往往会提供并发级别的设置。可以简单将其理解为缓存内部是使用多个 Map 来分段存储数据的，并发级别就用于计算出使用 Map 的数量。如果将这个参数设置过大，会引入更多的 Map，需要额外维护这些 Map 而导致更大的时间和空间上的开销；如果设置过小，又会导致在访问时产生线程阻塞，因为多个线程更新同一个 ConcurrentMap 的同一个值时会产生锁竞争。<li><strong>容量控制</strong>：缓存通常都支持指定初始容量和最大容量，初始容量目的是减少扩容频率，这与 Map 接口本身的初始容量含义是一致的。最大容量类似于控制 Java 堆的-Xmx 参数，当缓存接近最大容量时，会自动清理掉低价值的数据。<li><strong>引用方式</strong>：支持将数据设置为软引用或者弱引用，提供引用方式的设置是为了将缓存与 Java 虚拟机的垃圾收集机制联系起来。<li><strong>统计信息</strong>：提供诸如缓存命中率、平均加载时间、自动回收计数等统计。<li><strong>持久化</strong>：支持将缓存的内容存储到数据库或者磁盘中，进程内缓存提供持久化功能的作用不是太大，但分布式缓存大多都会考虑提供持久化功能。</ul><div class=table-container><table><thead><tr><th>ConcurrentHashMap<th>Ehcache<th>Guava Cache<th>Caffeine<th><tbody><tr><td>访问性能<td>最高<td>一般<td>良好<td>优秀 接近于 ConcurrentHashMap<tr><td>淘汰策略<td>无<td>支持多种淘汰策略 FIFO、LRU、LFU 等<td>LRU<td>W-TinyLFU<tr><td>扩展功能<td>只提供基础的访问接口<td>并发级别控制 失效策略 容量控制 事件通知 统计信息 ……<td>大致同左<td>大致同左</table></div><h4 id=分布式缓存><a class=headerlink href=#分布式缓存 title=分布式缓存></a>分布式缓存</h4><p>相比起缓存数据在进程内存中读写的速度，一旦涉及网络访问，由网络传输、数据复制、序列化和反序列化等操作所导致的延迟要比内存访问高得多，所以对分布式缓存来说，<strong>处理与网络有相关的操作是对吞吐量影响更大的因素</strong>，往往也是比淘汰策略、扩展功能更重要的关注点。<ul><li><p>从访问的角度来说，如果是频繁更新但甚少读取的数据，通常是不会有人把它拿去做缓存的，因为这样做没有收益。对于<strong>甚少更新但频繁读取的数据，理论上更适合做复制式缓存</strong>；对于<strong>更新和读取都较为频繁的数据，理论上就更适合做集中式缓存</strong>。笔者简要介绍这两种分布式缓存形式的差别与代表性产品：</p> <ul><li><strong>复制式缓存</strong>：复制式缓存可以<strong>看作是“能够支持分布式的进程内缓存”，它的工作原理与 Session 复制类似</strong>。<strong>缓存中所有数据在分布式集群的每个节点里面都存在有一份副本，读取数据时无须网络访问</strong>，直接从当前节点的进程内存中返回，<strong>理论上可以做到与进程内缓存一样高的读取性能；当数据发生变化时，就必须遵循复制协议</strong>，将变更同步到集群的每个节点中，复制性能随着节点的增加呈现平方级下降，变更数据的代价十分高昂。<br>复制式缓存的代表是<a href=https://jbosscache.jboss.org/ rel=noopener target=_blank>JBossCache</a>，这是 JBoss 针对企业级集群设计的缓存方案，支持 JTA 事务，依靠 JGroup 进行集群节点间数据同步。以 JBossCache 为典型的复制式缓存曾有一段短暂的兴盛期，但今天基本上已经很难再见到使用这种缓存形式的大型信息系统了，JBossCache 被淘汰的主要原因是写入性能实在差到不堪入目的程度，它在小规模集群中同步数据尚算差强人意，但在大规模集群下，很容易就因网络同步的速度跟不上写入速度，进而导致在内存中累计大量待重发对象，最终引发 OutOfMemory 崩溃。如果对 JBossCache 没有足够了解的话，稍有不慎就要被埋进坑里。<br>为了缓解复制式同步的写入效率问题，JBossCache 的继任者<a href=https://infinispan.org/ rel=noopener target=_blank>Infinispan</a>提供了另一种分布式同步模式（这种同步模式的名字就叫做“分布式”），允许用户配置数据需要复制的副本数量，譬如集群中有八个节点，可以要求每个数据只保存四份副本，此时，缓存的总容量相当于是传统复制模式的一倍，如果要访问的数据在本地缓存中没有存储，Infinispan 完全有能力感知网络的拓扑结构，知道应该到哪些节点中寻找数据。<li><strong>集中式缓存</strong>：集中式缓存是目前分布式缓存的主流形式，<strong>集中式缓存的读、写都需要网络访问，其好处是不会随着集群节点数量的增加而产生额外的负担，其坏处自然是读、写都不再可能达到进程内缓存那样的高性能。</strong><br>集中式缓存还有一个必须提到的关键特点，<strong>它与使用缓存的应用分处在独立的进程空间中，其好处是它能够为异构语言提供服务</strong>，譬如用 C 语言编写的<a href=https://memcached.org/ rel=noopener target=_blank>Memcached</a>完全可以毫无障碍地为 Java 语言编写的应用提供缓存服务；但其<strong>坏处是如果要缓存对象等复杂类型的话，基本上就只能靠序列化来支撑具体语言的类型系统（支持 Hash 类型的缓存，可以部分模拟对象类型），不仅有序列化的成本，还很容易导致传输成本也显著增加</strong>。举个例子，假设某个有 100 个字段的大对象变更了其中 1 个字段的值，通常缓存也不得不把整个对象所有内容重新序列化传输出去才能实现更新，因此，一般集中式缓存更提倡直接缓存原始数据类型而不是对象。相比之下，JBossCache 通过它的字节码自审（Introspection）功能和树状存储结构（TreeCache），做到了自动跟踪、处理对象的部分变动，用户修改了对象中哪些字段的数据，缓存就只会同步对象中真正变更那部分数据。<br>如今<a href=https://redis.io/ rel=noopener target=_blank>Redis</a>广为流行，基本上已经打败了 Memcached 及其他集中式缓存框架，成为集中式缓存的首选，甚至可以说成为了分布式缓存的实质上的首选，几乎到了不必管读取、写入哪种操作更频繁，都可以无脑上 Redis 的程度。</ul><li><p>从数据一致性角度说，缓存本身也有集群部署的需求，是否能接受不同节点取到的缓存数据有可能存在差异。譬如刚刚放入缓存中的数据，另外一个节点马上访问发现未能读到；刚刚更新缓存中的数据，另外一个节点访问在短时间内读取到的仍是旧的数据，等等。根据分布式缓存集群是否能保证数据一致性，可以将它分为 AP 和 CP 两种类型。实际开发中通常不太会把追求强一致性的数据使用缓存来处理，可以这样做，但是没必要（可类比 MESI 等缓存一致性协议）。譬如，Redis 集群就是典型的 AP 式，有着高性能高可用等特点，却并不保证强一致性。而能够保证强一致性的 ZooKeeper、Doozerd、Etcd 等分布式协调框架，通常不会有人将它们当为“缓存框架”来使用，这些分布式协调框架的吞吐量相对 Redis 来说是非常有限的。不过 ZooKeeper、Doozerd、Etcd 倒是常与 Redis 和其他分布式缓存搭配工作，用来实现其中的通知、协调、队列、分布式锁等功能。</p></ul><p>分布式缓存与进程内缓存各有所长，也有各有局限，它们是互补而非竞争的关系，如有需要，完全可以同时把进程内缓存和分布式缓存互相搭配，构成透明多级缓存（Transparent Multilevel Cache，TMC）<p>先不考虑“透明”的话，多级缓存是很好理解的，使用进程内缓存做一级缓存，分布式缓存做二级缓存，如果能在一级缓存中查询到结果就直接返回，否则便到二级缓存中去查询，再将二级缓存中的结果回填到一级缓存，以后再访问该数据就没有网络请求了。如果二级缓存也查询不到，就发起对最终数据源的查询，将结果回填到一、二级缓存中去。<p><img alt=image-20260130172503417 data-src=https://s2.loli.net/2026/01/30/UdWMCisZSTaYE2h.png style=zoom:80%;><p>尽管多级缓存结合了进程内缓存和分布式缓存的优点，但它的代码侵入性较大，需要由开发者承担多次查询、多次回填的工作，也不便于管理，如超时、刷新等策略都要设置多遍，数据更新更是麻烦，很容易会出现各个节点的一级缓存、以及二级缓存里数据互相不一致的问题。必须“透明”地解决以上问题，多级缓存才具有实用的价值。一种常见的设计原则是变更以分布式缓存中的数据为准，访问以进程内缓存的数据优先。大致做法是当数据发生变动时，在集群内发送推送通知（简单点的话可采用 Redis 的 PUB/SUB，求严谨的话引入 ZooKeeper 或 Etcd 来处理），让各个节点的一级缓存自动失效掉相应数据。当访问缓存时，提供统一封装好的一、二级缓存联合查询接口，接口外部是只查询一次，接口内部自动实现优先查询一级缓存，未获取到数据再自动查询二级缓存的逻辑。<h4 id=缓存风险><a class=headerlink href=#缓存风险 title=缓存风险></a>缓存风险</h4><p>缓存的目的是为了缓解 CPU 或者 I/O 的压力，譬如对数据库做缓存，大部分流量都从缓存中直接返回，只有缓存未能命中的数据请求才会流到数据库中，这样数据库压力自然就减小了。<p><strong>缓存穿透</strong><p><strong>如果查询的数据在数据库中根本不存在的话，缓存里自然也不会有，这类请求的流量每次都不会命中，每次都会触及到末端的数据库，缓存就起不到缓解压力的作用了，这种查询不存在数据的现象被称为缓存穿透</strong>。<p>缓存穿透有可能是业务逻辑本身就存在的固有问题，也有可能是被恶意攻击的所导致，为了解决缓存穿透，通常会采取下面两种办法：<ol><li>对于业务逻辑本身就不能避免的缓存穿透，<strong>可以约定在一定时间内对返回为空的 Key 值依然进行缓存</strong>（注意是正常返回但是结果为空，不应把抛异常的也当作空值来缓存了），使得在一段时间内缓存最多被穿透一次。如果后续业务在数据库中对该 Key 值插入了新记录，那应当在插入之后主动清理掉缓存的 Key 值。如果业务时效性允许的话，也可以将对缓存设置一个较短的超时时间来自动处理。<li>对于<strong>恶意攻击导致的缓存穿透，通常会在缓存之前设置一个布隆过滤器来解决</strong>。所谓恶意攻击是指请求者刻意构造数据库中肯定不存在的 Key 值，然后发送大量请求进行查询。<strong>布隆过滤器是用最小的代价来判断某个元素是否存在于某个集合的办法。如果布隆过滤器给出的判定结果是请求的数据不存在，那就直接返回即可，连缓存都不必去查</strong>。虽然维护布隆过滤器本身需要一定的成本，但比起攻击造成的资源损耗仍然是值得的。</ol><p><strong>缓存击穿</strong><p>缓存的基本工作原理是首次从真实数据源加载数据，完成加载后回填入缓存，以后其他相同的请求就从缓存中获取数据，缓解数据源的压力。<strong>如果缓存中某些热点数据忽然因某种原因失效了，譬如典型地由于超期而失效，此时又有多个针对该数据的请求同时发送过来</strong>，这些请求将全部未能命中缓存，都到达真实数据源中去，导致其压力剧增，这种现象被称为缓存击穿。要避免缓存击穿问题，通常会采取下面的两种办法：<ol><li>加锁同步，以请求该数据的 Key 值为锁，使得只有第一个请求可以流入到真实的数据源中，其他线程采取阻塞或重试策略。如果是进程内缓存出现问题，施加普通互斥锁即可，如果是分布式缓存中出现的问题，就施加分布式锁，这样数据源就不会同时收到大量针对同一个数据的请求了。<li>热点数据由代码来手动管理，缓存击穿是仅针对热点数据被自动失效才引发的问题，<strong>对于这类数据，可以直接由开发者通过代码来有计划地完成更新、失效，避免由缓存的策略自动管理</strong>。<li>逻辑过期。缓存本身永不过期，添加缓存实际过期时间戳，访问数据时判断是否过期，如果已经过期则开启异步线程进行更新。如果允许短期不一致，则直接返回过期值。</ol><p><strong>缓存雪崩</strong><p>缓存击穿是针对<strong>单个热点数据失效，由大量请求击穿缓存而给真实数据源带来压力</strong>。有另一种可能是更普遍的情况，不需要是针对单个热点数据的大量请求，而是由于<strong>大批不同的数据在短时间内一起失效，导致了这些数据的请求都击穿了缓存到达数据源</strong>，同样令数据源在短时间内压力剧增。<p>出现这种情况，<strong>往往是系统有专门的缓存预热功能，也可能大量公共数据是由某一次冷操作加载的，这样都可能出现由此载入缓存的大批数据具有相同的过期时间</strong>，在同一时刻一起失效。还有一种情况是<strong>缓存服务由于某些原因崩溃后重启，此时也会造成大量数据同时失效</strong>，这种现象被称为缓存雪崩。要避免缓存雪崩问题，通常会采取下面的三种办法：<ol><li>提升缓存系统可用性，建设分布式缓存的集群。<li><strong>启用透明多级缓存，各个服务节点一级缓存中的数据通常会具有不一样的加载时间</strong>，也就分散了它们的过期时间。<li>将缓存的生存期<strong>从固定时间改为一个时间段内的随机时间</strong>，譬如原本是一个小时过期，那可以缓存不同数据时，设置生存期为 55 分钟到 65 分钟之间的某个随机时间</ol><h3 id=缓存污染><a class=headerlink href=#缓存污染 title=缓存污染></a>缓存污染</h3><p>缓存污染是指缓存中的数据与真实数据源中的数据不一致的现象。尽管缓存通常不追求强一致性，但这显然不能等同于缓存和数据源间连最终的一致性都可以不要求了。<p><strong>缓存污染多数是由开发者更新缓存不规范造成的，譬如你从缓存中获得了某个对象，更新了对象的属性，但最后因为某些原因，譬如后续业务发生异常回滚了，最终没有成功写入到数据库，此时缓存的数据是新的，数据库中的数据是旧的</strong>。为了尽可能的提高使用缓存时的一致性，已经总结不少更新<strong>缓存可以遵循设计模式，譬如 Cache Aside、Read/Write Through、Write Behind Caching 等</strong>。其中最简单、成本最低的 Cache Aside 模式是指：<ul><li>读数据时，先读缓存，缓存没有的话，再读数据源，然后将数据放入缓存，再响应请求。<li>写数据时，先写数据源，然后失效（而不是更新）掉缓存。</ul><p>读数据方面一般没什么出错的余地，但是写数据时，就有必要专门强调两点：一是先后顺序是<strong>先数据源后缓存</strong>。试想一下，如果<strong>采用先失效缓存后写数据源的顺序，那一定存在一段时间缓存已经删除完毕，但数据源还未修改完成，此时新的查询请求到来，缓存未能命中，就会直接流到真实数据源中</strong>。这样请求读到的数据依然是旧数据，随后又重新回填到缓存中。当数据源的修改完成后，结果就成了数据在数据源中是新的，在缓存中是老的，两者就会有不一致的情况。<p>另一点是应当失效缓存，而不是去尝试更新缓存，这很容易理解，如果去更新缓存，更新过程中数据源又被其他请求再次修改的话，缓存又要面临处理多次赋值的复杂时序问题。所以直接失效缓存，等下次用到该数据时自动回填，期间无论数据源中的值被改了多少次都不会造成任何影响。<p>Cache Aside 模式依然是不能保证在一致性上绝对不出问题的，否则就无须设计出<a href=https://icyfenix.cn/distribution/consensus/paxos.html rel=noopener target=_blank>Paxos</a>这样复杂的共识算法了。典型的出错场景是<strong>如果某个数据是从未被缓存过的，请求会直接流到真实数据源中，如果数据源中的写操作发生在查询请求之后，结果回填到缓存之前</strong>，也会出现缓存中回填的内容与数据库的实际数据不一致的情况。但这种情况的概率是很低的，Cache Aside 模式仍然是以低成本更新缓存，并且获得相对可靠结果的解决方案。<h3 id=架构安全性><a class=headerlink href=#架构安全性 title=架构安全性></a>架构安全性</h3><ul><li><a href=https://icyfenix.cn/architect-perspective/general-architecture/system-security/authentication rel=noopener target=_blank><strong>认证</strong></a>（Authentication）：系统如何正确分辨出操作用户的真实身份？<li><a href=https://icyfenix.cn/architect-perspective/general-architecture/system-security/authorization rel=noopener target=_blank><strong>授权</strong></a>（ Authorization）：系统如何控制一个用户该看到哪些数据、能操作哪些功能？<li><a href=https://icyfenix.cn/architect-perspective/general-architecture/system-security/credentials rel=noopener target=_blank><strong>凭证</strong></a>（Credential）：系统如何保证它与用户之间的承诺是双方当时真实意图的体现，是准确、完整且不可抵赖的？<li><a href=https://icyfenix.cn/architect-perspective/general-architecture/system-security/confidentiality rel=noopener target=_blank><strong>保密</strong></a>（Confidentiality）：系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？<li><a href=https://icyfenix.cn/architect-perspective/general-architecture/system-security/transport-security rel=noopener target=_blank><strong>传输</strong></a>（Transport Security）：系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充？<li><a href=https://icyfenix.cn/architect-perspective/general-architecture/system-security/verification rel=noopener target=_blank><strong>验证</strong></a>（Verification）：系统如何确保提交到每项服务中的数据是合乎规则的，不会对系统稳定性、数据一致性、正确性产生风险</ul><p>这些问题基本上也都是与具体系统、具体业务无关的通用性问题，这意味着它们往往会存在着业界通行的、已被验证过是行之有效的解决方案，乃至已经形成行业标准，不需要开发者自己从头去构思如何解决<h4 id=认证><a class=headerlink href=#认证 title=认证></a>认证</h4><blockquote><p>系统如何正确分辨出操作用户的真实身份？<p>“你是谁？”（认证）、“你能干什么？”（授权）以及“你如何证明？”（凭证）</blockquote><p>随 J2EE 1.2发布的 Servlet 2.2 中，添加了一系列用于认证的 API，主要包括下列两部分内容：<ul><li>标准方面，添加了四种内置的、不可扩展的认证方案，即 Client-Cert、Basic、Digest 和 Form。<li>实现方面，添加了与认证和授权相关的一套程序接口，譬如<code>HttpServletRequest::isUserInRole()</code>、<code>HttpServletRequest::getUserPrincipal()</code>等方法</ul><p>它内置的 Basic、Digest、Form 和 Client-Cert 这四种认证方案都很有代表性，刚好分别覆盖了通信信道、协议和内容层面的认证。而这三种层面认证恰好涵盖了主流的三种认证方式，具体含义和应用场景列举如下。<ul><li><strong>通信信道上的认证</strong>：你和我建立通信连接之前，要先证明你是谁。在网络传输（Network）场景中的典型是基于 SSL/TLS 传输安全层的认证。<li><strong>通信协议上的认证</strong>：你请求获取我的资源之前，要先证明你是谁。在互联网（Internet）场景中的典型是基于 HTTP 协议的认证。<li><strong>通信内容上的认证</strong>：你使用我提供的服务之前，要先证明你是谁。在万维网（World Wide Web）场景中的典型是基于 Web 内容的认证。</ul><h5 id=HTTP认证><a class=headerlink href=#HTTP认证 title=HTTP认证></a>HTTP认证</h5><p>认证方案（Authentication Schemes），它是指<strong>生成用户身份凭证的某种方法</strong>，这个概念最初源于 HTTP 协议的认证框架。要求所有支持 HTTP 协议的服务器，在未授权的用户意图访问服务端保护区域的资源时，应返回 401 Unauthorized 的状态码，同时应在响应报文头里附带以下两个分别代表网页认证和代理认证的 Header 之一，告知客户端应该采取何种方式产生能代表访问者身份的凭证信息：<figure class="highlight http"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line><span class=attribute>WWW-Authenticate</span><span class=punctuation>: </span><认证方案> realm=<保护区域的描述信息></span><br><span class=line><span class=attribute>Proxy-Authenticate</span><span class=punctuation>: </span><认证方案> realm=<保护区域的描述信息></span><br></pre></table></figure><p>接收到该响应后，客户端必须遵循服务端指定的认证方案，在请求资源的报文头中加入身份凭证信息，由服务端核实通过后才会允许该请求正常返回，否则将返回 403 Forbidden 错误。请求头报文应包含以下 Header 项之一：<figure class="highlight http"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line><span class=attribute>Authorization</span><span class=punctuation>: </span><认证方案> <凭证内容></span><br><span class=line><span class=attribute>Proxy-Authorization</span><span class=punctuation>: </span><认证方案> <凭证内容></span><br></pre></table></figure><p><img alt=image-20260130194952557 data-src=https://s2.loli.net/2026/01/30/851eJUml9VXnKTG.png><p>Basic 认证产生用户身份凭证的方法是让用户输入用户名和密码，经过 Base64 编码“加密”后作为身份凭证。譬如请求资源<code>GET /admin</code>后，浏览器会收到来自服务端的如下响应：<figure class="highlight http"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br></pre><td class=code><pre><span class=line><span class=meta>HTTP/1.1</span> <span class=number>401</span> Unauthorized</span><br><span class=line><span class=attribute>Date</span><span class=punctuation>: </span>Mon, 24 Feb 2020 16:50:53 GMT</span><br><span class=line><span class=attribute>WWW-Authenticate</span><span class=punctuation>: </span>Basic realm="example from icyfenix.cn"</span><br></pre></table></figure><p>除 Basic 认证外，IETF 还定义了很多种可用于实际生产环境的认证方案，列举如下。<ul><li><strong>Digest</strong>：<a href=https://tools.ietf.org/html/rfc7616 rel=noopener target=_blank>RFC 7616</a>，HTTP 摘要认证，可视为 Basic 认证的改良版本，针对 Base64 明文发送的风险，Digest 认证把用户名和密码加盐（一个被称为 Nonce 的变化值作为盐值）后再通过 MD5/SHA 等哈希算法取摘要发送出去。但是这种认证方式依然是不安全的，无论客户端使用何种加密算法加密，无论是否采用了 Nonce 这样的动态盐值去抵御重放和冒认，遇到中间人攻击时依然存在显著的安全风险。<li><strong>Bearer</strong>：<a href=https://tools.ietf.org/html/rfc6750 rel=noopener target=_blank>RFC 6750</a>，基于 OAuth 2 规范来完成认证，OAuth2 是一个同时涉及认证与授权的协议，<li><strong>HOBA</strong>：<a href=https://tools.ietf.org/html/rfc7486 rel=noopener target=_blank>RFC 7486</a> ，HOBA（HTTP Origin-Bound Authentication）是一种基于自签名证书的认证方案。基于数字证书的信任关系主要有两类模型：一类是采用 CA（Certification Authority）层次结构的模型，由 CA 中心签发证书；另一种是以 IETF 的 Token Binding 协议为基础的 OBC（Origin Bound Certificate）自签名证书模型。</ul><h5 id=Web认证><a class=headerlink href=#Web认证 title=Web认证></a>Web认证</h5><p>以 HTTP 协议为基础的认证框架也只能面向传输协议而不是具体传输内容来设计，如果用户想要从服务器中下载文件，弹出一个 HTTP 服务器的对话框，让用户登录是可接受的；但如果用户访问信息系统中的具体服务，身份认证肯定希望是由系统本身的功能去完成的，而不是由 HTTP 服务器来负责认证。这种依靠内容而不是传输协议来实现的认证方式，在万维网里被称为“Web 认证”，由于实现形式上登录表单占了绝对的主流，因此通常也被称为“表单认证”（Form Authentication）<h4 id=授权><a class=headerlink href=#授权 title=授权></a>授权</h4><p>日常开发中最常用到的 RBAC 和 OAuth2 这两种访问控制和授权方案<h5 id=RBAC><a class=headerlink href=#RBAC title=RBAC></a>RBAC</h5><p>在 RBAC 模型中，角色拥有许可的数量是根据完成该角色工作职责所需的最小权限来赋予的，最典型例子是操作系统权限管理中的用户组，根据对不同角色的职责分工，如管理员（Administrator）、系统用户（System）、验证用户（Authenticated Users）、普通用户（Users）、来宾用户（Guests）等分配各自的权限，既保证用户能够正常工作，也避免用户出现越权操作的风险。当用户的职责发生变化时，在系统中就体现为它所隶属的角色被改变，譬如将“普通用户角色”改变“管理员角色”，就可以迅速让该用户具备管理员的多个细分权限，降低权限分配错误的风险。<p>RBAC 还允许对不同角色之间定义关联与约束，进一步强化它的抽象描述能力。如不同的角色之间可以有继承性，典型的是 RBAC-1 模型的角色权限继承关系。譬如描述开发经理应该和开发人员一样具有代码提交的权限，描述开发人员都应该和任何公司员工一样具有食堂就餐的权限，就可以直接将食堂就餐赋予公司员工的角色上，把代码提交赋予到开发人员的角色上，再让开发人员的角色从公司员工派生，开发经理的角色从开发人员中派生即可。<p>不同角色之间也可以具有互斥性，典型的是 RBAC-2 模型的角色职责分离关系。互斥性要求权限被赋予角色时，或角色被赋予用户时应遵循的强制性职责分离规定。举个例子，角色的互斥约束可限制同一用户只能分配到一组互斥角色集合中至多一个角色，譬如不能让同一名员工既当会计，也当出纳，否则资金安全无法保证。角色的基数约束可限制某一个用户拥有的最大角色数目，譬如不能让同一名员工从产品、设计、开发、测试全部包揽，否则产品质量无法保证。<p>建立访问控制模型的基本目的是为了管理垂直权限和水平权限。垂直权限即功能权限，譬如前面提到的审稿编辑有通过审核的权限、开发经理有代码提交的权限、出纳有从账户提取资金的权限，这一类某个角色完成某项操作的许可，都可以直接翻译为功能权限。由于实际应用与权限模型具有高度对应关系，将权限从具体的应用中抽离出来，放到通用的模型中是相对容易的，Spring Security、Apache Shiro 等权限框架就是这样的抽象产物，大多数系统都能采用这些权限框架来管理功能权限。<p>与此相对，水平权限即数据权限管理起来则要困难许多。譬如用户 A、B 都属于同一个角色，但它们各自在系统中产生的数据完全有可能是私有的，A 访问或删除了 B 的数据也照样属于越权。一般来说，数据权限是很难抽象与通用的，仅在角色层面控制并不能满足全部业务的需要，很多时候只能具体到用户，甚至要具体管理到发生数据的某一行、某一列之上，因此数据权限基本只能由信息系统自主来来完成，并不存在能放之四海皆准的通用数据权限框架<h5 id=OAuth2><a class=headerlink href=#OAuth2 title=OAuth2></a>OAuth2</h5><p>OAuth2 是<strong>面向于解决第三方应用</strong>（Third-Party Application）的认证授权协议。OAuth2 给出了多种解决办法，这些办法的共同特征是<strong>以令牌（Token）代替用户密码作为授权的凭证。有了令牌之后，哪怕令牌被泄漏，也不会导致密码的泄漏</strong>；令牌上可以设定访问资源的范围以及时效性；每个应用都持有独立的令牌，哪个失效都不会波及其他<p><img alt=image-20260130205237718 data-src=https://s2.loli.net/2026/01/30/PpsHoeAr2Utycv3.png><ul><li><strong>第三方应用</strong>（Third-Party Application）：需要得到授权访问我资源的那个应用，即此场景中的“Travis-CI”。<li><strong>授权服务器</strong>（Authorization Server）：能够根据我的意愿提供授权（授权之前肯定已经进行了必要的认证过程，但它与授权可以没有直接关系）的服务器，即此场景中的“GitHub”。<li><strong>资源服务器</strong>（Resource Server）：能够提供第三方应用所需资源的服务器，它与认证服务可以是相同的服务器，也可以是不同的服务器，此场景中的“我的代码仓库”。<li><strong>资源所有者</strong>（Resource Owner）： 拥有授权权限的人，即此场景中的“我”。<li><strong>操作代理</strong>（User Agent）：指用户用来访问服务器的工具，对于人类用户来说，这个通常是指浏览器，但在微服务中一个服务经常会作为另一个服务的用户，此时指的可能就是 HttpClient、RPCClient 或者其他访问途径。</ul><p>“用令牌代替密码”确实是解决问题的好方法，但这充其量只能算个思路，距离可实施的步骤还是不够具体的，时序图中的“要求/同意授权”、“要求/同意发放令牌”、“要求/同意开放资源”几个服务请求、响应该如何设计，这就是执行步骤的关键了。对此，OAuth2 一共提出了四种不同的授权方式（这也是 OAuth2 复杂烦琐的主要原因），分别为：<ul><li>授权码模式（Authorization Code）<li>隐式授权模式（Implicit）<li>密码模式（Resource Owner Password Credentials）<li>客户端模式（Client Credentials）</ul><h4 id=凭证><a class=headerlink href=#凭证 title=凭证></a>凭证</h4><p>以 HTTP 协议的 Cookie-Session 机制为代表的服务端状态存储在三十年来都是主流的解决方案。不过，到了最近十年，由于分布式系统中共享数据必然会受到 CAP 不兼容原理的打击限制，迫使人们重新去审视之前已基本放弃掉的客户端状态存储，这就让原本通常只在多方系统中采用的 JWT 令牌方案，在分布式系统中也有了另一块用武之地。<h5 id=Cookie-Session><a class=headerlink href=#Cookie-Session title=Cookie-Session></a>Cookie-Session</h5><p>HTTP 协议是一种无状态的传输协议，无状态是指协议对事务处理没有上下文的记忆能力，每一个请求都是完全独立的，但是我们中肯定有许多人并没有意识到 HTTP 协议无状态的重要性。<p>HTTP 协议的无状态特性又有悖于我们最常见的网络应用场景，典型就是认证授权，系统总得要获知用户身份才能提供合适的服务，因此，我们也希望 HTTP 能有一种手段，让服务器至少有办法能够区分出发送请求的用户是谁。为了实现这个目的，)规范定义了 HTTP 的状态管理机制，在 HTTP 协议中增加了 Set-Cookie 指令，该指令的含义是以键值对的方式向客户端发送一组信息，此信息将在此后一段时间内的每次 HTTP 请求中，以名为 Cookie 的 Header 附带着重新发回给服务端，以便服务端区分来自不同客户端的请求。<p>一般来说，系统会把状态信息保存在服务端，在 Cookie 里只传输的是一个无字面意义的、不重复的字符串，习惯上以<code>sessionid</code>或者<code>jsessionid</code>为名，服务器拿这个字符串为 Key，在内存中开辟一块空间，以 Key/Entity 的结构存储每一个在线用户的上下文状态，再辅以一些超时自动清理之类的管理措施。这种服务端的状态管理机制就是今天大家非常熟悉的 Session，Cookie-Session 也是最传统但今天依然广泛应用于大量系统中的，由服务端与客户端联动来完成的状态管理机制。<p>状态信息都存储于服务器，<strong>只要依靠客户端的同源策略和 HTTPS 的传输层安全，保证 Cookie 中的键值不被窃取而出现被冒认身份的情况</strong>，就能完全规避掉上下文信息在传输过程中被泄漏和篡改的风险。Cookie-Session 方案的另一大优点是<strong>服务端有主动的状态管理能力，可根据自己的意愿随时修改、清除任意上下文信息</strong>，譬如很轻易就能实现强制某用户下线的这样功能。<p>Session-Cookie <strong>在单节点的单体服务环境中是最合适的方案</strong>，但当需要水平扩展服务能力，要部署集群时就开始面临麻烦了，由于 Session 存储在服务器的内存中，当服务器水平拓展成多节点时，设计者必须在以下三种方案中选择其一：<ul><li>牺牲集群的一致性（Consistency），让均衡器采用亲和式的负载均衡算法，<strong>譬如根据用户 IP 或者 Session 来分配节点，每一个特定用户发出的所有请求都一直被分配到其中某一个节点来提供服务，每个节点都不重复地保存着一部分用户的状态</strong>，如果这个节点崩溃了，里面的用户状态便完全丢失。<li>牺牲集群的可用性（Availability），让各个节点之间采用复制式的 Session，<strong>每一个节点中的 Session 变动都会发送到组播地址的其他服务器上，这样某个节点崩溃了，不会中断对某个用户的服务，但 Session 之间组播复制的同步代价高昂</strong>，节点越多时，同步成本越高。<li>牺牲集群的分区容忍性（Partition Tolerance），让普通的服务节点中不再保留状态，将上下文集中放在一个所有服务节点都能访问到的数据节点中进行存储。此时的矛盾是数据节点就成为了单点，一旦数据节点损坏或出现网络分区，整个集群都不再能提供服务</ul><h5 id=JWT令牌><a class=headerlink href=#JWT令牌 title=JWT令牌></a>JWT令牌</h5><p>Cookie-Session 机制在<strong>分布式环境下会遇到 CAP 不可兼得的问题</strong>，而在多方系统中，就更不可能谈什么 Session 层面的数据共享了，<strong>哪怕服务端之间能共享数据，客户端的 Cookie 也没法跨域</strong>。所以我们不得不重新捡起最初被抛弃的思路，当服务器存在多个，客户端只有一个时，把状态信息存储在客户端，每次随着请求发回服务器去。这样做的<strong>缺点是无法携带大量信息，而且有泄漏和篡改的安全风险</strong>。信息量受限的问题并没有太好的解决办法，但是要确保信息不被中间人篡改则还是可以实现的。<p>它最常见的使用方式是附在名为 Authorization 的 Header 发送给服务端.JWT 令牌是以 JSON 结构存储的，结构总体上可划分为三个部分，每个部分间用点号<code>.</code>分隔开。第一部分是<strong>令牌头</strong>（Header）<blockquote><p>某种哈希算法前出现“HMAC”的前缀，这是指散列消息认证码（Hash-based Message Authentication Code，HMAC）。可以简单将它理解为一种带有密钥的哈希摘要算法，实现形式上通常是把密钥以加盐方式混入，与内容一起做哈希摘要。<p>HMAC 哈希与普通哈希算法的差别是普通的哈希算法通过 Hash 函数结果易变性保证了原有内容未被篡改，HMAC 不仅保证了内容未被篡改过，还保证了该哈希确实是由密钥的持有人所生成的。</blockquote><p>令牌的第二部分是<strong>负载</strong>（Payload），这是令牌真正需要向服务端传递的信息。针对认证问题，<strong>负载至少应该包含能够告知服务端“这个用户是谁”的信息，针对授权问题，令牌至少应该包含能够告知服务端“这个用户拥有什么角色/权限”的信息</strong>。JWT 的负载部分是可以完全自定义的，根据具体要解决的问题不同，设计自己所需要的信息，只是总容量不能太大，毕竟要受到 HTTP Header 大小的限制<p>令牌的第三部分是<strong>签名</strong>（Signature），签名的意思是：使用在对象头中公开的特定签名算法，通过特定的密钥（Secret，由服务器进行保密，不能公开）对前面两部分内容进行加密计算.<p><strong>签名的意义在于确保负载中的信息是可信的、没有被篡改的，也没有在传输过程中丢失任何信息。因为被签名的内容哪怕发生了一个字节的变动，也会导致整个签名发生显著变化</strong>。此外，由于签名这件事情只能由认证授权服务器完成（只有它知道 Secret），<strong>任何人都无法在篡改后重新计算出合法的签名值，所以服务端才能够完全信任客户端传上来的 JWT 中的负载信息</strong><p>JWT 默认的签名算法 HMAC SHA256 是一种带密钥的哈希摘要算法，加密与验证过程均只能由中心化的授权服务来提供，所以这种方式一般只适合于授权服务与应用服务处于同一个进程中的单体应用。<p>在多方系统或者授权服务与资源服务分离的分布式应用中，通常会采用非对称加密算法来进行签名，这时候除了授权服务端持有的可以用于签名的私钥外，还会对其他服务器公开一个公钥.公钥不能用来签名，但是能被其他服务用于验证签名是否由私钥所签发的。这样其他服务器也能不依赖授权服务器、无须远程通信即可独立判断 JWT 令牌中的信息的真伪。<p>例如 Istio 服务网格，终端用户认证会由服务网格的基础设施参来完成，此时就改用了非对称加密的 RSA SHA256 算法来进行签名。<p>尽管大型系统中只使用 JWT 来维护上下文状态，服务端完全不持有状态是不太现实的，不过将热点的服务单独抽离出来做成无状态，仍是一种有效提升系统吞吐能力的架构技巧。但是，JWT 也并非没有缺点的完美方案，它存在着以下几个经常被提及的缺点：<ul><li><strong>令牌难以主动失效</strong>：JWT 令牌一旦签发，理论上就和认证服务器再没有什么瓜葛了，在到期之前就会始终有效，除非服务器部署额外的逻辑去处理失效问题，这对某些管理功能的实现是很不利的。譬如一种颇为常见的需求是：<strong>要求一个用户只能在一台设备上登录，在 B 设备登录后，之前已经登录过的 A 设备就应该自动退出。如果采用 JWT，就必须设计一个“黑名单”的额外的逻辑，用来把要主动失效的令牌集中存储起来</strong>，而无论这个黑名单是实现在 Session、Redis 或者数据库中，都会让服务退化成有状态服务，降低了 JWT 本身的价值，<strong>但黑名单在使用 JWT 时依然是很常见的做法，需要维护的黑名单一般是很小的状态量，许多场景中还是有存在价值的。</strong><li><strong>相对更容易遭受重放攻击</strong>：首先说明 Cookie-Session 也是有重放攻击问题的，只是因为 Session 中的数据控制在服务端手上，应对重放攻击会相对主动一些。要在 JWT 层面解决重放攻击需要付出比较大的代价，无论是加入全局序列号（HTTPS 协议的思路）、Nonce 字符串（HTTP Digest 验证的思路）、挑战应答码（当下网银动态令牌的思路）、还是缩短令牌有效期强制频繁刷新令牌，在真正应用起来时都很麻烦。真要处理重放攻击，建议的解决方案是在信道层次（譬如启用 HTTPS）上解决，而不提倡在服务层次（譬如在令牌或接口其他参数上增加额外逻辑）上解决。</ul><blockquote><p><strong>重放攻击（Replay Attack）</strong> 是一种网络攻击手段，指攻击者截获了发送方发出的合法数据包，并在一段时间后重新发送给接收方，以此来欺骗接收方执行非授权的操作</blockquote><ul><li><strong>只能携带相当有限的数据</strong>：HTTP 协议并没有强制约束 Header 的最大长度，但是，各种服务器、浏览器都会有自己的约束，譬如 Tomcat 就要求 Header 最大不超过 8KB，而在 Nginx 中则默认为 4KB，因此在令牌中存储过多的数据不仅耗费传输带宽，还有额外的出错风险。<li><strong>必须考虑令牌在客户端如何存储</strong>：严谨地说，这个并不是 JWT 的问题而是系统设计的问题。如果授权之后，操作完关掉浏览器就结束了，那把令牌放到内存里面，压根不考虑持久化才是最理想的方案。但并不是谁都能忍受一个网站关闭之后下次就一定强制要重新登录的。这样的话，想想客户端该把令牌存放到哪里？Cookie？localStorage？Indexed DB？它们都有泄漏的可能，而令牌一旦泄漏，别人就可以冒充用户的身份做任何事情。<li><strong>无状态也不总是好的</strong>：这个其实不也是 JWT 的问题。如果不能想像无状态会有什么不好的话，我给你提个需求：请基于无状态 JWT 的方案，做一个在线用户实时统计功能。</ul><h4 id=保密><a class=headerlink href=#保密 title=保密></a>保密</h4><p>保密是加密和解密的统称，是指以某种特殊的算法改变原有的信息数据，使得未授权的用户即使获得了已加密的信息，但因不知解密的方法，或者知晓解密的算法但缺少解密所需的必要信息，仍然无法了解数据的真实内容。<p>按照需要保密信息所处的环节不同，可以划分为“信息在客户端时的保密”、“信息在传输时的保密”和“信息在服务端时的保密”三类<p><strong>客户端加密</strong><p>为了保证信息不被黑客窃取而做客户端加密没有太多意义，对绝大多数的信息系统来说，启用 HTTPS 可以说是唯一的实际可行的方案。<strong>但为了保证密码不在服务端被滥用，在客户端就开始加密是很有意义</strong>的。大网站被拖库的事情层出不穷，密码明文被写入数据库、被输出到日志中之类的事情也屡见不鲜，做系统设计时就应该把明文密码这种东西当成是最烫手的山芋来看待，越早消灭掉越好<p><strong>密码存储和验证</strong><p>多数信息系统来说，只要配合一定的密码规则约束，譬如密码要求长度、特殊字符等，再配合 HTTPS 传输，已足防御大多数风险了。即使在用户采用了弱密码、客户端通信被监听、服务端被拖库、泄漏了存储的密文和盐值等问题同时发生，也能够最大限度避免用户明文密码被逆推出来<p>一种方式是在客户端做密码哈希/伪动态加盐+慢哈希,服务端再动态生成盐值混入客户端传来的哈希值再做一次哈希，产生出最终的密文，并和上一步随机生成的盐值一起写入到同一条数据库记录中。<blockquote><p>慢哈希函数是指这个函数执行时间是可以调节的哈希函数，通常是以控制调用次数来实现的。</blockquote><p>以上加密存储的过程相对复杂，但是<strong>运算压力最大的过程（慢哈希）是在客户端完成的，对服务端压力很小，也不惧怕因网络通信被截获而导致明文密码泄漏</strong>。密码存储后，以后验证的过程与加密是类似的.<p>登陆时，经过与注册相同的加密过程，向服务端传输加密后的结果。服务端，接受到客户端传输上来的哈希值，从数据库中取出登录用户对应的密文和盐值，采用相同的哈希算法，对客户端传来的哈希值、服务端存储的盐值计算摘要结果最后进行对比。<h4 id=传输><a class=headerlink href=#传输 title=传输></a>传输</h4><p><strong>摘要、加密与签名</strong><p>摘要也称之为数字摘要（Digital Digest）或数字指纹（Digital Fingerprint）。<strong>JWT 令牌中默认的签名信息是对令牌头、负载和密钥三者通过令牌头中指定的哈希算</strong>法（HMAC SHA256）计算出来的摘要值<p>理想哈希算法:<ul><li>易变性，这是指算法的输入端发生了任何一点细微变动，都会引发雪崩效应，使得输出端的结果产生极大的变化<li>不可逆性，摘要的过程是单向的，不可能从摘要的结果中逆向还原出输入值来。</ul><p>在一些场合中，摘要也会被借用来做加密（如保密中介绍的慢哈希 Bcrypt 算法）和签名（如 JWT 签名中的 HMAC SHA256 算法），但在严格意义上看，摘要与这两者是有本质的区别。<p>加密与摘要的本质区别在于加密是可逆的，逆过程就是解密。<p>根据加密与解密是否采用同一个密钥，现代密码学算法可分为对称加密算法和非对称加密两大类型，这两类算法各自有很明确的优劣势与应用场景。对称加密的缺点显而易见，加密和解密使用相同的密钥，为保证两两通信都采用独立的密钥，<strong>密钥数量就与成员数量的平方成正比</strong>，这必然面临密钥管理的难题。而<strong>更尴尬的难题是当通信双方原本就不存在安全的信道时，如何才能将一个只能让通信双方才能知道的密钥传输给对方</strong><p>非对称加密算法从根本上解决了密钥分发的难题，它将密钥分成公钥和私钥，<strong>公钥可以完全公开，无须安全传输的保证。私钥由用户自行保管，不参与任何通信传输</strong>。根据这两个密钥加解密方式的不同，使得算法可以提供两种不同的功能：<ul><li><strong>公钥加密，私钥解密</strong>，<strong>这种就是加密，用于向私钥所有者发送信息，这个信息可能被他人篡改，但是无法被他人得知</strong>。如果甲想给乙发一个安全保密的数据，那么应该甲乙各自有一个私钥，甲先用乙的公钥加密这段数据，再用自己的私钥加密这段加密后的数据。最后再发给乙，这样确保了内容即不会被读取，也不能被篡改。<li><strong>私钥加密，公钥解密</strong>，<strong>这种就是签名，用于让所有公钥所有者验证私钥所有者的身份</strong>，并且用来防止私钥所有者发布的内容被篡改。但是不用来保证内容不被他人获得。</ul><p>单靠非对称加密算法，既做不了加密也做不了签名。原因是不论是加密还是解密，非对称加密算法的计算复杂度都相当高，性能比对称加密要差上好几个数量级.<p><strong>在加密方面，现在一般会结合对称与非对称加密的优点，以混合加密来保护信道安全，具体做法是用非对称加密来安全地传递少量数据给通信的另一方，然后再以这些数据为密钥</strong>，<strong>采用对称加密来安全高效地大量加密传输数据</strong>，这种由多种加密算法组合的应用形式被称为“密码学套件”。非对称加密在这个场景中发挥的作用称为“密钥协商”。<p>在签名方面，现在一般会<strong>结合摘要与非对称加密的优点</strong>，以对摘要结果做加密的形式来保证签名的适用性。由于<strong>对任何长度的输入源做摘要之后都能得到固定长度的结果，所以只要对摘要的结果进行签名</strong>，即相当于对整个输入源进行了背书，保证一旦内容遭到篡改，摘要结果就会变化，签名也就马上失效了。<div class=table-container><table><thead><tr><th>类型<th>特点<th>常见实现<th>主要用途<th>主要局限<tbody><tr><td>哈希摘要<td>不可逆，即不能解密，所以并不是加密算法，只是一些场景把它当作加密算法使用。 易变性，输入发生 1 Bit 变动，就可能导致输出结果 50%的内容发生改变。 无论输入长度多少，输出长度固定（2 的 N 次幂）。<td>MD2/4/5/6、SHA0/1/256/512<td>摘要<td>无法解密<tr><td>对称加密<td>加密是指加密和解密是一样的密钥。 设计难度相对较小，执行速度相对较块。 加密明文长度不受限制。<td>DES、AES、RC4、IDEA<td>加密<td>要解决如何把密钥安全地传递给解密者。<tr><td>非对称加密<td>加密和解密使用的是不同的密钥。 明文长度不能超过公钥长度。<td>RSA、BCDSA、ElGamal<td>签名、传递密钥<td>性能与加密明文长度受限。</table></div><h4 id=数字证书><a class=headerlink href=#数字证书 title=数字证书></a>数字证书</h4><p>网络中利用<strong>公开密钥基础设施</strong>，利用不通过网络，而是在浏览器与操作系统出厂时就预置好，或者提前安装好的根证书。<p>证书（Certificate），证书是权威 CA (Certificate Authority)中心对特定公钥信息的一种公证载体，也可以理解为是权威 CA 对特定公钥未被篡改的签名背书。由于<strong>客户的机器上已经预置了这些权威 CA 中心本身的证书（称为 CA 证书或者根证书），使得我们能够在不依靠网络的前提下，使用根证书里面的公钥信息对其所签发的证书中的签名进行确认</strong>。一个数字证书包含:版本号,序列号,签名算法,数字签名,认证机构,有效期,主题信息以及公钥。<h4 id=传输安全层><a class=headerlink href=#传输安全层 title=传输安全层></a>传输安全层</h4><p>TLS传输流程。TLS 1.2 在传输之前的握手过程一共需要进行上下两轮、共计四次通信，<p><strong>客户端请求</strong>：Client Hello<br>客户端向服务器请求进行加密通信，在这个请求里面，它会以<strong>明文</strong>的形式，向服务端提供支持的协议版本，密码学算法以及一个<strong>随机数</strong>。这个随机数将稍后用于产生加密的密钥<p><strong>服务器回应</strong>：Server Hello<br>服务器接收到客户端的通信请求后，如果客户端声明支持的协议版本和加密算法组合与服务端相匹配的话，就向客户端发出回应。如果不匹配，将会返回一个握手失败的警告提示。这次回应同样以明文发送的，包括第二个 32 Bytes 的<strong>随机数</strong>，稍后用于产生加密的密钥，服务端选定的密码学算法，<strong>证书(包括公钥)</strong>以及TLS版本等。<p><strong>客户端确认</strong>：Client Handshake Finished<br>客户端收到服务器应答后，先要验证服务器的证书合法性。如果证书不是可信机构颁布的，或者证书中信息存在问题，譬如域名与实际域名不一致、或者证书已经过期、或通过在线证书状态协议得知证书已被吊销，等等，都会向访问者显示一个“证书不可信任”的警告，由用户自行选择是否还要继续通信。如果证书没有问题，客户端就会从证书中取出服务器的公钥，并向服务器发送第三个随机数(以服务端传过来的公钥加密的，它被称为 PreMasterSecret，将与前两次发送的随机数一起，根据特定算法计算出 48 Bytes 的 MasterSecret ，这个 MasterSecret 即<strong>为后续内容传输时的对称加密算法所采用的私钥</strong>。<p><strong>服务端确认</strong>：Server Handshake Finished<br>服务端向客户端回应最后的确认通知,随后的信息都将用双方商定的加密方法和密钥发送。<p>这种处理方式对上层协议的功能上完全透明的，在传输性能上会有下降，但在功能上完全不会感知到有 TLS 的存在。建立在这层安全传输层之上的 HTTP 协议，就被称为“HTTP over SSL/TLS”，也即 HTTPS。<p>阶段任务使用的算法类型常见算法<strong>握手阶段</strong>身份验证、密钥交换<strong>非对称加密</strong>RSA, ECDHE<strong>数据传输</strong>加密实际内容<strong>对称加密</strong>AES, ChaCha20<strong>完整性校验</strong>防止数据被篡改<strong>哈希算法</strong>SHA-256<div class=table-container><table><thead><tr><th><strong>阶段</strong><th><strong>任务</strong><th><strong>使用的算法类型</strong><th><strong>常见算法</strong><tbody><tr><td><strong>握手阶段</strong><td>身份验证、密钥交换<td><strong>非对称加密</strong><td>RSA, ECDHE<tr><td><strong>数据传输</strong><td>加密实际内容<td><strong>对称加密</strong><td>AES, ChaCha20<tr><td><strong>完整性校验</strong><td>防止数据被篡改<td><strong>哈希算法</strong><td>SHA-256</table></div><h3 id=验证><a class=headerlink href=#验证 title=验证></a>验证</h3><p>系统如何确保提交到每项服务中的数据是合乎规则的，不会对系统稳定性、数据一致性、正确性产生风险？<p>最基础的数据问题可以在前端做表单校验来处理，但服务端验证肯定也是要做的，可能会有这样的答案：<ul><li>在 Controller 层做，在 Service 层不做。理由是从 Service 开始会有同级重用，出现 ServiceA.foo(params)调用 ServiceB.bar(params)时，就会对 params 重复校验了两次。<li>在 Service 层做，在 Controller 层不做。理由是无业务含义的格式校验已在前端表单验证处理过，有业务含义的校验，放在 Controller 层无论如何不合适。<li>在 Controller、Service 层各做各的。Controller 做格式校验，Service 层做业务校验，听起来很合理，但这其实就是上面段子中被嘲笑的行为。<li>还有其他一些意见，譬如还有提在持久层做校验，理由是这是最终入口，把守好写入数据库的质量最重要。</ul><p>把校验行为从分层中剥离出来，不是在哪一层做，而是在 Bean 上做。即 Java Bean Validation。<p>对校验项预置好默认的提示信息，这样当校验不通过时用户能获得明确的修正提示.<p>将不带业务含义的格式校验注解放到 Bean 的类定义之上，将带业务逻辑的校验放到 Bean 的类定义的外面。这两者的区别是放在类定义中的注解能够自动运行，而放到类外面则需要像前面代码那样，明确标出注解时才会运行<figure class="highlight java"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br></pre><td class=code><pre><span class=line><span class=comment>// 1. Bean 类：只管格式</span></span><br><span class=line><span class=keyword>public</span> <span class=class><span class=keyword>class</span> <span class=title>UserDTO</span> </span>{</span><br><span class=line>    <span class=meta>@NotBlank(message = "用户名不能为空")</span> <span class=comment>// 格式校验</span></span><br><span class=line>    <span class=keyword>private</span> String username;</span><br><span class=line>}</span><br><span class=line></span><br><span class=line><span class=comment>// 2. Service 层：管业务逻辑</span></span><br><span class=line><span class=meta>@Service</span></span><br><span class=line><span class=keyword>public</span> <span class=class><span class=keyword>class</span> <span class=title>UserService</span> </span>{</span><br><span class=line>    <span class=function><span class=keyword>public</span> <span class=keyword>void</span> <span class=title>register</span><span class=params>(UserDTO dto)</span> </span>{</span><br><span class=line>        <span class=comment>// 业务校验：放在外面</span></span><br><span class=line>        <span class=keyword>if</span> (userRepository.existsByUsername(dto.getUsername())) {</span><br><span class=line>            <span class=keyword>throw</span> <span class=keyword>new</span> BusinessException(<span class=string>"用户名已占用"</span>);</span><br><span class=line>        }</span><br><span class=line>        <span class=comment>// 执行注册...</span></span><br><span class=line>    }</span><br><span class=line>}</span><br></pre></table></figure><link href=/css/spoiler.css rel=stylesheet><script async src=/js/spoiler.js></script></div><div><div><div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div class=reward-container><div>感谢阅读.</div><button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">打赏</button><div style="display: none;" id=qr><div style="display: inline-block;"><img alt="Sekyoro 微信支付" src=/images/wechatpay.png><p>微信支付</div></div></div><div><ul class=post-copyright><li class=post-copyright-author><strong>本文作者： </strong>Sekyoro<li class=post-copyright-link><strong>本文链接：</strong> <a href=https://www.sekyoro.top/2025/12/30/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0/ title=凤凰架构学习>https://www.sekyoro.top/2025/12/30/凤凰架构学习/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ rel=noopener target=_blank><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</ul></div><div class=followme><p>欢迎关注我的其它发布渠道<div class=social-list><div class=social-item><a class=social-link href=/images/wxqrcode.png target=_blank> <span class=icon> <i class="fab fa-weixin"></i> </span> <span class=label>WeChat</span> </a></div><div class=social-item><a class=social-link href=/images/website.png target=_blank> <span class=icon> <i class="fa fa-user"></i> </span> <span class=label>PersonalWebsite</span> </a></div><div class=social-item><a class=social-link href=https://my-astro-git-main-drowning-in-codes.vercel.app target=_blank> <span class=icon> <i class="fas fa-share"></i> </span> <span class=label>杂鱼分享</span> </a></div><div class=social-item><a class=social-link href=/atom.xml target=_blank> <span class=icon> <i class="fa fa-rss"></i> </span> <span class=label>RSS</span> </a></div></div></div><footer class=post-footer><div class=post-nav><div class=post-nav-item><a href=/2025/12/30/%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97/ rel=prev title=博客网站构建指南> <i class="fa fa-chevron-left"></i> 博客网站构建指南 </a></div><div class=post-nav-item><a href=/2025/12/31/%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/ rel=next title=资源调度与项目管理平台> 资源调度与项目管理平台 <i class="fa fa-chevron-right"></i> </a></div></div></footer></article></div><!-- 评论区 --><div class=comments><div data-id=city data-uid=MTAyMC81MzE5Ny8yOTY3Mg== id=lv-container></div></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class=sidebar><div class=sidebar-inner><!-- canvas粒子时钟 --><div><canvas id=canvas style=width:60%;>当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();</script><!-- require APlayer --><link href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><!-- require MetingJS --><script src=/js/meting-js.js></script><ul class="sidebar-nav motion-element"><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#%E6%97%A9%E6%9C%9F%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%8E%A2%E7%B4%A2><span class=nav-number>1.</span> <span class=nav-text>早期的分布式探索</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%8D%95%E4%BD%93%E7%B3%BB%E7%BB%9F><span class=nav-number>2.</span> <span class=nav-text>单体系统</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E9%9D%A2%E5%90%91%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84SOA><span class=nav-number>3.</span> <span class=nav-text>面向服务架构SOA</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E7%83%9F%E5%9B%B1%E5%BC%8F%E6%9E%B6%E6%9E%84><span class=nav-number>3.1.</span> <span class=nav-text>烟囱式架构</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%BE%AE%E5%86%85%E6%A0%B8%E6%9E%B6%E6%9E%84><span class=nav-number>3.2.</span> <span class=nav-text>微内核架构</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E6%9E%B6%E6%9E%84><span class=nav-number>3.3.</span> <span class=nav-text>事件驱动架构</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%97%B6%E4%BB%A3><span class=nav-number>4.</span> <span class=nav-text>微服务时代</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%90%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%97%B6%E4%BB%A3><span class=nav-number>5.</span> <span class=nav-text>后微服务时代</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC><span class=nav-number>5.0.1.</span> <span class=nav-text>服务网格</span></a></ol></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E6%97%A0%E6%9C%8D%E5%8A%A1%E6%97%B6%E4%BB%A3Serverless><span class=nav-number>6.</span> <span class=nav-text>无服务时代Serverless</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8><span class=nav-number>7.</span> <span class=nav-text>远程服务调用</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1><span class=nav-number>7.1.</span> <span class=nav-text>进程间通信</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#Beyond-IPC-%E9%80%9A%E4%BF%A1%E7%9A%84%E6%88%90%E6%9C%AC><span class=nav-number>7.1.1.</span> <span class=nav-text>Beyond IPC 通信的成本</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#REST%E4%B8%8ERPC><span class=nav-number>7.2.</span> <span class=nav-text>REST与RPC</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3REST><span class=nav-number>7.2.1.</span> <span class=nav-text>如何理解REST</span></a></ol></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86><span class=nav-number>8.</span> <span class=nav-text>事务处理</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1><span class=nav-number>8.1.</span> <span class=nav-text>本地事务</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8E%9F%E5%AD%90%E6%80%A7%E5%92%8C%E6%8C%81%E4%B9%85%E6%80%A7><span class=nav-number>8.1.1.</span> <span class=nav-text>如何实现原子性和持久性</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%AE%9E%E7%8E%B0%E9%9A%94%E7%A6%BB%E6%80%A7><span class=nav-number>8.1.2.</span> <span class=nav-text>实现隔离性</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%85%A8%E5%B1%80%E4%BA%8B%E5%8A%A1><span class=nav-number>8.2.</span> <span class=nav-text>全局事务</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%85%B1%E4%BA%AB%E4%BA%8B%E5%8A%A1><span class=nav-number>8.3.</span> <span class=nav-text>共享事务</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1><span class=nav-number>8.4.</span> <span class=nav-text>分布式事务</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#CAP%E7%90%86%E8%AE%BA%E4%B8%8EACID><span class=nav-number>8.5.</span> <span class=nav-text>CAP理论与ACID</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%8F%AF%E9%9D%A0%E4%BA%8B%E5%8A%A1%E9%98%9F%E5%88%97><span class=nav-number>8.5.1.</span> <span class=nav-text>可靠事务队列</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#TCC%E4%BA%8B%E5%8A%A1><span class=nav-number>8.5.2.</span> <span class=nav-text>TCC事务</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#SAGA%E4%BA%8B%E5%8A%A1><span class=nav-number>8.5.3.</span> <span class=nav-text>SAGA事务</span></a></ol></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E9%80%8F%E6%98%8E%E5%A4%9A%E7%BA%A7%E5%88%86%E6%B5%81%E7%B3%BB%E7%BB%9F><span class=nav-number>9.</span> <span class=nav-text>透明多级分流系统</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BC%93%E5%AD%98><span class=nav-number>9.1.</span> <span class=nav-text>客户端缓存</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%BC%BA%E5%88%B6%E7%BC%93%E5%AD%98><span class=nav-number>9.1.1.</span> <span class=nav-text>强制缓存</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%8D%8F%E5%95%86%E7%BC%93%E5%AD%98><span class=nav-number>9.1.2.</span> <span class=nav-text>协商缓存</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90><span class=nav-number>9.2.</span> <span class=nav-text>域名解析</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%BC%A0%E8%BE%93%E9%93%BE%E8%B7%AF><span class=nav-number>9.3.</span> <span class=nav-text>传输链路</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E8%BF%9E%E6%8E%A5%E6%95%B0%E4%BC%98%E5%8C%96><span class=nav-number>9.3.1.</span> <span class=nav-text>连接数优化</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E4%BC%A0%E8%BE%93%E5%8E%8B%E7%BC%A9><span class=nav-number>9.3.2.</span> <span class=nav-text>传输压缩</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%BF%AB%E9%80%9FUDP%E8%BF%9E%E6%8E%A5><span class=nav-number>9.3.3.</span> <span class=nav-text>快速UDP连接</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C><span class=nav-number>9.4.</span> <span class=nav-text>内容分发网络</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E8%B7%AF%E7%94%B1%E8%A7%A3%E6%9E%90><span class=nav-number>9.4.1.</span> <span class=nav-text>路由解析</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91><span class=nav-number>9.4.2.</span> <span class=nav-text>内容分发</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1><span class=nav-number>9.5.</span> <span class=nav-text>负载均衡</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1><span class=nav-number>9.5.1.</span> <span class=nav-text>数据链路层的负载均衡</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E7%BD%91%E7%BB%9C%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1><span class=nav-number>9.5.2.</span> <span class=nav-text>网络层负载均衡</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%BA%94%E7%94%A8%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1><span class=nav-number>9.5.3.</span> <span class=nav-text>应用层负载均衡</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E5%AE%9E%E7%8E%B0><span class=nav-number>9.5.4.</span> <span class=nav-text>均衡策略实现</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%93%E5%AD%98><span class=nav-number>9.6.</span> <span class=nav-text>服务端缓存</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E5%B1%9E%E6%80%A7><span class=nav-number>9.6.1.</span> <span class=nav-text>缓存属性</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98><span class=nav-number>9.6.2.</span> <span class=nav-text>分布式缓存</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E9%A3%8E%E9%99%A9><span class=nav-number>9.6.3.</span> <span class=nav-text>缓存风险</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93><span class=nav-number>9.7.</span> <span class=nav-text>缓存污染</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%9E%B6%E6%9E%84%E5%AE%89%E5%85%A8%E6%80%A7><span class=nav-number>9.8.</span> <span class=nav-text>架构安全性</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E8%AE%A4%E8%AF%81><span class=nav-number>9.8.1.</span> <span class=nav-text>认证</span></a><ol class=nav-child><li class="nav-item nav-level-5"><a class=nav-link href=#HTTP%E8%AE%A4%E8%AF%81><span class=nav-number>9.8.1.1.</span> <span class=nav-text>HTTP认证</span></a><li class="nav-item nav-level-5"><a class=nav-link href=#Web%E8%AE%A4%E8%AF%81><span class=nav-number>9.8.1.2.</span> <span class=nav-text>Web认证</span></a></ol><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%8E%88%E6%9D%83><span class=nav-number>9.8.2.</span> <span class=nav-text>授权</span></a><ol class=nav-child><li class="nav-item nav-level-5"><a class=nav-link href=#RBAC><span class=nav-number>9.8.2.1.</span> <span class=nav-text>RBAC</span></a><li class="nav-item nav-level-5"><a class=nav-link href=#OAuth2><span class=nav-number>9.8.2.2.</span> <span class=nav-text>OAuth2</span></a></ol><li class="nav-item nav-level-4"><a class=nav-link href=#%E5%87%AD%E8%AF%81><span class=nav-number>9.8.3.</span> <span class=nav-text>凭证</span></a><ol class=nav-child><li class="nav-item nav-level-5"><a class=nav-link href=#Cookie-Session><span class=nav-number>9.8.3.1.</span> <span class=nav-text>Cookie-Session</span></a><li class="nav-item nav-level-5"><a class=nav-link href=#JWT%E4%BB%A4%E7%89%8C><span class=nav-number>9.8.3.2.</span> <span class=nav-text>JWT令牌</span></a></ol><li class="nav-item nav-level-4"><a class=nav-link href=#%E4%BF%9D%E5%AF%86><span class=nav-number>9.8.4.</span> <span class=nav-text>保密</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E4%BC%A0%E8%BE%93><span class=nav-number>9.8.5.</span> <span class=nav-text>传输</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6><span class=nav-number>9.8.6.</span> <span class=nav-text>数字证书</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E4%BC%A0%E8%BE%93%E5%AE%89%E5%85%A8%E5%B1%82><span class=nav-number>9.8.7.</span> <span class=nav-text>传输安全层</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#%E9%AA%8C%E8%AF%81><span class=nav-number>9.9.</span> <span class=nav-text>验证</span></a></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=Sekyoro class=site-author-image itemprop=image src=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg><p class=site-author-name itemprop=name>Sekyoro<div class=site-description itemprop=description>什么也无法舍弃的人，什么也做不了.</div></div><div class="site-state-wrap motion-element"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>263</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>16</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>224</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a title="Personal Website → http://proanimer.com" href=http://proanimer.com/ rel=noopener target=_blank><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a> </span><span class=links-of-author-item> <a title="GitHub → https://github.com/drowning-in-codes" href=https://github.com/drowning-in-codes rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a title="E-Mail → mailto:bukalala174@gmail.com" href=mailto:bukalala174@gmail.com rel=noopener target=_blank><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class=links-of-author-item> <a title="wxPublicAccount → https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" href=https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd rel=noopener target=_blank><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a> </span><span class=links-of-author-item> <a title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span><span class=links-of-author-item> <a title="CSDN → https://blog.csdn.net/aqwca" href=https://blog.csdn.net/aqwca rel=noopener target=_blank><i class="fa fa-handshake fa-fw"></i>CSDN</a> </span><span class=links-of-author-item> <a title="杂鱼分享 → https://my-astro-git-main-drowning-in-codes.vercel.app" href=https://my-astro-git-main-drowning-in-codes.vercel.app/ rel=noopener target=_blank><i class="fas fa-share fa-fw"></i>杂鱼分享</a> </span></div><div class="links-of-blogroll motion-element"><div class=links-of-blogroll-title><i class="fa fa-link fa-fw"></i> 友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=http://myqhs.top/ rel=noopener target=_blank title=http://myqhs.top/>myqhs</a><li class=links-of-blogroll-item><a href=https://www.lllomh.com/ rel=noopener target=_blank title=https://www.lllomh.com/>芈渡</a><li class=links-of-blogroll-item><a href=https://protool-ten.vercel.app/ rel=noopener target=_blank title=https://protool-ten.vercel.app/>protools</a></ul></div><div class="motion-element announcement"><div class=title></div><p class=content><p class=date></div></div><meting-js id=6856787487 order=random server=netease type=playlist> </meting-js><div class=widget-wrap><h3 class=widget-title style=margin:0>此文章目前无词云</h3></div><script id=clustrmaps src=https://clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a></script><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i><span>0%</span></div><!-- 边栏 --></div></aside><div id=sidebar-dimmer></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – <span itemprop=copyrightYear>2026</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Sekyoro</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-chart-area"></i> </span><span title=站点总字数>4.4m</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span><span title=站点阅读时长>66:09</span></div><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container_site_pv>总访问量<span id=busuanzi_value_site_pv></span>次</span><span class=post-meta-divider>|</span><span id=busuanzi_container_site_uv>总访客数<span id=busuanzi_value_site_uv></span>人</span><span class=post-meta-divider>|</span><!-- 不蒜子计数初始值纠正 --><script>document.addEventListener("DOMContentLoaded", function() {
    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {
        var pvContainer = document.getElementById("busuanzi_container_site_pv");
        if (pvContainer && pvContainer.style.display !== "none") {
            var pvElement = document.getElementById("busuanzi_value_site_pv");
            if (pvElement) {
                pvElement.innerHTML = parseInt(pvElement.innerHTML) + countOffset;
                clearInterval(int);
            }
        }
        
        var uvContainer = document.getElementById("busuanzi_container_site_uv");
        if (uvContainer && window.getComputedStyle(uvContainer).display !== "none")
        {
            var uvElement = document.getElementById("busuanzi_value_site_uv");
            if (uvElement) {
                uvElement.innerHTML = parseInt(uvElement.innerHTML) + countOffset; // 加上初始数据 
                clearInterval(int); // 停止检测
            }
        }
    }
});</script><div><span id=timeDate>载入天数...</span><span id=times>载入时分秒...</span><script>var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);</script></div><div class=busuanzi-count><script async data-pjax src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span style="display: none;" class=post-meta-item id=busuanzi_container_site_uv> <span class=post-meta-item-icon> <i class="fa fa-user"></i> </span> <span class=site-uv title=总访客量> <span id=busuanzi_value_site_uv></span> </span> </span><span class=post-meta-divider>|</span><span style="display: none;" class=post-meta-item id=busuanzi_container_site_pv> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=site-pv title=总访问量> <span id=busuanzi_value_site_pv></span> </span> </span></div></div></footer></div><script color=0,0,255 count=99 opacity=0.5 src=/lib/canvas-nest/canvas-nest.min.js zindex=-1></script><script src=/lib/anime.min.js></script><script src=https://cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js></script><script src=https://cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/schemes/pisces.js></script><script src=/js/next-boot.js></script><script src=/js/bookmark.js></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	 '.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
  
  // Reinitialize TagCanvas for tag cloud
  if (typeof TagCanvas !== 'undefined' && document.getElementById('resCanvas')) {
    try {
      TagCanvas.textFont = 'Trebuchet MS, Helvetica';
      TagCanvas.textColour = '#333';
      TagCanvas.textHeight = 20;
      TagCanvas.outlineColour = '#E2E1D1';
      TagCanvas.maxSpeed = 0.3;
      TagCanvas.freezeActive = true;
      TagCanvas.outlineMethod = 'block';
      TagCanvas.minBrightness = 0.2;
      TagCanvas.depth = 0.92;
      TagCanvas.pulsateTo = 0.6;
      TagCanvas.initial = [0.1,-0.1];
      TagCanvas.decel = 0.98;
      TagCanvas.reverse = true;
      TagCanvas.hideTags = false;
      TagCanvas.shadow = '#ccf';
      TagCanvas.shadowBlur = 3;
      TagCanvas.weight = false;
      TagCanvas.imageScale = null;
      TagCanvas.fadeIn = 1000;
      TagCanvas.clickToFront = 600;
      TagCanvas.lock = false;
      TagCanvas.Start('resCanvas');
      TagCanvas.tc['resCanvas'].Wheel(true);
    } catch(e) {
      console.log('TagCanvas initialization failed:', e);
    }
  }
});</script><script data-pjax>(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();</script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js></script><script src=/js/algolia-search.js></script><script data-pjax>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><div id=pjax><script charset=utf-8 defer src=/js/outdate.js></script></div><script charset=utf-8 defer src=/js/tagcanvas.js></script><script charset=utf-8 defer src=/js/tagcloud.js></script><script>NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});</script><script>var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });</script><script src=/js/src/activate-power-mode.min.js></script><script>POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);</script>