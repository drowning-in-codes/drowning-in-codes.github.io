<!doctypehtml><html lang=zh-CN><script defer src=/live2d-widget/autoload.js></script><meta charset=UTF-8><meta content=width=device-width,initial-scale=1,maximum-scale=2 name=viewport><meta content=#222 name=theme-color><meta content="Hexo 5.4.0" name=generator><link href=/images/blog_32px.png rel=apple-touch-icon sizes=180x180><link href=/images/blog_32px.png rel=icon sizes=32x32 type=image/png><link href=/images/blog_16px.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><meta content=EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w name=google-site-verification><!-- Google tag (gtag.js) --><!-- 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script> --><!-- google adsense in head.swig --><script async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123></script><meta content=7226864CE87CE9DE8C008385273846FF name=msvalidate.01><meta content=code-fjFXVtiL7j name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link as=style href=https://fonts.googleapis.com/css?family=Roboto%20Mono,Roboto:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext onload=this.rel='stylesheet' rel=preload><link as=style href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css onload=this.rel='stylesheet' rel=preload><link href=https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap rel=stylesheet><link href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/pace-js@1/pace.min.js></script><script id=hexo-configurations>var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"3G9PZZIKCH","apiKey":"8eb71f5ca3167e9ef3487882f10cfaad","indexName":"SekyoroSearch","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};</script><link href=//cdn.bootcss.com/animate.css/3.5.0/animate.min.css rel=stylesheet><meta content=代码还是很重要的,虽然发现有些代码库不怎么样. name=description><meta content=article property=og:type><meta content=协同融合代码学习 property=og:title><meta content=https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/index.html property=og:url><meta content=Sekyoro的博客小屋 property=og:site_name><meta content=代码还是很重要的,虽然发现有些代码库不怎么样. property=og:description><meta content=zh_CN property=og:locale><meta content=https://github.com/coperception/where2comm/raw/gh-pages/static/images/Intro.png property=og:image><meta content=https://s2.loli.net/2024/02/13/LK8F15wDS6jdkPJ.png property=og:image><meta content=https://s2.loli.net/2024/02/27/CQuUxlwvFV7ceB5.png property=og:image><meta content=https://s2.loli.net/2024/02/29/muRMCOTiKLwl6X9.png property=og:image><meta content=https://s2.loli.net/2024/02/29/ZheUYj6bvl9T7XP.png property=og:image><meta content=https://s2.loli.net/2024/02/29/COiPgxUSrsYvqQL.png property=og:image><meta content=https://s2.loli.net/2024/02/28/5jYTmRyw2iIEQeb.png property=og:image><meta content=https://s2.loli.net/2024/02/28/Cj1SE42UmL9IWYR.png property=og:image><meta content=https://s2.loli.net/2024/02/28/Jr9OnUyvfEkcxtD.png property=og:image><meta content=https://s2.loli.net/2024/02/28/WFc8MJjfDOny1Zt.png property=og:image><meta content=https://s2.loli.net/2024/03/04/4Qqgwk9uGciJBYj.png property=og:image><meta content=https://s2.loli.net/2024/03/04/4zjauARgEMekoSt.png property=og:image><meta content=https://s2.loli.net/2024/02/29/RANi2pLbKPZslu5.png property=og:image><meta content=https://s2.loli.net/2024/02/29/RP1nMsk5h2B4pzj.png property=og:image><meta content=https://s2.loli.net/2024/02/29/a5NIGnJloEwK4Hp.png property=og:image><meta content=https://github.com/jmgu0212/FeaCo/raw/main/images/Overview.png property=og:image><meta content=https://proanimer-img.oss-cn-shanghai.aliyuncs.com/alimg/image-20240401134935564.png property=og:image><meta content=2024-01-31T11:15:43.000Z property=article:published_time><meta content=2024-04-14T14:25:16.980Z property=article:modified_time><meta content=Sekyoro property=article:author><meta content="个人博客 技术学习 计算机 互联网 人工智能" property=article:tag><meta content=summary name=twitter:card><meta content=https://github.com/coperception/where2comm/raw/gh-pages/static/images/Intro.png name=twitter:image><link href=https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/ rel=canonical><script id=page-configurations>// https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };</script><title>协同融合代码学习 | Sekyoro的博客小屋</title><noscript><style>.use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }</style></noscript><link href=/atom.xml rel=alternate title=Sekyoro的博客小屋 type=application/atom+xml><body itemscope itemtype=http://schema.org/WebPage><canvas style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" class=fireworks></canvas><script defer src=https://cdn.bootcss.com/animejs/2.2.0/anime.min.js></script><script defer src=/js/src/fireworks.js></script><div class="container use-motion"><div class=headband></div><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <h1 class=site-title>Sekyoro的博客小屋</h1> <span class=logo-line-after><i></i></span> </a></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu" id=menu><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-bangumis"><a href=/bangumis/ rel=section><i class="fa fa-film fa-fw"></i>追番</a><li class="menu-item menu-item-resume"><a href=/resume/ rel=section><i class="fa fa-file-pdf fa-fw"></i>简历</a><li class="menu-item menu-item-materials"><a href=/materials/ rel=section><i class="fa fa-book fa-fw"></i>学习资料</a><li class="menu-item menu-item-sitemap"><a href=/sitemap.xml rel=section><i class="fa fa-sitemap fa-fw"></i>站点地图</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container></div><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span></div><div class=algolia-results><div id=algolia-stats></div><div id=algolia-hits></div><div class=algolia-pagination id=algolia-pagination></div></div></div></div></div></header><a class="book-mark-link book-mark-link-fixed" role=button></a><main class=main><div class=main-inner><div class=content-wrap><div class="content post posts-expand"><article class=post-block itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg itemprop=image> <meta content=Sekyoro itemprop=name> <meta content=什么也无法舍弃的人，什么也做不了. itemprop=description> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=Sekyoro的博客小屋 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>协同融合代码学习</h1><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2024-01-31 19:15:43" datetime=2024-01-31T19:15:43+08:00>2024-01-31</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2024-04-14 22:25:16" datetime=2024-04-14T22:25:16+08:00 itemprop=dateModified>2024-04-14</time> </span><span style="display: none;" class=post-meta-item id=busuanzi_container_page_pv title=阅读次数> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=post-meta-item-text>阅读次数：</span> <span id=busuanzi_value_page_pv></span> </span><br><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>41k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>38 分钟</span> </span></div></header><div class=post-body itemprop=articleBody><p>代码还是很重要的,虽然发现有些代码库不怎么样.<br><span id=more></span><p>目前协同感知算法主要就是利用注意力机制和图神经网络,利用backbone(包括voxelNet,Point Pillar等网络)处理后的特征进行融合,具体的codebase我找到三个(此外还有很多基于OpenCOOD的多模态、关注其他问题的代码,这里就放一些基础的).<ul><li>一个是<a href=https://github.com/coperception/where2comm?tab=readme-ov-file rel=noopener target=_blank>coperception/where2comm: [NeurIPS 2022] Where2comm (github.com)</a>,<li>还有<a href=https://github.com/GT-RIPL/MultiAgentPerception rel=noopener target=_blank>GT-RIPL/MultiAgentPerception: Official source code to CVPR’20 paper, “When2com: Multi-Agent Perception via Communication Graph Grouping” (github.com)</a>.<li>另一个是<a href=https://github.com/DerrickXuNu/OpenCOOD rel=noopener target=_blank>DerrickXuNu/OpenCOOD: [ICRA 2022] An opensource framework for cooperative detection. Official implementation for OPV2V. (github.com)</a>.可以说包含许多20年到现在的经典车辆协同感知的算法代码了,此外还有一些零散的算法代码,这里咱就细细把玩一下.</ul><h2 id=Coperceptions><a class=headerlink href=#Coperceptions title=Coperceptions></a>Coperceptions</h2><p>包括where2comm,v2vnet,disconet,v2x-vit以及when2comm的代码.<p><img alt=Where2comm data-src=https://github.com/coperception/where2comm/raw/gh-pages/static/images/Intro.png><p>本身有mean,max,cat以及agent的融合方式.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>MeanFusion</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_channels, n_classes, num_agent=<span class=number>5</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=keyword>return</span> torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class=number>0</span>)</span><br></pre></table></figure><p>继承自FusionBase,而<code>FusionBase</code>又继承自<code>SegModelBase</code>,后者实现了一系列模型.在<code>FusionBase</code>中,首先对特征进行下采样,然后转换除了ego agent的特征,然后进行融合,最后再上采样.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br><span class=line>84</span><br></pre><td class=code><pre><span class=line><span class=keyword>from</span> coperception.models.seg.SegModelBase <span class=keyword>import</span> SegModelBase</span><br><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.nn.functional <span class=keyword>as</span> F</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>FusionBase</span>(<span class=params>SegModelBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params></span></span></span><br><span class=line><span class=params><span class=function>        self, n_channels, n_classes, num_agent=<span class=number>5</span>, kd_flag=<span class=literal>False</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span></span></span><br><span class=line><span class=params><span class=function>    </span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line>        self.neighbor_feat_list = <span class=literal>None</span></span><br><span class=line>        self.tg_agent = <span class=literal>None</span></span><br><span class=line>        self.current_num_agent = <span class=literal>None</span></span><br><span class=line>        self.kd_flag = kd_flag</span><br><span class=line>        self.only_v2i = only_v2i</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=keyword>raise</span> NotImplementedError(</span><br><span class=line>            <span class=string>"Please implement this method for specific fusion strategies"</span></span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, trans_matrices, num_agent_tensor</span>):</span></span><br><span class=line>        x1 = self.inc(x)</span><br><span class=line>        x2 = self.down1(x1)</span><br><span class=line>        x3 = self.down2(x2)</span><br><span class=line>        x4 = self.down3(x3)  <span class=comment># b 512 32 32</span></span><br><span class=line>        size = (<span class=number>1</span>, <span class=number>512</span>, <span class=number>32</span>, <span class=number>32</span>)</span><br><span class=line></span><br><span class=line>        <span class=keyword>if</span> self.compress_level > <span class=number>0</span>:</span><br><span class=line>            x4 = F.relu(self.bn_compress(self.com_compresser(x4)))</span><br><span class=line>            x4 = F.relu(self.bn_decompress(self.com_decompresser(x4)))</span><br><span class=line></span><br><span class=line>        batch_size = x.size(<span class=number>0</span>) // self.num_agent</span><br><span class=line>        feat_list = <span class=built_in>super</span>().build_feat_list(x4, batch_size)</span><br><span class=line></span><br><span class=line>        local_com_mat = torch.cat(<span class=built_in>tuple</span>(feat_list), <span class=number>1</span>)</span><br><span class=line>        local_com_mat_update = torch.cat(<span class=built_in>tuple</span>(feat_list), <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        <span class=keyword>for</span> b <span class=keyword>in</span> <span class=built_in>range</span>(batch_size):</span><br><span class=line>            self.com_num_agent = num_agent_tensor[b, <span class=number>0</span>]</span><br><span class=line></span><br><span class=line>            agent_feat_list = <span class=built_in>list</span>()</span><br><span class=line>            <span class=keyword>for</span> nb <span class=keyword>in</span> <span class=built_in>range</span>(self.com_num_agent):</span><br><span class=line>                agent_feat_list.append(local_com_mat[b, nb])</span><br><span class=line></span><br><span class=line>            <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(self.com_num_agent):</span><br><span class=line>                self.tg_agent = local_com_mat[b, i]</span><br><span class=line></span><br><span class=line>                self.neighbor_feat_list = <span class=built_in>list</span>()</span><br><span class=line>                self.neighbor_feat_list.append(self.tg_agent)</span><br><span class=line></span><br><span class=line>                <span class=keyword>for</span> j <span class=keyword>in</span> <span class=built_in>range</span>(self.com_num_agent):</span><br><span class=line>                    <span class=keyword>if</span> j != i:</span><br><span class=line>                        <span class=keyword>if</span> self.only_v2i <span class=keyword>and</span> i != <span class=number>0</span> <span class=keyword>and</span> j != <span class=number>0</span>:</span><br><span class=line>                            <span class=keyword>continue</span></span><br><span class=line></span><br><span class=line>                        self.neighbor_feat_list.append(</span><br><span class=line>                            <span class=built_in>super</span>().feature_transformation(</span><br><span class=line>                                b,</span><br><span class=line>                                j,</span><br><span class=line>                                i,</span><br><span class=line>                                local_com_mat,</span><br><span class=line>                                size,</span><br><span class=line>                                trans_matrices,</span><br><span class=line>                            )</span><br><span class=line>                        )</span><br><span class=line></span><br><span class=line>                local_com_mat_update[b, i] = self.fusion()</span><br><span class=line></span><br><span class=line>        feat_mat = <span class=built_in>super</span>().agents_to_batch(local_com_mat_update)</span><br><span class=line></span><br><span class=line>        x5 = self.down4(feat_mat)</span><br><span class=line>        x6 = self.up1(x5, feat_mat)</span><br><span class=line>        x7 = self.up2(x6, x3)</span><br><span class=line>        x8 = self.up3(x7, x2)</span><br><span class=line>        x9 = self.up4(x8, x1)</span><br><span class=line>        logits = self.outc(x9)</span><br><span class=line></span><br><span class=line>        <span class=keyword>if</span> self.kd_flag:</span><br><span class=line>            <span class=keyword>return</span> logits, x9, x8, x7, x6, x5, feat_mat</span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            <span class=keyword>return</span> logits</span><br></pre></table></figure><p>使用了连续的下采样和上采样,先下采样,然后进行融合再进行上采样.这几种融合方式真是一层套一层,这么多参数效果不变强才怪…<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>SegModelBase</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params></span></span></span><br><span class=line><span class=params><span class=function>        self, n_channels, n_classes, bilinear=<span class=literal>True</span>, num_agent=<span class=number>5</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span></span></span><br><span class=line><span class=params><span class=function>    </span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.n_channels = n_channels</span><br><span class=line>        self.n_classes = n_classes</span><br><span class=line>        self.bilinear = bilinear</span><br><span class=line>        self.num_agent = num_agent</span><br><span class=line>        self.only_v2i = only_v2i</span><br><span class=line></span><br><span class=line>        self.inc = DoubleConv(n_channels, <span class=number>64</span>)</span><br><span class=line>        self.down1 = Down(<span class=number>64</span>, <span class=number>128</span>)</span><br><span class=line>        self.down2 = Down(<span class=number>128</span>, <span class=number>256</span>)</span><br><span class=line>        self.down3 = Down(<span class=number>256</span>, <span class=number>512</span>)</span><br><span class=line>        factor = <span class=number>2</span> <span class=keyword>if</span> bilinear <span class=keyword>else</span> <span class=number>1</span></span><br><span class=line>        self.down4 = Down(<span class=number>512</span>, <span class=number>1024</span> // factor)</span><br><span class=line>        self.up1 = Up(<span class=number>1024</span>, <span class=number>512</span> // factor, bilinear)</span><br><span class=line>        self.up2 = Up(<span class=number>512</span>, <span class=number>256</span> // factor, bilinear)</span><br><span class=line>        self.up3 = Up(<span class=number>256</span>, <span class=number>128</span> // factor, bilinear)</span><br><span class=line>        self.up4 = Up(<span class=number>128</span>, <span class=number>64</span>, bilinear)</span><br><span class=line>        self.outc = OutConv(<span class=number>64</span>, n_classes)</span><br><span class=line></span><br><span class=line>        self.compress_level = compress_level</span><br><span class=line>        <span class=keyword>if</span> compress_level > <span class=number>0</span>:</span><br><span class=line>            <span class=keyword>assert</span> compress_level <= <span class=number>9</span></span><br><span class=line>            feat_map_channel_num = <span class=number>512</span></span><br><span class=line>            compress_channel_num = feat_map_channel_num // (<span class=number>2</span>**compress_level)</span><br><span class=line></span><br><span class=line>            self.com_compresser = nn.Conv2d(</span><br><span class=line>                feat_map_channel_num, compress_channel_num, kernel_size=<span class=number>1</span>, stride=<span class=number>1</span></span><br><span class=line>            )</span><br><span class=line>            self.bn_compress = nn.BatchNorm2d(compress_channel_num)</span><br><span class=line></span><br><span class=line>            self.com_decompresser = nn.Conv2d(</span><br><span class=line>                compress_channel_num, feat_map_channel_num, kernel_size=<span class=number>1</span>, stride=<span class=number>1</span></span><br><span class=line>            )</span><br><span class=line>            self.bn_decompress = nn.BatchNorm2d(feat_map_channel_num)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>build_feat_list</span>(<span class=params>self, feat_maps, batch_size</span>):</span></span><br><span class=line>        feat_maps = torch.flip(feat_maps, (<span class=number>2</span>,))</span><br><span class=line></span><br><span class=line>        tmp_feat_map = {}</span><br><span class=line>        feat_list = []</span><br><span class=line>        <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(self.num_agent):</span><br><span class=line>            tmp_feat_map[i] = torch.unsqueeze(</span><br><span class=line>                feat_maps[batch_size * i : batch_size * (i + <span class=number>1</span>)], <span class=number>1</span></span><br><span class=line>            )</span><br><span class=line>            feat_list.append(tmp_feat_map[i])</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> feat_list</span><br><span class=line></span><br><span class=line><span class=meta>    @staticmethod</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>feature_transformation</span>(<span class=params>b, j, agent_idx, local_com_mat, size, trans_matrices</span>):</span></span><br><span class=line>        device = torch.device(<span class=string>'cuda'</span> <span class=keyword>if</span> torch.cuda.is_available() <span class=keyword>else</span> <span class=string>'cpu'</span>)</span><br><span class=line>        nb_agent = torch.unsqueeze(local_com_mat[b, j], <span class=number>0</span>)</span><br><span class=line></span><br><span class=line>        tfm_ji = trans_matrices[b, j, agent_idx]</span><br><span class=line>        M = (</span><br><span class=line>            torch.hstack((tfm_ji[:<span class=number>2</span>, :<span class=number>2</span>], -tfm_ji[:<span class=number>2</span>, <span class=number>3</span>:<span class=number>4</span>])).<span class=built_in>float</span>().unsqueeze(<span class=number>0</span>)</span><br><span class=line>        )  <span class=comment># [1,2,3]</span></span><br><span class=line>        M = M.to(device)</span><br><span class=line></span><br><span class=line>        mask = torch.tensor([[[<span class=number>1</span>, <span class=number>1</span>, <span class=number>4</span> / <span class=number>128</span>], [<span class=number>1</span>, <span class=number>1</span>, <span class=number>4</span> / <span class=number>128</span>]]], device=M.device)</span><br><span class=line></span><br><span class=line>        M *= mask</span><br><span class=line></span><br><span class=line>        grid = F.affine_grid(M, size=torch.Size(size))</span><br><span class=line>        warp_feat = F.grid_sample(nb_agent, grid).squeeze()</span><br><span class=line>        <span class=keyword>return</span> warp_feat</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>agents_to_batch</span>(<span class=params>self, feats</span>):</span></span><br><span class=line>        feat_list = []</span><br><span class=line>        <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(self.num_agent):</span><br><span class=line>            feat_list.append(feats[:, i, :, :, :])</span><br><span class=line>        feat_mat = torch.cat(feat_list, <span class=number>0</span>)</span><br><span class=line></span><br><span class=line>        feat_mat = torch.flip(feat_mat, (<span class=number>2</span>,))</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> feat_mat</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>DoubleConv</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_channels, out_channels, mid_channels=<span class=literal>None</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        <span class=keyword>if</span> <span class=keyword>not</span> mid_channels:</span><br><span class=line>            mid_channels = out_channels</span><br><span class=line>        self.double_conv = nn.Sequential(</span><br><span class=line>            nn.Conv2d(in_channels, mid_channels, kernel_size=<span class=number>3</span>, padding=<span class=number>1</span>),</span><br><span class=line>            nn.BatchNorm2d(mid_channels),</span><br><span class=line>            nn.ReLU(inplace=<span class=literal>True</span>),</span><br><span class=line>            nn.Conv2d(mid_channels, out_channels, kernel_size=<span class=number>3</span>, padding=<span class=number>1</span>),</span><br><span class=line>            nn.BatchNorm2d(out_channels),</span><br><span class=line>            nn.ReLU(inplace=<span class=literal>True</span>),</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=keyword>return</span> self.double_conv(x)</span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>Down</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_channels, out_channels</span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.maxpool_conv = nn.Sequential(</span><br><span class=line>            nn.MaxPool2d(<span class=number>2</span>),</span><br><span class=line>            DoubleConv(in_channels, out_channels),</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=keyword>return</span> self.maxpool_conv(x)</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>Up</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_channels, out_channels, bilinear=<span class=literal>True</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        <span class=keyword>if</span> bilinear:</span><br><span class=line>            self.up = nn.Upsample(scale_factor=<span class=number>2</span>, mode=<span class=string>"bilinear"</span>, align_corners=<span class=literal>True</span>)</span><br><span class=line>            self.conv = DoubleConv(in_channels, out_channels, in_channels // <span class=number>2</span>)</span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            self.up = nn.ConvTranspose2d(</span><br><span class=line>                in_channels, in_channels // <span class=number>2</span>, kernel_size=<span class=number>2</span>, stride=<span class=number>2</span></span><br><span class=line>            )</span><br><span class=line>            self.conv = DoubleConv(in_channels, out_channels)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x1, x2</span>):</span></span><br><span class=line>        x1 = self.up(x1)</span><br><span class=line>        diff_y = x2.size()[<span class=number>2</span>] - x1.size()[<span class=number>2</span>]</span><br><span class=line>        diff_x = x2.size()[<span class=number>3</span>] - x1.size()[<span class=number>3</span>]</span><br><span class=line></span><br><span class=line>        x1 = F.pad(</span><br><span class=line>            x1, [diff_x // <span class=number>2</span>, diff_x - diff_x // <span class=number>2</span>, diff_y // <span class=number>2</span>, diff_y - diff_y // <span class=number>2</span>]</span><br><span class=line>        )</span><br><span class=line>        x = torch.cat([x2, x1], dim=<span class=number>1</span>)</span><br><span class=line>        <span class=keyword>return</span> self.conv(x)</span><br></pre></table></figure><p>mean,max和sum不用多说,<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> torch</span><br><span class=line></span><br><span class=line><span class=keyword>from</span> coperception.models.seg.FusionBase <span class=keyword>import</span> FusionBase</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>SumFusion</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_channels, n_classes, num_agent=<span class=number>5</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=keyword>return</span> torch.<span class=built_in>sum</span>(torch.stack(self.neighbor_feat_list), dim=<span class=number>0</span>)</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>MeanFusion</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_channels, n_classes, num_agent=<span class=number>5</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=keyword>return</span> torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class=number>0</span>)</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>MaxFusion</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_channels, n_classes, num_agent=<span class=number>5</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=keyword>return</span> torch.<span class=built_in>max</span>(torch.stack(self.neighbor_feat_list), dim=<span class=number>0</span>).values</span><br><span class=line></span><br></pre></table></figure><p>catFusion将其他特征做个mean然后与自己的特征连接起来.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>CatFusion</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_channels, n_classes, num_agent, compress_level, only_v2i</span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line>        self.modulation_layer_3 = ModulationLayer3()</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        mean_feat = torch.mean(torch.stack(self.neighbor_feat_list), dim=<span class=number>0</span>)  <span class=comment># [c, h, w]</span></span><br><span class=line>        cat_feat = torch.cat([self.tg_agent, mean_feat], dim=<span class=number>0</span>)</span><br><span class=line>        cat_feat = cat_feat.unsqueeze(<span class=number>0</span>)  <span class=comment># [1, 1, c, h, w]</span></span><br><span class=line>        <span class=keyword>return</span> self.modulation_layer_3(cat_feat)</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=comment># <span class=doctag>FIXME:</span> Change size</span></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>ModulationLayer3</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(ModulationLayer3, self).__init__()</span><br><span class=line></span><br><span class=line>        self.conv1_1 = nn.Conv2d(<span class=number>1024</span>, <span class=number>512</span>, kernel_size=<span class=number>1</span>, stride=<span class=number>1</span>, padding=<span class=number>0</span>)</span><br><span class=line>        self.bn1_1 = nn.BatchNorm2d(<span class=number>512</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        x = x.view(-<span class=number>1</span>, x.size(-<span class=number>3</span>), x.size(-<span class=number>2</span>), x.size(-<span class=number>1</span>))</span><br><span class=line>        x_1 = F.relu(self.bn1_1(self.conv1_1(x)))</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> x_1</span><br></pre></table></figure><p>此外还有个<code>AgentWiseWeightedFusion</code>,每个ego_agent单独和每个其他特征cat在一起再通过,然后计算一个融合特征,再计算一个softmax作为特征的权重.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>AgentWiseWeightedFusion</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_channels, n_classes, num_agent=<span class=number>5</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels, n_classes, num_agent=num_agent, compress_level=compress_level, only_v2i=only_v2i</span><br><span class=line>        )</span><br><span class=line>        self.agent_weighted_fusion = AgentWeightedFusion()</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        agent_weight_list = <span class=built_in>list</span>()</span><br><span class=line>        <span class=keyword>for</span> k <span class=keyword>in</span> <span class=built_in>range</span>(self.com_num_agent):</span><br><span class=line>            cat_feat = torch.cat([self.tg_agent, self.neighbor_feat_list[k]], dim=<span class=number>0</span>)</span><br><span class=line>            cat_feat = cat_feat.unsqueeze(<span class=number>0</span>)</span><br><span class=line>            agent_weight = self.agent_weighted_fusion(cat_feat)</span><br><span class=line>            agent_weight_list.append(agent_weight)</span><br><span class=line></span><br><span class=line>        soft_agent_weight_list = torch.squeeze(</span><br><span class=line>            F.softmax(torch.tensor(agent_weight_list).unsqueeze(<span class=number>0</span>), dim=<span class=number>1</span>)</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>        agent_wise_weight_feat = <span class=number>0</span></span><br><span class=line>        <span class=keyword>for</span> k <span class=keyword>in</span> <span class=built_in>range</span>(self.com_num_agent):</span><br><span class=line>            agent_wise_weight_feat = (</span><br><span class=line>                agent_wise_weight_feat</span><br><span class=line>                + soft_agent_weight_list[k] * self.neighbor_feat_list[k]</span><br><span class=line>            )</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> agent_wise_weight_feat</span><br></pre></table></figure><p>discoNet特别之处就在于使用了所谓学生-教师模型进行知识蒸馏,在代码中添加了这个.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line>parser.add_argument(</span><br><span class=line>    <span class=string>"--kd_flag"</span>,</span><br><span class=line>    default=<span class=number>0</span>,</span><br><span class=line>    <span class=built_in>type</span>=<span class=built_in>int</span>,</span><br><span class=line>    <span class=built_in>help</span>=<span class=string>"Whether to enable distillation (only DiscNet is 1 )"</span>,</span><br><span class=line>)</span><br><span class=line><span class=comment># 还添加了权重参数,可见权重加得还挺大的.</span></span><br><span class=line>parser.add_argument(<span class=string>"--kd_weight"</span>, default=<span class=number>100000</span>, <span class=built_in>type</span>=<span class=built_in>int</span>, <span class=built_in>help</span>=<span class=string>"KD loss weight"</span>)</span><br></pre></table></figure><p>然后类似<code>AgentWiseWeightedFusion</code>,将ego的特征与通信的单独每辆车的特征cat在一起传入一个网络中,计算得到所有值的幂和.然后再用各自的值乘以和(跟softmax差不多).算按出来权重再乘以对应的特征.最后的值是相加起来<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>DiscoNet</span>(<span class=params>FusionBase</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params></span></span></span><br><span class=line><span class=params><span class=function>        self, n_channels, n_classes, num_agent, kd_flag=<span class=literal>True</span>, compress_level=<span class=number>0</span>, only_v2i=<span class=literal>False</span></span></span></span><br><span class=line><span class=params><span class=function>    </span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(</span><br><span class=line>            n_channels,</span><br><span class=line>            n_classes,</span><br><span class=line>            num_agent,</span><br><span class=line>            kd_flag=kd_flag,</span><br><span class=line>            compress_level=compress_level,</span><br><span class=line>            only_v2i=only_v2i,</span><br><span class=line>        )</span><br><span class=line>        self.pixel_weighted_fusion = PixelWeightedFusionSoftmax(<span class=number>512</span>)</span><br><span class=line> </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>fusion</span>(<span class=params>self</span>):</span></span><br><span class=line>        tmp_agent_weight_list = <span class=built_in>list</span>()</span><br><span class=line>        sum_weight = <span class=number>0</span></span><br><span class=line>        nb_len = <span class=built_in>len</span>(self.neighbor_feat_list)</span><br><span class=line>        <span class=keyword>for</span> k <span class=keyword>in</span> <span class=built_in>range</span>(nb_len):</span><br><span class=line>            cat_feat = torch.cat([self.tg_agent, self.neighbor_feat_list[k]], dim=<span class=number>0</span>)</span><br><span class=line>            cat_feat = cat_feat.unsqueeze(<span class=number>0</span>)</span><br><span class=line>            agent_weight = torch.squeeze(self.pixel_weighted_fusion(cat_feat))</span><br><span class=line>            tmp_agent_weight_list.append(torch.exp(agent_weight))</span><br><span class=line>            sum_weight = sum_weight + torch.exp(agent_weight)</span><br><span class=line></span><br><span class=line>        agent_weight_list = <span class=built_in>list</span>()</span><br><span class=line>        <span class=keyword>for</span> k <span class=keyword>in</span> <span class=built_in>range</span>(nb_len):</span><br><span class=line>            agent_weight = torch.div(tmp_agent_weight_list[k], sum_weight)</span><br><span class=line>            agent_weight.expand([<span class=number>256</span>, -<span class=number>1</span>, -<span class=number>1</span>])</span><br><span class=line>            agent_weight_list.append(agent_weight)</span><br><span class=line></span><br><span class=line>        agent_wise_weight_feat = <span class=number>0</span></span><br><span class=line>        <span class=keyword>for</span> k <span class=keyword>in</span> <span class=built_in>range</span>(nb_len):</span><br><span class=line>            agent_wise_weight_feat = (</span><br><span class=line>                agent_wise_weight_feat</span><br><span class=line>                + agent_weight_list[k] * self.neighbor_feat_list[k]</span><br><span class=line>            )</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> agent_wise_weight_feat</span><br></pre></table></figure><h3 id=V2VNet><a class=headerlink href=#V2VNet title=V2VNet></a>V2VNet</h3><p><img alt=image-20240213170444226 data-src=https://s2.loli.net/2024/02/13/LK8F15wDS6jdkPJ.png><p>说实话,看了代码感觉也就那样…<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br><span class=line>84</span><br><span class=line>85</span><br><span class=line>86</span><br><span class=line>87</span><br><span class=line>88</span><br><span class=line>89</span><br><span class=line>90</span><br><span class=line>91</span><br><span class=line>92</span><br><span class=line>93</span><br><span class=line>94</span><br><span class=line>95</span><br><span class=line>96</span><br><span class=line>97</span><br><span class=line>98</span><br><span class=line>99</span><br><span class=line>100</span><br><span class=line>101</span><br><span class=line>102</span><br><span class=line>103</span><br><span class=line>104</span><br><span class=line>105</span><br><span class=line>106</span><br><span class=line>107</span><br><span class=line>108</span><br><span class=line>109</span><br><span class=line>110</span><br><span class=line>111</span><br><span class=line>112</span><br><span class=line>113</span><br><span class=line>114</span><br><span class=line>115</span><br><span class=line>116</span><br><span class=line>117</span><br><span class=line>118</span><br><span class=line>119</span><br><span class=line>120</span><br><span class=line>121</span><br><span class=line>122</span><br><span class=line>123</span><br><span class=line>124</span><br><span class=line>125</span><br><span class=line>126</span><br><span class=line>127</span><br><span class=line>128</span><br><span class=line>129</span><br><span class=line>130</span><br><span class=line>131</span><br><span class=line>132</span><br><span class=line>133</span><br><span class=line>134</span><br><span class=line>135</span><br><span class=line>136</span><br><span class=line>137</span><br><span class=line>138</span><br><span class=line>139</span><br><span class=line>140</span><br><span class=line>141</span><br><span class=line>142</span><br><span class=line>143</span><br><span class=line>144</span><br><span class=line>145</span><br><span class=line>146</span><br><span class=line>147</span><br><span class=line>148</span><br><span class=line>149</span><br></pre><td class=code><pre><span class=line><span class=comment># -*- coding: utf-8 -*-</span></span><br><span class=line><span class=comment># Author: Hao Xiang &LThaxiang@g.ucla.edu></span></span><br><span class=line><span class=comment># License: TDG-Attribution-NonCommercial-NoDistrib</span></span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=string>"""</span></span><br><span class=line><span class=string>Implementation of V2VNet Fusion</span></span><br><span class=line><span class=string>"""</span></span><br><span class=line></span><br><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line></span><br><span class=line><span class=keyword>from</span> opencood.models.sub_modules.torch_transformation_utils <span class=keyword>import</span> \</span><br><span class=line>    get_discretized_transformation_matrix, get_transformation_matrix, \</span><br><span class=line>    warp_affine, get_rotated_roi</span><br><span class=line><span class=keyword>from</span> opencood.models.sub_modules.convgru <span class=keyword>import</span> ConvGRU</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>V2VNetFusion</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, args</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(V2VNetFusion, self).__init__()</span><br><span class=line>        </span><br><span class=line>        in_channels = args[<span class=string>'in_channels'</span>]</span><br><span class=line>        H, W = args[<span class=string>'conv_gru'</span>][<span class=string>'H'</span>], args[<span class=string>'conv_gru'</span>][<span class=string>'W'</span>]</span><br><span class=line>        kernel_size = args[<span class=string>'conv_gru'</span>][<span class=string>'kernel_size'</span>]</span><br><span class=line>        num_gru_layers = args[<span class=string>'conv_gru'</span>][<span class=string>'num_layers'</span>]</span><br><span class=line></span><br><span class=line>        self.discrete_ratio = args[<span class=string>'voxel_size'</span>][<span class=number>0</span>]</span><br><span class=line>        self.downsample_rate = args[<span class=string>'downsample_rate'</span>]</span><br><span class=line>        self.num_iteration = args[<span class=string>'num_iteration'</span>]</span><br><span class=line>        self.gru_flag = args[<span class=string>'gru_flag'</span>]</span><br><span class=line>        self.agg_operator = args[<span class=string>'agg_operator'</span>]</span><br><span class=line></span><br><span class=line>        self.msg_cnn = nn.Conv2d(in_channels * <span class=number>2</span>, in_channels, kernel_size=<span class=number>3</span>,</span><br><span class=line>                                 stride=<span class=number>1</span>, padding=<span class=number>1</span>)</span><br><span class=line>        self.conv_gru = ConvGRU(input_size=(H, W),</span><br><span class=line>                                input_dim=in_channels * <span class=number>2</span>,</span><br><span class=line>                                hidden_dim=[in_channels],</span><br><span class=line>                                kernel_size=kernel_size,</span><br><span class=line>                                num_layers=num_gru_layers,</span><br><span class=line>                                batch_first=<span class=literal>True</span>,</span><br><span class=line>                                bias=<span class=literal>True</span>,</span><br><span class=line>                                return_all_layers=<span class=literal>False</span>)</span><br><span class=line>        self.mlp = nn.Linear(in_channels, in_channels)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>regroup</span>(<span class=params>self, x, record_len</span>):</span></span><br><span class=line>        cum_sum_len = torch.cumsum(record_len, dim=<span class=number>0</span>)</span><br><span class=line>        split_x = torch.tensor_split(x, cum_sum_len[:-<span class=number>1</span>].cpu())</span><br><span class=line>        <span class=keyword>return</span> split_x</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, record_len, pairwise_t_matrix</span>):</span></span><br><span class=line>        <span class=string>"""</span></span><br><span class=line><span class=string>        Fusion forwarding.</span></span><br><span class=line><span class=string>        </span></span><br><span class=line><span class=string>        Parameters</span></span><br><span class=line><span class=string>        ----------</span></span><br><span class=line><span class=string>        x : torch.Tensor</span></span><br><span class=line><span class=string>            input data, (B, C, H, W)</span></span><br><span class=line><span class=string>            </span></span><br><span class=line><span class=string>        record_len : list</span></span><br><span class=line><span class=string>            shape: (B)</span></span><br><span class=line><span class=string>            </span></span><br><span class=line><span class=string>        pairwise_t_matrix : torch.Tensor</span></span><br><span class=line><span class=string>            The transformation matrix from each cav to ego, </span></span><br><span class=line><span class=string>            shape: (B, L, L, 4, 4) </span></span><br><span class=line><span class=string>            </span></span><br><span class=line><span class=string>        Returns</span></span><br><span class=line><span class=string>        -------</span></span><br><span class=line><span class=string>        Fused feature.</span></span><br><span class=line><span class=string>        """</span></span><br><span class=line>        _, C, H, W = x.shape</span><br><span class=line>        B, L = pairwise_t_matrix.shape[:<span class=number>2</span>]</span><br><span class=line></span><br><span class=line>        <span class=comment># split x:[(L1, C, H, W), (L2, C, H, W)]</span></span><br><span class=line>        split_x = self.regroup(x, record_len)</span><br><span class=line>        <span class=comment># (B,L,L,2,3)</span></span><br><span class=line>        pairwise_t_matrix = get_discretized_transformation_matrix(</span><br><span class=line>            pairwise_t_matrix.reshape(-<span class=number>1</span>, L, <span class=number>4</span>, <span class=number>4</span>), self.discrete_ratio,</span><br><span class=line>            self.downsample_rate).reshape(B, L, L, <span class=number>2</span>, <span class=number>3</span>)</span><br><span class=line>        <span class=comment># (B*L,L,1,H,W)</span></span><br><span class=line>        roi_mask = get_rotated_roi((B * L, L, <span class=number>1</span>, H, W),</span><br><span class=line>                                   pairwise_t_matrix.reshape(B * L * L, <span class=number>2</span>, <span class=number>3</span>))</span><br><span class=line>        roi_mask = roi_mask.reshape(B, L, L, <span class=number>1</span>, H, W)</span><br><span class=line>        batch_node_features = split_x</span><br><span class=line>        </span><br><span class=line>        <span class=comment># iteratively update the features for num_iteration times</span></span><br><span class=line>        <span class=keyword>for</span> l <span class=keyword>in</span> <span class=built_in>range</span>(self.num_iteration):</span><br><span class=line></span><br><span class=line>            batch_updated_node_features = []</span><br><span class=line>            <span class=comment># iterate each batch</span></span><br><span class=line>            <span class=keyword>for</span> b <span class=keyword>in</span> <span class=built_in>range</span>(B):</span><br><span class=line></span><br><span class=line>                <span class=comment># number of valid agent</span></span><br><span class=line>                N = record_len[b]</span><br><span class=line>                <span class=comment># (N,N,4,4)</span></span><br><span class=line>                <span class=comment># t_matrix[i, j]-> from i to j</span></span><br><span class=line>                t_matrix = pairwise_t_matrix[b][:N, :N, :, :]</span><br><span class=line>                updated_node_features = []</span><br><span class=line>                <span class=comment># update each node i</span></span><br><span class=line>                <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(N):</span><br><span class=line>                    <span class=comment># (N,1,H,W)</span></span><br><span class=line>                    mask = roi_mask[b, :N, i, ...]</span><br><span class=line></span><br><span class=line>                    current_t_matrix = t_matrix[:, i, :, :]</span><br><span class=line>                    current_t_matrix = get_transformation_matrix(</span><br><span class=line>                        current_t_matrix, (H, W))</span><br><span class=line></span><br><span class=line>                    <span class=comment># (N,C,H,W)</span></span><br><span class=line>                    neighbor_feature = warp_affine(batch_node_features[b],</span><br><span class=line>                                                   current_t_matrix,</span><br><span class=line>                                                   (H, W))</span><br><span class=line>                    <span class=comment># (N,C,H,W)</span></span><br><span class=line>                    ego_agent_feature = batch_node_features[b][i].unsqueeze(</span><br><span class=line>                        <span class=number>0</span>).repeat(N, <span class=number>1</span>, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>                    <span class=comment>#(N,2C,H,W)</span></span><br><span class=line>                    neighbor_feature = torch.cat(</span><br><span class=line>                        [neighbor_feature, ego_agent_feature], dim=<span class=number>1</span>)</span><br><span class=line>                    <span class=comment># (N,C,H,W)</span></span><br><span class=line>                    message = self.msg_cnn(neighbor_feature) * mask</span><br><span class=line></span><br><span class=line>                    <span class=comment># (C,H,W)</span></span><br><span class=line>                    <span class=keyword>if</span> self.agg_operator==<span class=string>"avg"</span>:</span><br><span class=line>                        agg_feature = torch.mean(message, dim=<span class=number>0</span>)</span><br><span class=line>                    <span class=keyword>elif</span> self.agg_operator==<span class=string>"max"</span>:</span><br><span class=line>                        agg_feature = torch.<span class=built_in>max</span>(message, dim=<span class=number>0</span>)[<span class=number>0</span>]</span><br><span class=line>                    <span class=keyword>else</span>:</span><br><span class=line>                        <span class=keyword>raise</span> ValueError(<span class=string>"agg_operator has wrong value"</span>)</span><br><span class=line>                    <span class=comment># (2C, H, W)</span></span><br><span class=line>                    cat_feature = torch.cat(</span><br><span class=line>                        [batch_node_features[b][i, ...], agg_feature], dim=<span class=number>0</span>)</span><br><span class=line>                    <span class=comment># (C,H,W)</span></span><br><span class=line>                    <span class=keyword>if</span> self.gru_flag:</span><br><span class=line>                        gru_out = \</span><br><span class=line>                            self.conv_gru(cat_feature.unsqueeze(<span class=number>0</span>).unsqueeze(<span class=number>0</span>))[</span><br><span class=line>                                <span class=number>0</span>][</span><br><span class=line>                                <span class=number>0</span>].squeeze(<span class=number>0</span>).squeeze(<span class=number>0</span>)</span><br><span class=line>                    <span class=keyword>else</span>:</span><br><span class=line>                        gru_out = batch_node_features[b][i, ...] + agg_feature</span><br><span class=line>                    updated_node_features.append(gru_out.unsqueeze(<span class=number>0</span>))</span><br><span class=line>                <span class=comment># (N,C,H,W)</span></span><br><span class=line>                batch_updated_node_features.append(</span><br><span class=line>                    torch.cat(updated_node_features, dim=<span class=number>0</span>))</span><br><span class=line>            batch_node_features = batch_updated_node_features</span><br><span class=line>        <span class=comment># (B,C,H,W)</span></span><br><span class=line>        out = torch.cat(</span><br><span class=line>            [itm[<span class=number>0</span>, ...].unsqueeze(<span class=number>0</span>) <span class=keyword>for</span> itm <span class=keyword>in</span> batch_node_features], dim=<span class=number>0</span>)</span><br><span class=line>        <span class=comment># (B,C,H,W)</span></span><br><span class=line>        out = self.mlp(out.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>)).permute(<span class=number>0</span>, <span class=number>3</span>, <span class=number>1</span>, <span class=number>2</span>)</span><br><span class=line>        <span class=keyword>return</span> out</span><br></pre></table></figure><p>有的实现没有RNN比如上面代码,也有的用了RNN和LSTM.后者代码代码简直就是屎…<h3 id=V2xvit><a class=headerlink href=#V2xvit title=V2xvit></a>V2xvit</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br><span class=line>84</span><br><span class=line>85</span><br><span class=line>86</span><br><span class=line>87</span><br><span class=line>88</span><br><span class=line>89</span><br><span class=line>90</span><br><span class=line>91</span><br><span class=line>92</span><br><span class=line>93</span><br><span class=line>94</span><br><span class=line>95</span><br><span class=line>96</span><br><span class=line>97</span><br><span class=line>98</span><br><span class=line>99</span><br><span class=line>100</span><br><span class=line>101</span><br><span class=line>102</span><br><span class=line>103</span><br><span class=line>104</span><br><span class=line>105</span><br><span class=line>106</span><br><span class=line>107</span><br><span class=line>108</span><br><span class=line>109</span><br><span class=line>110</span><br><span class=line>111</span><br><span class=line>112</span><br><span class=line>113</span><br><span class=line>114</span><br><span class=line>115</span><br><span class=line>116</span><br><span class=line>117</span><br><span class=line>118</span><br><span class=line>119</span><br><span class=line>120</span><br><span class=line>121</span><br><span class=line>122</span><br><span class=line>123</span><br><span class=line>124</span><br><span class=line>125</span><br><span class=line>126</span><br><span class=line>127</span><br><span class=line>128</span><br><span class=line>129</span><br><span class=line>130</span><br><span class=line>131</span><br><span class=line>132</span><br><span class=line>133</span><br><span class=line>134</span><br><span class=line>135</span><br><span class=line>136</span><br><span class=line>137</span><br><span class=line>138</span><br><span class=line>139</span><br><span class=line>140</span><br><span class=line>141</span><br><span class=line>142</span><br><span class=line>143</span><br><span class=line>144</span><br><span class=line>145</span><br><span class=line>146</span><br><span class=line>147</span><br><span class=line>148</span><br><span class=line>149</span><br><span class=line>150</span><br><span class=line>151</span><br><span class=line>152</span><br><span class=line>153</span><br><span class=line>154</span><br><span class=line>155</span><br><span class=line>156</span><br><span class=line>157</span><br><span class=line>158</span><br><span class=line>159</span><br><span class=line>160</span><br><span class=line>161</span><br><span class=line>162</span><br><span class=line>163</span><br><span class=line>164</span><br><span class=line>165</span><br><span class=line>166</span><br><span class=line>167</span><br><span class=line>168</span><br><span class=line>169</span><br><span class=line>170</span><br><span class=line>171</span><br><span class=line>172</span><br><span class=line>173</span><br><span class=line>174</span><br><span class=line>175</span><br><span class=line>176</span><br><span class=line>177</span><br><span class=line>178</span><br><span class=line>179</span><br><span class=line>180</span><br><span class=line>181</span><br><span class=line>182</span><br><span class=line>183</span><br><span class=line>184</span><br><span class=line>185</span><br><span class=line>186</span><br><span class=line>187</span><br><span class=line>188</span><br><span class=line>189</span><br><span class=line>190</span><br><span class=line>191</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> math</span><br><span class=line></span><br><span class=line><span class=keyword>from</span> v2xvit.models.sub_modules.base_transformer <span class=keyword>import</span> *</span><br><span class=line><span class=keyword>from</span> v2xvit.models.sub_modules.hmsa <span class=keyword>import</span> *</span><br><span class=line><span class=keyword>from</span> v2xvit.models.sub_modules.mswin <span class=keyword>import</span> *</span><br><span class=line><span class=keyword>from</span> v2xvit.models.sub_modules.torch_transformation_utils <span class=keyword>import</span> \</span><br><span class=line>    get_transformation_matrix, warp_affine, get_roi_and_cav_mask, \</span><br><span class=line>    get_discretized_transformation_matrix</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>STTF</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, args</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(STTF, self).__init__()</span><br><span class=line>        self.discrete_ratio = args[<span class=string>'voxel_size'</span>][<span class=number>0</span>]</span><br><span class=line>        self.downsample_rate = args[<span class=string>'downsample_rate'</span>]</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, mask, spatial_correction_matrix</span>):</span></span><br><span class=line>        x = x.permute(<span class=number>0</span>, <span class=number>1</span>, <span class=number>4</span>, <span class=number>2</span>, <span class=number>3</span>)</span><br><span class=line>        dist_correction_matrix = get_discretized_transformation_matrix(</span><br><span class=line>            spatial_correction_matrix, self.discrete_ratio,</span><br><span class=line>            self.downsample_rate)</span><br><span class=line>        <span class=comment># Only compensate non-ego vehicles</span></span><br><span class=line>        B, L, C, H, W = x.shape</span><br><span class=line></span><br><span class=line>        T = get_transformation_matrix(</span><br><span class=line>            dist_correction_matrix[:, <span class=number>1</span>:, :, :].reshape(-<span class=number>1</span>, <span class=number>2</span>, <span class=number>3</span>), (H, W))</span><br><span class=line>        cav_features = warp_affine(x[:, <span class=number>1</span>:, :, :, :].reshape(-<span class=number>1</span>, C, H, W), T,</span><br><span class=line>                                   (H, W))</span><br><span class=line>        cav_features = cav_features.reshape(B, -<span class=number>1</span>, C, H, W)</span><br><span class=line>        x = torch.cat([x[:, <span class=number>0</span>, :, :, :].unsqueeze(<span class=number>1</span>), cav_features], dim=<span class=number>1</span>)</span><br><span class=line>        x = x.permute(<span class=number>0</span>, <span class=number>1</span>, <span class=number>3</span>, <span class=number>4</span>, <span class=number>2</span>)</span><br><span class=line>        <span class=keyword>return</span> x</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>RelTemporalEncoding</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=string>"""</span></span><br><span class=line><span class=string>    Implement the Temporal Encoding (Sinusoid) function.</span></span><br><span class=line><span class=string>    """</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, n_hid, RTE_ratio, max_len=<span class=number>100</span>, dropout=<span class=number>0.2</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(RelTemporalEncoding, self).__init__()</span><br><span class=line>        position = torch.arange(<span class=number>0.</span>, max_len).unsqueeze(<span class=number>1</span>)</span><br><span class=line>        div_term = torch.exp(torch.arange(<span class=number>0</span>, n_hid, <span class=number>2</span>) *</span><br><span class=line>                             -(math.log(<span class=number>10000.0</span>) / n_hid))</span><br><span class=line>        emb = nn.Embedding(max_len, n_hid)</span><br><span class=line>        emb.weight.data[:, <span class=number>0</span>::<span class=number>2</span>] = torch.sin(position * div_term) / math.sqrt(</span><br><span class=line>            n_hid)</span><br><span class=line>        emb.weight.data[:, <span class=number>1</span>::<span class=number>2</span>] = torch.cos(position * div_term) / math.sqrt(</span><br><span class=line>            n_hid)</span><br><span class=line>        emb.requires_grad = <span class=literal>False</span></span><br><span class=line>        self.RTE_ratio = RTE_ratio</span><br><span class=line>        self.emb = emb</span><br><span class=line>        self.lin = nn.Linear(n_hid, n_hid)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, t</span>):</span></span><br><span class=line>        <span class=comment># When t has unit of 50ms, rte_ratio=1.</span></span><br><span class=line>        <span class=comment># So we can train on 100ms but test on 50ms</span></span><br><span class=line>        <span class=keyword>return</span> x + self.lin(self.emb(t * self.RTE_ratio)).unsqueeze(</span><br><span class=line>            <span class=number>0</span>).unsqueeze(<span class=number>1</span>)</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>RTE</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, dim, RTE_ratio=<span class=number>2</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(RTE, self).__init__()</span><br><span class=line>        self.RTE_ratio = RTE_ratio</span><br><span class=line></span><br><span class=line>        self.emb = RelTemporalEncoding(dim, RTE_ratio=self.RTE_ratio)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, dts</span>):</span></span><br><span class=line>        <span class=comment># x: (B,L,H,W,C)</span></span><br><span class=line>        <span class=comment># dts: (B,L)</span></span><br><span class=line>        rte_batch = []</span><br><span class=line>        <span class=keyword>for</span> b <span class=keyword>in</span> <span class=built_in>range</span>(x.shape[<span class=number>0</span>]):</span><br><span class=line>            rte_list = []</span><br><span class=line>            <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(x.shape[<span class=number>1</span>]):</span><br><span class=line>                rte_list.append(</span><br><span class=line>                    self.emb(x[b, i, :, :, :], dts[b, i]).unsqueeze(<span class=number>0</span>))</span><br><span class=line>            rte_batch.append(torch.cat(rte_list, dim=<span class=number>0</span>).unsqueeze(<span class=number>0</span>))</span><br><span class=line>        <span class=keyword>return</span> torch.cat(rte_batch, dim=<span class=number>0</span>)</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>V2XFusionBlock</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, num_blocks, cav_att_config, pwindow_config</span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        <span class=comment># first multi-agent attention and then multi-window attention</span></span><br><span class=line>        self.layers = nn.ModuleList([])</span><br><span class=line>        self.num_blocks = num_blocks</span><br><span class=line></span><br><span class=line>        <span class=keyword>for</span> _ <span class=keyword>in</span> <span class=built_in>range</span>(num_blocks):</span><br><span class=line>            att = HGTCavAttention(cav_att_config[<span class=string>'dim'</span>],</span><br><span class=line>                                  heads=cav_att_config[<span class=string>'heads'</span>],</span><br><span class=line>                                  dim_head=cav_att_config[<span class=string>'dim_head'</span>],</span><br><span class=line>                                  dropout=cav_att_config[<span class=string>'dropout'</span>]) <span class=keyword>if</span> \</span><br><span class=line>                cav_att_config[<span class=string>'use_hetero'</span>] <span class=keyword>else</span> \</span><br><span class=line>                CavAttention(cav_att_config[<span class=string>'dim'</span>],</span><br><span class=line>                             heads=cav_att_config[<span class=string>'heads'</span>],</span><br><span class=line>                             dim_head=cav_att_config[<span class=string>'dim_head'</span>],</span><br><span class=line>                             dropout=cav_att_config[<span class=string>'dropout'</span>])</span><br><span class=line>            self.layers.append(nn.ModuleList([</span><br><span class=line>                PreNorm(cav_att_config[<span class=string>'dim'</span>], att),</span><br><span class=line>                PreNorm(cav_att_config[<span class=string>'dim'</span>],</span><br><span class=line>                        PyramidWindowAttention(pwindow_config[<span class=string>'dim'</span>],</span><br><span class=line>                                               heads=pwindow_config[<span class=string>'heads'</span>],</span><br><span class=line>                                               dim_heads=pwindow_config[</span><br><span class=line>                                                   <span class=string>'dim_head'</span>],</span><br><span class=line>                                               drop_out=pwindow_config[</span><br><span class=line>                                                   <span class=string>'dropout'</span>],</span><br><span class=line>                                               window_size=pwindow_config[</span><br><span class=line>                                                   <span class=string>'window_size'</span>],</span><br><span class=line>                                               relative_pos_embedding=</span><br><span class=line>                                               pwindow_config[</span><br><span class=line>                                                   <span class=string>'relative_pos_embedding'</span>],</span><br><span class=line>                                               fuse_method=pwindow_config[</span><br><span class=line>                                                   <span class=string>'fusion_method'</span>]))]))</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, mask, prior_encoding</span>):</span></span><br><span class=line>        <span class=keyword>for</span> cav_attn, pwindow_attn <span class=keyword>in</span> self.layers:</span><br><span class=line>            x = cav_attn(x, mask=mask, prior_encoding=prior_encoding) + x</span><br><span class=line>            x = pwindow_attn(x) + x</span><br><span class=line>        <span class=keyword>return</span> x</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>V2XTEncoder</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, args</span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line></span><br><span class=line>        cav_att_config = args[<span class=string>'cav_att_config'</span>]</span><br><span class=line>        pwindow_att_config = args[<span class=string>'pwindow_att_config'</span>]</span><br><span class=line>        feed_config = args[<span class=string>'feed_forward'</span>]</span><br><span class=line></span><br><span class=line>        num_blocks = args[<span class=string>'num_blocks'</span>]</span><br><span class=line>        depth = args[<span class=string>'depth'</span>]</span><br><span class=line>        mlp_dim = feed_config[<span class=string>'mlp_dim'</span>]</span><br><span class=line>        dropout = feed_config[<span class=string>'dropout'</span>]</span><br><span class=line></span><br><span class=line>        self.downsample_rate = args[<span class=string>'sttf'</span>][<span class=string>'downsample_rate'</span>]</span><br><span class=line>        self.discrete_ratio = args[<span class=string>'sttf'</span>][<span class=string>'voxel_size'</span>][<span class=number>0</span>]</span><br><span class=line>        self.use_roi_mask = args[<span class=string>'use_roi_mask'</span>]</span><br><span class=line>        self.use_RTE = cav_att_config[<span class=string>'use_RTE'</span>]</span><br><span class=line>        self.RTE_ratio = cav_att_config[<span class=string>'RTE_ratio'</span>]</span><br><span class=line>        self.sttf = STTF(args[<span class=string>'sttf'</span>])</span><br><span class=line>        <span class=comment># adjust the channel numbers from 256+3 -> 256</span></span><br><span class=line>        self.prior_feed = nn.Linear(cav_att_config[<span class=string>'dim'</span>] + <span class=number>3</span>,</span><br><span class=line>                                    cav_att_config[<span class=string>'dim'</span>])</span><br><span class=line>        self.layers = nn.ModuleList([])</span><br><span class=line>        <span class=keyword>if</span> self.use_RTE:</span><br><span class=line>            self.rte = RTE(cav_att_config[<span class=string>'dim'</span>], self.RTE_ratio)</span><br><span class=line>        <span class=keyword>for</span> _ <span class=keyword>in</span> <span class=built_in>range</span>(depth):</span><br><span class=line>            self.layers.append(nn.ModuleList([</span><br><span class=line>                V2XFusionBlock(num_blocks, cav_att_config, pwindow_att_config),</span><br><span class=line>                PreNorm(cav_att_config[<span class=string>'dim'</span>],</span><br><span class=line>                        FeedForward(cav_att_config[<span class=string>'dim'</span>], mlp_dim,</span><br><span class=line>                                    dropout=dropout))</span><br><span class=line>            ]))</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, mask, spatial_correction_matrix</span>):</span></span><br><span class=line></span><br><span class=line>        <span class=comment># transform the features to the current timestamp</span></span><br><span class=line>        <span class=comment># velocity, time_delay, infra</span></span><br><span class=line>        <span class=comment># (B,L,H,W,3)</span></span><br><span class=line>        prior_encoding = x[..., -<span class=number>3</span>:]</span><br><span class=line>        <span class=comment># (B,L,H,W,C)</span></span><br><span class=line>        x = x[..., :-<span class=number>3</span>]</span><br><span class=line>        <span class=keyword>if</span> self.use_RTE:</span><br><span class=line>            <span class=comment># dt: (B,L)</span></span><br><span class=line>            dt = prior_encoding[:, :, <span class=number>0</span>, <span class=number>0</span>, <span class=number>1</span>].to(torch.<span class=built_in>int</span>)</span><br><span class=line>            x = self.rte(x, dt)</span><br><span class=line>        x = self.sttf(x, mask, spatial_correction_matrix)</span><br><span class=line>        com_mask = mask.unsqueeze(<span class=number>1</span>).unsqueeze(<span class=number>2</span>).unsqueeze(</span><br><span class=line>            <span class=number>3</span>) <span class=keyword>if</span> <span class=keyword>not</span> self.use_roi_mask <span class=keyword>else</span> get_roi_and_cav_mask(x.shape,</span><br><span class=line>                                                                  mask,</span><br><span class=line>                                                                  spatial_correction_matrix,</span><br><span class=line>                                                                  self.discrete_ratio,</span><br><span class=line>                                                                  self.downsample_rate)</span><br><span class=line>        <span class=keyword>for</span> attn, ff <span class=keyword>in</span> self.layers:</span><br><span class=line>            x = attn(x, mask=com_mask, prior_encoding=prior_encoding)</span><br><span class=line>            x = ff(x) + x</span><br><span class=line>        <span class=keyword>return</span> x</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>V2XTransformer</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, args</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(V2XTransformer, self).__init__()</span><br><span class=line></span><br><span class=line>        encoder_args = args[<span class=string>'encoder'</span>]</span><br><span class=line>        self.encoder = V2XTEncoder(encoder_args)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, mask, spatial_correction_matrix</span>):</span></span><br><span class=line>        output = self.encoder(x, mask, spatial_correction_matrix)</span><br><span class=line>        output = output[:, <span class=number>0</span>]</span><br><span class=line>        <span class=keyword>return</span> output</span><br></pre></table></figure><p>关键是脱离了agent2agent,而是vehicle2everything,向异构多模态发展.<h3 id=DiscoNet><a class=headerlink href=#DiscoNet title=DiscoNet></a>DiscoNet</h3><p>主要是利用了蒸馏,教师-学生模型这种理论.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br></pre><td class=code><pre><span class=line><span class=keyword>if</span> args.kd_flag == <span class=number>1</span>:</span><br><span class=line>        teacher = TeacherNet(config)</span><br><span class=line>        teacher = nn.DataParallel(teacher)</span><br><span class=line>        teacher = teacher.to(device)</span><br><span class=line>        faf_module = FaFModule(</span><br><span class=line>            model, teacher, config, optimizer, criterion, args.kd_flag</span><br><span class=line>        )</span><br><span class=line>        checkpoint_teacher = torch.load(args.resume_teacher)</span><br><span class=line>        start_epoch_teacher = checkpoint_teacher[<span class=string>"epoch"</span>]</span><br><span class=line>        faf_module.teacher.load_state_dict(checkpoint_teacher[<span class=string>"model_state_dict"</span>])</span><br><span class=line>        <span class=built_in>print</span>(</span><br><span class=line>            <span class=string>"Load teacher model from {}, at epoch {}"</span>.<span class=built_in>format</span>(</span><br><span class=line>                args.resume_teacher, start_epoch_teacher</span><br><span class=line>            )</span><br><span class=line>        )</span><br><span class=line>        faf_module.teacher.<span class=built_in>eval</span>()</span><br></pre></table></figure><p>先使用tearcherNet拿数据进行训练,然后拿训练后的模型加载<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>TeacherNet</span>(<span class=params>NonIntermediateModelBase</span>):</span></span><br><span class=line>    <span class=string>"""The teacher net for knowledged distillation in DiscoNet."""</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, config</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(TeacherNet, self).__init__(config, compress_level=<span class=number>0</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, bevs, maps=<span class=literal>None</span>, vis=<span class=literal>None</span></span>):</span></span><br><span class=line>        bevs = bevs.permute(<span class=number>0</span>, <span class=number>1</span>, <span class=number>4</span>, <span class=number>2</span>, <span class=number>3</span>)  <span class=comment># (Batch, seq, z, h, w)</span></span><br><span class=line>        <span class=comment># vis = vis.permute(0, 3, 1, 2)</span></span><br><span class=line>        <span class=keyword>return</span> self.stpn(bevs)</span><br></pre></table></figure><p>使用教师模型得到的结果和原本模型得到的结果(一些中间融合层)计算损失,代码中用的KL交叉熵损失<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>get_kd_loss</span>(<span class=params>self, batch_size, data, fused_layer, num_agent, x_5, x_6, x_7</span>):</span></span><br><span class=line>    <span class=keyword>if</span> self.kd_flag:</span><br><span class=line>        bev_seq_teacher = data[<span class=string>"bev_seq_teacher"</span>]</span><br><span class=line>        kd_weight = data[<span class=string>"kd_weight"</span>]</span><br><span class=line>        (</span><br><span class=line>            x_8_teacher,</span><br><span class=line>            x_7_teacher,</span><br><span class=line>            x_6_teacher,</span><br><span class=line>            x_5_teacher,</span><br><span class=line>            x_3_teacher,</span><br><span class=line>            x_2_teacher,</span><br><span class=line>        ) = self.teacher(bev_seq_teacher)</span><br><span class=line></span><br><span class=line>        <span class=comment># for k, v in self.teacher.named_parameters():</span></span><br><span class=line>        <span class=comment># 	if k != 'xxx.weight' and k != 'xxx.bias':</span></span><br><span class=line>        <span class=comment># 		print(v.requires_grad)  # should be False</span></span><br><span class=line></span><br><span class=line>        <span class=comment># for k, v in self.model.named_parameters():</span></span><br><span class=line>        <span class=comment># 	if k != 'xxx.weight' and k != 'xxx.bias':</span></span><br><span class=line>        <span class=comment># 		print(v.requires_grad)  # should be False</span></span><br><span class=line></span><br><span class=line>        <span class=comment># -------- KD loss---------#</span></span><br><span class=line>        kl_loss_mean = nn.KLDivLoss(size_average=<span class=literal>True</span>, reduce=<span class=literal>True</span>)</span><br><span class=line></span><br><span class=line>        <span class=comment># target_x8 = x_8_teacher.permute(0, 2, 3, 1).reshape(5 * batch_size * 256 * 256, -1)</span></span><br><span class=line>        <span class=comment># student_x8 = x_8.permute(0, 2, 3, 1).reshape(5 * batch_size * 256 * 256, -1)</span></span><br><span class=line>        <span class=comment># kd_loss_x8 = kl_loss_mean(F.log_softmax(student_x8, dim=1), F.softmax(target_x8, dim=1))</span></span><br><span class=line>        <span class=comment># #</span></span><br><span class=line>        target_x7 = x_7_teacher.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>128</span> * <span class=number>128</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        student_x7 = x_7.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>128</span> * <span class=number>128</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        kd_loss_x7 = kl_loss_mean(</span><br><span class=line>            F.log_softmax(student_x7, dim=<span class=number>1</span>), F.softmax(target_x7, dim=<span class=number>1</span>)</span><br><span class=line>        )</span><br><span class=line>        <span class=comment>#</span></span><br><span class=line>        target_x6 = x_6_teacher.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>64</span> * <span class=number>64</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        student_x6 = x_6.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>64</span> * <span class=number>64</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        kd_loss_x6 = kl_loss_mean(</span><br><span class=line>            F.log_softmax(student_x6, dim=<span class=number>1</span>), F.softmax(target_x6, dim=<span class=number>1</span>)</span><br><span class=line>        )</span><br><span class=line>        <span class=comment># #</span></span><br><span class=line>        target_x5 = x_5_teacher.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>32</span> * <span class=number>32</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        student_x5 = x_5.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>32</span> * <span class=number>32</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        kd_loss_x5 = kl_loss_mean(</span><br><span class=line>            F.log_softmax(student_x5, dim=<span class=number>1</span>), F.softmax(target_x5, dim=<span class=number>1</span>)</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>        target_x3 = x_3_teacher.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>32</span> * <span class=number>32</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        student_x3 = fused_layer.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>3</span>, <span class=number>1</span>).reshape(</span><br><span class=line>            num_agent * batch_size * <span class=number>32</span> * <span class=number>32</span>, -<span class=number>1</span></span><br><span class=line>        )</span><br><span class=line>        kd_loss_fused_layer = kl_loss_mean(</span><br><span class=line>            F.log_softmax(student_x3, dim=<span class=number>1</span>), F.softmax(target_x3, dim=<span class=number>1</span>)</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>        kd_loss = kd_weight * (</span><br><span class=line>            kd_loss_x7 + kd_loss_x6 + kd_loss_x5 + kd_loss_fused_layer</span><br><span class=line>        )</span><br><span class=line>        <span class=comment># kd_loss = kd_weight * (kd_loss_x6 + kd_loss_x5 + kd_loss_fused_layer)</span></span><br><span class=line>        <span class=comment># print(kd_loss)</span></span><br><span class=line></span><br><span class=line>    <span class=keyword>else</span>:</span><br><span class=line>        kd_loss = <span class=number>0</span></span><br><span class=line>    <span class=keyword>return</span> kd_loss</span><br><span class=line></span><br></pre></table></figure><p>KL损失定义如下<p><img alt=image-20240227225503889 data-src=https://s2.loli.net/2024/02/27/CQuUxlwvFV7ceB5.png><h2 id=Comunicaton-Mechanism><a title="Comunicaton Mechanism" class=headerlink href=#Comunicaton-Mechanism></a>Comunicaton Mechanism</h2><p>之前的方法基本都是使用通信范围内固定车辆的所有特征,之后有了自定义的通信机制,对通信的车辆,特征等进行选择.<h3 id=who2com-2020><a title="who2com 2020" class=headerlink href=#who2com-2020></a>who2com 2020</h3><p><a href=https://arxiv.org/abs/2003.09575 rel=noopener target=_blank>[2003.09575] Who2com: Collaborative Perception via Learnable Handshake Communication (arxiv.org)</a><p><img alt=image-20240229143700618 data-src=https://s2.loli.net/2024/02/29/muRMCOTiKLwl6X9.png><p><img alt=image-20240229143720495 data-src=https://s2.loli.net/2024/02/29/ZheUYj6bvl9T7XP.png><p><strong>Who2com 建立了首个带宽限制下的通信机制</strong>，通过三阶段握手实现。具体来说，<strong>Who2com 使用一般注意力函数计算代理之间的匹配分数，并选择最需要的代理，从而有效减少带宽</strong>。<p>定义了一个三阶段的handshake通信机制,分为request,match,connect.<p>具体来说，代理首先向邻近的代理广播其请求信息 μ~j~∈ R~m~，代理计算其keys κi∈ R~k~ 与请求信息之间的匹配得分 s~ji~。<p>一旦理将其匹配分数返回给降级ego代理,ego代理会进一步选择最佳的 n 个代理与之连接<p>在每个步骤中，每个代理 i 可以通过key生成器 G~i~^k^、信息生成器 G~i~^m^、图像编码器 E~i~ 和任务解码器 D~i~ 对信息进行压缩。<p>简单来说,对于一个ego代理,首先使用一个request生成器(就是一个网络)得到一个信息.此外其他车也会生成一个key发送给ego代理,然后使用注意力机制计算两者值作为相似度.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br></pre><td class=code><pre><span class=line><span class=comment># # Message generator</span></span><br><span class=line>       self.query_key_net = policy_net4(n_classes=n_classes, in_channels=in_channels, enc_backbone=enc_backbone)</span><br><span class=line>       <span class=keyword>if</span> self.has_query:</span><br><span class=line>           self.query_net = linear(out_size=self.query_size, input_feat_sz=image_size / <span class=number>32</span>)</span><br><span class=line></span><br><span class=line>       self.key_net = linear(out_size=self.key_size, input_feat_sz=image_size / <span class=number>32</span>)</span><br><span class=line>       <span class=keyword>if</span> attention == <span class=string>'additive'</span>:</span><br><span class=line>           self.attention_net = AdditiveAttentin()</span><br><span class=line>       <span class=keyword>elif</span> attention == <span class=string>'general'</span>:</span><br><span class=line>           self.attention_net = GeneralDotProductAttention(self.query_size, self.key_size)</span><br><span class=line>       <span class=keyword>else</span>:</span><br><span class=line>           self.attention_net = ScaledDotProductAttention(<span class=number>128</span> ** <span class=number>0.5</span>)</span><br></pre></table></figure><script type="math/tex; mode=display">
\mu_j=G_m^j(\tilde{x}_j;\theta_m)\in\mathbb{R}^m \\
s_{ji}=\Phi(\mu_j,\kappa_i),\quad\kappa_i=G_k^i(x_i;\theta_k)\in\mathbb{R}^k \\
\text{General: }\Phi=\mu_j^TW_a\kappa_i \\
\tilde{\boldsymbol{y}}_j=D^j([\tilde{\boldsymbol{f}}_j;f_{\hat{\imath}}];\boldsymbol{\theta}_d) \\
f_{\hat{\imath}}=E^i(x_{\hat{\imath}};\boldsymbol{\theta}_e)\in\mathbb{R}^{d_f\times d_f\times d_c}   \tilde{\boldsymbol{f}}_j=E^j(\tilde{\boldsymbol{x}}_j;\boldsymbol{\theta}_e) \\
\tilde{y}_{j}=D^{j}([\tilde{f}_{j};f_{sum}];\theta_{d}),\quad f_{sum}=\sum_{i=1}^{N}\alpha_{j,i}f_{i} \\
\hat{i}=\underset{i}{\operatorname*{argmax}}s_{ji}</script><blockquote><p>α~j,i~ is ith element of α~j~ = ρ([s~j1~; …; s~jN~ ]) ∈ R^N^ and ρ is a softmax operation</blockquote><p>attention方法如下<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>ScaledDotProductAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=string>''' Scaled Dot-Product Attention '''</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, temperature, attn_dropout=<span class=number>0.1</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.temperature = temperature</span><br><span class=line>        self.sparsemax = Sparsemax(dim=<span class=number>1</span>)</span><br><span class=line>        self.softmax = nn.Softmax(dim=<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, q, k, v, sparse=<span class=literal>True</span></span>):</span></span><br><span class=line>        attn_orig = torch.bmm(k, q.transpose(<span class=number>2</span>, <span class=number>1</span>))</span><br><span class=line>        attn_orig = attn_orig / self.temperature</span><br><span class=line>        <span class=keyword>if</span> sparse:</span><br><span class=line>            attn_orig = self.sparsemax(attn_orig)  </span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            attn_orig = self.softmax(attn_orig)  </span><br><span class=line>        attn = torch.unsqueeze(torch.unsqueeze(attn_orig, <span class=number>3</span>), <span class=number>4</span>)  </span><br><span class=line>        output = attn * v  <span class=comment># (batch,4,channel,size,size)</span></span><br><span class=line>        output = output.<span class=built_in>sum</span>(<span class=number>1</span>)  <span class=comment># (batch,1,channel,size,size)</span></span><br><span class=line>        <span class=keyword>return</span> output, attn_orig.transpose(<span class=number>2</span>, <span class=number>1</span>)</span><br><span class=line>        </span><br><span class=line> <span class=class><span class=keyword>class</span> <span class=title>AdditiveAttentin</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        <span class=comment># self.dropout = nn.Dropout(attn_dropout)</span></span><br><span class=line>        self.softmax = nn.Softmax(dim=<span class=number>1</span>)</span><br><span class=line>        self.sparsemax = Sparsemax(dim=<span class=number>1</span>)</span><br><span class=line>        self.linear_feat = nn.Linear(<span class=number>128</span>, <span class=number>128</span>)</span><br><span class=line>        self.linear_context = nn.Linear(<span class=number>128</span>, <span class=number>128</span>)</span><br><span class=line>        self.linear_out = nn.Linear(<span class=number>128</span>, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, q, k, v, sparse=<span class=literal>True</span></span>):</span></span><br><span class=line>        <span class=comment># q (batch,1,128)</span></span><br><span class=line>        <span class=comment># k (batch,4,128)</span></span><br><span class=line>        <span class=comment># v (batch,4,channel,size,size)</span></span><br><span class=line>        temp1 = self.linear_feat(k)  <span class=comment># (batch,4,128)</span></span><br><span class=line>        temp2 = self.linear_context(q)  <span class=comment># (batch,1,128)</span></span><br><span class=line>        attn_orig = self.linear_out(temp1 + temp2)  <span class=comment># (batch,4,1)</span></span><br><span class=line>        <span class=keyword>if</span> sparse:</span><br><span class=line>            attn_orig = self.sparsemax(attn_orig)  <span class=comment># (batch,4,1)</span></span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            attn_orig = self.softmax(attn_orig)  <span class=comment># (batch,4,1)</span></span><br><span class=line>        attn = torch.unsqueeze(torch.unsqueeze(attn_orig, <span class=number>3</span>), <span class=number>4</span>)  <span class=comment># (batch,4,1,1,1)</span></span><br><span class=line>        output = attn * v</span><br><span class=line>        output = output.<span class=built_in>sum</span>(<span class=number>1</span>)  <span class=comment># (batch,1,channel,size,size)</span></span><br><span class=line>        <span class=keyword>return</span> output, attn_orig.transpose(<span class=number>2</span>, <span class=number>1</span>)</span><br><span class=line>        </span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>GeneralDotProductAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=string>''' Scaled Dot-Product Attention '''</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, query_size, key_size, attn_dropout=<span class=number>0.1</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.sparsemax = Sparsemax(dim=<span class=number>1</span>)</span><br><span class=line>        self.softmax = nn.Softmax(dim=<span class=number>1</span>)</span><br><span class=line>        self.linear = nn.Linear(query_size, key_size)</span><br><span class=line>        <span class=built_in>print</span>(<span class=string>'Msg size: '</span>,query_size,<span class=string>'  Key size: '</span>, key_size)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, q, k, v, sparse=<span class=literal>True</span></span>):</span></span><br><span class=line>        <span class=comment># q (batch,1,128)</span></span><br><span class=line>        <span class=comment># k (batch,4,128)</span></span><br><span class=line>        <span class=comment># v (batch,4,channel*size*size)</span></span><br><span class=line>        query = self.linear(q)  <span class=comment># (batch,1,key_size)</span></span><br><span class=line>        attn_orig = torch.bmm(k, query.transpose(<span class=number>2</span>, <span class=number>1</span>))  <span class=comment># (batch,4,1)</span></span><br><span class=line>        <span class=keyword>if</span> sparse:</span><br><span class=line>            attn_orig = self.sparsemax(attn_orig)  <span class=comment># (batch,4,1)</span></span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            attn_orig = self.softmax(attn_orig)  <span class=comment># (batch,4,1)</span></span><br><span class=line>        attn = torch.unsqueeze(torch.unsqueeze(attn_orig, <span class=number>3</span>), <span class=number>4</span>)  <span class=comment># (batch,4,1,1,1)</span></span><br><span class=line>        output = attn * v  <span class=comment># (batch,4,channel,size,size)</span></span><br><span class=line>        output = output.<span class=built_in>sum</span>(<span class=number>1</span>)  <span class=comment># (batch,1,channel,size,size)</span></span><br><span class=line>        <span class=keyword>return</span> output, attn_orig.transpose(<span class=number>2</span>, <span class=number>1</span>)</span><br></pre></table></figure><h3 id=when2comm-2020><a title="when2comm 2020" class=headerlink href=#when2comm-2020></a>when2comm 2020</h3><p>who2comm的同作者.<p>在 Who2com 的基础上，When2com引入了缩放一般注意力来决定何时与他人交流。这样，自我代理只有在信息不足时才会与他人交流，从而有效地节省了协作资源。<p><img alt=image-20240229162328653 data-src=https://s2.loli.net/2024/02/29/COiPgxUSrsYvqQL.png><p>when2comm的代码就要复杂的多,它构建了很多块.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>KmGenerator</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, out_size=<span class=number>128</span>, input_feat_sz=<span class=number>32.0</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(KmGenerator, self).__init__()</span><br><span class=line>        feat_map_sz = input_feat_sz // <span class=number>4</span></span><br><span class=line>        self.n_feat = <span class=built_in>int</span>(<span class=number>256</span> * feat_map_sz * feat_map_sz)</span><br><span class=line>        self.fc = nn.Sequential(</span><br><span class=line>            nn.Linear(self.n_feat, <span class=number>256</span>),  <span class=comment>#</span></span><br><span class=line>            nn.ReLU(inplace=<span class=literal>True</span>),</span><br><span class=line>            nn.Linear(<span class=number>256</span>, <span class=number>128</span>),  <span class=comment>#</span></span><br><span class=line>            nn.ReLU(inplace=<span class=literal>True</span>),</span><br><span class=line>            nn.Linear(<span class=number>128</span>, out_size),</span><br><span class=line>        )  <span class=comment>#</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, features_map</span>):</span></span><br><span class=line>        outputs = self.fc(features_map.view(-<span class=number>1</span>, self.n_feat))</span><br><span class=line>        <span class=keyword>return</span> outputs</span><br><span class=line></span><br><span class=line> </span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>PolicyNet4</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_channels=<span class=number>13</span>, input_feat_sz=<span class=number>32</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(PolicyNet4, self).__init__()</span><br><span class=line>        feat_map_sz = input_feat_sz // <span class=number>4</span></span><br><span class=line>        self.n_feat = <span class=built_in>int</span>(<span class=number>256</span> * feat_map_sz * feat_map_sz)</span><br><span class=line>        self.lidar_encoder = LidarEncoder(height_feat_size=in_channels)</span><br><span class=line></span><br><span class=line>        <span class=comment># Encoder</span></span><br><span class=line>        <span class=comment># down 1</span></span><br><span class=line>        self.conv1 = Conv2DBatchNormRelu(<span class=number>512</span>, <span class=number>512</span>, k_size=<span class=number>3</span>, stride=<span class=number>1</span>, padding=<span class=number>1</span>)</span><br><span class=line>        self.conv2 = Conv2DBatchNormRelu(<span class=number>512</span>, <span class=number>256</span>, k_size=<span class=number>3</span>, stride=<span class=number>1</span>, padding=<span class=number>1</span>)</span><br><span class=line>        self.conv3 = Conv2DBatchNormRelu(<span class=number>256</span>, <span class=number>256</span>, k_size=<span class=number>3</span>, stride=<span class=number>2</span>, padding=<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        <span class=comment># down 2</span></span><br><span class=line>        self.conv4 = Conv2DBatchNormRelu(<span class=number>256</span>, <span class=number>256</span>, k_size=<span class=number>3</span>, stride=<span class=number>1</span>, padding=<span class=number>1</span>)</span><br><span class=line>        self.conv5 = Conv2DBatchNormRelu(<span class=number>256</span>, <span class=number>256</span>, k_size=<span class=number>3</span>, stride=<span class=number>2</span>, padding=<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, features_map</span>):</span></span><br><span class=line>        _, _, _, _, outputs1 = self.lidar_encoder(features_map)</span><br><span class=line>        outputs = self.conv1(outputs1)</span><br><span class=line>        outputs = self.conv2(outputs)</span><br><span class=line>        outputs = self.conv3(outputs)</span><br><span class=line>        outputs = self.conv4(outputs)</span><br><span class=line>        outputs = self.conv5(outputs)</span><br><span class=line>        <span class=keyword>return</span> outputs</span><br><span class=line>   </span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>LidarEncoder</span>(<span class=params>Backbone</span>):</span></span><br><span class=line>    <span class=string>"""The encoder class. Encodes input features in forward pass."""</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, height_feat_size=<span class=number>13</span>, compress_level=<span class=number>0</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(height_feat_size, compress_level)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=keyword>return</span> <span class=built_in>super</span>().encode(x)</span><br><span class=line></span><br><span class=line>    </span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>LidarDecoder</span>(<span class=params>Backbone</span>):</span></span><br><span class=line>    <span class=string>"""The decoder class. Decodes input features in forward pass."""</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, height_feat_size=<span class=number>13</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__(height_feat_size)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x, x_1, x_2, x_3, x_4, batch, kd_flag=<span class=literal>False</span></span>):</span></span><br><span class=line>        <span class=keyword>return</span> <span class=built_in>super</span>().decode(x, x_1, x_2, x_3, x_4, batch, kd_flag)</span><br><span class=line></span><br></pre></table></figure><p>首先使用encode进行降采样,选择某一层采样后的输出,利用采样后的输出计算q,k,v使用注意力机制融合.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br></pre><td class=code><pre><span class=line>self.key_net = KmGenerator(</span><br><span class=line>    out_size=self.key_size, input_feat_sz=image_size / <span class=number>32</span></span><br><span class=line>)</span><br><span class=line>self.attention_net = MIMOGeneralDotProductAttention(</span><br><span class=line>    self.query_size, self.key_size, self.warp_flag</span><br><span class=line>)</span><br><span class=line><span class=comment># # Message generator</span></span><br><span class=line>self.query_key_net = PolicyNet4(in_channels=in_channels)</span><br><span class=line><span class=keyword>if</span> self.has_query:</span><br><span class=line>    self.query_net = KmGenerator(</span><br><span class=line>        out_size=self.query_size, input_feat_sz=image_size / <span class=number>32</span></span><br><span class=line>    )</span><br><span class=line></span><br></pre></table></figure><p>利用query_key_net生成特征,再利用key_net生成key,query_net生成query,使用attention_net利用注意力机制进行融合.val_mat就是采样后的输出<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>key_mat = torch.cat(<span class=built_in>tuple</span>(key_list), <span class=number>1</span>)</span><br><span class=line>query_mat = torch.cat(<span class=built_in>tuple</span>(query_list), <span class=number>1</span>)</span><br></pre></table></figure><p>用的就是点积注意力,然后使用decoder回去.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br></pre><td class=code><pre><span class=line>   <span class=comment># hand-shake</span></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>MIMOGeneralDotProductAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=string>"""Scaled Dot-Product Attention"""</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, query_size, key_size, warp_flag, attn_dropout=<span class=number>0.1</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.sparsemax = Sparsemax(dim=<span class=number>1</span>)</span><br><span class=line>        self.softmax = nn.Softmax(dim=<span class=number>1</span>)</span><br><span class=line>        self.linear = nn.Linear(query_size, key_size)</span><br><span class=line>        self.warp_flag = warp_flag</span><br><span class=line>        <span class=built_in>print</span>(<span class=string>"Msg size: "</span>, query_size, <span class=string>"  Key size: "</span>, key_size)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, qu, k, v, sparse=<span class=literal>True</span></span>):</span></span><br><span class=line>      </span><br><span class=line>        query = self.linear(qu)  <span class=comment># (batch,5,key_size)</span></span><br><span class=line>        attn_orig = torch.bmm(</span><br><span class=line>            k, query.transpose(<span class=number>2</span>, <span class=number>1</span>)</span><br><span class=line>        )  </span><br><span class=line>        attn_orig_softmax = self.softmax(attn_orig)  <span class=comment># (batch,5,5)</span></span><br><span class=line></span><br><span class=line>        attn_shape = attn_orig_softmax.shape</span><br><span class=line>        bats, key_num, query_num = attn_shape[<span class=number>0</span>], attn_shape[<span class=number>1</span>], attn_shape[<span class=number>2</span>]</span><br><span class=line>        attn_orig_softmax_exp = attn_orig_softmax.view(</span><br><span class=line>            bats, key_num, query_num, <span class=number>1</span>, <span class=number>1</span>, <span class=number>1</span></span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>        <span class=keyword>if</span> self.warp_flag == <span class=number>1</span>:</span><br><span class=line>            v_exp = v</span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            v_exp = torch.unsqueeze(v, <span class=number>2</span>)</span><br><span class=line>            v_exp = v_exp.expand(-<span class=number>1</span>, -<span class=number>1</span>, query_num, -<span class=number>1</span>, -<span class=number>1</span>, -<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        output = attn_orig_softmax_exp * v_exp  <span class=comment># (batch,5,channel,size,size)</span></span><br><span class=line>        output_sum = output.<span class=built_in>sum</span>(<span class=number>1</span>)  <span class=comment># (batch,1,channel,size,size)</span></span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> output_sum, attn_orig_softmax</span><br></pre></table></figure><p>训练的时候基本就拿这些特征给分类和回归的head做输出了.但是inference的时候设置了多种输出.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br></pre><td class=code><pre><span class=line><span class=keyword>if</span> inference == <span class=string>'softmax'</span>:</span><br><span class=line>              action = torch.argmax(prob_action, dim=<span class=number>2</span>)</span><br><span class=line>              num_connect = <span class=number>4</span></span><br><span class=line>              <span class=keyword>return</span> pred, prob_action, action, num_connect</span><br><span class=line>          <span class=keyword>elif</span> inference == <span class=string>'argmax_test'</span>:</span><br><span class=line>              action = torch.argmax(prob_action, dim=<span class=number>2</span>)</span><br><span class=line>              feat_argmax, num_connect = self.argmax_select(feat_map1, feat_map2, feat_map3, feat_map4, feat_map5,</span><br><span class=line>                                                            action, batch_size)</span><br><span class=line>              featmaps_argmax = feat_argmax.detach()</span><br><span class=line>              pred_argmax = self.decoder(featmaps_argmax)</span><br><span class=line>              <span class=keyword>return</span> pred_argmax, prob_action, action, num_connect</span><br><span class=line>          <span class=keyword>elif</span> inference == <span class=string>'activated'</span>:</span><br><span class=line>              feat_act, action, num_connect = self.activated_select(vals, prob_action)</span><br><span class=line>              featmaps_act = feat_act.detach()</span><br><span class=line>              pred_act = self.decoder(featmaps_act)</span><br><span class=line>              <span class=keyword>return</span> pred_act, prob_action, action, num_connect</span><br><span class=line>          <span class=keyword>else</span>:</span><br><span class=line>              <span class=keyword>raise</span> ValueError(<span class=string>'Incorrect inference mode'</span>)</span><br></pre></table></figure><p>argmax_select和activated分别如下<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br></pre><td class=code><pre><span class=line><span class=function><span class=keyword>def</span> <span class=title>argmax_select</span>(<span class=params>self, val_mat, prob_action</span>):</span></span><br><span class=line>        <span class=comment># v(batch, query_num, channel, size, size)</span></span><br><span class=line>        cls_num = prob_action.shape[<span class=number>1</span>]</span><br><span class=line>		<span class=comment>#  进行one hot编码,</span></span><br><span class=line>        coef_argmax = F.one_hot(prob_action.<span class=built_in>max</span>(dim=<span class=number>1</span>)[<span class=number>1</span>],  num_classes=cls_num).<span class=built_in>type</span>(torch.cuda.FloatTensor)</span><br><span class=line>        coef_argmax = coef_argmax.transpose(<span class=number>1</span>, <span class=number>2</span>)</span><br><span class=line>        attn_shape = coef_argmax.shape</span><br><span class=line>        bats, key_num, query_num = attn_shape[<span class=number>0</span>], attn_shape[<span class=number>1</span>], attn_shape[<span class=number>2</span>]</span><br><span class=line>        coef_argmax_exp = coef_argmax.view(bats, key_num, query_num, <span class=number>1</span>, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        v_exp = torch.unsqueeze(val_mat, <span class=number>2</span>)</span><br><span class=line>        v_exp = v_exp.expand(-<span class=number>1</span>, -<span class=number>1</span>, query_num, -<span class=number>1</span>, -<span class=number>1</span>, -<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        output = coef_argmax_exp * v_exp  <span class=comment># (batch,4,channel,size,size)</span></span><br><span class=line>        feat_argmax = output.<span class=built_in>sum</span>(<span class=number>1</span>)  <span class=comment># (batch,1,channel,size,size)</span></span><br><span class=line></span><br><span class=line>        <span class=comment># compute connect</span></span><br><span class=line>        count_coef = copy.deepcopy(coef_argmax)</span><br><span class=line>        ind = np.diag_indices(self.agent_num)</span><br><span class=line>        count_coef[:, ind[<span class=number>0</span>], ind[<span class=number>1</span>]] = <span class=number>0</span></span><br><span class=line>        num_connect = torch.nonzero(count_coef).shape[<span class=number>0</span>] / (self.agent_num * count_coef.shape[<span class=number>0</span>])</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> feat_argmax, coef_argmax, num_connect</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>activated_select</span>(<span class=params>self, val_mat, prob_action, thres=<span class=number>0.2</span></span>):</span></span><br><span class=line></span><br><span class=line>        coef_act = torch.mul(prob_action, (prob_action > thres).<span class=built_in>float</span>())</span><br><span class=line>        attn_shape = coef_act.shape</span><br><span class=line>        bats, key_num, query_num = attn_shape[<span class=number>0</span>], attn_shape[<span class=number>1</span>], attn_shape[<span class=number>2</span>]</span><br><span class=line>        coef_act_exp = coef_act.view(bats, key_num, query_num, <span class=number>1</span>, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        v_exp = torch.unsqueeze(val_mat, <span class=number>2</span>)</span><br><span class=line>        v_exp = v_exp.expand(-<span class=number>1</span>, -<span class=number>1</span>, query_num, -<span class=number>1</span>, -<span class=number>1</span>, -<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        output = coef_act_exp * v_exp  <span class=comment># (batch,4,channel,size,size)</span></span><br><span class=line>        feat_act = output.<span class=built_in>sum</span>(<span class=number>1</span>)  <span class=comment># (batch,1,channel,size,size)</span></span><br><span class=line></span><br><span class=line>        <span class=comment># compute connect</span></span><br><span class=line>        count_coef = coef_act.clone()</span><br><span class=line>        ind = np.diag_indices(self.agent_num)</span><br><span class=line>        count_coef[:, ind[<span class=number>0</span>], ind[<span class=number>1</span>]] = <span class=number>0</span></span><br><span class=line>        num_connect = torch.nonzero(count_coef).shape[<span class=number>0</span>] / (self.agent_num * count_coef.shape[<span class=number>0</span>])</span><br><span class=line>        <span class=keyword>return</span> feat_act, coef_act, num_connect\</span><br></pre></table></figure><h3 id=where2comm-2022><a title="where2comm 2022" class=headerlink href=#where2comm-2022></a>where2comm 2022</h3><p><img alt=image-20240228210811764 data-src=https://s2.loli.net/2024/02/28/5jYTmRyw2iIEQeb.png><p><img alt=image-20240228170628090 data-src=https://s2.loli.net/2024/02/28/Cj1SE42UmL9IWYR.png><p>其中 where2comm 包括observation encoder、spatial confidence generator、the spatial confidence-aware communication module、the spatial confidence-aware message fusion和detection decoder.<p>在五个模块中，<strong>spatial confidence generator</strong>可生成空间置信度图,基于该空间置信度图，<strong>空间置信度感知通信</strong>(spatial confidence-aware communication)可生成紧凑的信息和稀疏的通信图，以节省通信带宽.<strong>spatial confidence-aware message fusion</strong> module利用信息丰富的空间置信度先验来实现更好的聚合.<p>我们使用检测解码器结构来生成检测置信度图。给定第 k 轮通信的特征图 F (k) i，相应的空间置信度图为</p><script type="math/tex; mode=display">
\mathbf{C}_i^{(k)}=\Phi_\text{generator}(\mathcal{F}_i^{(k)})\in[0,1]^{H\times W}</script><p>为了在不影响感知的情况下减少通信带宽，我们利用空间置信度图来选择特征图中信息量最大的空间区域（在哪里通信），并决定最有利的合作对象（谁来通信）。<p>这个communication包括message packing。message packing决定了要发送的信息中应包含哪些信息。包括：i) 一张request图，表明代理需要了解哪些空间区域的更多信息；ii) 一张空间稀疏但感知关键的特征图。<h3 id=what2comm-2023><a title="what2comm 2023" class=headerlink href=#what2comm-2023></a>what2comm 2023</h3><h4 id=摘要><a class=headerlink href=#摘要 title=摘要></a>摘要</h4><p>多智能体协同感知作为驾驶场景的新兴应用受到越来越多的关注。尽管以前的方法取得了进步，但由于<strong>冗余的通信模式</strong>和<strong>脆弱的协作过程</strong>，挑战仍然存在。<p>为了解决这些问题，我们提出了What2comm，一个<strong>端到端协作感知框架，以实现感知性能和通信带宽之间的权衡</strong>。我们的新奇性在于三个方面<p>首先，我们设计了一种基于<strong>特征解耦的高效通信机制</strong>，在异构代理之间传输排他的和共同的特征映射，以提供感知上的整体消息。<p>其次，<strong>引入了一个时空协作模块来整合来自协作者的互补信息和时间自我线索</strong>，从而形成一个<strong>针对传输延迟和定位误差</strong>的鲁棒协作过程。<p>最后，我们提出了一种<strong>公共感知的融合策略</strong>来细化具有信息共同特征的最终表示。<p>在真实世界和模拟场景中进行的综合实验证明了What2通信的有效性。<p>DAIR-V2X:第一个用于支持协作感知的大规模真实世界数据集，它包含了标记的车辆和基础设施的激光雷达点云。它包括100个自动驾驶场景和18000个数据样本，其中训练/验证/测试集以5：2：3的比例被分割。<p>V2XSet<p>OPV2V<h4 id=方法><a class=headerlink href=#方法 title=方法></a>方法</h4><p>元数据编码和特征投影、基于解耦的通信机制、时空协作模块、common感知融合策略和检测解码器。<p>This framework comprises five parts: metadata encoding and feature projection, decoupling-based communication mechanism, spatio-temporal collaboration module, common-aware<p>fusion strategy, and detection decoders<blockquote><p><strong>特征解耦</strong>前提是学习特征，<strong>解耦是分离出任务相关特征和无关特征</strong>，以分类为例，解耦的是类别特征和无关的背景及样式等特征。特征解耦一般利用信息熵或者变换空间后的数学特性来完成。<p>只要两个对象之间存在一方依赖一方的关系，那么我们就称这两个对象之间存在耦合。<p>作者：大虎甜面酱<br>链接：<a href=https://www.jianshu.com/p/67dc5f5e05da rel=noopener target=_blank>https://www.jianshu.com/p/67dc5f5e05da</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</blockquote><p><img alt=image-20240228101157638 data-src=https://s2.loli.net/2024/02/28/Jr9OnUyvfEkcxtD.png><p><img alt=image-20240228165036544 data-src=https://s2.loli.net/2024/02/28/WFc8MJjfDOny1Zt.png><p>创新点:feature decoupling,latency-aware 使用过去的特征.<h3 id=how2comm-2023><a title="how2comm 2023" class=headerlink href=#how2comm-2023></a>how2comm 2023</h3><p>系what2comm同作者<h2 id=Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception><a title="Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception" class=headerlink href=#Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception></a>Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception</h2><p>在接收到自我代理播放的元数据（如姿势和外部特征）后，合作者将其本地激光雷达点云投射到自我代理的坐标系中。同样，<strong>自我代理之前的点云帧也会同步到当前帧</strong>。<p>给定第 k 个代理在时间戳 t 处的点云 X (t) k，提取的特征为 F (t) k =f enc (X (t) k )∈R C ×H ×W ，其中 f enc (-) 是所有代理共享的 PointPillar编码器，C、H、W 分别代表通道、高度和宽度。<h3 id=Context-aware-Information-Aggregation><a title="Context-aware Information Aggregation" class=headerlink href=#Context-aware-Information-Aggregation></a>Context-aware Information Aggregation</h3><p>解决latency的问题<p><img alt=image-20240304214842491 data-src=https://s2.loli.net/2024/03/04/4Qqgwk9uGciJBYj.png><p>遗憾的是，目前的多机器人协作总是专注于探索当前帧，而忽略了之前帧的上下文线索。由于点云的稀疏性和不足，单帧解决方案无法有效检测快速移动的物体（如周围的车辆）。为此，我们提出了一个情境感知信息聚合（CIA）组件，用于捕捉自我代理<strong>之前帧的时空表征，以融合有价值的语义</strong>。<p>选择性信息过滤。这一阶段的目的是通过过滤目标 F (t) i ∈R C ×H ×W 中的冗余特征，并从先前的 F^(t-τ)^~i~ ∈R τ ×C×H×W 中提炼出有意义的特征，从而提取精炼信息，其中 τ 是时间偏移。<p>具体来说，首先利用通道平均和最大池化运算 Ψ a/m (-) 聚合丰富的通道语义</p><script type="math/tex; mode=display">\mathcal{U}=\sigma\cdot\aleph(\mathcal{M}_{a}^{(t)}\|\mathcal{M}_{m}^{(t)}+\mathcal{M}_{a}^{(\tau)}\|\mathcal{M}_{m}^{(\tau)})\in\mathbb{R}^{H\times W}</script><p>将过去帧相加做个max与avg池化然后concat起来,当前的帧也同样处理,然后加起来做个conv.将这些细化的特征图结合起来，就能得到一个精心选择的空间选择图</p><script type="math/tex; mode=display">H_i^{(\tau)}=(1-\mathcal{U})\odot tanh(F_i^{(t)})+\mathcal{U}\odot F_i^{(t-\tau)}</script><h4 id=Spatio-temporal-Feature-Integration><a title="Spatio-temporal Feature Integration." class=headerlink href=#Spatio-temporal-Feature-Integration></a>Spatio-temporal Feature Integration.</h4><p>为了整合historical prototype以提高当前表征的感知能力，我们引入了金字塔 LSTM来学习帧间特征 F (t) i ∥H (τ ) i 的上下文依赖关系。<p>在实践中，多尺度空间特征是通过在不同尺度之间连续进行两次二维卷积，然后进行批量归一化和 ReLU 激活来提取的。为了实现多层次空间语义融合，<strong>降低采样率的特征会通过横向连接逐步插值到提高采样率的层</strong>。<h3 id=Confidence-aware-Cross-agent-Collaboration><a title="Confidence-aware Cross-agent Collaboration" class=headerlink href=#Confidence-aware-Cross-agent-Collaboration></a>Confidence-aware Cross-agent Collaboration</h3><p>跨代理协作的目标是通过聚合协作者共享特征的互补语义来增强自我代理的视觉表征。<p>现有研究提出了基于注意力的per-location特征融合方法，但这种方法容易受到定位误差的影响，而且忽略了点云的稀疏性。为了解决这些问题，我们采用了a <strong>novel Confidenceaware Cross-agent Collaboration (CCC) component</strong><p><img alt=image-20240304221451619 data-src=https://s2.loli.net/2024/03/04/4zjauARgEMekoSt.png><p>CCC 组件将特征和置信度图编码为三个尺度，<strong>并在每个尺度上进行特征融合</strong>。<p>F^(t)^~k,l~ 和 S^(t)^~k,l~ 表示第 l 个尺度的特征图和置信度图.<p>为了预测包含有意义物体信息的空间位置，我们将所有置信度图的元素求和.<p>由于置信度图反映的是空间临界水平，S^(t)^~sum,l~ 显示的是探测范围内目标的潜在位置，称为参考点。<p>因此，我们采用基于阈值的选择函数 fsel(-) 来提取参考点 S^(t)^~re,l~。这种设计可以积极引导后续的融合网络集中在重要的空间区域。<p><strong>Deformable Cross-attention Module</strong> 我们在参考点提取自我代理的特征 F^(t)^ ~i,l~ 作为初始查询嵌入，并<strong>应用线性层将参考点的位置编码为位置嵌入</strong><p>为了解决特征图的不对齐问题，并获得更稳健的表征以抵御定位误差，可变形交叉注意模块（DCM）通过可变形交叉注意层聚合来自采样关键点的信息</p><script type="math/tex; mode=display">\mathrm{DCM}(q)=\sum_{a=1}^{\Lambda}W_{a}[\sum_{k=1}^{K}\sum_{m=1}^{M}\phi(W_{b}F_{i,l}^{(t)}(q))F_{k,l}^{(t)}(q+\Delta q_{m})],</script><p>Wa/b 是可学习权重，φ(-) 是软最大函数。最后，我们得出一个填充操作，根据初始位置 q 将 DCM(q) 填充到自我代理的特征 F (t) i,l 中，并输出 Z(t) i,l<p>三个尺度下的输出增强特征被编码成相同的大小，并在通道维度上进行串联。我们利用 1 × 1 卷积层融合三个尺度的信息，得到最终的协作特征 Z^(t)^~i~∈ R^C×H×W^<h3 id=Importance-aware-Adaptive-Fusion><a title="Importance-aware Adaptive Fusion" class=headerlink href=#Importance-aware-Adaptive-Fusion></a>Importance-aware Adaptive Fusion</h3><p>尽管之前的研究通过汇总协作信息的自我特征取得了令人印象深刻的性能，但它们可能会受到异步测量的协作者带来的噪声干扰。A promising solution is to <strong>consider purely ego-centered characteristics</strong>, which contain the natural perception advantages of the target agent.<p>我们提出了一种重要性感知自适应融合（IAF）组件，根据多源特征的互补性对其进行融合。</p><script type="math/tex; mode=display">\mathcal{H}_{i}^{(t)},\mathcal{Z}_{i}^{(t)},\mathcal{S}_{i}^{(t)}=\sigma\cdot\Psi_{m}(f_{gen}(H_{i}^{(t)},Z_{i}^{(t)},F_{i}^{(t)}))</script><script type="math/tex; mode=display">\mathcal{E}_{\mathcal{H}}^{(t)}=\phi(\mathcal{H}_{i}^{(t)})=\frac{exp(\mathcal{H}_{i}^{(t)})}{exp(\mathcal{H}_{i}^{(t)})+exp(\mathcal{Z}_{i}^{(t)})+exp(\mathcal{S}_{i}^{(t)})}.$$​

$$\mathcal{F}_i^{(t)}=\mathcal{E}_{\mathcal{H}}^{(t)}\odot H_i^{(t)}+\mathcal{E}_{\mathcal{Z}}^{(t)}\odot Z_i^{(t)}+\mathcal{E}_{\mathcal{S}}^{(t)}\odot F_i^{(t)}.</script><h3 id=FPV-RCNN-2021><a title="FPV-RCNN 2021" class=headerlink href=#FPV-RCNN-2021></a>FPV-RCNN 2021</h3><p><a href=https://arxiv.org/abs/2109.11615 rel=noopener target=_blank>[2109.11615] Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of Autonomous Driving (arxiv.org)</a><h3 id=Collaborative-3d-object-detection-for-automatic-vehicle-systems-via-learnable-communications-2022><a title="Collaborative 3d object detection for automatic vehicle systems via learnable communications 2022" class=headerlink href=#Collaborative-3d-object-detection-for-automatic-vehicle-systems-via-learnable-communications-2022></a>Collaborative 3d object detection for automatic vehicle systems via learnable communications 2022</h3><p><a href=https://arxiv.org/pdf/2205.11849.pdf rel=noopener target=_blank>2205.11849.pdf (arxiv.org)</a><p><img alt=image-20240229172548113 data-src=https://s2.loli.net/2024/02/29/RANi2pLbKPZslu5.png><p><img alt=image-20240229172522190 data-src=https://s2.loli.net/2024/02/29/RP1nMsk5h2B4pzj.png><h2 id=Customized-Loss><a title="Customized Loss" class=headerlink href=#Customized-Loss></a>Customized Loss</h2><p>除了分类和回归损失之外，虽然 V2V 通信为自我车辆提供了相对丰富的感知视野，但<strong>共享信息的冗余性</strong>和<strong>不确定性</strong>带来了新的挑战。<p>在协作场景中，邻居代理提供的类似信息对自我车辆来说是冗余的。为了有效利用协作信息，Luo 等人提出了一种互补增强和冗余最小化的协作网络（CRCNet）。具体来说，CRCNet 有两个模块来引导网络。在互补性增强模块中，CRCNet 利用对比学习来增强信息增益。在冗余最小化模块中，CRCNet 利用互信息鼓励融合特征对中的依赖性。在上述模块的指导下，CRCNet 能够在融合特征时从相邻代理中选择互补信息。</p><script type="math/tex; mode=display">
P_{i}=P_{i}+W_{k\rightarrow i}^{C}\odot P_{k\rightarrow i}\odot W_{k\rightarrow i}^{s} \\
\delta_{k}=\sum_{n}L_{cls}\big(p_{j}^{n}(P_{i}),y_{j}^{n}\big)-\sum_{n}L_{cls}\big(p_{j}^{n}(P_{i}+T_{i}^{k}),y_{j}^{n}\big) \\
L_{eff}=\sum_k\min(\delta_k-\delta_{thd},0)^2 \\
I[T_i^k;T_i^l]=\sum\limits_{x\in T_i^k}\sum\limits_{y\in T_i^l}p(x,y)\log\frac{p(x,y)}{p(x)p(y)} \\
\begin{aligned}
I[T_{i}^{k};T_{i}^{l}]=& \mathbb{E}_{p(T_{i}^{k};T_{i}^{l})}[\logq_{\theta_{2}}(T_{i}^{l}/T_{i}^{k})]  \\
&-\mathbb{E}_{p(T_{i}^{k})}\mathbb{E}_{p(T_{i}^{l})}[\logq_{\theta_{2}}(T_{i}^{l}/T_{i}^{k})],
\end{aligned} \\
L_{red}=\sum_k\sum_l[\logq_{\theta_2}(T_i^l/T_i^k)-\logq_{\theta_2}(T_i^l/T_n^k)]\\
min_{Q}L_{KL}=KL(p(T_i^k/T_i^l)||q_{\theta_2}(T_i^k/T_i^l) \\
L=L_{cls}+L_{loc}+L_{red}+L_{eff}\\</script><p><img alt=image-20240229180846509 data-src=https://s2.loli.net/2024/02/29/a5NIGnJloEwK4Hp.png><p>除了冗余信息，协作信息还包含感知上的不确定性，这反映了感知上的不准确或传感器噪声。Su 等人首先探讨了协作感知中的不确定性。具体来说，他们设计了一种量身定制的移动块引导方法来估计模型和数据的不确定性，并设计了一个良好的损失函数来直接捕捉数据的不确定性。实验表明，在不同的协作方案中，不确定性估计可以减少不确定性并提高准确性。<h3 id=FeaCo-2023-MM><a title="FeaCo 2023 MM" class=headerlink href=#FeaCo-2023-MM></a>FeaCo 2023 MM</h3><p><img alt=FeaCo_Overview data-src=https://github.com/jmgu0212/FeaCo/raw/main/images/Overview.png><p>主要看其中的融合模块<p><img alt=image-20240401134935564 data-src=https://proanimer-img.oss-cn-shanghai.aliyuncs.com/alimg/image-20240401134935564.png><h4 id=摘要-1><a class=headerlink href=#摘要-1 title=摘要></a>摘要</h4><p>协作感知为克服遮挡和远程数据处理等挑战提供了一种有前景的解决方案。<strong>然而</strong>，有限的传感器精度会导致车辆姿态出现噪声，导致车辆之间的观察不一致。<p><strong>为了解决这个问题</strong>，我们提出了 FeaCo，它可以在嘈杂的姿势条件下在协作代理之间实现强大的特征级共识，而无需额外的训练。<p>我们<strong>设计了一个</strong>高效的姿态误差校正模块（PRM）来对齐来自不同车辆的派生特征图，减少噪声姿态和带宽要求的不利影响。我们<strong>还提供了</strong>有效的多尺度跨级注意力模块（CAM）来增强各种尺度之间的信息聚合和交互。<p>我们的 FeaCo <strong>优于所有其他定位校正方法</strong>，<strong>经协作感知模拟数据集 OPV2V 和现实数据集 V2V4Real 验证</strong>，<strong>减少了航向误差并提高了各种误差级别的定位精度</strong>。<p>Collaborative perception offers a promising solution to overcome challenges such as occlusion and long-range data processing. However, limited sensor accuracy leads to noisy poses that misalign observations among vehicles.<p>To address this problem, we propose the FeaCo, which achieves robust Feature-level Consensus among collaborating agents in noisy pose conditions without additional training.<p>We design an efficient Pose-error Rectification Module (PRM) to align derived feature maps from different vehicles, reducing the adverse effect of noisy pose and bandwidth requirements. We also provide an effective multi-scale Cross-level Attention Module (CAM) to enhance information aggregation and interaction between various scales.<p>Our FeaCo outperforms all other localization rectification methods, as validated on both the collaborative perception simulation dataset OPV2V and real-world dataset V2V4Real, reducing heading error and enhancing localization accuracy across various error levels.</p><link href=/css/spoiler.css rel=stylesheet><script async src=/js/spoiler.js></script></div><div><div><div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div class=reward-container><div>感谢阅读.</div><button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">打赏</button><div style="display: none;" id=qr><div style="display: inline-block;"><img alt="Sekyoro 微信支付" src=/images/wechatpay.png><p>微信支付</div></div></div><div><ul class=post-copyright><li class=post-copyright-author><strong>本文作者： </strong>Sekyoro<li class=post-copyright-link><strong>本文链接：</strong> <a href=https://www.sekyoro.top/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/ title=协同融合代码学习>https://www.sekyoro.top/2024/01/31/协同融合代码学习/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ rel=noopener target=_blank><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</ul></div><div class=followme><p>欢迎关注我的其它发布渠道<div class=social-list><div class=social-item><a class=social-link href=/images/wxqrcode.png target=_blank> <span class=icon> <i class="fab fa-weixin"></i> </span> <span class=label>WeChat</span> </a></div><div class=social-item><a class=social-link href=/images/website.png target=_blank> <span class=icon> <i class="fa fa-user"></i> </span> <span class=label>PersonalWebsite</span> </a></div><div class=social-item><a class=social-link href=https://my-astro-git-main-drowning-in-codes.vercel.app target=_blank> <span class=icon> <i class="fas fa-share"></i> </span> <span class=label>杂鱼分享</span> </a></div><div class=social-item><a class=social-link href=/atom.xml target=_blank> <span class=icon> <i class="fa fa-rss"></i> </span> <span class=label>RSS</span> </a></div></div></div><footer class=post-footer><div class=post-nav><div class=post-nav-item><a title="transformer and attention(二):various attention modules" href=/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/ rel=prev> <i class="fa fa-chevron-left"></i> transformer and attention(二):various attention modules </a></div><div class=post-nav-item><a href=/2024/02/03/%E5%9B%9E%E5%A4%B4%E5%86%8D%E7%9C%8B%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6/ rel=next title=回头再看前端框架> 回头再看前端框架 <i class="fa fa-chevron-right"></i> </a></div></div></footer></article></div><!-- 评论区 --><div class=comments><div data-id=city data-uid=MTAyMC81MzE5Ny8yOTY3Mg== id=lv-container></div></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class=sidebar><div class=sidebar-inner><!-- canvas粒子时钟 --><div><canvas id=canvas style=width:60%;>当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();</script><!-- require APlayer --><link href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><!-- require MetingJS --><script src=/js/meting-js.js></script><ul class="sidebar-nav motion-element"><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#Coperceptions><span class=nav-number>1.</span> <span class=nav-text>Coperceptions</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#V2VNet><span class=nav-number>1.1.</span> <span class=nav-text>V2VNet</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#V2xvit><span class=nav-number>1.2.</span> <span class=nav-text>V2xvit</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#DiscoNet><span class=nav-number>1.3.</span> <span class=nav-text>DiscoNet</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#Comunicaton-Mechanism><span class=nav-number>2.</span> <span class=nav-text>Comunicaton Mechanism</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#who2com-2020><span class=nav-number>2.1.</span> <span class=nav-text>who2com 2020</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#when2comm-2020><span class=nav-number>2.2.</span> <span class=nav-text>when2comm 2020</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#where2comm-2022><span class=nav-number>2.3.</span> <span class=nav-text>where2comm 2022</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#what2comm-2023><span class=nav-number>2.4.</span> <span class=nav-text>what2comm 2023</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%91%98%E8%A6%81><span class=nav-number>2.4.1.</span> <span class=nav-text>摘要</span></a><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%96%B9%E6%B3%95><span class=nav-number>2.4.2.</span> <span class=nav-text>方法</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#how2comm-2023><span class=nav-number>2.5.</span> <span class=nav-text>how2comm 2023</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception><span class=nav-number>3.</span> <span class=nav-text>Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#Context-aware-Information-Aggregation><span class=nav-number>3.1.</span> <span class=nav-text>Context-aware Information Aggregation</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#Spatio-temporal-Feature-Integration><span class=nav-number>3.1.1.</span> <span class=nav-text>Spatio-temporal Feature Integration.</span></a></ol><li class="nav-item nav-level-3"><a class=nav-link href=#Confidence-aware-Cross-agent-Collaboration><span class=nav-number>3.2.</span> <span class=nav-text>Confidence-aware Cross-agent Collaboration</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Importance-aware-Adaptive-Fusion><span class=nav-number>3.3.</span> <span class=nav-text>Importance-aware Adaptive Fusion</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#FPV-RCNN-2021><span class=nav-number>3.4.</span> <span class=nav-text>FPV-RCNN 2021</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#Collaborative-3d-object-detection-for-automatic-vehicle-systems-via-learnable-communications-2022><span class=nav-number>3.5.</span> <span class=nav-text>Collaborative 3d object detection for automatic vehicle systems via learnable communications 2022</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#Customized-Loss><span class=nav-number>4.</span> <span class=nav-text>Customized Loss</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#FeaCo-2023-MM><span class=nav-number>4.1.</span> <span class=nav-text>FeaCo 2023 MM</span></a><ol class=nav-child><li class="nav-item nav-level-4"><a class=nav-link href=#%E6%91%98%E8%A6%81-1><span class=nav-number>4.1.1.</span> <span class=nav-text>摘要</span></a></ol></ol></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=Sekyoro class=site-author-image itemprop=image src=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg><p class=site-author-name itemprop=name>Sekyoro<div class=site-description itemprop=description>什么也无法舍弃的人，什么也做不了.</div></div><div class="site-state-wrap motion-element"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>186</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>17</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>188</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a title="Personal Website → http://proanimer.com" href=http://proanimer.com/ rel=noopener target=_blank><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a> </span><span class=links-of-author-item> <a title="GitHub → https://github.com/drowning-in-codes" href=https://github.com/drowning-in-codes rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a title="E-Mail → mailto:bukalala174@gmail.com" href=mailto:bukalala174@gmail.com rel=noopener target=_blank><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class=links-of-author-item> <a title="wxPublicAccount → https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" href=https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd rel=noopener target=_blank><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a> </span><span class=links-of-author-item> <a title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span><span class=links-of-author-item> <a title="CSDN → https://blog.csdn.net/aqwca" href=https://blog.csdn.net/aqwca rel=noopener target=_blank><i class="fa fa-handshake fa-fw"></i>CSDN</a> </span><span class=links-of-author-item> <a title="杂鱼分享 → https://my-astro-git-main-drowning-in-codes.vercel.app" href=https://my-astro-git-main-drowning-in-codes.vercel.app/ rel=noopener target=_blank><i class="fas fa-share fa-fw"></i>杂鱼分享</a> </span></div><div class="links-of-blogroll motion-element"><div class=links-of-blogroll-title><i class="fa fa-link fa-fw"></i> 友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=http://myqhs.top/ rel=noopener target=_blank title=http://myqhs.top/>myqhs</a><li class=links-of-blogroll-item><a href=https://www.lllomh.com/ rel=noopener target=_blank title=https://www.lllomh.com/>芈渡</a></ul></div><div class="motion-element announcement"><div class=title>注意</div><p class=content>由于最近图床更新,可能有些图片显示不了.如果发现了有些图片无法显示影响阅读的,还烦请联系我,我有空补上.<p class=date>2023-10-6</div></div><meting-js id=6856787487 order=random server=netease type=playlist> </meting-js><div class=widget-wrap><h3 class=widget-title style=margin:0>此文章目前无词云</h3></div><script id=clustrmaps src=https://clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a></script><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i><span>0%</span></div><!-- 边栏 --></div></aside><div id=sidebar-dimmer></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – <span itemprop=copyrightYear>2024</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Sekyoro</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-chart-area"></i> </span><span title=站点总字数>1.4m</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span><span title=站点阅读时长>20:31</span></div><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container_site_pv>总访问量<span id=busuanzi_value_site_pv></span>次</span><span class=post-meta-divider>|</span><span id=busuanzi_container_site_uv>总访客数<span id=busuanzi_value_site_uv></span>人</span><span class=post-meta-divider>|</span><!-- 不蒜子计数初始值纠正 --><script>$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});</script><div><span id=timeDate>载入天数...</span><span id=times>载入时分秒...</span><script>var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);</script></div><div class=busuanzi-count><script async data-pjax src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span style="display: none;" class=post-meta-item id=busuanzi_container_site_uv> <span class=post-meta-item-icon> <i class="fa fa-user"></i> </span> <span class=site-uv title=总访客量> <span id=busuanzi_value_site_uv></span> </span> </span><span class=post-meta-divider>|</span><span style="display: none;" class=post-meta-item id=busuanzi_container_site_pv> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=site-pv title=总访问量> <span id=busuanzi_value_site_pv></span> </span> </span></div></div></footer></div><script color=0,0,255 count=99 opacity=0.5 src=/lib/canvas-nest/canvas-nest.min.js zindex=-1></script><script src=/lib/anime.min.js></script><script src=https://cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js></script><script src=https://cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/schemes/pisces.js></script><script src=/js/next-boot.js></script><script src=/js/bookmark.js></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	'.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});</script><script data-pjax>(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();</script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js></script><script src=/js/algolia-search.js></script><script data-pjax>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><div id=pjax><script charset=utf-8 defer src=/js/outdate.js></script></div><script charset=utf-8 defer src=/js/tagcanvas.js></script><script charset=utf-8 defer src=/js/tagcloud.js></script><script>NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});</script><script>var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });</script><script src=/js/src/activate-power-mode.min.js></script><script>POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);</script>