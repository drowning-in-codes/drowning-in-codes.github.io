<!doctypehtml><html lang=zh-CN><script defer src=/live2d-widget/autoload.js></script><meta charset=UTF-8><meta content=width=device-width,initial-scale=1,maximum-scale=2 name=viewport><meta content=#222 name=theme-color><meta content="Hexo 5.4.0" name=generator><link href=/images/blog_32px.png rel=apple-touch-icon sizes=180x180><link href=/images/blog_32px.png rel=icon sizes=32x32 type=image/png><link href=/images/blog_16px.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><meta content=EPrJAp11bJwHULpQUaSNSZ8_3RcvTsPDAEGOME4pl1w name=google-site-verification><!-- Google tag (gtag.js) --><!-- 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB21D8MKKW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VB21D8MKKW');
</script> --><!-- google adsense in head.swig --><script async crossorigin=anonymous src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4034523802263123></script><meta content=7226864CE87CE9DE8C008385273846FF name=msvalidate.01><meta content=code-fjFXVtiL7j name=baidu-site-verification><link href=/css/main.css rel=stylesheet><link as=style href=https://fonts.googleapis.com/css?family=Roboto%20Mono,Roboto:300,300italic,400,400italic,700,700italic|Roboto:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext onload=this.rel='stylesheet' rel=preload><link as=style href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css onload=this.rel='stylesheet' rel=preload><link href=https://fonts.googleapis.com/css?family=Noto+Serif+SC|Roboto&display=swap rel=stylesheet><link href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/pace-js@1/pace.min.js></script><script id=hexo-configurations>var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.sekyoro.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"0F9LEEVW82","apiKey":"78839e9f9be09d081c5c4da81975cd19","indexName":"sekyoblog_sec","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};</script><link href=//cdn.bootcss.com/animate.css/3.5.0/animate.min.css rel=stylesheet><meta content=介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码. name=description><meta content=article property=og:type><meta content="transformer and attention(二):various attention modules" property=og:title><meta content=https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/index.html property=og:url><meta content=Sekyoro的博客小屋 property=og:site_name><meta content=介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码. property=og:description><meta content=zh_CN property=og:locale><meta content=https://s2.loli.net/2024/01/10/Lq6VRkQuoUpYSmc.png property=og:image><meta content=https://s2.loli.net/2024/01/10/ZrhKeEALunoDxpF.png property=og:image><meta content=https://s2.loli.net/2024/01/23/7XzeCTDLwFEuiSM.png property=og:image><meta content=https://s2.loli.net/2024/01/23/3PEUjp2y9aMLI8u.png property=og:image><meta content=https://s2.loli.net/2024/01/23/R9GMVDrs23ca7Qp.png property=og:image><meta content=https://s2.loli.net/2024/01/10/uPRhgXEveC9JbFS.png property=og:image><meta content=https://s2.loli.net/2024/01/10/wxDGep963Qzs5tq.png property=og:image><meta content=https://s2.loli.net/2024/01/10/hyUFPErbDKB3TwI.png property=og:image><meta content=https://s2.loli.net/2024/01/10/MQNWLjZP2yH8cwd.png property=og:image><meta content=https://s2.loli.net/2024/01/11/IW6cKRTQN178kp4.png property=og:image><meta content=https://s2.loli.net/2024/01/19/9eNWHCpuiFsYLtU.png property=og:image><meta content=https://s2.loli.net/2024/01/23/ypZfsSKPBq9iLV6.png property=og:image><meta content=https://pic4.zhimg.com/80/v2-322dae3099e1ed29c2751c7c7efd88b7_720w.webp property=og:image><meta content=https://pic4.zhimg.com/80/v2-03942c1de5a5a77aafbdb1a1fe697fb3_720w.webp property=og:image><meta content=https://s2.loli.net/2024/01/19/ZrmAMkChLcbFpfg.png property=og:image><meta content=2024-01-23T12:18:17.000Z property=article:published_time><meta content=2024-01-24T06:01:28.000Z property=article:modified_time><meta content=Sekyoro property=article:author><meta content="deep learning" property=article:tag><meta content=summary name=twitter:card><meta content=https://s2.loli.net/2024/01/10/Lq6VRkQuoUpYSmc.png name=twitter:image><link href=https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/ rel=canonical><script id=page-configurations>// https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };</script><title>transformer and attention(二):various attention modules | Sekyoro的博客小屋</title><noscript><style>.use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }</style></noscript><link href=/atom.xml rel=alternate title=Sekyoro的博客小屋 type=application/atom+xml><body itemscope itemtype=http://schema.org/WebPage><canvas style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" class=fireworks></canvas><script defer src=https://cdn.bootcss.com/animejs/2.2.0/anime.min.js></script><script defer src=/js/src/fireworks.js></script><div class="container use-motion"><div class=headband></div><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <h1 class=site-title>Sekyoro的博客小屋</h1> <span class=logo-line-after><i></i></span> </a></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu" id=menu><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-bangumis"><a href=/bangumis/ rel=section><i class="fa fa-film fa-fw"></i>追番</a><li class="menu-item menu-item-resume"><a href=/resume/ rel=section><i class="fa fa-file-pdf fa-fw"></i>简历</a><li class="menu-item menu-item-materials"><a href=/materials/ rel=section><i class="fa fa-book fa-fw"></i>学习资料</a><li class="menu-item menu-item-sitemap"><a href=/sitemap.xml rel=section><i class="fa fa-sitemap fa-fw"></i>站点地图</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container></div><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span></div><div class=algolia-results><div id=algolia-stats></div><div id=algolia-hits></div><div class=algolia-pagination id=algolia-pagination></div></div></div></div></div></header><a class="book-mark-link book-mark-link-fixed" role=button></a><main class=main><div class=main-inner><div class=content-wrap><div class="content post posts-expand"><article class=post-block itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg itemprop=image> <meta content=Sekyoro itemprop=name> <meta content=什么也无法舍弃的人，什么也做不了. itemprop=description> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=Sekyoro的博客小屋 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>transformer and attention(二):various attention modules</h1><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2024-01-23 20:18:17" datetime=2024-01-23T20:18:17+08:00>2024-01-23</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2024-01-24 14:01:28" datetime=2024-01-24T14:01:28+08:00 itemprop=dateModified>2024-01-24</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/deep-learning/ itemprop=url rel=index><span itemprop=name>deep learning</span></a> </span> </span><span style="display: none;" class=post-meta-item id=busuanzi_container_page_pv title=阅读次数> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=post-meta-item-text>阅读次数：</span> <span id=busuanzi_value_page_pv></span> </span><br><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>18k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>16 分钟</span> </span></div></header><div class=post-body itemprop=articleBody><div class=post-tags><a href=/tags/deep-learning/ rel=tag># deep learning</a></div><p>介绍现在的各种各样(空间上,通道上)的attention模块以及相关代码.<br><span id=more></span><h2 id=Squeeze-and-Excitation-Networks-2018><a title="Squeeze-and-Excitation Networks 2018" class=headerlink href=#Squeeze-and-Excitation-Networks-2018></a>Squeeze-and-Excitation Networks 2018</h2><p><img alt=image-20240110094833740 data-src=https://s2.loli.net/2024/01/10/Lq6VRkQuoUpYSmc.png><blockquote><ol><li>SENet通过学习channel之间的相关性，筛选出了针对通道的注意力，稍微增加了一点计算量，但是效果提升较明显<li>Squeeze-and-Excitation(SE) block是一个子结构，可以有效地嵌到其他分类或检测模型中。<li>SENet的核心思想在于通过网络根据loss去学习feature map的特征权重来使模型达到更好的结果<li>SE模块本质上是一种attention机制</ol></blockquote><p><img alt=image-20240110095007870 data-src=https://s2.loli.net/2024/01/10/ZrhKeEALunoDxpF.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> numpy <span class=keyword>as</span> np</span><br><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>from</span> torch <span class=keyword>import</span> nn</span><br><span class=line><span class=keyword>from</span> torch.nn <span class=keyword>import</span> init</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=comment># implement SEAttention</span></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>SEAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, channel=<span class=number>512</span>, reduction=<span class=number>16</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(SEAttention, self).__init__()</span><br><span class=line>        self.avg_pool = nn.AdaptiveAvgPool2d(<span class=number>1</span>)</span><br><span class=line>        self.fc = nn.Sequential(</span><br><span class=line>            nn.Linear(channel, channel // reduction),</span><br><span class=line>            nn.ReLU(),</span><br><span class=line>            nn.Linear(channel // reduction, channel),</span><br><span class=line>            nn.Sigmoid()</span><br><span class=line>        )</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>init_weights</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=keyword>for</span> m <span class=keyword>in</span> self.modules():</span><br><span class=line>            <span class=keyword>if</span> <span class=built_in>isinstance</span>(m, nn.Conv2d):</span><br><span class=line>                init.kaiming_normal_(m.weight, mode=<span class=string>'fan_out'</span>)</span><br><span class=line>                <span class=keyword>if</span> m.bias <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span>:</span><br><span class=line>                    init.constant_(m.bias, <span class=number>0</span>)</span><br><span class=line>            <span class=keyword>elif</span> <span class=built_in>isinstance</span>(m, nn.BatchNorm2d):</span><br><span class=line>                init.constant_(m.weight, <span class=number>1</span>)</span><br><span class=line>                init.constant_(m.bias, <span class=number>0</span>)</span><br><span class=line>            <span class=keyword>elif</span> <span class=built_in>isinstance</span>(m, nn.Linear):</span><br><span class=line>                init.normal_(m.weight, std=<span class=number>0.001</span>)</span><br><span class=line>                <span class=keyword>if</span> m.bias <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span>:</span><br><span class=line>                    init.constant_(m.bias, <span class=number>0</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        b, c, _, _ = x.size()</span><br><span class=line>        y = self.avg_pool(x).view(b, c)</span><br><span class=line>        y = self.fc(y).view(b, c, <span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        <span class=keyword>return</span> x * y.expand_as(x)</span><br></pre></table></figure><h2 id=Bottlenet-attention-Module-BAM-2018><a title="Bottlenet attention Module (BAM) 2018" class=headerlink href=#Bottlenet-attention-Module-BAM-2018></a>Bottlenet attention Module (BAM) 2018</h2><p><img alt=image-20240123200825093 data-src=https://s2.loli.net/2024/01/23/7XzeCTDLwFEuiSM.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line><span class=keyword>from</span> torch.nn <span class=keyword>import</span> init</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>Flatten</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, <span class=built_in>input</span></span>):</span></span><br><span class=line>        <span class=keyword>return</span> <span class=built_in>input</span>.view(<span class=built_in>input</span>.size(<span class=number>0</span>), -<span class=number>1</span>)</span><br><span class=line></span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>ChannelAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,channel,reduction:<span class=built_in>int</span>=<span class=number>16</span>,num_layer:<span class=built_in>int</span>=<span class=number>3</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.avg_pool = nn.AdaptiveAvgPool2d(<span class=number>1</span>)</span><br><span class=line>        gate_channels = [channel]</span><br><span class=line>        gate_channels += [channel // reduction] * num_layer</span><br><span class=line>        gate_channels += [channel]</span><br><span class=line></span><br><span class=line>        self.ca = nn.Sequential()</span><br><span class=line>        self.ca.add_module(<span class=string>'flatten'</span>,Flatten())</span><br><span class=line>        <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(num_layer):</span><br><span class=line>            self.ca.add_module(<span class=string>'fc{}'</span>.<span class=built_in>format</span>(i),nn.Linear(gate_channels[i],gate_channels[i+<span class=number>1</span>]))</span><br><span class=line>            self.ca.add_module(<span class=string>'bn%d'</span> % i, nn.BatchNorm1d(gate_channels[i+<span class=number>1</span>]))</span><br><span class=line>            self.ca.add_module(<span class=string>'relu{}'</span>.<span class=built_in>format</span>(i),nn.ReLU())</span><br><span class=line></span><br><span class=line>        self.ca.add_module(<span class=string>'last_fc'</span>,nn.Linear(gate_channels[-<span class=number>2</span>],gate_channels[-<span class=number>1</span>]))</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self,x</span>):</span></span><br><span class=line>        res = self.avg_pool(x)</span><br><span class=line>        res = self.ca(res)</span><br><span class=line>        <span class=keyword>return</span> res.unsqueeze(-<span class=number>1</span>).unsqueeze(-<span class=number>1</span>).expand_as(x)</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>SpatialAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,channel,reduction=<span class=number>16</span>,num_layers=<span class=number>3</span>,dia_val=<span class=number>2</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.sa = nn.Sequential()</span><br><span class=line>        self.sa.add_module(<span class=string>'conv_reduce1'</span>,nn.Conv2d(in_channels=channel,out_channels=channel//reduction,kernel_size=<span class=number>1</span>))</span><br><span class=line>        self.sa.add_module(<span class=string>'bn_reduce1'</span>,nn.BatchNorm2d(channel//reduction))</span><br><span class=line>        self.sa.add_module(<span class=string>'relu_reduce1'</span>,nn.ReLU())</span><br><span class=line>        <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(num_layers):</span><br><span class=line>            self.sa.add_module(<span class=string>'conv_%d'</span> % i,nn.Conv2d(in_channels=channel//reduction,out_channels=channel//reduction,kernel_size=<span class=number>3</span>,padding=<span class=number>1</span>,dilation=dia_val))</span><br><span class=line>            self.sa.add_module(<span class=string>'bn_%d'</span> % i,nn.BatchNorm2d(channel//reduction))</span><br><span class=line>            self.sa.add_module(<span class=string>'relu_%d'</span> % i,nn.ReLU())</span><br><span class=line>        self.sa.add_module(<span class=string>'conv_last'</span>,nn.Conv2d(in_channels=channel//reduction,out_channels=channel,kernel_size=<span class=number>1</span>))</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self,x</span>):</span></span><br><span class=line>        res = self.sa(x)</span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> res.expand_as(x)</span><br><span class=line></span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>BAMBlock</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,channel:<span class=built_in>int</span>=<span class=number>512</span>,reduction:<span class=built_in>int</span>=<span class=number>16</span>,dia_val:<span class=built_in>int</span>=<span class=number>2</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.ca = ChannelAttention(channel=channel,reduction=reduction)</span><br><span class=line>        self.sa = SpatialAttention(channel=channel,reduction=reduction,dia_val=dia_val)</span><br><span class=line>        self.sigmoid = nn.Sigmoid()</span><br><span class=line>        self.init_weights()</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self,x</span>):</span></span><br><span class=line>        b, c, _, _ = x.size()</span><br><span class=line>        sa_out = self.sa(x)</span><br><span class=line>        ca_out = self.ca(x)</span><br><span class=line>        weight = self.sigmoid(sa_out + ca_out)</span><br><span class=line>        out = (<span class=number>1</span> + weight) * x</span><br><span class=line>        <span class=keyword>return</span> out</span><br><span class=line></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>init_weights</span>(<span class=params>self</span>):</span></span><br><span class=line>        <span class=comment># initial weights for the model</span></span><br><span class=line>        <span class=keyword>for</span> m <span class=keyword>in</span> self.modules():</span><br><span class=line>            <span class=keyword>if</span> <span class=built_in>isinstance</span>(m, nn.Conv2d):</span><br><span class=line>                nn.init.kaiming_normal_(m.weight, mode=<span class=string>'fan_in'</span>, nonlinearity=<span class=string>'relu'</span>)</span><br><span class=line>                <span class=keyword>if</span> m.bias <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span>:</span><br><span class=line>                    init.constant_(m.bias, <span class=number>0</span>)</span><br><span class=line>            <span class=keyword>elif</span> <span class=built_in>isinstance</span>(m,nn.BatchNorm2d):</span><br><span class=line>                init.constant_(m.weight,<span class=number>1</span>)</span><br><span class=line>                init.constant_(m.bias,<span class=number>0</span>)</span><br><span class=line>            <span class=keyword>elif</span> <span class=built_in>isinstance</span>(m,nn.Linear):</span><br><span class=line>                init.normal_(m.weight,std=<span class=number>0.001</span>)</span><br><span class=line>                <span class=keyword>if</span> m.bias <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span>:</span><br><span class=line>                    init.constant_(m.bias,<span class=number>0</span>)</span><br></pre></table></figure><p><img alt=image-20240123200842336 data-src=https://s2.loli.net/2024/01/23/3PEUjp2y9aMLI8u.png><h2 id=DANet-Dual-Attention-Network-2018><a title="DANet: Dual Attention Network 2018" class=headerlink href=#DANet-Dual-Attention-Network-2018></a>DANet: Dual Attention Network 2018</h2><p><img alt=image-20240123210612879 data-src=https://s2.loli.net/2024/01/23/R9GMVDrs23ca7Qp.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>PositionAttentionModule</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,d_model=<span class=number>512</span>,kernel_size=<span class=number>3</span>,H=<span class=number>7</span>,W=<span class=number>7</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-<span class=number>1</span>)//<span class=number>2</span>)</span><br><span class=line>        self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=<span class=number>1</span>)</span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self,x</span>):</span></span><br><span class=line>        bs,c,h,w=x.shape</span><br><span class=line>        y=self.cnn(x)</span><br><span class=line>        y=y.view(bs,c,-<span class=number>1</span>).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>) <span class=comment>#bs,h*w,c</span></span><br><span class=line>        y=self.pa(y,y,y) <span class=comment>#bs,h*w,c</span></span><br><span class=line>        <span class=keyword>return</span> y</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>ChannelAttentionModule</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,d_model=<span class=number>512</span>,kernel_size=<span class=number>3</span>,H=<span class=number>7</span>,W=<span class=number>7</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-<span class=number>1</span>)//<span class=number>2</span>)</span><br><span class=line>        self.pa=SimplifiedScaledDotProductAttention(H*W,h=<span class=number>1</span>)</span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self,x</span>):</span></span><br><span class=line>        bs,c,h,w=x.shape</span><br><span class=line>        y=self.cnn(x)</span><br><span class=line>        y=y.view(bs,c,-<span class=number>1</span>) <span class=comment>#bs,c,h*w</span></span><br><span class=line>        y=self.pa(y,y,y) <span class=comment>#bs,c,h*w</span></span><br><span class=line>        <span class=keyword>return</span> y</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>DAModule</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self,d_model=<span class=number>512</span>,kernel_size=<span class=number>3</span>,H=<span class=number>7</span>,W=<span class=number>7</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        self.position_attention_module=PositionAttentionModule(d_model=<span class=number>512</span>,kernel_size=<span class=number>3</span>,H=<span class=number>7</span>,W=<span class=number>7</span>)</span><br><span class=line>        self.channel_attention_module=ChannelAttentionModule(d_model=<span class=number>512</span>,kernel_size=<span class=number>3</span>,H=<span class=number>7</span>,W=<span class=number>7</span>)</span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self,<span class=built_in>input</span></span>):</span></span><br><span class=line>        bs,c,h,w=<span class=built_in>input</span>.shape</span><br><span class=line>        p_out=self.position_attention_module(<span class=built_in>input</span>)</span><br><span class=line>        c_out=self.channel_attention_module(<span class=built_in>input</span>)</span><br><span class=line>        p_out=p_out.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>).view(bs,c,h,w)</span><br><span class=line>        c_out=c_out.view(bs,c,h,w)</span><br><span class=line>        <span class=keyword>return</span> p_out+c_out</span><br><span class=line></span><br><span class=line></span><br></pre></table></figure><h2 id=CBAM-Convolutional-Block-Attention-Module-2018><a title="CBAM: Convolutional Block Attention Module 2018" class=headerlink href=#CBAM-Convolutional-Block-Attention-Module-2018></a>CBAM: Convolutional Block Attention Module 2018</h2><p><img alt=image-20240110104503985 data-src=https://s2.loli.net/2024/01/10/uPRhgXEveC9JbFS.png><p>通道注意力<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>ChannelAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_planes, ratio=<span class=number>16</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(ChannelAttention, self).__init__()</span><br><span class=line>        self.avg_pool = nn.AdaptiveAvgPool2d(<span class=number>1</span>)</span><br><span class=line>        self.max_pool = nn.AdaptiveMaxPool2d(<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        self.fc1   = nn.Conv2d(in_planes, in_planes // <span class=number>16</span>, <span class=number>1</span>, bias=<span class=literal>False</span>)</span><br><span class=line>        self.relu1 = nn.ReLU()</span><br><span class=line>        self.fc2   = nn.Conv2d(in_planes // <span class=number>16</span>, in_planes, <span class=number>1</span>, bias=<span class=literal>False</span>)</span><br><span class=line></span><br><span class=line>        self.sigmoid = nn.Sigmoid()</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))</span><br><span class=line>        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))</span><br><span class=line>        out = avg_out + max_out</span><br><span class=line>        <span class=keyword>return</span> self.sigmoid(out)</span><br></pre></table></figure><p><img alt=image-20240110104513785 data-src=https://s2.loli.net/2024/01/10/wxDGep963Qzs5tq.png><p>空间注意力<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>SpatialAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, kernel_size=<span class=number>7</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(SpatialAttention, self).__init__()</span><br><span class=line></span><br><span class=line>        <span class=keyword>assert</span> kernel_size <span class=keyword>in</span> (<span class=number>3</span>, <span class=number>7</span>), <span class=string>'kernel size must be 3 or 7'</span></span><br><span class=line>        padding = <span class=number>3</span> <span class=keyword>if</span> kernel_size == <span class=number>7</span> <span class=keyword>else</span> <span class=number>1</span></span><br><span class=line></span><br><span class=line>        self.conv1 = nn.Conv2d(<span class=number>2</span>, <span class=number>1</span>, kernel_size, padding=padding, bias=<span class=literal>False</span>)</span><br><span class=line>        self.sigmoid = nn.Sigmoid()</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        avg_out = torch.mean(x, dim=<span class=number>1</span>, keepdim=<span class=literal>True</span>)</span><br><span class=line>        max_out, _ = torch.<span class=built_in>max</span>(x, dim=<span class=number>1</span>, keepdim=<span class=literal>True</span>)</span><br><span class=line>        x = torch.cat([avg_out, max_out], dim=<span class=number>1</span>)</span><br><span class=line>        x = self.conv1(x)</span><br><span class=line>        <span class=keyword>return</span> self.sigmoid(x)</span><br></pre></table></figure><p><img alt=image-20240110104523806 data-src=https://s2.loli.net/2024/01/10/hyUFPErbDKB3TwI.png></p><script type="math/tex; mode=display">
\begin{aligned}\mathbf{F^{\prime}=M_c(F)\otimes F,}\\\mathbf{F^{\prime\prime}=M_s(F^{\prime})\otimes F^{\prime},}\end{aligned}</script><script type="math/tex; mode=display">
\begin{gathered}
\mathbf{M_{c}}(\mathbf{F}) =\sigma(MLP(AvgPool(\mathbf{F}))+MLP(MaxPool(\mathbf{F}))) \\
=\sigma(\mathbf{W_1}(\mathbf{W_0}(\mathbf{F_{avg}^c}))+\mathbf{W_1}(\mathbf{W_0}(\mathbf{F_{max}^c}))), 
\end{gathered}</script><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{M_{s}}(\mathbf{F})& =\sigma(f^{7\times7}([AvgPool(\mathbf{F});MaxPool(\mathbf{F})]))  \\
&=\sigma(f^{7\times7}([\mathbf{F_{avg}^{s}};\mathbf{F_{max}^{s}}])),
\end{aligned}</script><p><img alt=image-20240110142553774 data-src=https://s2.loli.net/2024/01/10/MQNWLjZP2yH8cwd.png><h2 id=Non-Local-2018><a title="Non-Local 2018" class=headerlink href=#Non-Local-2018></a>Non-Local 2018</h2><p><img alt=image-20240111161108109 data-src=https://s2.loli.net/2024/01/11/IW6cKRTQN178kp4.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>NonLocalNet</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, input_dim=<span class=number>64</span>, output_dim=<span class=number>64</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(NonLocalNet, self).__init__()</span><br><span class=line>        intermediate_dim = input_dim // <span class=number>2</span></span><br><span class=line>        self.to_q = nn.Conv2d(input_dim, intermediate_dim, <span class=number>1</span>)</span><br><span class=line>        self.to_k = nn.Conv2d(input_dim, intermediate_dim, <span class=number>1</span>)</span><br><span class=line>        self.to_v = nn.Conv2d(input_dim, intermediate_dim, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        self.conv = nn.Conv2d(intermediate_dim, output_dim, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        q = self.to_q(x).squeeze()</span><br><span class=line>        k = self.to_k(x).squeeze()</span><br><span class=line>        v = self.to_v(x).squeeze()</span><br><span class=line></span><br><span class=line>        u = torch.bmm(q, k.transpose(<span class=number>1</span>, <span class=number>2</span>))</span><br><span class=line>        u = torch.softmax(u, dim=<span class=number>1</span>)</span><br><span class=line>        out = torch.bmm(u, v)</span><br><span class=line>        out = out.unsqueeze(<span class=number>2</span>)</span><br><span class=line>        out = self.conv(out)</span><br><span class=line>        <span class=keyword>return</span> out + x</span><br><span class=line></span><br></pre></table></figure><p><img alt=image-20240119110302126 data-src=https://s2.loli.net/2024/01/19/9eNWHCpuiFsYLtU.png><h2 id=SKNet-2019><a title="SKNet 2019" class=headerlink href=#SKNet-2019></a>SKNet 2019</h2><p><img alt=image-20240123192700386 data-src=https://s2.loli.net/2024/01/23/ypZfsSKPBq9iLV6.png><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>SKConv</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=string>"""</span></span><br><span class=line><span class=string>    https://arxiv.org/pdf/1903.06586.pdf</span></span><br><span class=line><span class=string>    """</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, feature_dim, WH, M, G, r, stride=<span class=number>1</span>, L=<span class=number>32</span></span>):</span></span><br><span class=line></span><br><span class=line>        <span class=string>""" Constructor</span></span><br><span class=line><span class=string>         Args:</span></span><br><span class=line><span class=string>             features: input channel dimensionality.</span></span><br><span class=line><span class=string>             WH: input spatial dimensionality, used for GAP kernel size.</span></span><br><span class=line><span class=string>             M: the number of branchs.</span></span><br><span class=line><span class=string>             G: num of convolution groups.</span></span><br><span class=line><span class=string>             r: the radio for compute d, the length of z.</span></span><br><span class=line><span class=string>             stride: stride, default 1.</span></span><br><span class=line><span class=string>             L: the minimum dim of the vector z in paper, default 32.</span></span><br><span class=line><span class=string>        """</span></span><br><span class=line>        <span class=built_in>super</span>().__init__()</span><br><span class=line>        d = <span class=built_in>max</span>(<span class=built_in>int</span>(feature_dim / r), L)</span><br><span class=line>        self.M = M</span><br><span class=line>        self.feature_dim = feature_dim</span><br><span class=line>        self.convs = nn.ModuleList()</span><br><span class=line>        <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(M):</span><br><span class=line>            self.convs.append(nn.Sequential(</span><br><span class=line>                nn.Conv2d(feature_dim, feature_dim, kernel_size=<span class=number>3</span> + i * <span class=number>2</span>, stride=stride, padding=<span class=number>1</span> + i, groups=G),</span><br><span class=line>                nn.BatchNorm2d(feature_dim),</span><br><span class=line>                nn.ReLU(inplace=<span class=literal>False</span>)</span><br><span class=line>            ))</span><br><span class=line>        self.gap = nn.AdaptiveAvgPool2d((<span class=number>1</span>, <span class=number>1</span>))</span><br><span class=line>        self.fc = nn.Linear(feature_dim, d)</span><br><span class=line>        self.fcs = nn.ModuleList()</span><br><span class=line>        <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(M):</span><br><span class=line>            self.fcs.append(</span><br><span class=line>                nn.Linear(d, feature_dim)</span><br><span class=line>            )</span><br><span class=line>        self.softmax = nn.Softmax(dim=<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=keyword>for</span> i, conv <span class=keyword>in</span> <span class=built_in>enumerate</span>(self.convs):</span><br><span class=line>            feat = conv(x).unsqueeze_(dim=<span class=number>1</span>)</span><br><span class=line>            <span class=keyword>if</span> i == <span class=number>0</span>:</span><br><span class=line>                feas = feat</span><br><span class=line>            <span class=keyword>else</span>:</span><br><span class=line>                feas = torch.cat((feas, feat), dim=<span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        fea_U = torch.<span class=built_in>sum</span>(feas, dim=<span class=number>1</span>)</span><br><span class=line>        fea_s = self.gap(fea_U).squeeze_()</span><br><span class=line>        fea_z = self.fc(fea_s)</span><br><span class=line>        <span class=keyword>for</span> i, fc <span class=keyword>in</span> <span class=built_in>enumerate</span>(self.fcs):</span><br><span class=line>            vector = fc(fea_z).unsqueeze_(dim=<span class=number>1</span>)</span><br><span class=line>            <span class=keyword>if</span> i == <span class=number>0</span>:</span><br><span class=line>                attention_vectors = vector</span><br><span class=line>            <span class=keyword>else</span>:</span><br><span class=line>                attention_vectors = torch.cat((attention_vectors, vector), dim=<span class=number>1</span>)</span><br><span class=line>        attention_vectors = self.softmax(attention_vectors)</span><br><span class=line>        attention_vectors = attention_vectors.unsqueeze(-<span class=number>1</span>).unsqueeze(-<span class=number>1</span>)</span><br><span class=line>        fea_v = (feas*attention_vectors).<span class=built_in>sum</span>(dim=<span class=number>1</span>)</span><br><span class=line>        <span class=keyword>return</span> fea_v</span><br></pre></table></figure><h2 id=CC-Net和Axial-Attention><a title="CC-Net和Axial Attention" class=headerlink href=#CC-Net和Axial-Attention></a>CC-Net和Axial Attention</h2><p>看论文时提到了CC-Net使用了交叉注意了.<p>参考<a href=https://www.codenong.com/cs106760382/ rel=noopener target=_blank>Axial Attention 和 Criss-Cross Attention及其代码实现 | 码农家园 (codenong.com)</a>这篇blog,写的不错.<h2 id=Axial-Attention><a title="Axial Attention" class=headerlink href=#Axial-Attention></a>Axial Attention</h2><p>轴向注意力,Axial Attention 的感受野是目标像素的同一行(或者同一列) 的W(或H)个像素<p>比如row attention<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br></pre><td class=code><pre><span class=line><span class=comment>#实现轴向注意力中的 row Attention</span></span><br><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line><span class=keyword>import</span> torch.nn.functional <span class=keyword>as</span> F</span><br><span class=line><span class=keyword>from</span> torch.nn <span class=keyword>import</span> Softmax</span><br><span class=line></span><br><span class=line><span class=comment># device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')</span></span><br><span class=line>device = torch.device(<span class=string>'cuda:0'</span> <span class=keyword>if</span> torch.cuda.device_count() > <span class=number>1</span> <span class=keyword>else</span> <span class=string>'cpu'</span>)</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>RowAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_dim, q_k_dim, device</span>):</span></span><br><span class=line>        <span class=string>'''</span></span><br><span class=line><span class=string>        Parameters</span></span><br><span class=line><span class=string>        ----------</span></span><br><span class=line><span class=string>        in_dim : int</span></span><br><span class=line><span class=string>            channel of input img tensor</span></span><br><span class=line><span class=string>        q_k_dim: int</span></span><br><span class=line><span class=string>            channel of Q, K vector</span></span><br><span class=line><span class=string>        device : torch.device</span></span><br><span class=line><span class=string>        '''</span></span><br><span class=line>        <span class=built_in>super</span>(RowAttention, self).__init__()</span><br><span class=line>        self.in_dim = in_dim</span><br><span class=line>        self.q_k_dim = q_k_dim</span><br><span class=line>        self.device = device</span><br><span class=line>        </span><br><span class=line>        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class=number>1</span>)</span><br><span class=line>        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class=number>1</span>)</span><br><span class=line>        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.in_dim, kernel_size=<span class=number>1</span>)</span><br><span class=line>        self.softmax = Softmax(dim=<span class=number>2</span>)</span><br><span class=line>        self.gamma = nn.Parameter(torch.zeros(<span class=number>1</span>)).to(self.device)</span><br><span class=line>        </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=string>'''</span></span><br><span class=line><span class=string>        Parameters</span></span><br><span class=line><span class=string>        ----------</span></span><br><span class=line><span class=string>        x : Tensor</span></span><br><span class=line><span class=string>            4-D , (batch, in_dims, height, width) -- (b,c1,h,w)</span></span><br><span class=line><span class=string>        '''</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>## c1 = in_dims; c2 = q_k_dim</span></span><br><span class=line>        b, _, h, w = x.size()</span><br><span class=line>        </span><br><span class=line>        Q = self.query_conv(x) <span class=comment>#size = (b,c2, h,w)</span></span><br><span class=line>        K = self.key_conv(x)   <span class=comment>#size = (b, c2, h, w)</span></span><br><span class=line>        V = self.value_conv(x) <span class=comment>#size = (b, c1,h,w)</span></span><br><span class=line>        </span><br><span class=line>        Q = Q.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(b*h, -<span class=number>1</span>,w).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>) <span class=comment>#size = (b*h,w,c2)</span></span><br><span class=line>        K = K.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(b*h, -<span class=number>1</span>,w)  <span class=comment>#size = (b*h,c2,w)</span></span><br><span class=line>        V = V.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(b*h, -<span class=number>1</span>,w)  <span class=comment>#size = (b*h, c1,w)</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>#size = (b*h,w,w) [:,i,j] 表示Q的所有h的第 Wi行位置上所有通道值与 K的所有h的第 Wj列位置上的所有通道值的乘积，</span></span><br><span class=line>        <span class=comment># 即(1,c2) * (c2,1) = (1,1)</span></span><br><span class=line>        row_attn = torch.bmm(Q,K) </span><br><span class=line>        <span class=comment>########</span></span><br><span class=line>        <span class=comment>#此时的 row_atten的[:,i,0:w] 表示Q的所有h的第 Wi行位置上所有通道值与 K的所有行的 所有列(0:w)的逐个位置上的所有通道值的乘积</span></span><br><span class=line>        <span class=comment>#此操作即为 Q的某个（i,j）与 K的（i,0:w）逐个位置的值的乘积，得到行attn</span></span><br><span class=line>        <span class=comment>########</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>#对row_attn进行softmax</span></span><br><span class=line>        row_attn = self.softmax(row_attn) <span class=comment>#对列进行softmax，即[k,i,0:w] ，某一行的所有列加起来等于1，</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>#size = (b*h,c1,w) 这里先需要对row_atten进行 行列置换，使得某一列的所有行加起来等于1</span></span><br><span class=line>        <span class=comment>#[:,i,j]即为V的所有行的某个通道上，所有列的值 与 row_attn的行的乘积，即求权重和</span></span><br><span class=line>        out = torch.bmm(V,row_attn.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>)) </span><br><span class=line>        <span class=comment>#size = (b,c1,h,2)</span></span><br><span class=line>        out = out.view(b,h,-<span class=number>1</span>,w).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>)  </span><br><span class=line>        out = self.gamma*out + x </span><br><span class=line>        <span class=keyword>return</span> out</span><br><span class=line><span class=comment>#实现轴向注意力中的 cols Attention</span></span><br><span class=line>x = torch.randn(<span class=number>4</span>, <span class=number>8</span>, <span class=number>16</span>, <span class=number>20</span>).to(device)</span><br><span class=line>row_attn = RowAttention(in_dim = <span class=number>8</span>, q_k_dim = <span class=number>4</span>,device = device).to(device)</span><br><span class=line><span class=built_in>print</span>(row_attn(x).size())</span><br></pre></table></figure><p>列注意力同理<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br></pre><td class=code><pre><span class=line><span class=comment>#实现轴向注意力中的 column Attention</span></span><br><span class=line><span class=keyword>import</span> torch</span><br><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line><span class=keyword>import</span> torch.nn.functional <span class=keyword>as</span> F</span><br><span class=line><span class=keyword>from</span> torch.nn <span class=keyword>import</span> Softmax</span><br><span class=line></span><br><span class=line><span class=comment># device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')</span></span><br><span class=line>device = torch.device(<span class=string>'cuda:0'</span> <span class=keyword>if</span> torch.cuda.device_count() > <span class=number>1</span> <span class=keyword>else</span> <span class=string>'cpu'</span>)</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>ColAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_dim, q_k_dim, device</span>):</span></span><br><span class=line>        <span class=string>'''</span></span><br><span class=line><span class=string>        Parameters</span></span><br><span class=line><span class=string>        ----------</span></span><br><span class=line><span class=string>        in_dim : int</span></span><br><span class=line><span class=string>            channel of input img tensor</span></span><br><span class=line><span class=string>        q_k_dim: int</span></span><br><span class=line><span class=string>            channel of Q, K vector</span></span><br><span class=line><span class=string>        device : torch.device</span></span><br><span class=line><span class=string>        '''</span></span><br><span class=line>        <span class=built_in>super</span>(ColAttention, self).__init__()</span><br><span class=line>        self.in_dim = in_dim</span><br><span class=line>        self.q_k_dim = q_k_dim</span><br><span class=line>        self.device = device</span><br><span class=line>        </span><br><span class=line>        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class=number>1</span>)</span><br><span class=line>        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.q_k_dim, kernel_size=<span class=number>1</span>)</span><br><span class=line>        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels = self.in_dim, kernel_size=<span class=number>1</span>)</span><br><span class=line>        self.softmax = Softmax(dim=<span class=number>2</span>)</span><br><span class=line>        self.gamma = nn.Parameter(torch.zeros(<span class=number>1</span>)).to(self.device)</span><br><span class=line>        </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=string>'''</span></span><br><span class=line><span class=string>        Parameters</span></span><br><span class=line><span class=string>        ----------</span></span><br><span class=line><span class=string>        x : Tensor</span></span><br><span class=line><span class=string>            4-D , (batch, in_dims, height, width) -- (b,c1,h,w)</span></span><br><span class=line><span class=string>        '''</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>## c1 = in_dims; c2 = q_k_dim</span></span><br><span class=line>        b, _, h, w = x.size()</span><br><span class=line>        </span><br><span class=line>        Q = self.query_conv(x) <span class=comment>#size = (b,c2, h,w)</span></span><br><span class=line>        K = self.key_conv(x)   <span class=comment>#size = (b, c2, h, w)</span></span><br><span class=line>        V = self.value_conv(x) <span class=comment>#size = (b, c1,h,w)</span></span><br><span class=line>        </span><br><span class=line>        Q = Q.permute(<span class=number>0</span>,<span class=number>3</span>,<span class=number>1</span>,<span class=number>2</span>).contiguous().view(b*w, -<span class=number>1</span>,h).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>) <span class=comment>#size = (b*w,h,c2)</span></span><br><span class=line>        K = K.permute(<span class=number>0</span>,<span class=number>3</span>,<span class=number>1</span>,<span class=number>2</span>).contiguous().view(b*w, -<span class=number>1</span>,h)  <span class=comment>#size = (b*w,c2,h)</span></span><br><span class=line>        V = V.permute(<span class=number>0</span>,<span class=number>3</span>,<span class=number>1</span>,<span class=number>2</span>).contiguous().view(b*w, -<span class=number>1</span>,h)  <span class=comment>#size = (b*w,c1,h)</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>#size = (b*w,h,h) [:,i,j] 表示Q的所有W的第 Hi行位置上所有通道值与 K的所有W的第 Hj列位置上的所有通道值的乘积，</span></span><br><span class=line>        <span class=comment># 即(1,c2) * (c2,1) = (1,1)</span></span><br><span class=line>        col_attn = torch.bmm(Q,K) </span><br><span class=line>        <span class=comment>########</span></span><br><span class=line>        <span class=comment>#此时的 col_atten的[:,i,0:w] 表示Q的所有W的第 Hi行位置上所有通道值与 K的所有W的 所有列(0:h)的逐个位置上的所有通道值的乘积</span></span><br><span class=line>        <span class=comment>#此操作即为 Q的某个（i,j）与 K的（i,0:h）逐个位置的值的乘积，得到列attn</span></span><br><span class=line>        <span class=comment>########</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>#对row_attn进行softmax</span></span><br><span class=line>        col_attn = self.softmax(col_attn) <span class=comment>#对列进行softmax，即[k,i,0:w] ，某一行的所有列加起来等于1，</span></span><br><span class=line>        </span><br><span class=line>        <span class=comment>#size = (b*w,c1,h) 这里先需要对col_atten进行 行列置换，使得某一列的所有行加起来等于1</span></span><br><span class=line>        <span class=comment>#[:,i,j]即为V的所有行的某个通道上，所有列的值 与 col_attn的行的乘积，即求权重和</span></span><br><span class=line>        out = torch.bmm(V,col_attn.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>)) </span><br><span class=line>        </span><br><span class=line>        <span class=comment>#size = (b,c1,h,w)</span></span><br><span class=line>        out = out.view(b,w,-<span class=number>1</span>,h).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>3</span>,<span class=number>1</span>)</span><br><span class=line>        </span><br><span class=line>        out = self.gamma*out + x </span><br><span class=line></span><br><span class=line>        <span class=keyword>return</span> out</span><br><span class=line>    </span><br><span class=line><span class=comment>#实现轴向注意力中的 cols Attention</span></span><br><span class=line>x = torch.randn(<span class=number>4</span>, <span class=number>8</span>, <span class=number>16</span>, <span class=number>20</span>).to(device)</span><br><span class=line>col_attn = ColAttention(<span class=number>8</span>, <span class=number>4</span>, device = device)</span><br><span class=line></span><br><span class=line><span class=built_in>print</span>(col_attn(x).size())</span><br><span class=line></span><br></pre></table></figure><h2 id=Criss-Cross-Attention-Module-2019><a title="Criss-Cross Attention Module 2019" class=headerlink href=#Criss-Cross-Attention-Module-2019></a>Criss-Cross Attention Module 2019</h2><p><img alt=img data-src=https://pic4.zhimg.com/80/v2-322dae3099e1ed29c2751c7c7efd88b7_720w.webp><p>CC-Attention 的感受野是与目标像素的同一行和同一列的(H + W - 1)个像素,目标元素的同一行和同一列.<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>CrissCrossAttention</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=string>""" Criss-Cross Attention Module</span></span><br><span class=line><span class=string></span></span><br><span class=line><span class=string>    reference: https://github.com/speedinghzl/CCNet</span></span><br><span class=line><span class=string>    </span></span><br><span class=line><span class=string>    """</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, in_dim</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(CrissCrossAttention,self).__init__()</span><br><span class=line></span><br><span class=line></span><br><span class=line>        self.query_conv = nn.Sequential(</span><br><span class=line>                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class=number>1</span>),</span><br><span class=line>                nn.BatchNorm2d(in_dim,eps=<span class=number>1e-5</span>, momentum=<span class=number>0.01</span>, affine=<span class=literal>True</span>),</span><br><span class=line>                nn.ReLU()</span><br><span class=line>            )</span><br><span class=line>        self.key_conv = nn.Sequential(</span><br><span class=line>                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class=number>1</span>),</span><br><span class=line>                nn.BatchNorm2d(in_dim,eps=<span class=number>1e-5</span>, momentum=<span class=number>0.01</span>, affine=<span class=literal>True</span>),</span><br><span class=line>                nn.ReLU()</span><br><span class=line>            )</span><br><span class=line>        self.value_conv = nn.Sequential(</span><br><span class=line>                nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class=number>1</span>),</span><br><span class=line>                nn.BatchNorm2d(in_dim,eps=<span class=number>1e-5</span>, momentum=<span class=number>0.01</span>, affine=<span class=literal>True</span>),</span><br><span class=line>                nn.ReLU()</span><br><span class=line>            )</span><br><span class=line></span><br><span class=line></span><br><span class=line>        self.softmax = Softmax(dim=<span class=number>3</span>)</span><br><span class=line>        self.INF = INF</span><br><span class=line>        self.gamma = nn.Parameter(torch.zeros(<span class=number>1</span>))</span><br><span class=line></span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, query, key, value</span>):</span></span><br><span class=line>        m_batchsize, _, height, width = query.size()</span><br><span class=line></span><br><span class=line>        </span><br><span class=line>        proj_query = self.query_conv(query)</span><br><span class=line>        proj_query_H = proj_query.permute(<span class=number>0</span>,<span class=number>3</span>,<span class=number>1</span>,<span class=number>2</span>).contiguous().view(m_batchsize*width,-<span class=number>1</span>,height).permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>1</span>)</span><br><span class=line>        proj_query_W = proj_query.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(m_batchsize*height,-<span class=number>1</span>,width).permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>        </span><br><span class=line>        proj_key = self.key_conv(key)</span><br><span class=line>        proj_key_H = proj_key.permute(<span class=number>0</span>,<span class=number>3</span>,<span class=number>1</span>,<span class=number>2</span>).contiguous().view(m_batchsize*width,-<span class=number>1</span>,height)</span><br><span class=line>        proj_key_W = proj_key.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(m_batchsize*height,-<span class=number>1</span>,width)</span><br><span class=line>        </span><br><span class=line>        </span><br><span class=line>        proj_value = self.value_conv(value)</span><br><span class=line>        proj_value_H = proj_value.permute(<span class=number>0</span>,<span class=number>3</span>,<span class=number>1</span>,<span class=number>2</span>).contiguous().view(m_batchsize*width,-<span class=number>1</span>,height)</span><br><span class=line>        proj_value_W = proj_value.permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(m_batchsize*height,-<span class=number>1</span>,width)</span><br><span class=line>        energy_H = (torch.bmm(proj_query_H, proj_key_H)+self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>)</span><br><span class=line>        energy_W = torch.bmm(proj_query_W, proj_key_W).view(m_batchsize,height,width,width)</span><br><span class=line>        concate = self.softmax(torch.cat([energy_H, energy_W], <span class=number>3</span>))</span><br><span class=line></span><br><span class=line>        att_H = concate[:,:,:,<span class=number>0</span>:height].permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>).contiguous().view(m_batchsize*width,height,height)</span><br><span class=line>        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width)</span><br><span class=line>        out_H = torch.bmm(proj_value_H, att_H.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>1</span>)).view(m_batchsize,width,-<span class=number>1</span>,height).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>3</span>,<span class=number>1</span>)</span><br><span class=line>        out_W = torch.bmm(proj_value_W, att_W.permute(<span class=number>0</span>, <span class=number>2</span>, <span class=number>1</span>)).view(m_batchsize,height,-<span class=number>1</span>,width).permute(<span class=number>0</span>,<span class=number>2</span>,<span class=number>1</span>,<span class=number>3</span>)</span><br><span class=line>        <span class=keyword>return</span> self.gamma*(out_H + out_W) + value</span><br></pre></table></figure><p><img alt=img data-src=https://pic4.zhimg.com/80/v2-03942c1de5a5a77aafbdb1a1fe697fb3_720w.webp><h2 id=Coordinate-Attention-2021><a title="Coordinate Attention 2021" class=headerlink href=#Coordinate-Attention-2021></a>Coordinate Attention 2021</h2><p><img alt=image-20240119195945841 data-src=https://s2.loli.net/2024/01/19/ZrmAMkChLcbFpfg.png><p>在通道注意力的基础上兼顾其位置关系，将通道注意力与空间注意力联合起来<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>class</span> <span class=title>h_sigmoid</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, inplace=<span class=literal>True</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(h_sigmoid, self).__init__()</span><br><span class=line>        self.relu = nn.ReLU6(inplace=inplace)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=keyword>return</span> self.relu(x + <span class=number>3</span>) / <span class=number>6</span></span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>h_swish</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, inplace=<span class=literal>True</span></span>):</span></span><br><span class=line>        <span class=built_in>super</span>(h_swish, self).__init__()</span><br><span class=line>        self.sigmoid = h_sigmoid(inplace=inplace)</span><br><span class=line></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        <span class=keyword>return</span> x * self.sigmoid(</span><br><span class=line></span><br><span class=line><span class=class><span class=keyword>class</span> <span class=title>CA</span>(<span class=params>nn.Module</span>):</span></span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>__init__</span>(<span class=params>self, inp, reduction</span>):</span></span><br><span class=line>        <span class=built_in>super</span>(CA, self).__init__()</span><br><span class=line>        <span class=comment># h:height(行)   w:width(列)</span></span><br><span class=line>        self.pool_h = nn.AdaptiveAvgPool2d((<span class=literal>None</span>, <span class=number>1</span>))  <span class=comment># (b,c,h,w)-->(b,c,h,1)</span></span><br><span class=line>        self.pool_w = nn.AdaptiveAvgPool2d((<span class=number>1</span>, <span class=literal>None</span>))  <span class=comment># (b,c,h,w)-->(b,c,1,w)</span></span><br><span class=line></span><br><span class=line>         <span class=comment># mip = max(8, inp // reduction)  论文作者所用</span></span><br><span class=line>        mip =  inp // reduction  </span><br><span class=line> </span><br><span class=line>        self.conv1 = nn.Conv2d(inp, mip, kernel_size=<span class=number>1</span>, stride=<span class=number>1</span>, padding=<span class=number>0</span>)</span><br><span class=line>        self.bn1 = nn.BatchNorm2d(mip)</span><br><span class=line>        self.act = h_swish()</span><br><span class=line> </span><br><span class=line>        self.conv_h = nn.Conv2d(mip, inp, kernel_size=<span class=number>1</span>, stride=<span class=number>1</span>, padding=<span class=number>0</span>)</span><br><span class=line>        self.conv_w = nn.Conv2d(mip, inp, kernel_size=<span class=number>1</span>, stride=<span class=number>1</span>, padding=<span class=number>0</span>)</span><br><span class=line> </span><br><span class=line>    <span class=function><span class=keyword>def</span> <span class=title>forward</span>(<span class=params>self, x</span>):</span></span><br><span class=line>        identity = x</span><br><span class=line> </span><br><span class=line>        n, c, h, w = x.size()</span><br><span class=line>        x_h = self.pool_h(x)  <span class=comment># (b,c,h,1)</span></span><br><span class=line>        x_w = self.pool_w(x).permute(<span class=number>0</span>, <span class=number>1</span>, <span class=number>3</span>, <span class=number>2</span>)  <span class=comment># (b,c,w,1)</span></span><br><span class=line> </span><br><span class=line>        y = torch.cat([x_h, x_w], dim=<span class=number>2</span>)</span><br><span class=line>        y = self.conv1(y)</span><br><span class=line>        y = self.bn1(y)</span><br><span class=line>        y = self.act(y)</span><br><span class=line> </span><br><span class=line>        x_h, x_w = torch.split(y, [h, w], dim=<span class=number>2</span>)</span><br><span class=line>        x_w = x_w.permute(<span class=number>0</span>, <span class=number>1</span>, <span class=number>3</span>, <span class=number>2</span>)</span><br><span class=line> </span><br><span class=line>        a_h = self.conv_h(x_h).sigmoid()</span><br><span class=line>        a_w = self.conv_w(x_w).sigmoid()</span><br><span class=line> </span><br><span class=line>        out = identity * a_w * a_h</span><br><span class=line> </span><br><span class=line>        <span class=keyword>return</span> out</span><br></pre></table></figure><h2 id=Attentional-Feature-Fusion-2021><a title="Attentional Feature Fusion  2021" class=headerlink href=#Attentional-Feature-Fusion-2021></a>Attentional Feature Fusion 2021</h2><p><a href=https://openaccess.thecvf.com/content/WACV2021/html/Dai_Attentional_Feature_Fusion_WACV_2021_paper.html rel=noopener target=_blank>WACV 2021 Open Access Repository (thecvf.com)</a><p><a href=https://github.com/YimianDai/open-aff rel=noopener target=_blank>YimianDai/open-aff: code and trained models for “Attentional Feature Fusion” (github.com)</a><p>这些注意力模块通常用在一些block(或叫unit)块中,然后一般把这些块放到多尺度的网络下<h2 id=参考资料><a class=headerlink href=#参考资料 title=参考资料></a>参考资料</h2><ol><li><a href=https://blog.csdn.net/weixin_43718675/article/details/106760382 rel=noopener target=_blank>Axial Attention 和 Criss-Cross Attention及其代码实现_cross attention代码-CSDN博客</a><li><a href=https://blog.csdn.net/qwedsaewq/article/details/89052643 rel=noopener target=_blank>sknet阅读笔记及pytorch实现代码_pytorch sknet-CSDN博客</a><li><a href=https://blog.csdn.net/weixin_43427721/article/details/124652525?ops_request_misc=%7B%22request%5Fid%22%3A%22170601489116800226596213%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=170601489116800226596213&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-124652525-null-null.nonecase&utm_term=注意力&spm=1018.2226.3001.4450 rel=noopener target=_blank>【注意力机制集锦】Channel Attention通道注意力网络结构、源码解读系列一_通道注意力机制结构图-CSDN博客</a><li><a href=https://blog.csdn.net/weixin_43427721/article/details/124766242 rel=noopener target=_blank>【注意力机制集锦2】BAM&SGE&DAN原文、结构、源码详解_bam注意力机制-CSDN博客</a></ol><p>Thanks to <a href=https://github.com/lyp2333/External-Attention-pytorch/tree/master rel=noopener target=_blank>lyp2333/External-Attention-pytorch (github.com)</a> and <a href=https://github.com/xmu-xiaoma666/External-Attention-pytorch rel=noopener target=_blank>xmu-xiaoma666/External-Attention-pytorch: 🍀 Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.⭐⭐⭐ (github.com)</a></p><link href=/css/spoiler.css rel=stylesheet><script async src=/js/spoiler.js></script></div><div><div><div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div class=popular-posts-header>相关文章</div><ul class=popular-posts><li class=popular-posts-item><div class=popular-posts-title><a href=\2024\11\18\vqvae及其变体代码学习\ rel=bookmark>vqvae及其变体代码学习</a></div><li class=popular-posts-item><div class=popular-posts-title><a href=\2024\11\03\文生图相关模型最新进展小结\ rel=bookmark>文生图相关模型最新进展小结</a></div><li class=popular-posts-item><div class=popular-posts-title><a href=\2024\09\24\回看深度学习-经典网络学习\ rel=bookmark>回看深度学习:经典网络学习</a></div><li class=popular-posts-item><div class=popular-posts-title><a href=\2024\07\30\profile-a-deep-learning-model\ rel=bookmark>profile a deep learning model</a></div><li class=popular-posts-item><div class=popular-posts-title><a href=\2024\06\18\从论文中看AI绘画-二\ rel=bookmark>从论文中看AI绘画(二)</a></div></ul><div class=reward-container><div>感谢阅读.</div><button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">打赏</button><div style="display: none;" id=qr><div style="display: inline-block;"><img alt="Sekyoro 微信支付" src=/images/wechatpay.png><p>微信支付</div></div></div><div><ul class=post-copyright><li class=post-copyright-author><strong>本文作者： </strong>Sekyoro<li class=post-copyright-link><strong>本文链接：</strong> <a title="transformer and attention(二):various attention modules" href=https://www.sekyoro.top/2024/01/23/transformer-and-attention-%E4%BA%8C-various-attention-modules/>https://www.sekyoro.top/2024/01/23/transformer-and-attention-二-various-attention-modules/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ rel=noopener target=_blank><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</ul></div><div class=followme><p>欢迎关注我的其它发布渠道<div class=social-list><div class=social-item><a class=social-link href=/images/wxqrcode.png target=_blank> <span class=icon> <i class="fab fa-weixin"></i> </span> <span class=label>WeChat</span> </a></div><div class=social-item><a class=social-link href=/images/website.png target=_blank> <span class=icon> <i class="fa fa-user"></i> </span> <span class=label>PersonalWebsite</span> </a></div><div class=social-item><a class=social-link href=https://my-astro-git-main-drowning-in-codes.vercel.app target=_blank> <span class=icon> <i class="fas fa-share"></i> </span> <span class=label>杂鱼分享</span> </a></div><div class=social-item><a class=social-link href=/atom.xml target=_blank> <span class=icon> <i class="fa fa-rss"></i> </span> <span class=label>RSS</span> </a></div></div></div><footer class=post-footer><div class=post-tags><a href=/tags/deep-learning/ rel=tag><i class="fa fa-tag"></i> deep learning</a></div><div class=post-nav><div class=post-nav-item><a href=/2024/01/17/Golang%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8Gin/ rel=prev title=Golang学习:使用Gin> <i class="fa fa-chevron-left"></i> Golang学习:使用Gin </a></div><div class=post-nav-item><a href=/2024/01/31/%E5%8D%8F%E5%90%8C%E8%9E%8D%E5%90%88%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/ rel=next title=协同融合代码学习> 协同融合代码学习 <i class="fa fa-chevron-right"></i> </a></div></div></footer></article></div><!-- 评论区 --><div class=comments><div data-id=city data-uid=MTAyMC81MzE5Ny8yOTY3Mg== id=lv-container></div></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class=sidebar><div class=sidebar-inner><!-- canvas粒子时钟 --><div><canvas id=canvas style=width:60%;>当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();</script><!-- require APlayer --><link href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><!-- require MetingJS --><script src=/js/meting-js.js></script><ul class="sidebar-nav motion-element"><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#Squeeze-and-Excitation-Networks-2018><span class=nav-number>1.</span> <span class=nav-text>Squeeze-and-Excitation Networks 2018</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#Bottlenet-attention-Module-BAM-2018><span class=nav-number>2.</span> <span class=nav-text>Bottlenet attention Module (BAM) 2018</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#DANet-Dual-Attention-Network-2018><span class=nav-number>3.</span> <span class=nav-text>DANet: Dual Attention Network 2018</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#CBAM-Convolutional-Block-Attention-Module-2018><span class=nav-number>4.</span> <span class=nav-text>CBAM: Convolutional Block Attention Module 2018</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#Non-Local-2018><span class=nav-number>5.</span> <span class=nav-text>Non-Local 2018</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#SKNet-2019><span class=nav-number>6.</span> <span class=nav-text>SKNet 2019</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#CC-Net%E5%92%8CAxial-Attention><span class=nav-number>7.</span> <span class=nav-text>CC-Net和Axial Attention</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#Axial-Attention><span class=nav-number>8.</span> <span class=nav-text>Axial Attention</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#Criss-Cross-Attention-Module-2019><span class=nav-number>9.</span> <span class=nav-text>Criss-Cross Attention Module 2019</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#Coordinate-Attention-2021><span class=nav-number>10.</span> <span class=nav-text>Coordinate Attention 2021</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#Attentional-Feature-Fusion-2021><span class=nav-number>11.</span> <span class=nav-text>Attentional Feature Fusion 2021</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99><span class=nav-number>12.</span> <span class=nav-text>参考资料</span></a></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=Sekyoro class=site-author-image itemprop=image src=https://i.loli.net/2021/05/17/YqoavnXdGTpPO9R.jpg><p class=site-author-name itemprop=name>Sekyoro<div class=site-description itemprop=description>什么也无法舍弃的人，什么也做不了.</div></div><div class="site-state-wrap motion-element"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>259</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>16</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>220</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a title="Personal Website → http://proanimer.com" href=http://proanimer.com/ rel=noopener target=_blank><i class="fab fa-internet-explorer fa-fw"></i>Personal Website</a> </span><span class=links-of-author-item> <a title="GitHub → https://github.com/drowning-in-codes" href=https://github.com/drowning-in-codes rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a title="E-Mail → mailto:bukalala174@gmail.com" href=mailto:bukalala174@gmail.com rel=noopener target=_blank><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class=links-of-author-item> <a title="wxPublicAccount → https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd" href=https://mp.weixin.qq.com/s?__biz=Mzg3ODY1MDkzMg==&mid=2247483770&idx=1&sn=fdf88faab01d5c219ac609570a21c9d6&chksm=cf113221f866bb373938cfca03cf095ff4fe1e4dc37d68ef5de4cd4876ee1260fca0c015a4d6&token=1096259873&lang=zh_CN#rd rel=noopener target=_blank><i class="fab fa-weixin fa-fw"></i>wxPublicAccount</a> </span><span class=links-of-author-item> <a title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span><span class=links-of-author-item> <a title="CSDN → https://blog.csdn.net/aqwca" href=https://blog.csdn.net/aqwca rel=noopener target=_blank><i class="fa fa-handshake fa-fw"></i>CSDN</a> </span><span class=links-of-author-item> <a title="杂鱼分享 → https://my-astro-git-main-drowning-in-codes.vercel.app" href=https://my-astro-git-main-drowning-in-codes.vercel.app/ rel=noopener target=_blank><i class="fas fa-share fa-fw"></i>杂鱼分享</a> </span></div><div class="links-of-blogroll motion-element"><div class=links-of-blogroll-title><i class="fa fa-link fa-fw"></i> 友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=http://myqhs.top/ rel=noopener target=_blank title=http://myqhs.top/>myqhs</a><li class=links-of-blogroll-item><a href=https://www.lllomh.com/ rel=noopener target=_blank title=https://www.lllomh.com/>芈渡</a><li class=links-of-blogroll-item><a href=https://protool-ten.vercel.app/ rel=noopener target=_blank title=https://protool-ten.vercel.app/>protools</a></ul></div><div class="motion-element announcement"><div class=title></div><p class=content><p class=date></div></div><meting-js id=6856787487 order=random server=netease type=playlist> </meting-js><div class=widget-wrap><h3 class=widget-title style=margin:0>文章词云</h3><div class="widget tagcloud" id=myCanvasContainer><canvas height=250 id=resCanvas style=width:100% width=250><ul class=tag-list itemprop=keywords><li class=tag-list-item><a class=tag-list-link href=/tags/deep-learning/ rel=tag>deep learning</a><span class=tag-list-count>11</span></ul></canvas></div></div><script id=clustrmaps src=https://clustrmaps.com/map_v2.js?d=xQdGTxqARTBiNIwX2aUban-ixkj2s6VaZQWo-aVCgY8&cl=ffffff&w=a></script><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i><span>0%</span></div><!-- 边栏 --></div></aside><div id=sidebar-dimmer></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© Wed Apr 08 2020 08:00:00 GMT+0800 (中国标准时间) – <span itemprop=copyrightYear>2026</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Sekyoro</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-chart-area"></i> </span><span title=站点总字数>4.3m</span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span><span title=站点阅读时长>64:52</span></div><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container_site_pv>总访问量<span id=busuanzi_value_site_pv></span>次</span><span class=post-meta-divider>|</span><span id=busuanzi_container_site_uv>总访客数<span id=busuanzi_value_site_uv></span>人</span><span class=post-meta-divider>|</span><!-- 不蒜子计数初始值纠正 --><script>document.addEventListener("DOMContentLoaded", function() {
    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {
        var pvContainer = document.getElementById("busuanzi_container_site_pv");
        if (pvContainer && pvContainer.style.display !== "none") {
            var pvElement = document.getElementById("busuanzi_value_site_pv");
            if (pvElement) {
                pvElement.innerHTML = parseInt(pvElement.innerHTML) + countOffset;
                clearInterval(int);
            }
        }
        
        var uvContainer = document.getElementById("busuanzi_container_site_uv");
        if (uvContainer && window.getComputedStyle(uvContainer).display !== "none")
        {
            var uvElement = document.getElementById("busuanzi_value_site_uv");
            if (uvElement) {
                uvElement.innerHTML = parseInt(uvElement.innerHTML) + countOffset; // 加上初始数据 
                clearInterval(int); // 停止检测
            }
        }
    }
});</script><div><span id=timeDate>载入天数...</span><span id=times>载入时分秒...</span><script>var now = new Date();
    function createtime() {
        var grt= new Date("04/08/2021 20:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);</script></div><div class=busuanzi-count><script async data-pjax src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span style="display: none;" class=post-meta-item id=busuanzi_container_site_uv> <span class=post-meta-item-icon> <i class="fa fa-user"></i> </span> <span class=site-uv title=总访客量> <span id=busuanzi_value_site_uv></span> </span> </span><span class=post-meta-divider>|</span><span style="display: none;" class=post-meta-item id=busuanzi_container_site_pv> <span class=post-meta-item-icon> <i class="fa fa-eye"></i> </span> <span class=site-pv title=总访问量> <span id=busuanzi_value_site_pv></span> </span> </span></div></div></footer></div><script color=0,0,255 count=99 opacity=0.5 src=/lib/canvas-nest/canvas-nest.min.js zindex=-1></script><script src=/lib/anime.min.js></script><script src=https://cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js></script><script src=https://cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.min.js></script><script src=https://cdn.jsdelivr.net/npm/velocity-animate@1/velocity.ui.min.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/schemes/pisces.js></script><script src=/js/next-boot.js></script><script src=/js/bookmark.js></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax',
	 '.widget-wrap'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
 
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
  
  // Reinitialize TagCanvas for tag cloud
  if (typeof TagCanvas !== 'undefined' && document.getElementById('resCanvas')) {
    try {
      TagCanvas.textFont = 'Trebuchet MS, Helvetica';
      TagCanvas.textColour = '#333';
      TagCanvas.textHeight = 20;
      TagCanvas.outlineColour = '#E2E1D1';
      TagCanvas.maxSpeed = 0.3;
      TagCanvas.freezeActive = true;
      TagCanvas.outlineMethod = 'block';
      TagCanvas.minBrightness = 0.2;
      TagCanvas.depth = 0.92;
      TagCanvas.pulsateTo = 0.6;
      TagCanvas.initial = [0.1,-0.1];
      TagCanvas.decel = 0.98;
      TagCanvas.reverse = true;
      TagCanvas.hideTags = false;
      TagCanvas.shadow = '#ccf';
      TagCanvas.shadowBlur = 3;
      TagCanvas.weight = false;
      TagCanvas.imageScale = null;
      TagCanvas.fadeIn = 1000;
      TagCanvas.clickToFront = 600;
      TagCanvas.lock = false;
      TagCanvas.Start('resCanvas');
      TagCanvas.tc['resCanvas'].Wheel(true);
    } catch(e) {
      console.log('TagCanvas initialization failed:', e);
    }
  }
});</script><script data-pjax>(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();</script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js></script><script src=/js/algolia-search.js></script><script data-pjax>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><div id=pjax><script charset=utf-8 defer src=/js/outdate.js></script></div><script charset=utf-8 defer src=/js/tagcanvas.js></script><script charset=utf-8 defer src=/js/tagcloud.js></script><script>NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});</script><script>var OriginTitile = document.title;
  var titleTime;
  document.addEventListener("visibilitychange", function() {
    if (document.hidden) {
      document.title = "(つェ⊂)我藏好了哦~" + OriginTitile;
      clearTimeout(titleTime);
    } else {
      document.title = "(*´∇｀*) 被你发现啦~" + OriginTitile;
      titleTime = setTimeout(function() {
        document.title = OriginTitile;
      }, 2000);
    }
  });</script><script src=/js/src/activate-power-mode.min.js></script><script>POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);</script>